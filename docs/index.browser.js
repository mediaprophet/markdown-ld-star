(function (global, factory) {
	typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('stream')) :
	typeof define === 'function' && define.amd ? define(['exports', 'stream'], factory) :
	(global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.MarkdownLDStar = {}, global.stream$1));
})(this, (function (exports, stream$1) { 'use strict';

	var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

	function getDefaultExportFromCjs (x) {
		return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
	}

	function getAugmentedNamespace(n) {
	  if (Object.prototype.hasOwnProperty.call(n, '__esModule')) return n;
	  var f = n.default;
		if (typeof f == "function") {
			var a = function a () {
				var isInstance = false;
	      try {
	        isInstance = this instanceof a;
	      } catch {}
				if (isInstance) {
	        return Reflect.construct(f, arguments, this.constructor);
				}
				return f.apply(this, arguments);
			};
			a.prototype = f.prototype;
	  } else a = {};
	  Object.defineProperty(a, '__esModule', {value: true});
		Object.keys(n).forEach(function (k) {
			var d = Object.getOwnPropertyDescriptor(n, k);
			Object.defineProperty(a, k, d.get ? d : {
				enumerable: true,
				get: function () {
					return n[k];
				}
			});
		});
		return a;
	}

	var buffer = {};

	var base64Js = {};

	var hasRequiredBase64Js;

	function requireBase64Js () {
		if (hasRequiredBase64Js) return base64Js;
		hasRequiredBase64Js = 1;

		base64Js.byteLength = byteLength;
		base64Js.toByteArray = toByteArray;
		base64Js.fromByteArray = fromByteArray;

		var lookup = [];
		var revLookup = [];
		var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array;

		var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
		for (var i = 0, len = code.length; i < len; ++i) {
		  lookup[i] = code[i];
		  revLookup[code.charCodeAt(i)] = i;
		}

		// Support decoding URL-safe base64 strings, as Node.js does.
		// See: https://en.wikipedia.org/wiki/Base64#URL_applications
		revLookup['-'.charCodeAt(0)] = 62;
		revLookup['_'.charCodeAt(0)] = 63;

		function getLens (b64) {
		  var len = b64.length;

		  if (len % 4 > 0) {
		    throw new Error('Invalid string. Length must be a multiple of 4')
		  }

		  // Trim off extra bytes after placeholder bytes are found
		  // See: https://github.com/beatgammit/base64-js/issues/42
		  var validLen = b64.indexOf('=');
		  if (validLen === -1) validLen = len;

		  var placeHoldersLen = validLen === len
		    ? 0
		    : 4 - (validLen % 4);

		  return [validLen, placeHoldersLen]
		}

		// base64 is 4/3 + up to two characters of the original data
		function byteLength (b64) {
		  var lens = getLens(b64);
		  var validLen = lens[0];
		  var placeHoldersLen = lens[1];
		  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
		}

		function _byteLength (b64, validLen, placeHoldersLen) {
		  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
		}

		function toByteArray (b64) {
		  var tmp;
		  var lens = getLens(b64);
		  var validLen = lens[0];
		  var placeHoldersLen = lens[1];

		  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen));

		  var curByte = 0;

		  // if there are placeholders, only get up to the last complete 4 chars
		  var len = placeHoldersLen > 0
		    ? validLen - 4
		    : validLen;

		  var i;
		  for (i = 0; i < len; i += 4) {
		    tmp =
		      (revLookup[b64.charCodeAt(i)] << 18) |
		      (revLookup[b64.charCodeAt(i + 1)] << 12) |
		      (revLookup[b64.charCodeAt(i + 2)] << 6) |
		      revLookup[b64.charCodeAt(i + 3)];
		    arr[curByte++] = (tmp >> 16) & 0xFF;
		    arr[curByte++] = (tmp >> 8) & 0xFF;
		    arr[curByte++] = tmp & 0xFF;
		  }

		  if (placeHoldersLen === 2) {
		    tmp =
		      (revLookup[b64.charCodeAt(i)] << 2) |
		      (revLookup[b64.charCodeAt(i + 1)] >> 4);
		    arr[curByte++] = tmp & 0xFF;
		  }

		  if (placeHoldersLen === 1) {
		    tmp =
		      (revLookup[b64.charCodeAt(i)] << 10) |
		      (revLookup[b64.charCodeAt(i + 1)] << 4) |
		      (revLookup[b64.charCodeAt(i + 2)] >> 2);
		    arr[curByte++] = (tmp >> 8) & 0xFF;
		    arr[curByte++] = tmp & 0xFF;
		  }

		  return arr
		}

		function tripletToBase64 (num) {
		  return lookup[num >> 18 & 0x3F] +
		    lookup[num >> 12 & 0x3F] +
		    lookup[num >> 6 & 0x3F] +
		    lookup[num & 0x3F]
		}

		function encodeChunk (uint8, start, end) {
		  var tmp;
		  var output = [];
		  for (var i = start; i < end; i += 3) {
		    tmp =
		      ((uint8[i] << 16) & 0xFF0000) +
		      ((uint8[i + 1] << 8) & 0xFF00) +
		      (uint8[i + 2] & 0xFF);
		    output.push(tripletToBase64(tmp));
		  }
		  return output.join('')
		}

		function fromByteArray (uint8) {
		  var tmp;
		  var len = uint8.length;
		  var extraBytes = len % 3; // if we have 1 byte left, pad 2 bytes
		  var parts = [];
		  var maxChunkLength = 16383; // must be multiple of 3

		  // go through the array every three bytes, we'll deal with trailing stuff later
		  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
		    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)));
		  }

		  // pad the end with zeros, but make sure to not forget the extra bytes
		  if (extraBytes === 1) {
		    tmp = uint8[len - 1];
		    parts.push(
		      lookup[tmp >> 2] +
		      lookup[(tmp << 4) & 0x3F] +
		      '=='
		    );
		  } else if (extraBytes === 2) {
		    tmp = (uint8[len - 2] << 8) + uint8[len - 1];
		    parts.push(
		      lookup[tmp >> 10] +
		      lookup[(tmp >> 4) & 0x3F] +
		      lookup[(tmp << 2) & 0x3F] +
		      '='
		    );
		  }

		  return parts.join('')
		}
		return base64Js;
	}

	var ieee754 = {};

	/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */

	var hasRequiredIeee754;

	function requireIeee754 () {
		if (hasRequiredIeee754) return ieee754;
		hasRequiredIeee754 = 1;
		ieee754.read = function (buffer, offset, isLE, mLen, nBytes) {
		  var e, m;
		  var eLen = (nBytes * 8) - mLen - 1;
		  var eMax = (1 << eLen) - 1;
		  var eBias = eMax >> 1;
		  var nBits = -7;
		  var i = isLE ? (nBytes - 1) : 0;
		  var d = isLE ? -1 : 1;
		  var s = buffer[offset + i];

		  i += d;

		  e = s & ((1 << (-nBits)) - 1);
		  s >>= (-nBits);
		  nBits += eLen;
		  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

		  m = e & ((1 << (-nBits)) - 1);
		  e >>= (-nBits);
		  nBits += mLen;
		  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

		  if (e === 0) {
		    e = 1 - eBias;
		  } else if (e === eMax) {
		    return m ? NaN : ((s ? -1 : 1) * Infinity)
		  } else {
		    m = m + Math.pow(2, mLen);
		    e = e - eBias;
		  }
		  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
		};

		ieee754.write = function (buffer, value, offset, isLE, mLen, nBytes) {
		  var e, m, c;
		  var eLen = (nBytes * 8) - mLen - 1;
		  var eMax = (1 << eLen) - 1;
		  var eBias = eMax >> 1;
		  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0);
		  var i = isLE ? 0 : (nBytes - 1);
		  var d = isLE ? 1 : -1;
		  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0;

		  value = Math.abs(value);

		  if (isNaN(value) || value === Infinity) {
		    m = isNaN(value) ? 1 : 0;
		    e = eMax;
		  } else {
		    e = Math.floor(Math.log(value) / Math.LN2);
		    if (value * (c = Math.pow(2, -e)) < 1) {
		      e--;
		      c *= 2;
		    }
		    if (e + eBias >= 1) {
		      value += rt / c;
		    } else {
		      value += rt * Math.pow(2, 1 - eBias);
		    }
		    if (value * c >= 2) {
		      e++;
		      c /= 2;
		    }

		    if (e + eBias >= eMax) {
		      m = 0;
		      e = eMax;
		    } else if (e + eBias >= 1) {
		      m = ((value * c) - 1) * Math.pow(2, mLen);
		      e = e + eBias;
		    } else {
		      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen);
		      e = 0;
		    }
		  }

		  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

		  e = (e << mLen) | m;
		  eLen += mLen;
		  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

		  buffer[offset + i - d] |= s * 128;
		};
		return ieee754;
	}

	/*!
	 * The buffer module from node.js, for the browser.
	 *
	 * @author   Feross Aboukhadijeh <https://feross.org>
	 * @license  MIT
	 */

	var hasRequiredBuffer;

	function requireBuffer () {
		if (hasRequiredBuffer) return buffer;
		hasRequiredBuffer = 1;
		(function (exports) {

			const base64 = requireBase64Js();
			const ieee754 = requireIeee754();
			const customInspectSymbol =
			  (typeof Symbol === 'function' && typeof Symbol['for'] === 'function') // eslint-disable-line dot-notation
			    ? Symbol['for']('nodejs.util.inspect.custom') // eslint-disable-line dot-notation
			    : null;

			exports.Buffer = Buffer;
			exports.SlowBuffer = SlowBuffer;
			exports.INSPECT_MAX_BYTES = 50;

			const K_MAX_LENGTH = 0x7fffffff;
			exports.kMaxLength = K_MAX_LENGTH;

			/**
			 * If `Buffer.TYPED_ARRAY_SUPPORT`:
			 *   === true    Use Uint8Array implementation (fastest)
			 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
			 *               implementation (most compatible, even IE6)
			 *
			 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
			 * Opera 11.6+, iOS 4.2+.
			 *
			 * We report that the browser does not support typed arrays if the are not subclassable
			 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
			 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
			 * for __proto__ and has a buggy typed array implementation.
			 */
			Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport();

			if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
			    typeof console.error === 'function') {
			  console.error(
			    'This browser lacks typed array (Uint8Array) support which is required by ' +
			    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
			  );
			}

			function typedArraySupport () {
			  // Can typed array instances can be augmented?
			  try {
			    const arr = new Uint8Array(1);
			    const proto = { foo: function () { return 42 } };
			    Object.setPrototypeOf(proto, Uint8Array.prototype);
			    Object.setPrototypeOf(arr, proto);
			    return arr.foo() === 42
			  } catch (e) {
			    return false
			  }
			}

			Object.defineProperty(Buffer.prototype, 'parent', {
			  enumerable: true,
			  get: function () {
			    if (!Buffer.isBuffer(this)) return undefined
			    return this.buffer
			  }
			});

			Object.defineProperty(Buffer.prototype, 'offset', {
			  enumerable: true,
			  get: function () {
			    if (!Buffer.isBuffer(this)) return undefined
			    return this.byteOffset
			  }
			});

			function createBuffer (length) {
			  if (length > K_MAX_LENGTH) {
			    throw new RangeError('The value "' + length + '" is invalid for option "size"')
			  }
			  // Return an augmented `Uint8Array` instance
			  const buf = new Uint8Array(length);
			  Object.setPrototypeOf(buf, Buffer.prototype);
			  return buf
			}

			/**
			 * The Buffer constructor returns instances of `Uint8Array` that have their
			 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
			 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
			 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
			 * returns a single octet.
			 *
			 * The `Uint8Array` prototype remains unmodified.
			 */

			function Buffer (arg, encodingOrOffset, length) {
			  // Common case.
			  if (typeof arg === 'number') {
			    if (typeof encodingOrOffset === 'string') {
			      throw new TypeError(
			        'The "string" argument must be of type string. Received type number'
			      )
			    }
			    return allocUnsafe(arg)
			  }
			  return from(arg, encodingOrOffset, length)
			}

			Buffer.poolSize = 8192; // not used by this implementation

			function from (value, encodingOrOffset, length) {
			  if (typeof value === 'string') {
			    return fromString(value, encodingOrOffset)
			  }

			  if (ArrayBuffer.isView(value)) {
			    return fromArrayView(value)
			  }

			  if (value == null) {
			    throw new TypeError(
			      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
			      'or Array-like Object. Received type ' + (typeof value)
			    )
			  }

			  if (isInstance(value, ArrayBuffer) ||
			      (value && isInstance(value.buffer, ArrayBuffer))) {
			    return fromArrayBuffer(value, encodingOrOffset, length)
			  }

			  if (typeof SharedArrayBuffer !== 'undefined' &&
			      (isInstance(value, SharedArrayBuffer) ||
			      (value && isInstance(value.buffer, SharedArrayBuffer)))) {
			    return fromArrayBuffer(value, encodingOrOffset, length)
			  }

			  if (typeof value === 'number') {
			    throw new TypeError(
			      'The "value" argument must not be of type number. Received type number'
			    )
			  }

			  const valueOf = value.valueOf && value.valueOf();
			  if (valueOf != null && valueOf !== value) {
			    return Buffer.from(valueOf, encodingOrOffset, length)
			  }

			  const b = fromObject(value);
			  if (b) return b

			  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
			      typeof value[Symbol.toPrimitive] === 'function') {
			    return Buffer.from(value[Symbol.toPrimitive]('string'), encodingOrOffset, length)
			  }

			  throw new TypeError(
			    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
			    'or Array-like Object. Received type ' + (typeof value)
			  )
			}

			/**
			 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
			 * if value is a number.
			 * Buffer.from(str[, encoding])
			 * Buffer.from(array)
			 * Buffer.from(buffer)
			 * Buffer.from(arrayBuffer[, byteOffset[, length]])
			 **/
			Buffer.from = function (value, encodingOrOffset, length) {
			  return from(value, encodingOrOffset, length)
			};

			// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
			// https://github.com/feross/buffer/pull/148
			Object.setPrototypeOf(Buffer.prototype, Uint8Array.prototype);
			Object.setPrototypeOf(Buffer, Uint8Array);

			function assertSize (size) {
			  if (typeof size !== 'number') {
			    throw new TypeError('"size" argument must be of type number')
			  } else if (size < 0) {
			    throw new RangeError('The value "' + size + '" is invalid for option "size"')
			  }
			}

			function alloc (size, fill, encoding) {
			  assertSize(size);
			  if (size <= 0) {
			    return createBuffer(size)
			  }
			  if (fill !== undefined) {
			    // Only pay attention to encoding if it's a string. This
			    // prevents accidentally sending in a number that would
			    // be interpreted as a start offset.
			    return typeof encoding === 'string'
			      ? createBuffer(size).fill(fill, encoding)
			      : createBuffer(size).fill(fill)
			  }
			  return createBuffer(size)
			}

			/**
			 * Creates a new filled Buffer instance.
			 * alloc(size[, fill[, encoding]])
			 **/
			Buffer.alloc = function (size, fill, encoding) {
			  return alloc(size, fill, encoding)
			};

			function allocUnsafe (size) {
			  assertSize(size);
			  return createBuffer(size < 0 ? 0 : checked(size) | 0)
			}

			/**
			 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
			 * */
			Buffer.allocUnsafe = function (size) {
			  return allocUnsafe(size)
			};
			/**
			 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
			 */
			Buffer.allocUnsafeSlow = function (size) {
			  return allocUnsafe(size)
			};

			function fromString (string, encoding) {
			  if (typeof encoding !== 'string' || encoding === '') {
			    encoding = 'utf8';
			  }

			  if (!Buffer.isEncoding(encoding)) {
			    throw new TypeError('Unknown encoding: ' + encoding)
			  }

			  const length = byteLength(string, encoding) | 0;
			  let buf = createBuffer(length);

			  const actual = buf.write(string, encoding);

			  if (actual !== length) {
			    // Writing a hex string, for example, that contains invalid characters will
			    // cause everything after the first invalid character to be ignored. (e.g.
			    // 'abxxcd' will be treated as 'ab')
			    buf = buf.slice(0, actual);
			  }

			  return buf
			}

			function fromArrayLike (array) {
			  const length = array.length < 0 ? 0 : checked(array.length) | 0;
			  const buf = createBuffer(length);
			  for (let i = 0; i < length; i += 1) {
			    buf[i] = array[i] & 255;
			  }
			  return buf
			}

			function fromArrayView (arrayView) {
			  if (isInstance(arrayView, Uint8Array)) {
			    const copy = new Uint8Array(arrayView);
			    return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength)
			  }
			  return fromArrayLike(arrayView)
			}

			function fromArrayBuffer (array, byteOffset, length) {
			  if (byteOffset < 0 || array.byteLength < byteOffset) {
			    throw new RangeError('"offset" is outside of buffer bounds')
			  }

			  if (array.byteLength < byteOffset + (length || 0)) {
			    throw new RangeError('"length" is outside of buffer bounds')
			  }

			  let buf;
			  if (byteOffset === undefined && length === undefined) {
			    buf = new Uint8Array(array);
			  } else if (length === undefined) {
			    buf = new Uint8Array(array, byteOffset);
			  } else {
			    buf = new Uint8Array(array, byteOffset, length);
			  }

			  // Return an augmented `Uint8Array` instance
			  Object.setPrototypeOf(buf, Buffer.prototype);

			  return buf
			}

			function fromObject (obj) {
			  if (Buffer.isBuffer(obj)) {
			    const len = checked(obj.length) | 0;
			    const buf = createBuffer(len);

			    if (buf.length === 0) {
			      return buf
			    }

			    obj.copy(buf, 0, 0, len);
			    return buf
			  }

			  if (obj.length !== undefined) {
			    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
			      return createBuffer(0)
			    }
			    return fromArrayLike(obj)
			  }

			  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
			    return fromArrayLike(obj.data)
			  }
			}

			function checked (length) {
			  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
			  // length is NaN (which is otherwise coerced to zero.)
			  if (length >= K_MAX_LENGTH) {
			    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
			                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
			  }
			  return length | 0
			}

			function SlowBuffer (length) {
			  if (+length != length) { // eslint-disable-line eqeqeq
			    length = 0;
			  }
			  return Buffer.alloc(+length)
			}

			Buffer.isBuffer = function isBuffer (b) {
			  return b != null && b._isBuffer === true &&
			    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
			};

			Buffer.compare = function compare (a, b) {
			  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength);
			  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength);
			  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
			    throw new TypeError(
			      'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
			    )
			  }

			  if (a === b) return 0

			  let x = a.length;
			  let y = b.length;

			  for (let i = 0, len = Math.min(x, y); i < len; ++i) {
			    if (a[i] !== b[i]) {
			      x = a[i];
			      y = b[i];
			      break
			    }
			  }

			  if (x < y) return -1
			  if (y < x) return 1
			  return 0
			};

			Buffer.isEncoding = function isEncoding (encoding) {
			  switch (String(encoding).toLowerCase()) {
			    case 'hex':
			    case 'utf8':
			    case 'utf-8':
			    case 'ascii':
			    case 'latin1':
			    case 'binary':
			    case 'base64':
			    case 'ucs2':
			    case 'ucs-2':
			    case 'utf16le':
			    case 'utf-16le':
			      return true
			    default:
			      return false
			  }
			};

			Buffer.concat = function concat (list, length) {
			  if (!Array.isArray(list)) {
			    throw new TypeError('"list" argument must be an Array of Buffers')
			  }

			  if (list.length === 0) {
			    return Buffer.alloc(0)
			  }

			  let i;
			  if (length === undefined) {
			    length = 0;
			    for (i = 0; i < list.length; ++i) {
			      length += list[i].length;
			    }
			  }

			  const buffer = Buffer.allocUnsafe(length);
			  let pos = 0;
			  for (i = 0; i < list.length; ++i) {
			    let buf = list[i];
			    if (isInstance(buf, Uint8Array)) {
			      if (pos + buf.length > buffer.length) {
			        if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf);
			        buf.copy(buffer, pos);
			      } else {
			        Uint8Array.prototype.set.call(
			          buffer,
			          buf,
			          pos
			        );
			      }
			    } else if (!Buffer.isBuffer(buf)) {
			      throw new TypeError('"list" argument must be an Array of Buffers')
			    } else {
			      buf.copy(buffer, pos);
			    }
			    pos += buf.length;
			  }
			  return buffer
			};

			function byteLength (string, encoding) {
			  if (Buffer.isBuffer(string)) {
			    return string.length
			  }
			  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
			    return string.byteLength
			  }
			  if (typeof string !== 'string') {
			    throw new TypeError(
			      'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
			      'Received type ' + typeof string
			    )
			  }

			  const len = string.length;
			  const mustMatch = (arguments.length > 2 && arguments[2] === true);
			  if (!mustMatch && len === 0) return 0

			  // Use a for loop to avoid recursion
			  let loweredCase = false;
			  for (;;) {
			    switch (encoding) {
			      case 'ascii':
			      case 'latin1':
			      case 'binary':
			        return len
			      case 'utf8':
			      case 'utf-8':
			        return utf8ToBytes(string).length
			      case 'ucs2':
			      case 'ucs-2':
			      case 'utf16le':
			      case 'utf-16le':
			        return len * 2
			      case 'hex':
			        return len >>> 1
			      case 'base64':
			        return base64ToBytes(string).length
			      default:
			        if (loweredCase) {
			          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
			        }
			        encoding = ('' + encoding).toLowerCase();
			        loweredCase = true;
			    }
			  }
			}
			Buffer.byteLength = byteLength;

			function slowToString (encoding, start, end) {
			  let loweredCase = false;

			  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
			  // property of a typed array.

			  // This behaves neither like String nor Uint8Array in that we set start/end
			  // to their upper/lower bounds if the value passed is out of range.
			  // undefined is handled specially as per ECMA-262 6th Edition,
			  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
			  if (start === undefined || start < 0) {
			    start = 0;
			  }
			  // Return early if start > this.length. Done here to prevent potential uint32
			  // coercion fail below.
			  if (start > this.length) {
			    return ''
			  }

			  if (end === undefined || end > this.length) {
			    end = this.length;
			  }

			  if (end <= 0) {
			    return ''
			  }

			  // Force coercion to uint32. This will also coerce falsey/NaN values to 0.
			  end >>>= 0;
			  start >>>= 0;

			  if (end <= start) {
			    return ''
			  }

			  if (!encoding) encoding = 'utf8';

			  while (true) {
			    switch (encoding) {
			      case 'hex':
			        return hexSlice(this, start, end)

			      case 'utf8':
			      case 'utf-8':
			        return utf8Slice(this, start, end)

			      case 'ascii':
			        return asciiSlice(this, start, end)

			      case 'latin1':
			      case 'binary':
			        return latin1Slice(this, start, end)

			      case 'base64':
			        return base64Slice(this, start, end)

			      case 'ucs2':
			      case 'ucs-2':
			      case 'utf16le':
			      case 'utf-16le':
			        return utf16leSlice(this, start, end)

			      default:
			        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
			        encoding = (encoding + '').toLowerCase();
			        loweredCase = true;
			    }
			  }
			}

			// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
			// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
			// reliably in a browserify context because there could be multiple different
			// copies of the 'buffer' package in use. This method works even for Buffer
			// instances that were created from another copy of the `buffer` package.
			// See: https://github.com/feross/buffer/issues/154
			Buffer.prototype._isBuffer = true;

			function swap (b, n, m) {
			  const i = b[n];
			  b[n] = b[m];
			  b[m] = i;
			}

			Buffer.prototype.swap16 = function swap16 () {
			  const len = this.length;
			  if (len % 2 !== 0) {
			    throw new RangeError('Buffer size must be a multiple of 16-bits')
			  }
			  for (let i = 0; i < len; i += 2) {
			    swap(this, i, i + 1);
			  }
			  return this
			};

			Buffer.prototype.swap32 = function swap32 () {
			  const len = this.length;
			  if (len % 4 !== 0) {
			    throw new RangeError('Buffer size must be a multiple of 32-bits')
			  }
			  for (let i = 0; i < len; i += 4) {
			    swap(this, i, i + 3);
			    swap(this, i + 1, i + 2);
			  }
			  return this
			};

			Buffer.prototype.swap64 = function swap64 () {
			  const len = this.length;
			  if (len % 8 !== 0) {
			    throw new RangeError('Buffer size must be a multiple of 64-bits')
			  }
			  for (let i = 0; i < len; i += 8) {
			    swap(this, i, i + 7);
			    swap(this, i + 1, i + 6);
			    swap(this, i + 2, i + 5);
			    swap(this, i + 3, i + 4);
			  }
			  return this
			};

			Buffer.prototype.toString = function toString () {
			  const length = this.length;
			  if (length === 0) return ''
			  if (arguments.length === 0) return utf8Slice(this, 0, length)
			  return slowToString.apply(this, arguments)
			};

			Buffer.prototype.toLocaleString = Buffer.prototype.toString;

			Buffer.prototype.equals = function equals (b) {
			  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
			  if (this === b) return true
			  return Buffer.compare(this, b) === 0
			};

			Buffer.prototype.inspect = function inspect () {
			  let str = '';
			  const max = exports.INSPECT_MAX_BYTES;
			  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim();
			  if (this.length > max) str += ' ... ';
			  return '<Buffer ' + str + '>'
			};
			if (customInspectSymbol) {
			  Buffer.prototype[customInspectSymbol] = Buffer.prototype.inspect;
			}

			Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
			  if (isInstance(target, Uint8Array)) {
			    target = Buffer.from(target, target.offset, target.byteLength);
			  }
			  if (!Buffer.isBuffer(target)) {
			    throw new TypeError(
			      'The "target" argument must be one of type Buffer or Uint8Array. ' +
			      'Received type ' + (typeof target)
			    )
			  }

			  if (start === undefined) {
			    start = 0;
			  }
			  if (end === undefined) {
			    end = target ? target.length : 0;
			  }
			  if (thisStart === undefined) {
			    thisStart = 0;
			  }
			  if (thisEnd === undefined) {
			    thisEnd = this.length;
			  }

			  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
			    throw new RangeError('out of range index')
			  }

			  if (thisStart >= thisEnd && start >= end) {
			    return 0
			  }
			  if (thisStart >= thisEnd) {
			    return -1
			  }
			  if (start >= end) {
			    return 1
			  }

			  start >>>= 0;
			  end >>>= 0;
			  thisStart >>>= 0;
			  thisEnd >>>= 0;

			  if (this === target) return 0

			  let x = thisEnd - thisStart;
			  let y = end - start;
			  const len = Math.min(x, y);

			  const thisCopy = this.slice(thisStart, thisEnd);
			  const targetCopy = target.slice(start, end);

			  for (let i = 0; i < len; ++i) {
			    if (thisCopy[i] !== targetCopy[i]) {
			      x = thisCopy[i];
			      y = targetCopy[i];
			      break
			    }
			  }

			  if (x < y) return -1
			  if (y < x) return 1
			  return 0
			};

			// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
			// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
			//
			// Arguments:
			// - buffer - a Buffer to search
			// - val - a string, Buffer, or number
			// - byteOffset - an index into `buffer`; will be clamped to an int32
			// - encoding - an optional encoding, relevant is val is a string
			// - dir - true for indexOf, false for lastIndexOf
			function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
			  // Empty buffer means no match
			  if (buffer.length === 0) return -1

			  // Normalize byteOffset
			  if (typeof byteOffset === 'string') {
			    encoding = byteOffset;
			    byteOffset = 0;
			  } else if (byteOffset > 0x7fffffff) {
			    byteOffset = 0x7fffffff;
			  } else if (byteOffset < -2147483648) {
			    byteOffset = -2147483648;
			  }
			  byteOffset = +byteOffset; // Coerce to Number.
			  if (numberIsNaN(byteOffset)) {
			    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
			    byteOffset = dir ? 0 : (buffer.length - 1);
			  }

			  // Normalize byteOffset: negative offsets start from the end of the buffer
			  if (byteOffset < 0) byteOffset = buffer.length + byteOffset;
			  if (byteOffset >= buffer.length) {
			    if (dir) return -1
			    else byteOffset = buffer.length - 1;
			  } else if (byteOffset < 0) {
			    if (dir) byteOffset = 0;
			    else return -1
			  }

			  // Normalize val
			  if (typeof val === 'string') {
			    val = Buffer.from(val, encoding);
			  }

			  // Finally, search either indexOf (if dir is true) or lastIndexOf
			  if (Buffer.isBuffer(val)) {
			    // Special case: looking for empty string/buffer always fails
			    if (val.length === 0) {
			      return -1
			    }
			    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
			  } else if (typeof val === 'number') {
			    val = val & 0xFF; // Search for a byte value [0-255]
			    if (typeof Uint8Array.prototype.indexOf === 'function') {
			      if (dir) {
			        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
			      } else {
			        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
			      }
			    }
			    return arrayIndexOf(buffer, [val], byteOffset, encoding, dir)
			  }

			  throw new TypeError('val must be string, number or Buffer')
			}

			function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
			  let indexSize = 1;
			  let arrLength = arr.length;
			  let valLength = val.length;

			  if (encoding !== undefined) {
			    encoding = String(encoding).toLowerCase();
			    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
			        encoding === 'utf16le' || encoding === 'utf-16le') {
			      if (arr.length < 2 || val.length < 2) {
			        return -1
			      }
			      indexSize = 2;
			      arrLength /= 2;
			      valLength /= 2;
			      byteOffset /= 2;
			    }
			  }

			  function read (buf, i) {
			    if (indexSize === 1) {
			      return buf[i]
			    } else {
			      return buf.readUInt16BE(i * indexSize)
			    }
			  }

			  let i;
			  if (dir) {
			    let foundIndex = -1;
			    for (i = byteOffset; i < arrLength; i++) {
			      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
			        if (foundIndex === -1) foundIndex = i;
			        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
			      } else {
			        if (foundIndex !== -1) i -= i - foundIndex;
			        foundIndex = -1;
			      }
			    }
			  } else {
			    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength;
			    for (i = byteOffset; i >= 0; i--) {
			      let found = true;
			      for (let j = 0; j < valLength; j++) {
			        if (read(arr, i + j) !== read(val, j)) {
			          found = false;
			          break
			        }
			      }
			      if (found) return i
			    }
			  }

			  return -1
			}

			Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
			  return this.indexOf(val, byteOffset, encoding) !== -1
			};

			Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
			  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
			};

			Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
			  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
			};

			function hexWrite (buf, string, offset, length) {
			  offset = Number(offset) || 0;
			  const remaining = buf.length - offset;
			  if (!length) {
			    length = remaining;
			  } else {
			    length = Number(length);
			    if (length > remaining) {
			      length = remaining;
			    }
			  }

			  const strLen = string.length;

			  if (length > strLen / 2) {
			    length = strLen / 2;
			  }
			  let i;
			  for (i = 0; i < length; ++i) {
			    const parsed = parseInt(string.substr(i * 2, 2), 16);
			    if (numberIsNaN(parsed)) return i
			    buf[offset + i] = parsed;
			  }
			  return i
			}

			function utf8Write (buf, string, offset, length) {
			  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
			}

			function asciiWrite (buf, string, offset, length) {
			  return blitBuffer(asciiToBytes(string), buf, offset, length)
			}

			function base64Write (buf, string, offset, length) {
			  return blitBuffer(base64ToBytes(string), buf, offset, length)
			}

			function ucs2Write (buf, string, offset, length) {
			  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
			}

			Buffer.prototype.write = function write (string, offset, length, encoding) {
			  // Buffer#write(string)
			  if (offset === undefined) {
			    encoding = 'utf8';
			    length = this.length;
			    offset = 0;
			  // Buffer#write(string, encoding)
			  } else if (length === undefined && typeof offset === 'string') {
			    encoding = offset;
			    length = this.length;
			    offset = 0;
			  // Buffer#write(string, offset[, length][, encoding])
			  } else if (isFinite(offset)) {
			    offset = offset >>> 0;
			    if (isFinite(length)) {
			      length = length >>> 0;
			      if (encoding === undefined) encoding = 'utf8';
			    } else {
			      encoding = length;
			      length = undefined;
			    }
			  } else {
			    throw new Error(
			      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
			    )
			  }

			  const remaining = this.length - offset;
			  if (length === undefined || length > remaining) length = remaining;

			  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
			    throw new RangeError('Attempt to write outside buffer bounds')
			  }

			  if (!encoding) encoding = 'utf8';

			  let loweredCase = false;
			  for (;;) {
			    switch (encoding) {
			      case 'hex':
			        return hexWrite(this, string, offset, length)

			      case 'utf8':
			      case 'utf-8':
			        return utf8Write(this, string, offset, length)

			      case 'ascii':
			      case 'latin1':
			      case 'binary':
			        return asciiWrite(this, string, offset, length)

			      case 'base64':
			        // Warning: maxLength not taken into account in base64Write
			        return base64Write(this, string, offset, length)

			      case 'ucs2':
			      case 'ucs-2':
			      case 'utf16le':
			      case 'utf-16le':
			        return ucs2Write(this, string, offset, length)

			      default:
			        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
			        encoding = ('' + encoding).toLowerCase();
			        loweredCase = true;
			    }
			  }
			};

			Buffer.prototype.toJSON = function toJSON () {
			  return {
			    type: 'Buffer',
			    data: Array.prototype.slice.call(this._arr || this, 0)
			  }
			};

			function base64Slice (buf, start, end) {
			  if (start === 0 && end === buf.length) {
			    return base64.fromByteArray(buf)
			  } else {
			    return base64.fromByteArray(buf.slice(start, end))
			  }
			}

			function utf8Slice (buf, start, end) {
			  end = Math.min(buf.length, end);
			  const res = [];

			  let i = start;
			  while (i < end) {
			    const firstByte = buf[i];
			    let codePoint = null;
			    let bytesPerSequence = (firstByte > 0xEF)
			      ? 4
			      : (firstByte > 0xDF)
			          ? 3
			          : (firstByte > 0xBF)
			              ? 2
			              : 1;

			    if (i + bytesPerSequence <= end) {
			      let secondByte, thirdByte, fourthByte, tempCodePoint;

			      switch (bytesPerSequence) {
			        case 1:
			          if (firstByte < 0x80) {
			            codePoint = firstByte;
			          }
			          break
			        case 2:
			          secondByte = buf[i + 1];
			          if ((secondByte & 0xC0) === 0x80) {
			            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F);
			            if (tempCodePoint > 0x7F) {
			              codePoint = tempCodePoint;
			            }
			          }
			          break
			        case 3:
			          secondByte = buf[i + 1];
			          thirdByte = buf[i + 2];
			          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
			            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F);
			            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
			              codePoint = tempCodePoint;
			            }
			          }
			          break
			        case 4:
			          secondByte = buf[i + 1];
			          thirdByte = buf[i + 2];
			          fourthByte = buf[i + 3];
			          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
			            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F);
			            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
			              codePoint = tempCodePoint;
			            }
			          }
			      }
			    }

			    if (codePoint === null) {
			      // we did not generate a valid codePoint so insert a
			      // replacement char (U+FFFD) and advance only 1 byte
			      codePoint = 0xFFFD;
			      bytesPerSequence = 1;
			    } else if (codePoint > 0xFFFF) {
			      // encode to utf16 (surrogate pair dance)
			      codePoint -= 0x10000;
			      res.push(codePoint >>> 10 & 0x3FF | 0xD800);
			      codePoint = 0xDC00 | codePoint & 0x3FF;
			    }

			    res.push(codePoint);
			    i += bytesPerSequence;
			  }

			  return decodeCodePointsArray(res)
			}

			// Based on http://stackoverflow.com/a/22747272/680742, the browser with
			// the lowest limit is Chrome, with 0x10000 args.
			// We go 1 magnitude less, for safety
			const MAX_ARGUMENTS_LENGTH = 0x1000;

			function decodeCodePointsArray (codePoints) {
			  const len = codePoints.length;
			  if (len <= MAX_ARGUMENTS_LENGTH) {
			    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
			  }

			  // Decode in chunks to avoid "call stack size exceeded".
			  let res = '';
			  let i = 0;
			  while (i < len) {
			    res += String.fromCharCode.apply(
			      String,
			      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
			    );
			  }
			  return res
			}

			function asciiSlice (buf, start, end) {
			  let ret = '';
			  end = Math.min(buf.length, end);

			  for (let i = start; i < end; ++i) {
			    ret += String.fromCharCode(buf[i] & 0x7F);
			  }
			  return ret
			}

			function latin1Slice (buf, start, end) {
			  let ret = '';
			  end = Math.min(buf.length, end);

			  for (let i = start; i < end; ++i) {
			    ret += String.fromCharCode(buf[i]);
			  }
			  return ret
			}

			function hexSlice (buf, start, end) {
			  const len = buf.length;

			  if (!start || start < 0) start = 0;
			  if (!end || end < 0 || end > len) end = len;

			  let out = '';
			  for (let i = start; i < end; ++i) {
			    out += hexSliceLookupTable[buf[i]];
			  }
			  return out
			}

			function utf16leSlice (buf, start, end) {
			  const bytes = buf.slice(start, end);
			  let res = '';
			  // If bytes.length is odd, the last 8 bits must be ignored (same as node.js)
			  for (let i = 0; i < bytes.length - 1; i += 2) {
			    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256));
			  }
			  return res
			}

			Buffer.prototype.slice = function slice (start, end) {
			  const len = this.length;
			  start = ~~start;
			  end = end === undefined ? len : ~~end;

			  if (start < 0) {
			    start += len;
			    if (start < 0) start = 0;
			  } else if (start > len) {
			    start = len;
			  }

			  if (end < 0) {
			    end += len;
			    if (end < 0) end = 0;
			  } else if (end > len) {
			    end = len;
			  }

			  if (end < start) end = start;

			  const newBuf = this.subarray(start, end);
			  // Return an augmented `Uint8Array` instance
			  Object.setPrototypeOf(newBuf, Buffer.prototype);

			  return newBuf
			};

			/*
			 * Need to make sure that buffer isn't trying to write out of bounds.
			 */
			function checkOffset (offset, ext, length) {
			  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
			  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
			}

			Buffer.prototype.readUintLE =
			Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) checkOffset(offset, byteLength, this.length);

			  let val = this[offset];
			  let mul = 1;
			  let i = 0;
			  while (++i < byteLength && (mul *= 0x100)) {
			    val += this[offset + i] * mul;
			  }

			  return val
			};

			Buffer.prototype.readUintBE =
			Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) {
			    checkOffset(offset, byteLength, this.length);
			  }

			  let val = this[offset + --byteLength];
			  let mul = 1;
			  while (byteLength > 0 && (mul *= 0x100)) {
			    val += this[offset + --byteLength] * mul;
			  }

			  return val
			};

			Buffer.prototype.readUint8 =
			Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 1, this.length);
			  return this[offset]
			};

			Buffer.prototype.readUint16LE =
			Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 2, this.length);
			  return this[offset] | (this[offset + 1] << 8)
			};

			Buffer.prototype.readUint16BE =
			Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 2, this.length);
			  return (this[offset] << 8) | this[offset + 1]
			};

			Buffer.prototype.readUint32LE =
			Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);

			  return ((this[offset]) |
			      (this[offset + 1] << 8) |
			      (this[offset + 2] << 16)) +
			      (this[offset + 3] * 0x1000000)
			};

			Buffer.prototype.readUint32BE =
			Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);

			  return (this[offset] * 0x1000000) +
			    ((this[offset + 1] << 16) |
			    (this[offset + 2] << 8) |
			    this[offset + 3])
			};

			Buffer.prototype.readBigUInt64LE = defineBigIntMethod(function readBigUInt64LE (offset) {
			  offset = offset >>> 0;
			  validateNumber(offset, 'offset');
			  const first = this[offset];
			  const last = this[offset + 7];
			  if (first === undefined || last === undefined) {
			    boundsError(offset, this.length - 8);
			  }

			  const lo = first +
			    this[++offset] * 2 ** 8 +
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 24;

			  const hi = this[++offset] +
			    this[++offset] * 2 ** 8 +
			    this[++offset] * 2 ** 16 +
			    last * 2 ** 24;

			  return BigInt(lo) + (BigInt(hi) << BigInt(32))
			});

			Buffer.prototype.readBigUInt64BE = defineBigIntMethod(function readBigUInt64BE (offset) {
			  offset = offset >>> 0;
			  validateNumber(offset, 'offset');
			  const first = this[offset];
			  const last = this[offset + 7];
			  if (first === undefined || last === undefined) {
			    boundsError(offset, this.length - 8);
			  }

			  const hi = first * 2 ** 24 +
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 8 +
			    this[++offset];

			  const lo = this[++offset] * 2 ** 24 +
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 8 +
			    last;

			  return (BigInt(hi) << BigInt(32)) + BigInt(lo)
			});

			Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) checkOffset(offset, byteLength, this.length);

			  let val = this[offset];
			  let mul = 1;
			  let i = 0;
			  while (++i < byteLength && (mul *= 0x100)) {
			    val += this[offset + i] * mul;
			  }
			  mul *= 0x80;

			  if (val >= mul) val -= Math.pow(2, 8 * byteLength);

			  return val
			};

			Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) checkOffset(offset, byteLength, this.length);

			  let i = byteLength;
			  let mul = 1;
			  let val = this[offset + --i];
			  while (i > 0 && (mul *= 0x100)) {
			    val += this[offset + --i] * mul;
			  }
			  mul *= 0x80;

			  if (val >= mul) val -= Math.pow(2, 8 * byteLength);

			  return val
			};

			Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 1, this.length);
			  if (!(this[offset] & 0x80)) return (this[offset])
			  return ((0xff - this[offset] + 1) * -1)
			};

			Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 2, this.length);
			  const val = this[offset] | (this[offset + 1] << 8);
			  return (val & 0x8000) ? val | 0xFFFF0000 : val
			};

			Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 2, this.length);
			  const val = this[offset + 1] | (this[offset] << 8);
			  return (val & 0x8000) ? val | 0xFFFF0000 : val
			};

			Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);

			  return (this[offset]) |
			    (this[offset + 1] << 8) |
			    (this[offset + 2] << 16) |
			    (this[offset + 3] << 24)
			};

			Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);

			  return (this[offset] << 24) |
			    (this[offset + 1] << 16) |
			    (this[offset + 2] << 8) |
			    (this[offset + 3])
			};

			Buffer.prototype.readBigInt64LE = defineBigIntMethod(function readBigInt64LE (offset) {
			  offset = offset >>> 0;
			  validateNumber(offset, 'offset');
			  const first = this[offset];
			  const last = this[offset + 7];
			  if (first === undefined || last === undefined) {
			    boundsError(offset, this.length - 8);
			  }

			  const val = this[offset + 4] +
			    this[offset + 5] * 2 ** 8 +
			    this[offset + 6] * 2 ** 16 +
			    (last << 24); // Overflow

			  return (BigInt(val) << BigInt(32)) +
			    BigInt(first +
			    this[++offset] * 2 ** 8 +
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 24)
			});

			Buffer.prototype.readBigInt64BE = defineBigIntMethod(function readBigInt64BE (offset) {
			  offset = offset >>> 0;
			  validateNumber(offset, 'offset');
			  const first = this[offset];
			  const last = this[offset + 7];
			  if (first === undefined || last === undefined) {
			    boundsError(offset, this.length - 8);
			  }

			  const val = (first << 24) + // Overflow
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 8 +
			    this[++offset];

			  return (BigInt(val) << BigInt(32)) +
			    BigInt(this[++offset] * 2 ** 24 +
			    this[++offset] * 2 ** 16 +
			    this[++offset] * 2 ** 8 +
			    last)
			});

			Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);
			  return ieee754.read(this, offset, true, 23, 4)
			};

			Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 4, this.length);
			  return ieee754.read(this, offset, false, 23, 4)
			};

			Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 8, this.length);
			  return ieee754.read(this, offset, true, 52, 8)
			};

			Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
			  offset = offset >>> 0;
			  if (!noAssert) checkOffset(offset, 8, this.length);
			  return ieee754.read(this, offset, false, 52, 8)
			};

			function checkInt (buf, value, offset, ext, max, min) {
			  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
			  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
			  if (offset + ext > buf.length) throw new RangeError('Index out of range')
			}

			Buffer.prototype.writeUintLE =
			Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) {
			    const maxBytes = Math.pow(2, 8 * byteLength) - 1;
			    checkInt(this, value, offset, byteLength, maxBytes, 0);
			  }

			  let mul = 1;
			  let i = 0;
			  this[offset] = value & 0xFF;
			  while (++i < byteLength && (mul *= 0x100)) {
			    this[offset + i] = (value / mul) & 0xFF;
			  }

			  return offset + byteLength
			};

			Buffer.prototype.writeUintBE =
			Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  byteLength = byteLength >>> 0;
			  if (!noAssert) {
			    const maxBytes = Math.pow(2, 8 * byteLength) - 1;
			    checkInt(this, value, offset, byteLength, maxBytes, 0);
			  }

			  let i = byteLength - 1;
			  let mul = 1;
			  this[offset + i] = value & 0xFF;
			  while (--i >= 0 && (mul *= 0x100)) {
			    this[offset + i] = (value / mul) & 0xFF;
			  }

			  return offset + byteLength
			};

			Buffer.prototype.writeUint8 =
			Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0);
			  this[offset] = (value & 0xff);
			  return offset + 1
			};

			Buffer.prototype.writeUint16LE =
			Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
			  this[offset] = (value & 0xff);
			  this[offset + 1] = (value >>> 8);
			  return offset + 2
			};

			Buffer.prototype.writeUint16BE =
			Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
			  this[offset] = (value >>> 8);
			  this[offset + 1] = (value & 0xff);
			  return offset + 2
			};

			Buffer.prototype.writeUint32LE =
			Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
			  this[offset + 3] = (value >>> 24);
			  this[offset + 2] = (value >>> 16);
			  this[offset + 1] = (value >>> 8);
			  this[offset] = (value & 0xff);
			  return offset + 4
			};

			Buffer.prototype.writeUint32BE =
			Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
			  this[offset] = (value >>> 24);
			  this[offset + 1] = (value >>> 16);
			  this[offset + 2] = (value >>> 8);
			  this[offset + 3] = (value & 0xff);
			  return offset + 4
			};

			function wrtBigUInt64LE (buf, value, offset, min, max) {
			  checkIntBI(value, min, max, buf, offset, 7);

			  let lo = Number(value & BigInt(0xffffffff));
			  buf[offset++] = lo;
			  lo = lo >> 8;
			  buf[offset++] = lo;
			  lo = lo >> 8;
			  buf[offset++] = lo;
			  lo = lo >> 8;
			  buf[offset++] = lo;
			  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
			  buf[offset++] = hi;
			  hi = hi >> 8;
			  buf[offset++] = hi;
			  hi = hi >> 8;
			  buf[offset++] = hi;
			  hi = hi >> 8;
			  buf[offset++] = hi;
			  return offset
			}

			function wrtBigUInt64BE (buf, value, offset, min, max) {
			  checkIntBI(value, min, max, buf, offset, 7);

			  let lo = Number(value & BigInt(0xffffffff));
			  buf[offset + 7] = lo;
			  lo = lo >> 8;
			  buf[offset + 6] = lo;
			  lo = lo >> 8;
			  buf[offset + 5] = lo;
			  lo = lo >> 8;
			  buf[offset + 4] = lo;
			  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
			  buf[offset + 3] = hi;
			  hi = hi >> 8;
			  buf[offset + 2] = hi;
			  hi = hi >> 8;
			  buf[offset + 1] = hi;
			  hi = hi >> 8;
			  buf[offset] = hi;
			  return offset + 8
			}

			Buffer.prototype.writeBigUInt64LE = defineBigIntMethod(function writeBigUInt64LE (value, offset = 0) {
			  return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))
			});

			Buffer.prototype.writeBigUInt64BE = defineBigIntMethod(function writeBigUInt64BE (value, offset = 0) {
			  return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))
			});

			Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) {
			    const limit = Math.pow(2, (8 * byteLength) - 1);

			    checkInt(this, value, offset, byteLength, limit - 1, -limit);
			  }

			  let i = 0;
			  let mul = 1;
			  let sub = 0;
			  this[offset] = value & 0xFF;
			  while (++i < byteLength && (mul *= 0x100)) {
			    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
			      sub = 1;
			    }
			    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
			  }

			  return offset + byteLength
			};

			Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) {
			    const limit = Math.pow(2, (8 * byteLength) - 1);

			    checkInt(this, value, offset, byteLength, limit - 1, -limit);
			  }

			  let i = byteLength - 1;
			  let mul = 1;
			  let sub = 0;
			  this[offset + i] = value & 0xFF;
			  while (--i >= 0 && (mul *= 0x100)) {
			    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
			      sub = 1;
			    }
			    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
			  }

			  return offset + byteLength
			};

			Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -128);
			  if (value < 0) value = 0xff + value + 1;
			  this[offset] = (value & 0xff);
			  return offset + 1
			};

			Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -32768);
			  this[offset] = (value & 0xff);
			  this[offset + 1] = (value >>> 8);
			  return offset + 2
			};

			Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -32768);
			  this[offset] = (value >>> 8);
			  this[offset + 1] = (value & 0xff);
			  return offset + 2
			};

			Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -2147483648);
			  this[offset] = (value & 0xff);
			  this[offset + 1] = (value >>> 8);
			  this[offset + 2] = (value >>> 16);
			  this[offset + 3] = (value >>> 24);
			  return offset + 4
			};

			Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -2147483648);
			  if (value < 0) value = 0xffffffff + value + 1;
			  this[offset] = (value >>> 24);
			  this[offset + 1] = (value >>> 16);
			  this[offset + 2] = (value >>> 8);
			  this[offset + 3] = (value & 0xff);
			  return offset + 4
			};

			Buffer.prototype.writeBigInt64LE = defineBigIntMethod(function writeBigInt64LE (value, offset = 0) {
			  return wrtBigUInt64LE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))
			});

			Buffer.prototype.writeBigInt64BE = defineBigIntMethod(function writeBigInt64BE (value, offset = 0) {
			  return wrtBigUInt64BE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))
			});

			function checkIEEE754 (buf, value, offset, ext, max, min) {
			  if (offset + ext > buf.length) throw new RangeError('Index out of range')
			  if (offset < 0) throw new RangeError('Index out of range')
			}

			function writeFloat (buf, value, offset, littleEndian, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) {
			    checkIEEE754(buf, value, offset, 4);
			  }
			  ieee754.write(buf, value, offset, littleEndian, 23, 4);
			  return offset + 4
			}

			Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
			  return writeFloat(this, value, offset, true, noAssert)
			};

			Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
			  return writeFloat(this, value, offset, false, noAssert)
			};

			function writeDouble (buf, value, offset, littleEndian, noAssert) {
			  value = +value;
			  offset = offset >>> 0;
			  if (!noAssert) {
			    checkIEEE754(buf, value, offset, 8);
			  }
			  ieee754.write(buf, value, offset, littleEndian, 52, 8);
			  return offset + 8
			}

			Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
			  return writeDouble(this, value, offset, true, noAssert)
			};

			Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
			  return writeDouble(this, value, offset, false, noAssert)
			};

			// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
			Buffer.prototype.copy = function copy (target, targetStart, start, end) {
			  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
			  if (!start) start = 0;
			  if (!end && end !== 0) end = this.length;
			  if (targetStart >= target.length) targetStart = target.length;
			  if (!targetStart) targetStart = 0;
			  if (end > 0 && end < start) end = start;

			  // Copy 0 bytes; we're done
			  if (end === start) return 0
			  if (target.length === 0 || this.length === 0) return 0

			  // Fatal error conditions
			  if (targetStart < 0) {
			    throw new RangeError('targetStart out of bounds')
			  }
			  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
			  if (end < 0) throw new RangeError('sourceEnd out of bounds')

			  // Are we oob?
			  if (end > this.length) end = this.length;
			  if (target.length - targetStart < end - start) {
			    end = target.length - targetStart + start;
			  }

			  const len = end - start;

			  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
			    // Use built-in when available, missing from IE11
			    this.copyWithin(targetStart, start, end);
			  } else {
			    Uint8Array.prototype.set.call(
			      target,
			      this.subarray(start, end),
			      targetStart
			    );
			  }

			  return len
			};

			// Usage:
			//    buffer.fill(number[, offset[, end]])
			//    buffer.fill(buffer[, offset[, end]])
			//    buffer.fill(string[, offset[, end]][, encoding])
			Buffer.prototype.fill = function fill (val, start, end, encoding) {
			  // Handle string cases:
			  if (typeof val === 'string') {
			    if (typeof start === 'string') {
			      encoding = start;
			      start = 0;
			      end = this.length;
			    } else if (typeof end === 'string') {
			      encoding = end;
			      end = this.length;
			    }
			    if (encoding !== undefined && typeof encoding !== 'string') {
			      throw new TypeError('encoding must be a string')
			    }
			    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
			      throw new TypeError('Unknown encoding: ' + encoding)
			    }
			    if (val.length === 1) {
			      const code = val.charCodeAt(0);
			      if ((encoding === 'utf8' && code < 128) ||
			          encoding === 'latin1') {
			        // Fast path: If `val` fits into a single byte, use that numeric value.
			        val = code;
			      }
			    }
			  } else if (typeof val === 'number') {
			    val = val & 255;
			  } else if (typeof val === 'boolean') {
			    val = Number(val);
			  }

			  // Invalid ranges are not set to a default, so can range check early.
			  if (start < 0 || this.length < start || this.length < end) {
			    throw new RangeError('Out of range index')
			  }

			  if (end <= start) {
			    return this
			  }

			  start = start >>> 0;
			  end = end === undefined ? this.length : end >>> 0;

			  if (!val) val = 0;

			  let i;
			  if (typeof val === 'number') {
			    for (i = start; i < end; ++i) {
			      this[i] = val;
			    }
			  } else {
			    const bytes = Buffer.isBuffer(val)
			      ? val
			      : Buffer.from(val, encoding);
			    const len = bytes.length;
			    if (len === 0) {
			      throw new TypeError('The value "' + val +
			        '" is invalid for argument "value"')
			    }
			    for (i = 0; i < end - start; ++i) {
			      this[i + start] = bytes[i % len];
			    }
			  }

			  return this
			};

			// CUSTOM ERRORS
			// =============

			// Simplified versions from Node, changed for Buffer-only usage
			const errors = {};
			function E (sym, getMessage, Base) {
			  errors[sym] = class NodeError extends Base {
			    constructor () {
			      super();

			      Object.defineProperty(this, 'message', {
			        value: getMessage.apply(this, arguments),
			        writable: true,
			        configurable: true
			      });

			      // Add the error code to the name to include it in the stack trace.
			      this.name = `${this.name} [${sym}]`;
			      // Access the stack to generate the error message including the error code
			      // from the name.
			      this.stack; // eslint-disable-line no-unused-expressions
			      // Reset the name to the actual name.
			      delete this.name;
			    }

			    get code () {
			      return sym
			    }

			    set code (value) {
			      Object.defineProperty(this, 'code', {
			        configurable: true,
			        enumerable: true,
			        value,
			        writable: true
			      });
			    }

			    toString () {
			      return `${this.name} [${sym}]: ${this.message}`
			    }
			  };
			}

			E('ERR_BUFFER_OUT_OF_BOUNDS',
			  function (name) {
			    if (name) {
			      return `${name} is outside of buffer bounds`
			    }

			    return 'Attempt to access memory outside buffer bounds'
			  }, RangeError);
			E('ERR_INVALID_ARG_TYPE',
			  function (name, actual) {
			    return `The "${name}" argument must be of type number. Received type ${typeof actual}`
			  }, TypeError);
			E('ERR_OUT_OF_RANGE',
			  function (str, range, input) {
			    let msg = `The value of "${str}" is out of range.`;
			    let received = input;
			    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
			      received = addNumericalSeparator(String(input));
			    } else if (typeof input === 'bigint') {
			      received = String(input);
			      if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) {
			        received = addNumericalSeparator(received);
			      }
			      received += 'n';
			    }
			    msg += ` It must be ${range}. Received ${received}`;
			    return msg
			  }, RangeError);

			function addNumericalSeparator (val) {
			  let res = '';
			  let i = val.length;
			  const start = val[0] === '-' ? 1 : 0;
			  for (; i >= start + 4; i -= 3) {
			    res = `_${val.slice(i - 3, i)}${res}`;
			  }
			  return `${val.slice(0, i)}${res}`
			}

			// CHECK FUNCTIONS
			// ===============

			function checkBounds (buf, offset, byteLength) {
			  validateNumber(offset, 'offset');
			  if (buf[offset] === undefined || buf[offset + byteLength] === undefined) {
			    boundsError(offset, buf.length - (byteLength + 1));
			  }
			}

			function checkIntBI (value, min, max, buf, offset, byteLength) {
			  if (value > max || value < min) {
			    const n = typeof min === 'bigint' ? 'n' : '';
			    let range;
			    {
			      if (min === 0 || min === BigInt(0)) {
			        range = `>= 0${n} and < 2${n} ** ${(byteLength + 1) * 8}${n}`;
			      } else {
			        range = `>= -(2${n} ** ${(byteLength + 1) * 8 - 1}${n}) and < 2 ** ` +
			                `${(byteLength + 1) * 8 - 1}${n}`;
			      }
			    }
			    throw new errors.ERR_OUT_OF_RANGE('value', range, value)
			  }
			  checkBounds(buf, offset, byteLength);
			}

			function validateNumber (value, name) {
			  if (typeof value !== 'number') {
			    throw new errors.ERR_INVALID_ARG_TYPE(name, 'number', value)
			  }
			}

			function boundsError (value, length, type) {
			  if (Math.floor(value) !== value) {
			    validateNumber(value, type);
			    throw new errors.ERR_OUT_OF_RANGE('offset', 'an integer', value)
			  }

			  if (length < 0) {
			    throw new errors.ERR_BUFFER_OUT_OF_BOUNDS()
			  }

			  throw new errors.ERR_OUT_OF_RANGE('offset',
			                                    `>= ${0} and <= ${length}`,
			                                    value)
			}

			// HELPER FUNCTIONS
			// ================

			const INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g;

			function base64clean (str) {
			  // Node takes equal signs as end of the Base64 encoding
			  str = str.split('=')[0];
			  // Node strips out invalid characters like \n and \t from the string, base64-js does not
			  str = str.trim().replace(INVALID_BASE64_RE, '');
			  // Node converts strings with length < 2 to ''
			  if (str.length < 2) return ''
			  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
			  while (str.length % 4 !== 0) {
			    str = str + '=';
			  }
			  return str
			}

			function utf8ToBytes (string, units) {
			  units = units || Infinity;
			  let codePoint;
			  const length = string.length;
			  let leadSurrogate = null;
			  const bytes = [];

			  for (let i = 0; i < length; ++i) {
			    codePoint = string.charCodeAt(i);

			    // is surrogate component
			    if (codePoint > 0xD7FF && codePoint < 0xE000) {
			      // last char was a lead
			      if (!leadSurrogate) {
			        // no lead yet
			        if (codePoint > 0xDBFF) {
			          // unexpected trail
			          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
			          continue
			        } else if (i + 1 === length) {
			          // unpaired lead
			          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
			          continue
			        }

			        // valid lead
			        leadSurrogate = codePoint;

			        continue
			      }

			      // 2 leads in a row
			      if (codePoint < 0xDC00) {
			        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
			        leadSurrogate = codePoint;
			        continue
			      }

			      // valid surrogate pair
			      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000;
			    } else if (leadSurrogate) {
			      // valid bmp char, but last char was a lead
			      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
			    }

			    leadSurrogate = null;

			    // encode utf8
			    if (codePoint < 0x80) {
			      if ((units -= 1) < 0) break
			      bytes.push(codePoint);
			    } else if (codePoint < 0x800) {
			      if ((units -= 2) < 0) break
			      bytes.push(
			        codePoint >> 0x6 | 0xC0,
			        codePoint & 0x3F | 0x80
			      );
			    } else if (codePoint < 0x10000) {
			      if ((units -= 3) < 0) break
			      bytes.push(
			        codePoint >> 0xC | 0xE0,
			        codePoint >> 0x6 & 0x3F | 0x80,
			        codePoint & 0x3F | 0x80
			      );
			    } else if (codePoint < 0x110000) {
			      if ((units -= 4) < 0) break
			      bytes.push(
			        codePoint >> 0x12 | 0xF0,
			        codePoint >> 0xC & 0x3F | 0x80,
			        codePoint >> 0x6 & 0x3F | 0x80,
			        codePoint & 0x3F | 0x80
			      );
			    } else {
			      throw new Error('Invalid code point')
			    }
			  }

			  return bytes
			}

			function asciiToBytes (str) {
			  const byteArray = [];
			  for (let i = 0; i < str.length; ++i) {
			    // Node's code seems to be doing this and not & 0x7F..
			    byteArray.push(str.charCodeAt(i) & 0xFF);
			  }
			  return byteArray
			}

			function utf16leToBytes (str, units) {
			  let c, hi, lo;
			  const byteArray = [];
			  for (let i = 0; i < str.length; ++i) {
			    if ((units -= 2) < 0) break

			    c = str.charCodeAt(i);
			    hi = c >> 8;
			    lo = c % 256;
			    byteArray.push(lo);
			    byteArray.push(hi);
			  }

			  return byteArray
			}

			function base64ToBytes (str) {
			  return base64.toByteArray(base64clean(str))
			}

			function blitBuffer (src, dst, offset, length) {
			  let i;
			  for (i = 0; i < length; ++i) {
			    if ((i + offset >= dst.length) || (i >= src.length)) break
			    dst[i + offset] = src[i];
			  }
			  return i
			}

			// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
			// the `instanceof` check but they should be treated as of that type.
			// See: https://github.com/feross/buffer/issues/166
			function isInstance (obj, type) {
			  return obj instanceof type ||
			    (obj != null && obj.constructor != null && obj.constructor.name != null &&
			      obj.constructor.name === type.name)
			}
			function numberIsNaN (obj) {
			  // For IE11 support
			  return obj !== obj // eslint-disable-line no-self-compare
			}

			// Create lookup table for `toString('hex')`
			// See: https://github.com/feross/buffer/issues/219
			const hexSliceLookupTable = (function () {
			  const alphabet = '0123456789abcdef';
			  const table = new Array(256);
			  for (let i = 0; i < 16; ++i) {
			    const i16 = i * 16;
			    for (let j = 0; j < 16; ++j) {
			      table[i16 + j] = alphabet[i] + alphabet[j];
			    }
			  }
			  return table
			})();

			// Return not function with Error if BigInt not supported
			function defineBigIntMethod (fn) {
			  return typeof BigInt === 'undefined' ? BufferBigIntNotDefined : fn
			}

			function BufferBigIntNotDefined () {
			  throw new Error('BigInt not supported')
			} 
		} (buffer));
		return buffer;
	}

	var bufferExports = requireBuffer();

	const RDF  = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',
	    XSD  = 'http://www.w3.org/2001/XMLSchema#',
	    SWAP = 'http://www.w3.org/2000/10/swap/';

	var namespaces = {
	  xsd: {
	    decimal: `${XSD}decimal`,
	    boolean: `${XSD}boolean`,
	    double:  `${XSD}double`,
	    integer: `${XSD}integer`,
	    string:  `${XSD}string`,
	  },
	  rdf: {
	    type:       `${RDF}type`,
	    nil:        `${RDF}nil`,
	    first:      `${RDF}first`,
	    rest:       `${RDF}rest`,
	    langString: `${RDF}langString`,
	  },
	  owl: {
	    sameAs: 'http://www.w3.org/2002/07/owl#sameAs',
	  },
	  r: {
	    forSome: `${SWAP}reify#forSome`,
	    forAll:  `${SWAP}reify#forAll`,
	  },
	  log: {
	    implies: `${SWAP}log#implies`,
	    isImpliedBy: `${SWAP}log#isImpliedBy`,
	  },
	};

	// **N3Lexer** tokenizes N3 documents.

	const { xsd: xsd$2 } = namespaces;

	// Regular expression and replacement string to escape N3 strings
	const escapeSequence = /\\u([a-fA-F0-9]{4})|\\U([a-fA-F0-9]{8})|\\([^])/g;
	const escapeReplacements = {
	  '\\': '\\', "'": "'", '"': '"',
	  'n': '\n', 'r': '\r', 't': '\t', 'f': '\f', 'b': '\b',
	  '_': '_', '~': '~', '.': '.', '-': '-', '!': '!', '$': '$', '&': '&',
	  '(': '(', ')': ')', '*': '*', '+': '+', ',': ',', ';': ';', '=': '=',
	  '/': '/', '?': '?', '#': '#', '@': '@', '%': '%',
	};
	const illegalIriChars = /[\x00-\x20<>\\"\{\}\|\^\`]/;

	const lineModeRegExps = {
	  _iri: true,
	  _unescapedIri: true,
	  _simpleQuotedString: true,
	  _langcode: true,
	  _blank: true,
	  _newline: true,
	  _comment: true,
	  _whitespace: true,
	  _endOfFile: true,
	};
	const invalidRegExp = /$0^/;

	// ## Constructor
	class N3Lexer {
	  constructor(options) {
	    // ## Regular expressions
	    // It's slightly faster to have these as properties than as in-scope variables
	    this._iri = /^<((?:[^ <>{}\\]|\\[uU])+)>[ \t]*/; // IRI with escape sequences; needs sanity check after unescaping
	    this._unescapedIri = /^<([^\x00-\x20<>\\"\{\}\|\^\`]*)>[ \t]*/; // IRI without escape sequences; no unescaping
	    this._simpleQuotedString = /^"([^"\\\r\n]*)"(?=[^"])/; // string without escape sequences
	    this._simpleApostropheString = /^'([^'\\\r\n]*)'(?=[^'])/;
	    this._langcode = /^@([a-z]+(?:-[a-z0-9]+)*)(?=[^a-z0-9\-])/i;
	    this._prefix = /^((?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)?:(?=[#\s<])/;
	    this._prefixed = /^((?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)?:((?:(?:[0-:A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~])(?:(?:[\.\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~])*(?:[\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~]))?)?)(?:[ \t]+|(?=\.?[,;!\^\s#()\[\]\{\}"'<>]))/;
	    this._variable = /^\?(?:(?:[A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:[\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)(?=[.,;!\^\s#()\[\]\{\}"'<>])/;
	    this._blank = /^_:((?:[0-9A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)(?:[ \t]+|(?=\.?[,;:\s#()\[\]\{\}"'<>]))/;
	    this._number = /^[\-+]?(?:(\d+\.\d*|\.?\d+)[eE][\-+]?|\d*(\.)?)\d+(?=\.?[,;:\s#()\[\]\{\}"'<>])/;
	    this._boolean = /^(?:true|false)(?=[.,;\s#()\[\]\{\}"'<>])/;
	    this._keyword = /^@[a-z]+(?=[\s#<:])/i;
	    this._sparqlKeyword = /^(?:PREFIX|BASE|GRAPH)(?=[\s#<])/i;
	    this._shortPredicates = /^a(?=[\s#()\[\]\{\}"'<>])/;
	    this._newline = /^[ \t]*(?:#[^\n\r]*)?(?:\r\n|\n|\r)[ \t]*/;
	    this._comment = /#([^\n\r]*)/;
	    this._whitespace = /^[ \t]+/;
	    this._endOfFile = /^(?:#[^\n\r]*)?$/;
	    options = options || {};

	    // Whether the log:isImpliedBy predicate is supported
	    this._isImpliedBy = options.isImpliedBy;

	    // In line mode (N-Triples or N-Quads), only simple features may be parsed
	    if (this._lineMode = !!options.lineMode) {
	      this._n3Mode = false;
	      // Don't tokenize special literals
	      for (const key in this) {
	        if (!(key in lineModeRegExps) && this[key] instanceof RegExp)
	          this[key] = invalidRegExp;
	      }
	    }
	    // When not in line mode, enable N3 functionality by default
	    else {
	      this._n3Mode = options.n3 !== false;
	    }
	    // Don't output comment tokens by default
	    this.comments = !!options.comments;
	    // Cache the last tested closing position of long literals
	    this._literalClosingPos = 0;
	  }

	  // ## Private methods

	  // ### `_tokenizeToEnd` tokenizes as for as possible, emitting tokens through the callback
	  _tokenizeToEnd(callback, inputFinished) {
	    // Continue parsing as far as possible; the loop will return eventually
	    let input = this._input;
	    let currentLineLength = input.length;
	    while (true) {
	      // Count and skip whitespace lines
	      let whiteSpaceMatch, comment;
	      while (whiteSpaceMatch = this._newline.exec(input)) {
	        // Try to find a comment
	        if (this.comments && (comment = this._comment.exec(whiteSpaceMatch[0])))
	          emitToken('comment', comment[1], '', this._line, whiteSpaceMatch[0].length);
	        // Advance the input
	        input = input.substr(whiteSpaceMatch[0].length, input.length);
	        currentLineLength = input.length;
	        this._line++;
	      }
	      // Skip whitespace on current line
	      if (!whiteSpaceMatch && (whiteSpaceMatch = this._whitespace.exec(input)))
	        input = input.substr(whiteSpaceMatch[0].length, input.length);

	      // Stop for now if we're at the end
	      if (this._endOfFile.test(input)) {
	        // If the input is finished, emit EOF
	        if (inputFinished) {
	          // Try to find a final comment
	          if (this.comments && (comment = this._comment.exec(input)))
	            emitToken('comment', comment[1], '', this._line, input.length);
	          input = null;
	          emitToken('eof', '', '', this._line, 0);
	        }
	        return this._input = input;
	      }

	      // Look for specific token types based on the first character
	      const line = this._line, firstChar = input[0];
	      let type = '', value = '', prefix = '',
	          match = null, matchLength = 0, inconclusive = false;
	      switch (firstChar) {
	      case '^':
	        // We need at least 3 tokens lookahead to distinguish ^^<IRI> and ^^pre:fixed
	        if (input.length < 3)
	          break;
	        // Try to match a type
	        else if (input[1] === '^') {
	          this._previousMarker = '^^';
	          // Move to type IRI or prefixed name
	          input = input.substr(2);
	          if (input[0] !== '<') {
	            inconclusive = true;
	            break;
	          }
	        }
	        // If no type, it must be a path expression
	        else {
	          if (this._n3Mode) {
	            matchLength = 1;
	            type = '^';
	          }
	          break;
	        }
	        // Fall through in case the type is an IRI
	      case '<':
	        // Try to find a full IRI without escape sequences
	        if (match = this._unescapedIri.exec(input))
	          type = 'IRI', value = match[1];
	        // Try to find a full IRI with escape sequences
	        else if (match = this._iri.exec(input)) {
	          value = this._unescape(match[1]);
	          if (value === null || illegalIriChars.test(value))
	            return reportSyntaxError(this);
	          type = 'IRI';
	        }
	        // Try to find a nested triple
	        else if (input.length > 1 && input[1] === '<')
	          type = '<<', matchLength = 2;
	        // Try to find a backwards implication arrow
	        else if (this._n3Mode && input.length > 1 && input[1] === '=') {
	          matchLength = 2;
	          if (this._isImpliedBy) type = 'abbreviation', value = '<';
	          else type = 'inverse', value = '>';
	        }
	        break;

	      case '>':
	        if (input.length > 1 && input[1] === '>')
	          type = '>>', matchLength = 2;
	        break;

	      case '_':
	        // Try to find a blank node. Since it can contain (but not end with) a dot,
	        // we always need a non-dot character before deciding it is a blank node.
	        // Therefore, try inserting a space if we're at the end of the input.
	        if ((match = this._blank.exec(input)) ||
	            inputFinished && (match = this._blank.exec(`${input} `)))
	          type = 'blank', prefix = '_', value = match[1];
	        break;

	      case '"':
	        // Try to find a literal without escape sequences
	        if (match = this._simpleQuotedString.exec(input))
	          value = match[1];
	        // Try to find a literal wrapped in three pairs of quotes
	        else {
	          ({ value, matchLength } = this._parseLiteral(input));
	          if (value === null)
	            return reportSyntaxError(this);
	        }
	        if (match !== null || matchLength !== 0) {
	          type = 'literal';
	          this._literalClosingPos = 0;
	        }
	        break;

	      case "'":
	        if (!this._lineMode) {
	          // Try to find a literal without escape sequences
	          if (match = this._simpleApostropheString.exec(input))
	            value = match[1];
	          // Try to find a literal wrapped in three pairs of quotes
	          else {
	            ({ value, matchLength } = this._parseLiteral(input));
	            if (value === null)
	              return reportSyntaxError(this);
	          }
	          if (match !== null || matchLength !== 0) {
	            type = 'literal';
	            this._literalClosingPos = 0;
	          }
	        }
	        break;

	      case '?':
	        // Try to find a variable
	        if (this._n3Mode && (match = this._variable.exec(input)))
	          type = 'var', value = match[0];
	        break;

	      case '@':
	        // Try to find a language code
	        if (this._previousMarker === 'literal' && (match = this._langcode.exec(input)))
	          type = 'langcode', value = match[1];
	        // Try to find a keyword
	        else if (match = this._keyword.exec(input))
	          type = match[0];
	        break;

	      case '.':
	        // Try to find a dot as punctuation
	        if (input.length === 1 ? inputFinished : (input[1] < '0' || input[1] > '9')) {
	          type = '.';
	          matchLength = 1;
	          break;
	        }
	        // Fall through to numerical case (could be a decimal dot)

	      case '0':
	      case '1':
	      case '2':
	      case '3':
	      case '4':
	      case '5':
	      case '6':
	      case '7':
	      case '8':
	      case '9':
	      case '+':
	      case '-':
	        // Try to find a number. Since it can contain (but not end with) a dot,
	        // we always need a non-dot character before deciding it is a number.
	        // Therefore, try inserting a space if we're at the end of the input.
	        if (match = this._number.exec(input) ||
	            inputFinished && (match = this._number.exec(`${input} `))) {
	          type = 'literal', value = match[0];
	          prefix = (typeof match[1] === 'string' ? xsd$2.double :
	                    (typeof match[2] === 'string' ? xsd$2.decimal : xsd$2.integer));
	        }
	        break;

	      case 'B':
	      case 'b':
	      case 'p':
	      case 'P':
	      case 'G':
	      case 'g':
	        // Try to find a SPARQL-style keyword
	        if (match = this._sparqlKeyword.exec(input))
	          type = match[0].toUpperCase();
	        else
	          inconclusive = true;
	        break;

	      case 'f':
	      case 't':
	        // Try to match a boolean
	        if (match = this._boolean.exec(input))
	          type = 'literal', value = match[0], prefix = xsd$2.boolean;
	        else
	          inconclusive = true;
	        break;

	      case 'a':
	        // Try to find an abbreviated predicate
	        if (match = this._shortPredicates.exec(input))
	          type = 'abbreviation', value = 'a';
	        else
	          inconclusive = true;
	        break;

	      case '=':
	        // Try to find an implication arrow or equals sign
	        if (this._n3Mode && input.length > 1) {
	          type = 'abbreviation';
	          if (input[1] !== '>')
	            matchLength = 1, value = '=';
	          else
	            matchLength = 2, value = '>';
	        }
	        break;

	      case '!':
	        if (!this._n3Mode)
	          break;
	      case ',':
	      case ';':
	      case '[':
	      case ']':
	      case '(':
	      case ')':
	      case '}':
	        if (!this._lineMode) {
	          matchLength = 1;
	          type = firstChar;
	        }
	        break;
	      case '{':
	        // We need at least 2 tokens lookahead to distinguish "{|" and "{ "
	        if (!this._lineMode && input.length >= 2) {
	          // Try to find a quoted triple annotation start
	          if (input[1] === '|')
	            type = '{|', matchLength = 2;
	          else
	            type = firstChar, matchLength = 1;
	        }
	        break;
	      case '|':
	        // We need 2 tokens lookahead to parse "|}"
	        // Try to find a quoted triple annotation end
	        if (input.length >= 2 && input[1] === '}')
	          type = '|}', matchLength = 2;
	        break;

	      default:
	        inconclusive = true;
	      }

	      // Some first characters do not allow an immediate decision, so inspect more
	      if (inconclusive) {
	        // Try to find a prefix
	        if ((this._previousMarker === '@prefix' || this._previousMarker === 'PREFIX') &&
	            (match = this._prefix.exec(input)))
	          type = 'prefix', value = match[1] || '';
	        // Try to find a prefixed name. Since it can contain (but not end with) a dot,
	        // we always need a non-dot character before deciding it is a prefixed name.
	        // Therefore, try inserting a space if we're at the end of the input.
	        else if ((match = this._prefixed.exec(input)) ||
	                 inputFinished && (match = this._prefixed.exec(`${input} `)))
	          type = 'prefixed', prefix = match[1] || '', value = this._unescape(match[2]);
	      }

	      // A type token is special: it can only be emitted after an IRI or prefixed name is read
	      if (this._previousMarker === '^^') {
	        switch (type) {
	        case 'prefixed': type = 'type';    break;
	        case 'IRI':      type = 'typeIRI'; break;
	        default:         type = '';
	        }
	      }

	      // What if nothing of the above was found?
	      if (!type) {
	        // We could be in streaming mode, and then we just wait for more input to arrive.
	        // Otherwise, a syntax error has occurred in the input.
	        // One exception: error on an unaccounted linebreak (= not inside a triple-quoted literal).
	        if (inputFinished || (!/^'''|^"""/.test(input) && /\n|\r/.test(input)))
	          return reportSyntaxError(this);
	        else
	          return this._input = input;
	      }

	      // Emit the parsed token
	      const length = matchLength || match[0].length;
	      const token = emitToken(type, value, prefix, line, length);
	      this.previousToken = token;
	      this._previousMarker = type;

	      // Advance to next part to tokenize
	      input = input.substr(length, input.length);
	    }

	    // Emits the token through the callback
	    function emitToken(type, value, prefix, line, length) {
	      const start = input ? currentLineLength - input.length : currentLineLength;
	      const end = start + length;
	      const token = { type, value, prefix, line, start, end };
	      callback(null, token);
	      return token;
	    }
	    // Signals the syntax error through the callback
	    function reportSyntaxError(self) { callback(self._syntaxError(/^\S*/.exec(input)[0])); }
	  }

	  // ### `_unescape` replaces N3 escape codes by their corresponding characters
	  _unescape(item) {
	    let invalid = false;
	    const replaced = item.replace(escapeSequence, (sequence, unicode4, unicode8, escapedChar) => {
	      // 4-digit unicode character
	      if (typeof unicode4 === 'string')
	        return String.fromCharCode(Number.parseInt(unicode4, 16));
	      // 8-digit unicode character
	      if (typeof unicode8 === 'string') {
	        let charCode = Number.parseInt(unicode8, 16);
	        return charCode <= 0xFFFF ? String.fromCharCode(Number.parseInt(unicode8, 16)) :
	          String.fromCharCode(0xD800 + ((charCode -= 0x10000) >> 10), 0xDC00 + (charCode & 0x3FF));
	      }
	      // fixed escape sequence
	      if (escapedChar in escapeReplacements)
	        return escapeReplacements[escapedChar];
	      // invalid escape sequence
	      invalid = true;
	      return '';
	    });
	    return invalid ? null : replaced;
	  }

	  // ### `_parseLiteral` parses a literal into an unescaped value
	  _parseLiteral(input) {
	    // Ensure we have enough lookahead to identify triple-quoted strings
	    if (input.length >= 3) {
	      // Identify the opening quote(s)
	      const opening = input.match(/^(?:"""|"|'''|'|)/)[0];
	      const openingLength = opening.length;

	      // Find the next candidate closing quotes
	      let closingPos = Math.max(this._literalClosingPos, openingLength);
	      while ((closingPos = input.indexOf(opening, closingPos)) > 0) {
	        // Count backslashes right before the closing quotes
	        let backslashCount = 0;
	        while (input[closingPos - backslashCount - 1] === '\\')
	          backslashCount++;

	        // An even number of backslashes (in particular 0)
	        // means these are actual, non-escaped closing quotes
	        if (backslashCount % 2 === 0) {
	          // Extract and unescape the value
	          const raw = input.substring(openingLength, closingPos);
	          const lines = raw.split(/\r\n|\r|\n/).length - 1;
	          const matchLength = closingPos + openingLength;
	          // Only triple-quoted strings can be multi-line
	          if (openingLength === 1 && lines !== 0 ||
	              openingLength === 3 && this._lineMode)
	            break;
	          this._line += lines;
	          return { value: this._unescape(raw), matchLength };
	        }
	        closingPos++;
	      }
	      this._literalClosingPos = input.length - openingLength + 1;
	    }
	    return { value: '', matchLength: 0 };
	  }

	  // ### `_syntaxError` creates a syntax error for the given issue
	  _syntaxError(issue) {
	    this._input = null;
	    const err = new Error(`Unexpected "${issue}" on line ${this._line}.`);
	    err.context = {
	      token: undefined,
	      line: this._line,
	      previousToken: this.previousToken,
	    };
	    return err;
	  }

	  // ### Strips off any starting UTF BOM mark.
	  _readStartingBom(input) {
	    return input.startsWith('\ufeff') ? input.substr(1) : input;
	  }

	  // ## Public methods

	  // ### `tokenize` starts the transformation of an N3 document into an array of tokens.
	  // The input can be a string or a stream.
	  tokenize(input, callback) {
	    this._line = 1;

	    // If the input is a string, continuously emit tokens through the callback until the end
	    if (typeof input === 'string') {
	      this._input = this._readStartingBom(input);
	      // If a callback was passed, asynchronously call it
	      if (typeof callback === 'function')
	        queueMicrotask(() => this._tokenizeToEnd(callback, true));
	      // If no callback was passed, tokenize synchronously and return
	      else {
	        const tokens = [];
	        let error;
	        this._tokenizeToEnd((e, t) => e ? (error = e) : tokens.push(t), true);
	        if (error) throw error;
	        return tokens;
	      }
	    }
	    // Otherwise, the input must be a stream
	    else {
	      this._pendingBuffer = null;
	      if (typeof input.setEncoding === 'function')
	        input.setEncoding('utf8');
	      // Adds the data chunk to the buffer and parses as far as possible
	      input.on('data', data => {
	        if (this._input !== null && data.length !== 0) {
	          // Prepend any previous pending writes
	          if (this._pendingBuffer) {
	            data = bufferExports.Buffer.concat([this._pendingBuffer, data]);
	            this._pendingBuffer = null;
	          }
	          // Hold if the buffer ends in an incomplete unicode sequence
	          if (data[data.length - 1] & 0x80) {
	            this._pendingBuffer = data;
	          }
	          // Otherwise, tokenize as far as possible
	          else {
	            // Only read a BOM at the start
	            if (typeof this._input === 'undefined')
	              this._input = this._readStartingBom(typeof data === 'string' ? data : data.toString());
	            else
	              this._input += data;
	            this._tokenizeToEnd(callback, false);
	          }
	        }
	      });
	      // Parses until the end
	      input.on('end', () => {
	        if (typeof this._input === 'string')
	          this._tokenizeToEnd(callback, true);
	      });
	      input.on('error', callback);
	    }
	  }
	}

	// N3.js implementations of the RDF/JS core data types
	// See http://rdf.js.org/data-model-spec/


	const { rdf: rdf$1, xsd: xsd$1 } = namespaces;

	// eslint-disable-next-line prefer-const
	let DEFAULTGRAPH$1;
	let _blankNodeCounter = 0;

	// ## DataFactory singleton
	const DataFactory = {
	  namedNode: namedNode$1,
	  blankNode: blankNode$1,
	  variable,
	  literal: literal$1,
	  defaultGraph,
	  quad: quad$1,
	  triple: quad$1,
	  fromTerm,
	  fromQuad,
	};

	// ## Term constructor
	class Term {
	  constructor(id) {
	    this.id = id;
	  }

	  // ### The value of this term
	  get value() {
	    return this.id;
	  }

	  // ### Returns whether this object represents the same term as the other
	  equals(other) {
	    // If both terms were created by this library,
	    // equality can be computed through ids
	    if (other instanceof Term)
	      return this.id === other.id;
	    // Otherwise, compare term type and value
	    return !!other && this.termType === other.termType &&
	                      this.value    === other.value;
	  }

	  // ### Implement hashCode for Immutable.js, since we implement `equals`
	  // https://immutable-js.com/docs/v4.0.0/ValueObject/#hashCode()
	  hashCode() {
	    return 0;
	  }

	  // ### Returns a plain object representation of this term
	  toJSON() {
	    return {
	      termType: this.termType,
	      value:    this.value,
	    };
	  }
	}


	// ## NamedNode constructor
	class NamedNode extends Term {
	  // ### The term type of this term
	  get termType() {
	    return 'NamedNode';
	  }
	}

	// ## Literal constructor
	class Literal extends Term {
	  // ### The term type of this term
	  get termType() {
	    return 'Literal';
	  }

	  // ### The text value of this literal
	  get value() {
	    return this.id.substring(1, this.id.lastIndexOf('"'));
	  }

	  // ### The language of this literal
	  get language() {
	    // Find the last quotation mark (e.g., '"abc"@en-us')
	    const id = this.id;
	    let atPos = id.lastIndexOf('"') + 1;
	    // If "@" it follows, return the remaining substring; empty otherwise
	    return atPos < id.length && id[atPos++] === '@' ? id.substr(atPos).toLowerCase() : '';
	  }

	  // ### The datatype IRI of this literal
	  get datatype() {
	    return new NamedNode(this.datatypeString);
	  }

	  // ### The datatype string of this literal
	  get datatypeString() {
	    // Find the last quotation mark (e.g., '"abc"^^http://ex.org/types#t')
	    const id = this.id, dtPos = id.lastIndexOf('"') + 1;
	    const char = dtPos < id.length ? id[dtPos] : '';
	    // If "^" it follows, return the remaining substring
	    return char === '^' ? id.substr(dtPos + 2) :
	           // If "@" follows, return rdf:langString; xsd:string otherwise
	           (char !== '@' ? xsd$1.string : rdf$1.langString);
	  }

	  // ### Returns whether this object represents the same term as the other
	  equals(other) {
	    // If both literals were created by this library,
	    // equality can be computed through ids
	    if (other instanceof Literal)
	      return this.id === other.id;
	    // Otherwise, compare term type, value, language, and datatype
	    return !!other && !!other.datatype &&
	                      this.termType === other.termType &&
	                      this.value    === other.value    &&
	                      this.language === other.language &&
	                      this.datatype.value === other.datatype.value;
	  }

	  toJSON() {
	    return {
	      termType: this.termType,
	      value:    this.value,
	      language: this.language,
	      datatype: { termType: 'NamedNode', value: this.datatypeString },
	    };
	  }
	}

	// ## BlankNode constructor
	class BlankNode extends Term {
	  constructor(name) {
	    super(`_:${name}`);
	  }

	  // ### The term type of this term
	  get termType() {
	    return 'BlankNode';
	  }

	  // ### The name of this blank node
	  get value() {
	    return this.id.substr(2);
	  }
	}

	class Variable extends Term {
	  constructor(name) {
	    super(`?${name}`);
	  }

	  // ### The term type of this term
	  get termType() {
	    return 'Variable';
	  }

	  // ### The name of this variable
	  get value() {
	    return this.id.substr(1);
	  }
	}

	// ## DefaultGraph constructor
	class DefaultGraph extends Term {
	  constructor() {
	    super('');
	    return DEFAULTGRAPH$1 || this;
	  }

	  // ### The term type of this term
	  get termType() {
	    return 'DefaultGraph';
	  }

	  // ### Returns whether this object represents the same term as the other
	  equals(other) {
	    // If both terms were created by this library,
	    // equality can be computed through strict equality;
	    // otherwise, compare term types.
	    return (this === other) || (!!other && (this.termType === other.termType));
	  }
	}

	// ## DefaultGraph singleton
	DEFAULTGRAPH$1 = new DefaultGraph();

	// ### Constructs a term from the given internal string ID
	// The third 'nested' parameter of this function is to aid
	// with recursion over nested terms. It should not be used
	// by consumers of this library.
	// See https://github.com/rdfjs/N3.js/pull/311#discussion_r1061042725
	function termFromId(id, factory, nested) {
	  factory = factory || DataFactory;

	  // Falsy value or empty string indicate the default graph
	  if (!id)
	    return factory.defaultGraph();

	  // Identify the term type based on the first character
	  switch (id[0]) {
	  case '?':
	    return factory.variable(id.substr(1));
	  case '_':
	    return factory.blankNode(id.substr(2));
	  case '"':
	    // Shortcut for internal literals
	    if (factory === DataFactory)
	      return new Literal(id);
	    // Literal without datatype or language
	    if (id[id.length - 1] === '"')
	      return factory.literal(id.substr(1, id.length - 2));
	    // Literal with datatype or language
	    const endPos = id.lastIndexOf('"', id.length - 1);
	    return factory.literal(id.substr(1, endPos - 1),
	            id[endPos + 1] === '@' ? id.substr(endPos + 2)
	                                   : factory.namedNode(id.substr(endPos + 3)));
	  case '[':
	    id = JSON.parse(id);
	    break;
	  default:
	    if (!nested || !Array.isArray(id)) {
	      return factory.namedNode(id);
	    }
	  }
	  return factory.quad(
	    termFromId(id[0], factory, true),
	    termFromId(id[1], factory, true),
	    termFromId(id[2], factory, true),
	    id[3] && termFromId(id[3], factory, true),
	  );
	}

	// ### Constructs an internal string ID from the given term or ID string
	// The third 'nested' parameter of this function is to aid
	// with recursion over nested terms. It should not be used
	// by consumers of this library.
	// See https://github.com/rdfjs/N3.js/pull/311#discussion_r1061042725
	function termToId(term, nested) {
	  if (typeof term === 'string')
	    return term;
	  if (term instanceof Term && term.termType !== 'Quad')
	    return term.id;
	  if (!term)
	    return DEFAULTGRAPH$1.id;

	  // Term instantiated with another library
	  switch (term.termType) {
	  case 'NamedNode':    return term.value;
	  case 'BlankNode':    return `_:${term.value}`;
	  case 'Variable':     return `?${term.value}`;
	  case 'DefaultGraph': return '';
	  case 'Literal':      return `"${term.value}"${
    term.language ? `@${term.language}` :
      (term.datatype && term.datatype.value !== xsd$1.string ? `^^${term.datatype.value}` : '')}`;
	  case 'Quad':
	    const res = [
	      termToId(term.subject, true),
	      termToId(term.predicate, true),
	      termToId(term.object, true),
	    ];
	    if (term.graph && term.graph.termType !== 'DefaultGraph') {
	      res.push(termToId(term.graph, true));
	    }
	    return nested ? res : JSON.stringify(res);
	  default: throw new Error(`Unexpected termType: ${term.termType}`);
	  }
	}


	// ## Quad constructor
	class Quad extends Term {
	  constructor(subject, predicate, object, graph) {
	    super('');
	    this._subject   = subject;
	    this._predicate = predicate;
	    this._object    = object;
	    this._graph     = graph || DEFAULTGRAPH$1;
	  }

	  // ### The term type of this term
	  get termType() {
	    return 'Quad';
	  }

	  get subject() {
	    return this._subject;
	  }

	  get predicate() {
	    return this._predicate;
	  }

	  get object() {
	    return this._object;
	  }

	  get graph() {
	    return this._graph;
	  }

	  // ### Returns a plain object representation of this quad
	  toJSON() {
	    return {
	      termType:  this.termType,
	      subject:   this._subject.toJSON(),
	      predicate: this._predicate.toJSON(),
	      object:    this._object.toJSON(),
	      graph:     this._graph.toJSON(),
	    };
	  }

	  // ### Returns whether this object represents the same quad as the other
	  equals(other) {
	    return !!other && this._subject.equals(other.subject)     &&
	                      this._predicate.equals(other.predicate) &&
	                      this._object.equals(other.object)       &&
	                      this._graph.equals(other.graph);
	  }
	}

	// ### Creates an IRI
	function namedNode$1(iri) {
	  return new NamedNode(iri);
	}

	// ### Creates a blank node
	function blankNode$1(name) {
	  return new BlankNode(name || `n3-${_blankNodeCounter++}`);
	}

	// ### Creates a literal
	function literal$1(value, languageOrDataType) {
	  // Create a language-tagged string
	  if (typeof languageOrDataType === 'string')
	    return new Literal(`"${value}"@${languageOrDataType.toLowerCase()}`);

	  // Automatically determine datatype for booleans and numbers
	  let datatype = languageOrDataType ? languageOrDataType.value : '';
	  if (datatype === '') {
	    // Convert a boolean
	    if (typeof value === 'boolean')
	      datatype = xsd$1.boolean;
	    // Convert an integer or double
	    else if (typeof value === 'number') {
	      if (Number.isFinite(value))
	        datatype = Number.isInteger(value) ? xsd$1.integer : xsd$1.double;
	      else {
	        datatype = xsd$1.double;
	        if (!Number.isNaN(value))
	          value = value > 0 ? 'INF' : '-INF';
	      }
	    }
	  }

	  // Create a datatyped literal
	  return (datatype === '' || datatype === xsd$1.string) ?
	    new Literal(`"${value}"`) :
	    new Literal(`"${value}"^^${datatype}`);
	}

	// ### Creates a variable
	function variable(name) {
	  return new Variable(name);
	}

	// ### Returns the default graph
	function defaultGraph() {
	  return DEFAULTGRAPH$1;
	}

	// ### Creates a quad
	function quad$1(subject, predicate, object, graph) {
	  return new Quad(subject, predicate, object, graph);
	}

	function fromTerm(term) {
	  if (term instanceof Term)
	    return term;

	  // Term instantiated with another library
	  switch (term.termType) {
	  case 'NamedNode':    return namedNode$1(term.value);
	  case 'BlankNode':    return blankNode$1(term.value);
	  case 'Variable':     return variable(term.value);
	  case 'DefaultGraph': return DEFAULTGRAPH$1;
	  case 'Literal':      return literal$1(term.value, term.language || term.datatype);
	  case 'Quad':         return fromQuad(term);
	  default:             throw new Error(`Unexpected termType: ${term.termType}`);
	  }
	}

	function fromQuad(inQuad) {
	  if (inQuad instanceof Quad)
	    return inQuad;

	  if (inQuad.termType !== 'Quad')
	    throw new Error(`Unexpected termType: ${inQuad.termType}`);

	  return quad$1(fromTerm(inQuad.subject), fromTerm(inQuad.predicate), fromTerm(inQuad.object), fromTerm(inQuad.graph));
	}

	// **N3Parser** parses N3 documents.

	let blankNodePrefix = 0;

	// ## Constructor
	class N3Parser {
	  constructor(options) {
	    this._contextStack = [];
	    this._graph = null;

	    // Set the document IRI
	    options = options || {};
	    this._setBase(options.baseIRI);
	    options.factory && initDataFactory(this, options.factory);

	    // Set supported features depending on the format
	    const format = (typeof options.format === 'string') ?
	                 options.format.match(/\w*$/)[0].toLowerCase() : '',
	        isTurtle = /turtle/.test(format), isTriG = /trig/.test(format),
	        isNTriples = /triple/.test(format), isNQuads = /quad/.test(format),
	        isN3 = this._n3Mode = /n3/.test(format),
	        isLineMode = isNTriples || isNQuads;
	    if (!(this._supportsNamedGraphs = !(isTurtle || isN3)))
	      this._readPredicateOrNamedGraph = this._readPredicate;
	    // Support triples in other graphs
	    this._supportsQuads = !(isTurtle || isTriG || isNTriples || isN3);
	    // Whether the log:isImpliedBy predicate is supported
	    this._isImpliedBy = options.isImpliedBy;
	    // Support nesting of triples
	    this._supportsRDFStar = format === '' || /star|\*$/.test(format);
	    // Disable relative IRIs in N-Triples or N-Quads mode
	    if (isLineMode)
	      this._resolveRelativeIRI = iri => { return null; };
	    this._blankNodePrefix = typeof options.blankNodePrefix !== 'string' ? '' :
	                              options.blankNodePrefix.replace(/^(?!_:)/, '_:');
	    this._lexer = options.lexer || new N3Lexer({ lineMode: isLineMode, n3: isN3, isImpliedBy: this._isImpliedBy });
	    // Disable explicit quantifiers by default
	    this._explicitQuantifiers = !!options.explicitQuantifiers;
	  }

	  // ## Static class methods

	  // ### `_resetBlankNodePrefix` restarts blank node prefix identification
	  static _resetBlankNodePrefix() {
	    blankNodePrefix = 0;
	  }

	  // ## Private methods

	  // ### `_setBase` sets the base IRI to resolve relative IRIs
	  _setBase(baseIRI) {
	    if (!baseIRI) {
	      this._base = '';
	      this._basePath = '';
	    }
	    else {
	      // Remove fragment if present
	      const fragmentPos = baseIRI.indexOf('#');
	      if (fragmentPos >= 0)
	        baseIRI = baseIRI.substr(0, fragmentPos);
	      // Set base IRI and its components
	      this._base = baseIRI;
	      this._basePath   = baseIRI.indexOf('/') < 0 ? baseIRI :
	                         baseIRI.replace(/[^\/?]*(?:\?.*)?$/, '');
	      baseIRI = baseIRI.match(/^(?:([a-z][a-z0-9+.-]*:))?(?:\/\/[^\/]*)?/i);
	      this._baseRoot   = baseIRI[0];
	      this._baseScheme = baseIRI[1];
	    }
	  }

	  // ### `_saveContext` stores the current parsing context
	  // when entering a new scope (list, blank node, formula)
	  _saveContext(type, graph, subject, predicate, object) {
	    const n3Mode = this._n3Mode;
	    this._contextStack.push({
	      type,
	      subject, predicate, object, graph,
	      inverse: n3Mode ? this._inversePredicate : false,
	      blankPrefix: n3Mode ? this._prefixes._ : '',
	      quantified: n3Mode ? this._quantified : null,
	    });
	    // The settings below only apply to N3 streams
	    if (n3Mode) {
	      // Every new scope resets the predicate direction
	      this._inversePredicate = false;
	      // In N3, blank nodes are scoped to a formula
	      // (using a dot as separator, as a blank node label cannot start with it)
	      this._prefixes._ = (this._graph ? `${this._graph.value}.` : '.');
	      // Quantifiers are scoped to a formula
	      this._quantified = Object.create(this._quantified);
	    }
	  }

	  // ### `_restoreContext` restores the parent context
	  // when leaving a scope (list, blank node, formula)
	  _restoreContext(type, token) {
	    // Obtain the previous context
	    const context = this._contextStack.pop();
	    if (!context || context.type !== type)
	      return this._error(`Unexpected ${token.type}`, token);

	    // Restore the quad of the previous context
	    this._subject   = context.subject;
	    this._predicate = context.predicate;
	    this._object    = context.object;
	    this._graph     = context.graph;

	    // Restore N3 context settings
	    if (this._n3Mode) {
	      this._inversePredicate = context.inverse;
	      this._prefixes._ = context.blankPrefix;
	      this._quantified = context.quantified;
	    }
	  }

	  // ### `_readInTopContext` reads a token when in the top context
	  _readInTopContext(token) {
	    switch (token.type) {
	    // If an EOF token arrives in the top context, signal that we're done
	    case 'eof':
	      if (this._graph !== null)
	        return this._error('Unclosed graph', token);
	      delete this._prefixes._;
	      return this._callback(null, null, this._prefixes);
	    // It could be a prefix declaration
	    case 'PREFIX':
	      this._sparqlStyle = true;
	    case '@prefix':
	      return this._readPrefix;
	    // It could be a base declaration
	    case 'BASE':
	      this._sparqlStyle = true;
	    case '@base':
	      return this._readBaseIRI;
	    // It could be a graph
	    case '{':
	      if (this._supportsNamedGraphs) {
	        this._graph = '';
	        this._subject = null;
	        return this._readSubject;
	      }
	    case 'GRAPH':
	      if (this._supportsNamedGraphs)
	        return this._readNamedGraphLabel;
	    // Otherwise, the next token must be a subject
	    default:
	      return this._readSubject(token);
	    }
	  }

	  // ### `_readEntity` reads an IRI, prefixed name, blank node, or variable
	  _readEntity(token, quantifier) {
	    let value;
	    switch (token.type) {
	    // Read a relative or absolute IRI
	    case 'IRI':
	    case 'typeIRI':
	      const iri = this._resolveIRI(token.value);
	      if (iri === null)
	        return this._error('Invalid IRI', token);
	      value = this._factory.namedNode(iri);
	      break;
	    // Read a prefixed name
	    case 'type':
	    case 'prefixed':
	      const prefix = this._prefixes[token.prefix];
	      if (prefix === undefined)
	        return this._error(`Undefined prefix "${token.prefix}:"`, token);
	      value = this._factory.namedNode(prefix + token.value);
	      break;
	    // Read a blank node
	    case 'blank':
	      value = this._factory.blankNode(this._prefixes[token.prefix] + token.value);
	      break;
	    // Read a variable
	    case 'var':
	      value = this._factory.variable(token.value.substr(1));
	      break;
	    // Everything else is not an entity
	    default:
	      return this._error(`Expected entity but got ${token.type}`, token);
	    }
	    // In N3 mode, replace the entity if it is quantified
	    if (!quantifier && this._n3Mode && (value.id in this._quantified))
	      value = this._quantified[value.id];
	    return value;
	  }

	  // ### `_readSubject` reads a quad's subject
	  _readSubject(token) {
	    this._predicate = null;
	    switch (token.type) {
	    case '[':
	      // Start a new quad with a new blank node as subject
	      this._saveContext('blank', this._graph,
	                        this._subject = this._factory.blankNode(), null, null);
	      return this._readBlankNodeHead;
	    case '(':
	      // Start a new list
	      this._saveContext('list', this._graph, this.RDF_NIL, null, null);
	      this._subject = null;
	      return this._readListItem;
	    case '{':
	      // Start a new formula
	      if (!this._n3Mode)
	        return this._error('Unexpected graph', token);
	      this._saveContext('formula', this._graph,
	                        this._graph = this._factory.blankNode(), null, null);
	      return this._readSubject;
	    case '}':
	       // No subject; the graph in which we are reading is closed instead
	      return this._readPunctuation(token);
	    case '@forSome':
	      if (!this._n3Mode)
	        return this._error('Unexpected "@forSome"', token);
	      this._subject = null;
	      this._predicate = this.N3_FORSOME;
	      this._quantifier = 'blankNode';
	      return this._readQuantifierList;
	    case '@forAll':
	      if (!this._n3Mode)
	        return this._error('Unexpected "@forAll"', token);
	      this._subject = null;
	      this._predicate = this.N3_FORALL;
	      this._quantifier = 'variable';
	      return this._readQuantifierList;
	    case 'literal':
	      if (!this._n3Mode)
	        return this._error('Unexpected literal', token);

	      if (token.prefix.length === 0) {
	        this._literalValue = token.value;
	        return this._completeSubjectLiteral;
	      }
	      else
	        this._subject = this._factory.literal(token.value, this._factory.namedNode(token.prefix));

	      break;
	    case '<<':
	      if (!this._supportsRDFStar)
	        return this._error('Unexpected RDF-star syntax', token);
	      this._saveContext('<<', this._graph, null, null, null);
	      this._graph = null;
	      return this._readSubject;
	    default:
	      // Read the subject entity
	      if ((this._subject = this._readEntity(token)) === undefined)
	        return;
	      // In N3 mode, the subject might be a path
	      if (this._n3Mode)
	        return this._getPathReader(this._readPredicateOrNamedGraph);
	    }

	    // The next token must be a predicate,
	    // or, if the subject was actually a graph IRI, a named graph
	    return this._readPredicateOrNamedGraph;
	  }

	  // ### `_readPredicate` reads a quad's predicate
	  _readPredicate(token) {
	    const type = token.type;
	    switch (type) {
	    case 'inverse':
	      this._inversePredicate = true;
	    case 'abbreviation':
	      this._predicate = this.ABBREVIATIONS[token.value];
	      break;
	    case '.':
	    case ']':
	    case '}':
	      // Expected predicate didn't come, must have been trailing semicolon
	      if (this._predicate === null)
	        return this._error(`Unexpected ${type}`, token);
	      this._subject = null;
	      return type === ']' ? this._readBlankNodeTail(token) : this._readPunctuation(token);
	    case ';':
	      // Additional semicolons can be safely ignored
	      return this._predicate !== null ? this._readPredicate :
	             this._error('Expected predicate but got ;', token);
	    case '[':
	      if (this._n3Mode) {
	        // Start a new quad with a new blank node as subject
	        this._saveContext('blank', this._graph, this._subject,
	                          this._subject = this._factory.blankNode(), null);
	        return this._readBlankNodeHead;
	      }
	    case 'blank':
	      if (!this._n3Mode)
	        return this._error('Disallowed blank node as predicate', token);
	    default:
	      if ((this._predicate = this._readEntity(token)) === undefined)
	        return;
	    }
	    // The next token must be an object
	    return this._readObject;
	  }

	  // ### `_readObject` reads a quad's object
	  _readObject(token) {
	    switch (token.type) {
	    case 'literal':
	      // Regular literal, can still get a datatype or language
	      if (token.prefix.length === 0) {
	        this._literalValue = token.value;
	        return this._readDataTypeOrLang;
	      }
	      // Pre-datatyped string literal (prefix stores the datatype)
	      else
	        this._object = this._factory.literal(token.value, this._factory.namedNode(token.prefix));
	      break;
	    case '[':
	      // Start a new quad with a new blank node as subject
	      this._saveContext('blank', this._graph, this._subject, this._predicate,
	                        this._subject = this._factory.blankNode());
	      return this._readBlankNodeHead;
	    case '(':
	      // Start a new list
	      this._saveContext('list', this._graph, this._subject, this._predicate, this.RDF_NIL);
	      this._subject = null;
	      return this._readListItem;
	    case '{':
	      // Start a new formula
	      if (!this._n3Mode)
	        return this._error('Unexpected graph', token);
	      this._saveContext('formula', this._graph, this._subject, this._predicate,
	                        this._graph = this._factory.blankNode());
	      return this._readSubject;
	    case '<<':
	      if (!this._supportsRDFStar)
	        return this._error('Unexpected RDF-star syntax', token);
	      this._saveContext('<<', this._graph, this._subject, this._predicate, null);
	      this._graph = null;
	      return this._readSubject;
	    default:
	      // Read the object entity
	      if ((this._object = this._readEntity(token)) === undefined)
	        return;
	      // In N3 mode, the object might be a path
	      if (this._n3Mode)
	        return this._getPathReader(this._getContextEndReader());
	    }
	    return this._getContextEndReader();
	  }

	  // ### `_readPredicateOrNamedGraph` reads a quad's predicate, or a named graph
	  _readPredicateOrNamedGraph(token) {
	    return token.type === '{' ? this._readGraph(token) : this._readPredicate(token);
	  }

	  // ### `_readGraph` reads a graph
	  _readGraph(token) {
	    if (token.type !== '{')
	      return this._error(`Expected graph but got ${token.type}`, token);
	    // The "subject" we read is actually the GRAPH's label
	    this._graph = this._subject, this._subject = null;
	    return this._readSubject;
	  }

	  // ### `_readBlankNodeHead` reads the head of a blank node
	  _readBlankNodeHead(token) {
	    if (token.type === ']') {
	      this._subject = null;
	      return this._readBlankNodeTail(token);
	    }
	    else {
	      this._predicate = null;
	      return this._readPredicate(token);
	    }
	  }

	  // ### `_readBlankNodeTail` reads the end of a blank node
	  _readBlankNodeTail(token) {
	    if (token.type !== ']')
	      return this._readBlankNodePunctuation(token);

	    // Store blank node quad
	    if (this._subject !== null)
	      this._emit(this._subject, this._predicate, this._object, this._graph);

	    // Restore the parent context containing this blank node
	    const empty = this._predicate === null;
	    this._restoreContext('blank', token);
	    // If the blank node was the object, restore previous context and read punctuation
	    if (this._object !== null)
	      return this._getContextEndReader();
	    // If the blank node was the predicate, continue reading the object
	    else if (this._predicate !== null)
	      return this._readObject;
	    // If the blank node was the subject, continue reading the predicate
	    else
	      // If the blank node was empty, it could be a named graph label
	      return empty ? this._readPredicateOrNamedGraph : this._readPredicateAfterBlank;
	  }

	  // ### `_readPredicateAfterBlank` reads a predicate after an anonymous blank node
	  _readPredicateAfterBlank(token) {
	    switch (token.type) {
	    case '.':
	    case '}':
	      // No predicate is coming if the triple is terminated here
	      this._subject = null;
	      return this._readPunctuation(token);
	    default:
	      return this._readPredicate(token);
	    }
	  }

	  // ### `_readListItem` reads items from a list
	  _readListItem(token) {
	    let item = null,                      // The item of the list
	        list = null,                      // The list itself
	        next = this._readListItem;        // The next function to execute
	    const previousList = this._subject,   // The previous list that contains this list
	        stack = this._contextStack,       // The stack of parent contexts
	        parent = stack[stack.length - 1]; // The parent containing the current list

	    switch (token.type) {
	    case '[':
	      // Stack the current list quad and start a new quad with a blank node as subject
	      this._saveContext('blank', this._graph,
	                        list = this._factory.blankNode(), this.RDF_FIRST,
	                        this._subject = item = this._factory.blankNode());
	      next = this._readBlankNodeHead;
	      break;
	    case '(':
	      // Stack the current list quad and start a new list
	      this._saveContext('list', this._graph,
	                        list = this._factory.blankNode(), this.RDF_FIRST, this.RDF_NIL);
	      this._subject = null;
	      break;
	    case ')':
	      // Closing the list; restore the parent context
	      this._restoreContext('list', token);
	      // If this list is contained within a parent list, return the membership quad here.
	      // This will be `<parent list element> rdf:first <this list>.`.
	      if (stack.length !== 0 && stack[stack.length - 1].type === 'list')
	        this._emit(this._subject, this._predicate, this._object, this._graph);
	      // Was this list the parent's subject?
	      if (this._predicate === null) {
	        // The next token is the predicate
	        next = this._readPredicate;
	        // No list tail if this was an empty list
	        if (this._subject === this.RDF_NIL)
	          return next;
	      }
	      // The list was in the parent context's object
	      else {
	        next = this._getContextEndReader();
	        // No list tail if this was an empty list
	        if (this._object === this.RDF_NIL)
	          return next;
	      }
	      // Close the list by making the head nil
	      list = this.RDF_NIL;
	      break;
	    case 'literal':
	      // Regular literal, can still get a datatype or language
	      if (token.prefix.length === 0) {
	        this._literalValue = token.value;
	        next = this._readListItemDataTypeOrLang;
	      }
	      // Pre-datatyped string literal (prefix stores the datatype)
	      else {
	        item = this._factory.literal(token.value, this._factory.namedNode(token.prefix));
	        next = this._getContextEndReader();
	      }
	      break;
	    case '{':
	      // Start a new formula
	      if (!this._n3Mode)
	        return this._error('Unexpected graph', token);
	      this._saveContext('formula', this._graph, this._subject, this._predicate,
	                        this._graph = this._factory.blankNode());
	      return this._readSubject;
	    default:
	      if ((item = this._readEntity(token)) === undefined)
	        return;
	    }

	     // Create a new blank node if no item head was assigned yet
	    if (list === null)
	      this._subject = list = this._factory.blankNode();

	    // Is this the first element of the list?
	    if (previousList === null) {
	      // This list is either the subject or the object of its parent
	      if (parent.predicate === null)
	        parent.subject = list;
	      else
	        parent.object = list;
	    }
	    else {
	      // Continue the previous list with the current list
	      this._emit(previousList, this.RDF_REST, list, this._graph);
	    }
	    // If an item was read, add it to the list
	    if (item !== null) {
	      // In N3 mode, the item might be a path
	      if (this._n3Mode && (token.type === 'IRI' || token.type === 'prefixed')) {
	        // Create a new context to add the item's path
	        this._saveContext('item', this._graph, list, this.RDF_FIRST, item);
	        this._subject = item, this._predicate = null;
	        // _readPath will restore the context and output the item
	        return this._getPathReader(this._readListItem);
	      }
	      // Output the item
	      this._emit(list, this.RDF_FIRST, item, this._graph);
	    }
	    return next;
	  }

	  // ### `_readDataTypeOrLang` reads an _optional_ datatype or language
	  _readDataTypeOrLang(token) {
	    return this._completeObjectLiteral(token, false);
	  }


	  // ### `_readListItemDataTypeOrLang` reads an _optional_ datatype or language in a list
	  _readListItemDataTypeOrLang(token) {
	    return this._completeObjectLiteral(token, true);
	  }

	  // ### `_completeLiteral` completes a literal with an optional datatype or language
	  _completeLiteral(token) {
	    // Create a simple string literal by default
	    let literal = this._factory.literal(this._literalValue);

	    switch (token.type) {
	    // Create a datatyped literal
	    case 'type':
	    case 'typeIRI':
	      const datatype = this._readEntity(token);
	      if (datatype === undefined) return; // No datatype means an error occurred
	      literal = this._factory.literal(this._literalValue, datatype);
	      token = null;
	      break;
	    // Create a language-tagged string
	    case 'langcode':
	      literal = this._factory.literal(this._literalValue, token.value);
	      token = null;
	      break;
	    }

	    return { token, literal };
	  }

	  // Completes a literal in subject position
	  _completeSubjectLiteral(token) {
	    this._subject = this._completeLiteral(token).literal;
	    return this._readPredicateOrNamedGraph;
	  }

	  // Completes a literal in object position
	  _completeObjectLiteral(token, listItem) {
	    const completed = this._completeLiteral(token);
	    if (!completed)
	      return;
	    this._object = completed.literal;

	    // If this literal was part of a list, write the item
	    // (we could also check the context stack, but passing in a flag is faster)
	    if (listItem)
	      this._emit(this._subject, this.RDF_FIRST, this._object, this._graph);
	    // If the token was consumed, continue with the rest of the input
	    if (completed.token === null)
	      return this._getContextEndReader();
	    // Otherwise, consume the token now
	    else {
	      this._readCallback = this._getContextEndReader();
	      return this._readCallback(completed.token);
	    }
	  }

	  // ### `_readFormulaTail` reads the end of a formula
	  _readFormulaTail(token) {
	    if (token.type !== '}')
	      return this._readPunctuation(token);

	    // Store the last quad of the formula
	    if (this._subject !== null)
	      this._emit(this._subject, this._predicate, this._object, this._graph);

	    // Restore the parent context containing this formula
	    this._restoreContext('formula', token);
	    // If the formula was the subject, continue reading the predicate.
	    // If the formula was the object, read punctuation.
	    return this._object === null ? this._readPredicate : this._getContextEndReader();
	  }

	  // ### `_readPunctuation` reads punctuation between quads or quad parts
	  _readPunctuation(token) {
	    let next, graph = this._graph;
	    const subject = this._subject, inversePredicate = this._inversePredicate;
	    switch (token.type) {
	    // A closing brace ends a graph
	    case '}':
	      if (this._graph === null)
	        return this._error('Unexpected graph closing', token);
	      if (this._n3Mode)
	        return this._readFormulaTail(token);
	      this._graph = null;
	    // A dot just ends the statement, without sharing anything with the next
	    case '.':
	      this._subject = null;
	      next = this._contextStack.length ? this._readSubject : this._readInTopContext;
	      if (inversePredicate) this._inversePredicate = false;
	      break;
	    // Semicolon means the subject is shared; predicate and object are different
	    case ';':
	      next = this._readPredicate;
	      break;
	    // Comma means both the subject and predicate are shared; the object is different
	    case ',':
	      next = this._readObject;
	      break;
	    // {| means that the current triple is annotated with predicate-object pairs.
	    case '{|':
	      if (!this._supportsRDFStar)
	        return this._error('Unexpected RDF-star syntax', token);
	      // Continue using the last triple as quoted triple subject for the predicate-object pairs.
	      const predicate = this._predicate, object = this._object;
	      this._subject = this._factory.quad(subject, predicate, object, this.DEFAULTGRAPH);
	      next = this._readPredicate;
	      break;
	    // |} means that the current quoted triple in annotation syntax is finalized.
	    case '|}':
	      if (this._subject.termType !== 'Quad')
	        return this._error('Unexpected asserted triple closing', token);
	      this._subject = null;
	      next = this._readPunctuation;
	      break;
	    default:
	      // An entity means this is a quad (only allowed if not already inside a graph)
	      if (this._supportsQuads && this._graph === null && (graph = this._readEntity(token)) !== undefined) {
	        next = this._readQuadPunctuation;
	        break;
	      }
	      return this._error(`Expected punctuation to follow "${this._object.id}"`, token);
	    }
	    // A quad has been completed now, so return it
	    if (subject !== null) {
	      const predicate = this._predicate, object = this._object;
	      if (!inversePredicate)
	        this._emit(subject, predicate, object,  graph);
	      else
	        this._emit(object,  predicate, subject, graph);
	    }
	    return next;
	  }

	    // ### `_readBlankNodePunctuation` reads punctuation in a blank node
	  _readBlankNodePunctuation(token) {
	    let next;
	    switch (token.type) {
	    // Semicolon means the subject is shared; predicate and object are different
	    case ';':
	      next = this._readPredicate;
	      break;
	    // Comma means both the subject and predicate are shared; the object is different
	    case ',':
	      next = this._readObject;
	      break;
	    default:
	      return this._error(`Expected punctuation to follow "${this._object.id}"`, token);
	    }
	    // A quad has been completed now, so return it
	    this._emit(this._subject, this._predicate, this._object, this._graph);
	    return next;
	  }

	  // ### `_readQuadPunctuation` reads punctuation after a quad
	  _readQuadPunctuation(token) {
	    if (token.type !== '.')
	      return this._error('Expected dot to follow quad', token);
	    return this._readInTopContext;
	  }

	  // ### `_readPrefix` reads the prefix of a prefix declaration
	  _readPrefix(token) {
	    if (token.type !== 'prefix')
	      return this._error('Expected prefix to follow @prefix', token);
	    this._prefix = token.value;
	    return this._readPrefixIRI;
	  }

	  // ### `_readPrefixIRI` reads the IRI of a prefix declaration
	  _readPrefixIRI(token) {
	    if (token.type !== 'IRI')
	      return this._error(`Expected IRI to follow prefix "${this._prefix}:"`, token);
	    const prefixNode = this._readEntity(token);
	    this._prefixes[this._prefix] = prefixNode.value;
	    this._prefixCallback(this._prefix, prefixNode);
	    return this._readDeclarationPunctuation;
	  }

	  // ### `_readBaseIRI` reads the IRI of a base declaration
	  _readBaseIRI(token) {
	    const iri = token.type === 'IRI' && this._resolveIRI(token.value);
	    if (!iri)
	      return this._error('Expected valid IRI to follow base declaration', token);
	    this._setBase(iri);
	    return this._readDeclarationPunctuation;
	  }

	  // ### `_readNamedGraphLabel` reads the label of a named graph
	  _readNamedGraphLabel(token) {
	    switch (token.type) {
	    case 'IRI':
	    case 'blank':
	    case 'prefixed':
	      return this._readSubject(token), this._readGraph;
	    case '[':
	      return this._readNamedGraphBlankLabel;
	    default:
	      return this._error('Invalid graph label', token);
	    }
	  }

	  // ### `_readNamedGraphLabel` reads a blank node label of a named graph
	  _readNamedGraphBlankLabel(token) {
	    if (token.type !== ']')
	      return this._error('Invalid graph label', token);
	    this._subject = this._factory.blankNode();
	    return this._readGraph;
	  }

	  // ### `_readDeclarationPunctuation` reads the punctuation of a declaration
	  _readDeclarationPunctuation(token) {
	    // SPARQL-style declarations don't have punctuation
	    if (this._sparqlStyle) {
	      this._sparqlStyle = false;
	      return this._readInTopContext(token);
	    }

	    if (token.type !== '.')
	      return this._error('Expected declaration to end with a dot', token);
	    return this._readInTopContext;
	  }

	  // Reads a list of quantified symbols from a @forSome or @forAll statement
	  _readQuantifierList(token) {
	    let entity;
	    switch (token.type) {
	    case 'IRI':
	    case 'prefixed':
	      if ((entity = this._readEntity(token, true)) !== undefined)
	        break;
	    default:
	      return this._error(`Unexpected ${token.type}`, token);
	    }
	    // Without explicit quantifiers, map entities to a quantified entity
	    if (!this._explicitQuantifiers)
	      this._quantified[entity.id] = this._factory[this._quantifier](this._factory.blankNode().value);
	    // With explicit quantifiers, output the reified quantifier
	    else {
	      // If this is the first item, start a new quantifier list
	      if (this._subject === null)
	        this._emit(this._graph || this.DEFAULTGRAPH, this._predicate,
	                   this._subject = this._factory.blankNode(), this.QUANTIFIERS_GRAPH);
	      // Otherwise, continue the previous list
	      else
	        this._emit(this._subject, this.RDF_REST,
	                   this._subject = this._factory.blankNode(), this.QUANTIFIERS_GRAPH);
	      // Output the list item
	      this._emit(this._subject, this.RDF_FIRST, entity, this.QUANTIFIERS_GRAPH);
	    }
	    return this._readQuantifierPunctuation;
	  }

	  // Reads punctuation from a @forSome or @forAll statement
	  _readQuantifierPunctuation(token) {
	    // Read more quantifiers
	    if (token.type === ',')
	      return this._readQuantifierList;
	    // End of the quantifier list
	    else {
	      // With explicit quantifiers, close the quantifier list
	      if (this._explicitQuantifiers) {
	        this._emit(this._subject, this.RDF_REST, this.RDF_NIL, this.QUANTIFIERS_GRAPH);
	        this._subject = null;
	      }
	      // Read a dot
	      this._readCallback = this._getContextEndReader();
	      return this._readCallback(token);
	    }
	  }

	  // ### `_getPathReader` reads a potential path and then resumes with the given function
	  _getPathReader(afterPath) {
	    this._afterPath = afterPath;
	    return this._readPath;
	  }

	  // ### `_readPath` reads a potential path
	  _readPath(token) {
	    switch (token.type) {
	    // Forward path
	    case '!': return this._readForwardPath;
	    // Backward path
	    case '^': return this._readBackwardPath;
	    // Not a path; resume reading where we left off
	    default:
	      const stack = this._contextStack, parent = stack.length && stack[stack.length - 1];
	      // If we were reading a list item, we still need to output it
	      if (parent && parent.type === 'item') {
	        // The list item is the remaining subejct after reading the path
	        const item = this._subject;
	        // Switch back to the context of the list
	        this._restoreContext('item', token);
	        // Output the list item
	        this._emit(this._subject, this.RDF_FIRST, item, this._graph);
	      }
	      return this._afterPath(token);
	    }
	  }

	  // ### `_readForwardPath` reads a '!' path
	  _readForwardPath(token) {
	    let subject, predicate;
	    const object = this._factory.blankNode();
	    // The next token is the predicate
	    if ((predicate = this._readEntity(token)) === undefined)
	      return;
	    // If we were reading a subject, replace the subject by the path's object
	    if (this._predicate === null)
	      subject = this._subject, this._subject = object;
	    // If we were reading an object, replace the subject by the path's object
	    else
	      subject = this._object,  this._object  = object;
	    // Emit the path's current quad and read its next section
	    this._emit(subject, predicate, object, this._graph);
	    return this._readPath;
	  }

	  // ### `_readBackwardPath` reads a '^' path
	  _readBackwardPath(token) {
	    const subject = this._factory.blankNode();
	    let predicate, object;
	    // The next token is the predicate
	    if ((predicate = this._readEntity(token)) === undefined)
	      return;
	    // If we were reading a subject, replace the subject by the path's subject
	    if (this._predicate === null)
	      object = this._subject, this._subject = subject;
	    // If we were reading an object, replace the subject by the path's subject
	    else
	      object = this._object,  this._object  = subject;
	    // Emit the path's current quad and read its next section
	    this._emit(subject, predicate, object, this._graph);
	    return this._readPath;
	  }

	  // ### `_readRDFStarTailOrGraph` reads the graph of a nested RDF-star quad or the end of a nested RDF-star triple
	  _readRDFStarTailOrGraph(token) {
	    if (token.type !== '>>') {
	      // An entity means this is a quad (only allowed if not already inside a graph)
	      if (this._supportsQuads && this._graph === null && (this._graph = this._readEntity(token)) !== undefined)
	        return this._readRDFStarTail;
	      return this._error(`Expected >> to follow "${this._object.id}"`, token);
	    }
	    return this._readRDFStarTail(token);
	  }

	  // ### `_readRDFStarTail` reads the end of a nested RDF-star triple
	  _readRDFStarTail(token) {
	    if (token.type !== '>>')
	      return this._error(`Expected >> but got ${token.type}`, token);
	    // Read the quad and restore the previous context
	    const quad = this._factory.quad(this._subject, this._predicate, this._object,
	      this._graph || this.DEFAULTGRAPH);
	    this._restoreContext('<<', token);
	    // If the triple was the subject, continue by reading the predicate.
	    if (this._subject === null) {
	      this._subject = quad;
	      return this._readPredicate;
	    }
	    // If the triple was the object, read context end.
	    else {
	      this._object = quad;
	      return this._getContextEndReader();
	    }
	  }

	  // ### `_getContextEndReader` gets the next reader function at the end of a context
	  _getContextEndReader() {
	    const contextStack = this._contextStack;
	    if (!contextStack.length)
	      return this._readPunctuation;

	    switch (contextStack[contextStack.length - 1].type) {
	    case 'blank':
	      return this._readBlankNodeTail;
	    case 'list':
	      return this._readListItem;
	    case 'formula':
	      return this._readFormulaTail;
	    case '<<':
	      return this._readRDFStarTailOrGraph;
	    }
	  }

	  // ### `_emit` sends a quad through the callback
	  _emit(subject, predicate, object, graph) {
	    this._callback(null, this._factory.quad(subject, predicate, object, graph || this.DEFAULTGRAPH));
	  }

	  // ### `_error` emits an error message through the callback
	  _error(message, token) {
	    const err = new Error(`${message} on line ${token.line}.`);
	    err.context = {
	      token: token,
	      line: token.line,
	      previousToken: this._lexer.previousToken,
	    };
	    this._callback(err);
	    this._callback = noop;
	  }

	  // ### `_resolveIRI` resolves an IRI against the base path
	  _resolveIRI(iri) {
	    return /^[a-z][a-z0-9+.-]*:/i.test(iri) ? iri : this._resolveRelativeIRI(iri);
	  }

	  // ### `_resolveRelativeIRI` resolves an IRI against the base path,
	  // assuming that a base path has been set and that the IRI is indeed relative
	  _resolveRelativeIRI(iri) {
	    // An empty relative IRI indicates the base IRI
	    if (!iri.length)
	      return this._base;
	    // Decide resolving strategy based in the first character
	    switch (iri[0]) {
	    // Resolve relative fragment IRIs against the base IRI
	    case '#': return this._base + iri;
	    // Resolve relative query string IRIs by replacing the query string
	    case '?': return this._base.replace(/(?:\?.*)?$/, iri);
	    // Resolve root-relative IRIs at the root of the base IRI
	    case '/':
	      // Resolve scheme-relative IRIs to the scheme
	      return (iri[1] === '/' ? this._baseScheme : this._baseRoot) + this._removeDotSegments(iri);
	    // Resolve all other IRIs at the base IRI's path
	    default:
	      // Relative IRIs cannot contain a colon in the first path segment
	      return (/^[^/:]*:/.test(iri)) ? null : this._removeDotSegments(this._basePath + iri);
	    }
	  }

	  // ### `_removeDotSegments` resolves './' and '../' path segments in an IRI as per RFC3986
	  _removeDotSegments(iri) {
	    // Don't modify the IRI if it does not contain any dot segments
	    if (!/(^|\/)\.\.?($|[/#?])/.test(iri))
	      return iri;

	    // Start with an imaginary slash before the IRI in order to resolve trailing './' and '../'
	    const length = iri.length;
	    let result = '', i = -1, pathStart = -1, segmentStart = 0, next = '/';

	    while (i < length) {
	      switch (next) {
	      // The path starts with the first slash after the authority
	      case ':':
	        if (pathStart < 0) {
	          // Skip two slashes before the authority
	          if (iri[++i] === '/' && iri[++i] === '/')
	            // Skip to slash after the authority
	            while ((pathStart = i + 1) < length && iri[pathStart] !== '/')
	              i = pathStart;
	        }
	        break;
	      // Don't modify a query string or fragment
	      case '?':
	      case '#':
	        i = length;
	        break;
	      // Handle '/.' or '/..' path segments
	      case '/':
	        if (iri[i + 1] === '.') {
	          next = iri[++i + 1];
	          switch (next) {
	          // Remove a '/.' segment
	          case '/':
	            result += iri.substring(segmentStart, i - 1);
	            segmentStart = i + 1;
	            break;
	          // Remove a trailing '/.' segment
	          case undefined:
	          case '?':
	          case '#':
	            return result + iri.substring(segmentStart, i) + iri.substr(i + 1);
	          // Remove a '/..' segment
	          case '.':
	            next = iri[++i + 1];
	            if (next === undefined || next === '/' || next === '?' || next === '#') {
	              result += iri.substring(segmentStart, i - 2);
	              // Try to remove the parent path from result
	              if ((segmentStart = result.lastIndexOf('/')) >= pathStart)
	                result = result.substr(0, segmentStart);
	              // Remove a trailing '/..' segment
	              if (next !== '/')
	                return `${result}/${iri.substr(i + 1)}`;
	              segmentStart = i + 1;
	            }
	          }
	        }
	      }
	      next = iri[++i];
	    }
	    return result + iri.substring(segmentStart);
	  }

	  // ## Public methods

	  // ### `parse` parses the N3 input and emits each parsed quad through the onQuad callback.
	  parse(input, quadCallback, prefixCallback) {
	    // The second parameter accepts an object { onQuad: ..., onPrefix: ..., onComment: ...}
	    // As a second and third parameter it still accepts a separate quadCallback and prefixCallback for backward compatibility as well
	    let onQuad, onPrefix, onComment;
	    if (quadCallback && (quadCallback.onQuad || quadCallback.onPrefix || quadCallback.onComment)) {
	      onQuad = quadCallback.onQuad;
	      onPrefix = quadCallback.onPrefix;
	      onComment = quadCallback.onComment;
	    }
	    else {
	      onQuad = quadCallback;
	      onPrefix = prefixCallback;
	    }
	    // The read callback is the next function to be executed when a token arrives.
	    // We start reading in the top context.
	    this._readCallback = this._readInTopContext;
	    this._sparqlStyle = false;
	    this._prefixes = Object.create(null);
	    this._prefixes._ = this._blankNodePrefix ? this._blankNodePrefix.substr(2)
	                                             : `b${blankNodePrefix++}_`;
	    this._prefixCallback = onPrefix || noop;
	    this._inversePredicate = false;
	    this._quantified = Object.create(null);

	    // Parse synchronously if no quad callback is given
	    if (!onQuad) {
	      const quads = [];
	      let error;
	      this._callback = (e, t) => { e ? (error = e) : t && quads.push(t); };
	      this._lexer.tokenize(input).every(token => {
	        return this._readCallback = this._readCallback(token);
	      });
	      if (error) throw error;
	      return quads;
	    }

	    let processNextToken = (error, token) => {
	      if (error !== null)
	        this._callback(error), this._callback = noop;
	      else if (this._readCallback)
	        this._readCallback = this._readCallback(token);
	    };

	    // Enable checking for comments on every token when a commentCallback has been set
	    if (onComment) {
	      // Enable the lexer to return comments as tokens first (disabled by default)
	      this._lexer.comments = true;
	      // Patch the processNextToken function
	      processNextToken = (error, token) => {
	        if (error !== null)
	          this._callback(error), this._callback = noop;
	        else if (this._readCallback) {
	          if (token.type === 'comment')
	            onComment(token.value);
	          else
	            this._readCallback = this._readCallback(token);
	        }
	      };
	    }

	    // Parse asynchronously otherwise, executing the read callback when a token arrives
	    this._callback = onQuad;
	    this._lexer.tokenize(input, processNextToken);
	  }
	}

	// The empty function
	function noop() {}

	// Initializes the parser with the given data factory
	function initDataFactory(parser, factory) {
	  parser._factory = factory;

	  parser.DEFAULTGRAPH = factory.defaultGraph();

	  // Set common named nodes
	  parser.RDF_FIRST  = factory.namedNode(namespaces.rdf.first);
	  parser.RDF_REST   = factory.namedNode(namespaces.rdf.rest);
	  parser.RDF_NIL    = factory.namedNode(namespaces.rdf.nil);
	  parser.N3_FORALL  = factory.namedNode(namespaces.r.forAll);
	  parser.N3_FORSOME = factory.namedNode(namespaces.r.forSome);
	  parser.ABBREVIATIONS = {
	    'a': factory.namedNode(namespaces.rdf.type),
	    '=': factory.namedNode(namespaces.owl.sameAs),
	    '>': factory.namedNode(namespaces.log.implies),
	    '<': factory.namedNode(namespaces.log.isImpliedBy),
	  };
	  parser.QUANTIFIERS_GRAPH = factory.namedNode('urn:n3:quantifiers');
	}
	initDataFactory(N3Parser.prototype, DataFactory);

	// **N3Util** provides N3 utility functions.


	// Tests whether the given term represents the default graph
	function isDefaultGraph(term) {
	  return !!term && term.termType === 'DefaultGraph';
	}

	function escapeRegex(regex) {
	  return regex.replace(/[\]\/\(\)\*\+\?\.\\\$]/g, '\\$&');
	}

	// Do not handle base IRIs without scheme, and currently unsupported cases:
	// - file: IRIs (which could also use backslashes)
	// - IRIs containing /. or /.. or //
	const BASE_UNSUPPORTED = /^:?[^:?#]*(?:[?#]|$)|^file:|^[^:]*:\/*[^?#]+?\/(?:\.\.?(?:\/|$)|\/)/i;
	const SUFFIX_SUPPORTED = /^(?:(?:[^/?#]{3,}|\.?[^/?#.]\.?)(?:\/[^/?#]{3,}|\.?[^/?#.]\.?)*\/?)?(?:[?#]|$)/;
	const CURRENT = './';
	const PARENT = '../';
	const QUERY = '?';
	const FRAGMENT = '#';

	class BaseIRI {
	  constructor(base) {
	    this.base = base;
	    this._baseLength = 0;
	    this._baseMatcher = null;
	    this._pathReplacements = new Array(base.length + 1);
	  }

	  static supports(base) {
	    return !BASE_UNSUPPORTED.test(base);
	  }

	  _getBaseMatcher() {
	    if (this._baseMatcher)
	      return this._baseMatcher;
	    if (!BaseIRI.supports(this.base))
	      return this._baseMatcher = /.^/;

	    // Extract the scheme
	    const scheme = /^[^:]*:\/*/.exec(this.base)[0];
	    const regexHead = ['^', escapeRegex(scheme)];
	    const regexTail = [];

	    // Generate a regex for every path segment
	    const segments = [], segmenter = /[^/?#]*([/?#])/y;
	    let segment, query = 0, fragment = 0, last = segmenter.lastIndex = scheme.length;
	    while (!query && !fragment && (segment = segmenter.exec(this.base))) {
	      // Truncate base resolution path at fragment start
	      if (segment[1] === FRAGMENT)
	        fragment = segmenter.lastIndex - 1;
	      else {
	        // Create regex that matches the segment
	        regexHead.push(escapeRegex(segment[0]), '(?:');
	        regexTail.push(')?');

	        // Create dedicated query string replacement
	        if (segment[1] !== QUERY)
	          segments.push(last = segmenter.lastIndex);
	        else {
	          query = last = segmenter.lastIndex;
	          fragment = this.base.indexOf(FRAGMENT, query);
	          this._pathReplacements[query] = QUERY;
	        }
	      }
	    }

	    // Precalculate parent path substitutions
	    for (let i = 0; i < segments.length; i++)
	      this._pathReplacements[segments[i]] = PARENT.repeat(segments.length - i - 1);
	    this._pathReplacements[segments[segments.length - 1]] = CURRENT;

	    // Add the remainder of the base IRI (without fragment) to the regex
	    this._baseLength = fragment > 0 ? fragment : this.base.length;
	    regexHead.push(
	      escapeRegex(this.base.substring(last, this._baseLength)),
	      query ? '(?:#|$)' : '(?:[?#]|$)',
	    );
	    return this._baseMatcher = new RegExp([...regexHead, ...regexTail].join(''));
	  }

	  toRelative(iri) {
	    // Unsupported or non-matching base IRI
	    const match = this._getBaseMatcher().exec(iri);
	    if (!match)
	      return iri;

	    // Exact base IRI match
	    const length = match[0].length;
	    if (length === this._baseLength && length === iri.length)
	      return '';

	    // Parent path match
	    const parentPath = this._pathReplacements[length];
	    if (parentPath) {
	      const suffix = iri.substring(length);
	      // Don't abbreviate unsupported path
	      if (parentPath !== QUERY && !SUFFIX_SUPPORTED.test(suffix))
	        return iri;
	      // Omit ./ with fragment or query string
	      if (parentPath === CURRENT && /^[^?#]/.test(suffix))
	        return suffix;
	      // Append suffix to relative parent path
	      return parentPath + suffix;
	    }

	    // Fragment or query string, so include delimiter
	    return iri.substring(length - 1);
	  }
	}

	// **N3Writer** writes N3 documents.

	const DEFAULTGRAPH = DataFactory.defaultGraph();

	const { rdf, xsd } = namespaces;

	// Characters in literals that require escaping
	const escape    = /["\\\t\n\r\b\f\u0000-\u0019\ud800-\udbff]/,
	    escapeAll = /["\\\t\n\r\b\f\u0000-\u0019]|[\ud800-\udbff][\udc00-\udfff]/g,
	    escapedCharacters = {
	      '\\': '\\\\', '"': '\\"', '\t': '\\t',
	      '\n': '\\n', '\r': '\\r', '\b': '\\b', '\f': '\\f',
	    };

	// ## Placeholder class to represent already pretty-printed terms
	class SerializedTerm extends Term {
	  // Pretty-printed nodes are not equal to any other node
	  // (e.g., [] does not equal [])
	  equals(other) {
	    return other === this;
	  }
	}

	// ## Constructor
	class N3Writer {
	  constructor(outputStream, options) {
	    // ### `_prefixRegex` matches a prefixed name or IRI that begins with one of the added prefixes
	    this._prefixRegex = /$0^/;

	    // Shift arguments if the first argument is not a stream
	    if (outputStream && typeof outputStream.write !== 'function')
	      options = outputStream, outputStream = null;
	    options = options || {};
	    this._lists = options.lists;

	    // If no output stream given, send the output as string through the end callback
	    if (!outputStream) {
	      let output = '';
	      this._outputStream = {
	        write(chunk, encoding, done) { output += chunk; done && done(); },
	        end: done => { done && done(null, output); },
	      };
	      this._endStream = true;
	    }
	    else {
	      this._outputStream = outputStream;
	      this._endStream = options.end === undefined ? true : !!options.end;
	    }

	    // Initialize writer, depending on the format
	    this._subject = null;
	    if (!(/triple|quad/i).test(options.format)) {
	      this._lineMode = false;
	      this._graph = DEFAULTGRAPH;
	      this._prefixIRIs = Object.create(null);
	      options.prefixes && this.addPrefixes(options.prefixes);
	      if (options.baseIRI) {
	        this._baseIri = new BaseIRI(options.baseIRI);
	      }
	    }
	    else {
	      this._lineMode = true;
	      this._writeQuad = this._writeQuadLine;
	    }
	  }

	  // ## Private methods

	  // ### Whether the current graph is the default graph
	  get _inDefaultGraph() {
	    return DEFAULTGRAPH.equals(this._graph);
	  }

	  // ### `_write` writes the argument to the output stream
	  _write(string, callback) {
	    this._outputStream.write(string, 'utf8', callback);
	  }

	  // ### `_writeQuad` writes the quad to the output stream
	  _writeQuad(subject, predicate, object, graph, done) {
	    try {
	      // Write the graph's label if it has changed
	      if (!graph.equals(this._graph)) {
	        // Close the previous graph and start the new one
	        this._write((this._subject === null ? '' : (this._inDefaultGraph ? '.\n' : '\n}\n')) +
	                    (DEFAULTGRAPH.equals(graph) ? '' : `${this._encodeIriOrBlank(graph)} {\n`));
	        this._graph = graph;
	        this._subject = null;
	      }
	      // Don't repeat the subject if it's the same
	      if (subject.equals(this._subject)) {
	        // Don't repeat the predicate if it's the same
	        if (predicate.equals(this._predicate))
	          this._write(`, ${this._encodeObject(object)}`, done);
	        // Same subject, different predicate
	        else
	          this._write(`;\n    ${
                      this._encodePredicate(this._predicate = predicate)} ${
                      this._encodeObject(object)}`, done);
	      }
	      // Different subject; write the whole quad
	      else
	        this._write(`${(this._subject === null ? '' : '.\n') +
                    this._encodeSubject(this._subject = subject)} ${
                    this._encodePredicate(this._predicate = predicate)} ${
                    this._encodeObject(object)}`, done);
	    }
	    catch (error) { done && done(error); }
	  }

	  // ### `_writeQuadLine` writes the quad to the output stream as a single line
	  _writeQuadLine(subject, predicate, object, graph, done) {
	    // Write the quad without prefixes
	    delete this._prefixMatch;
	    this._write(this.quadToString(subject, predicate, object, graph), done);
	  }

	  // ### `quadToString` serializes a quad as a string
	  quadToString(subject, predicate, object, graph) {
	    return  `${this._encodeSubject(subject)} ${
            this._encodeIriOrBlank(predicate)} ${
            this._encodeObject(object)
            }${graph && graph.value ? ` ${this._encodeIriOrBlank(graph)} .\n` : ' .\n'}`;
	  }

	  // ### `quadsToString` serializes an array of quads as a string
	  quadsToString(quads) {
	    let quadsString = '';
	    for (const quad of quads)
	      quadsString += this.quadToString(quad.subject, quad.predicate, quad.object, quad.graph);
	    return quadsString;
	  }

	  // ### `_encodeSubject` represents a subject
	  _encodeSubject(entity) {
	    return entity.termType === 'Quad' ?
	      this._encodeQuad(entity) : this._encodeIriOrBlank(entity);
	  }

	  // ### `_encodeIriOrBlank` represents an IRI or blank node
	  _encodeIriOrBlank(entity) {
	    // A blank node or list is represented as-is
	    if (entity.termType !== 'NamedNode') {
	      // If it is a list head, pretty-print it
	      if (this._lists && (entity.value in this._lists))
	        entity = this.list(this._lists[entity.value]);
	      return 'id' in entity ? entity.id : `_:${entity.value}`;
	    }
	    let iri = entity.value;
	    // Use relative IRIs if requested and possible
	    if (this._baseIri) {
	      iri = this._baseIri.toRelative(iri);
	    }
	    // Escape special characters
	    if (escape.test(iri))
	      iri = iri.replace(escapeAll, characterReplacer);
	    // Try to represent the IRI as prefixed name
	    const prefixMatch = this._prefixRegex.exec(iri);
	    return !prefixMatch ? `<${iri}>` :
	           (!prefixMatch[1] ? iri : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2]);
	  }

	  // ### `_encodeLiteral` represents a literal
	  _encodeLiteral(literal) {
	    // Escape special characters
	    let value = literal.value;
	    if (escape.test(value))
	      value = value.replace(escapeAll, characterReplacer);

	    // Write a language-tagged literal
	    if (literal.language)
	      return `"${value}"@${literal.language}`;

	    // Write dedicated literals per data type
	    if (this._lineMode) {
	      // Only abbreviate strings in N-Triples or N-Quads
	      if (literal.datatype.value === xsd.string)
	        return `"${value}"`;
	    }
	    else {
	      // Use common datatype abbreviations in Turtle or TriG
	      switch (literal.datatype.value) {
	      case xsd.string:
	        return `"${value}"`;
	      case xsd.boolean:
	        if (value === 'true' || value === 'false')
	          return value;
	        break;
	      case xsd.integer:
	        if (/^[+-]?\d+$/.test(value))
	          return value;
	        break;
	      case xsd.decimal:
	        if (/^[+-]?\d*\.\d+$/.test(value))
	          return value;
	        break;
	      case xsd.double:
	        if (/^[+-]?(?:\d+\.\d*|\.?\d+)[eE][+-]?\d+$/.test(value))
	          return value;
	        break;
	      }
	    }

	    // Write a regular datatyped literal
	    return `"${value}"^^${this._encodeIriOrBlank(literal.datatype)}`;
	  }

	  // ### `_encodePredicate` represents a predicate
	  _encodePredicate(predicate) {
	    return predicate.value === rdf.type ? 'a' : this._encodeIriOrBlank(predicate);
	  }

	  // ### `_encodeObject` represents an object
	  _encodeObject(object) {
	    switch (object.termType) {
	    case 'Quad':
	      return this._encodeQuad(object);
	    case 'Literal':
	      return this._encodeLiteral(object);
	    default:
	      return this._encodeIriOrBlank(object);
	    }
	  }

	  // ### `_encodeQuad` encodes an RDF-star quad
	  _encodeQuad({ subject, predicate, object, graph }) {
	    return `<<${
      this._encodeSubject(subject)} ${
      this._encodePredicate(predicate)} ${
      this._encodeObject(object)}${
      isDefaultGraph(graph) ? '' : ` ${this._encodeIriOrBlank(graph)}`}>>`;
	  }

	  // ### `_blockedWrite` replaces `_write` after the writer has been closed
	  _blockedWrite() {
	    throw new Error('Cannot write because the writer has been closed.');
	  }

	  // ### `addQuad` adds the quad to the output stream
	  addQuad(subject, predicate, object, graph, done) {
	    // The quad was given as an object, so shift parameters
	    if (object === undefined)
	      this._writeQuad(subject.subject, subject.predicate, subject.object, subject.graph, predicate);
	    // The optional `graph` parameter was not provided
	    else if (typeof graph === 'function')
	      this._writeQuad(subject, predicate, object, DEFAULTGRAPH, graph);
	    // The `graph` parameter was provided
	    else
	      this._writeQuad(subject, predicate, object, graph || DEFAULTGRAPH, done);
	  }

	  // ### `addQuads` adds the quads to the output stream
	  addQuads(quads) {
	    for (let i = 0; i < quads.length; i++)
	      this.addQuad(quads[i]);
	  }

	  // ### `addPrefix` adds the prefix to the output stream
	  addPrefix(prefix, iri, done) {
	    const prefixes = {};
	    prefixes[prefix] = iri;
	    this.addPrefixes(prefixes, done);
	  }

	  // ### `addPrefixes` adds the prefixes to the output stream
	  addPrefixes(prefixes, done) {
	    // Ignore prefixes if not supported by the serialization
	    if (!this._prefixIRIs)
	      return done && done();

	    // Write all new prefixes
	    let hasPrefixes = false;
	    for (let prefix in prefixes) {
	      let iri = prefixes[prefix];
	      if (typeof iri !== 'string')
	        iri = iri.value;
	      hasPrefixes = true;
	      // Finish a possible pending quad
	      if (this._subject !== null) {
	        this._write(this._inDefaultGraph ? '.\n' : '\n}\n');
	        this._subject = null, this._graph = '';
	      }
	      // Store and write the prefix
	      this._prefixIRIs[iri] = (prefix += ':');
	      this._write(`@prefix ${prefix} <${iri}>.\n`);
	    }
	    // Recreate the prefix matcher
	    if (hasPrefixes) {
	      let IRIlist = '', prefixList = '';
	      for (const prefixIRI in this._prefixIRIs) {
	        IRIlist += IRIlist ? `|${prefixIRI}` : prefixIRI;
	        prefixList += (prefixList ? '|' : '') + this._prefixIRIs[prefixIRI];
	      }
	      IRIlist = escapeRegex(IRIlist);
	      this._prefixRegex = new RegExp(`^(?:${prefixList})[^\/]*$|` +
	                                     `^(${IRIlist})([_a-zA-Z0-9][\\-_a-zA-Z0-9]*)$`);
	    }
	    // End a prefix block with a newline
	    this._write(hasPrefixes ? '\n' : '', done);
	  }

	  // ### `blank` creates a blank node with the given content
	  blank(predicate, object) {
	    let children = predicate, child, length;
	    // Empty blank node
	    if (predicate === undefined)
	      children = [];
	    // Blank node passed as blank(Term("predicate"), Term("object"))
	    else if (predicate.termType)
	      children = [{ predicate: predicate, object: object }];
	    // Blank node passed as blank({ predicate: predicate, object: object })
	    else if (!('length' in predicate))
	      children = [predicate];

	    switch (length = children.length) {
	    // Generate an empty blank node
	    case 0:
	      return new SerializedTerm('[]');
	    // Generate a non-nested one-triple blank node
	    case 1:
	      child = children[0];
	      if (!(child.object instanceof SerializedTerm))
	        return new SerializedTerm(`[ ${this._encodePredicate(child.predicate)} ${
                                  this._encodeObject(child.object)} ]`);
	    // Generate a multi-triple or nested blank node
	    default:
	      let contents = '[';
	      // Write all triples in order
	      for (let i = 0; i < length; i++) {
	        child = children[i];
	        // Write only the object is the predicate is the same as the previous
	        if (child.predicate.equals(predicate))
	          contents += `, ${this._encodeObject(child.object)}`;
	        // Otherwise, write the predicate and the object
	        else {
	          contents += `${(i ? ';\n  ' : '\n  ') +
                      this._encodePredicate(child.predicate)} ${
                      this._encodeObject(child.object)}`;
	          predicate = child.predicate;
	        }
	      }
	      return new SerializedTerm(`${contents}\n]`);
	    }
	  }

	  // ### `list` creates a list node with the given content
	  list(elements) {
	    const length = elements && elements.length || 0, contents = new Array(length);
	    for (let i = 0; i < length; i++)
	      contents[i] = this._encodeObject(elements[i]);
	    return new SerializedTerm(`(${contents.join(' ')})`);
	  }

	  // ### `end` signals the end of the output stream
	  end(done) {
	    // Finish a possible pending quad
	    if (this._subject !== null) {
	      this._write(this._inDefaultGraph ? '.\n' : '\n}\n');
	      this._subject = null;
	    }
	    // Disallow further writing
	    this._write = this._blockedWrite;

	    // Try to end the underlying stream, ensuring done is called exactly one time
	    let singleDone = done && ((error, result) => { singleDone = null, done(error, result); });
	    if (this._endStream) {
	      try { return this._outputStream.end(singleDone); }
	      catch (error) { /* error closing stream */ }
	    }
	    singleDone && singleDone();
	  }
	}

	// Replaces a character by its escaped version
	function characterReplacer(character) {
	  // Replace a single character by its escaped version
	  let result = escapedCharacters[character];
	  if (result === undefined) {
	    // Replace a single character with its 4-bit unicode escape sequence
	    if (character.length === 1) {
	      result = character.charCodeAt(0).toString(16);
	      result = '\\u0000'.substr(0, 6 - result.length) + result;
	    }
	    // Replace a surrogate pair with its 8-bit unicode escape sequence
	    else {
	      result = ((character.charCodeAt(0) - 0xD800) * 0x400 +
	                 character.charCodeAt(1) + 0x2400).toString(16);
	      result = '\\U00000000'.substr(0, 10 - result.length) + result;
	    }
	  }
	  return result;
	}

	var browser$2 = {exports: {}};

	var stream = {exports: {}};

	var primordials;
	var hasRequiredPrimordials;

	function requirePrimordials () {
		if (hasRequiredPrimordials) return primordials;
		hasRequiredPrimordials = 1;

		/*
		  This file is a reduced and adapted version of the main lib/internal/per_context/primordials.js file defined at

		  https://github.com/nodejs/node/blob/main/lib/internal/per_context/primordials.js

		  Don't try to replace with the original file and keep it up to date with the upstream file.
		*/

		// This is a simplified version of AggregateError
		class AggregateError extends Error {
		  constructor(errors) {
		    if (!Array.isArray(errors)) {
		      throw new TypeError(`Expected input to be an Array, got ${typeof errors}`)
		    }
		    let message = '';
		    for (let i = 0; i < errors.length; i++) {
		      message += `    ${errors[i].stack}\n`;
		    }
		    super(message);
		    this.name = 'AggregateError';
		    this.errors = errors;
		  }
		}
		primordials = {
		  AggregateError,
		  ArrayIsArray(self) {
		    return Array.isArray(self)
		  },
		  ArrayPrototypeIncludes(self, el) {
		    return self.includes(el)
		  },
		  ArrayPrototypeIndexOf(self, el) {
		    return self.indexOf(el)
		  },
		  ArrayPrototypeJoin(self, sep) {
		    return self.join(sep)
		  },
		  ArrayPrototypeMap(self, fn) {
		    return self.map(fn)
		  },
		  ArrayPrototypePop(self, el) {
		    return self.pop(el)
		  },
		  ArrayPrototypePush(self, el) {
		    return self.push(el)
		  },
		  ArrayPrototypeSlice(self, start, end) {
		    return self.slice(start, end)
		  },
		  Error,
		  FunctionPrototypeCall(fn, thisArgs, ...args) {
		    return fn.call(thisArgs, ...args)
		  },
		  FunctionPrototypeSymbolHasInstance(self, instance) {
		    return Function.prototype[Symbol.hasInstance].call(self, instance)
		  },
		  MathFloor: Math.floor,
		  Number,
		  NumberIsInteger: Number.isInteger,
		  NumberIsNaN: Number.isNaN,
		  NumberMAX_SAFE_INTEGER: Number.MAX_SAFE_INTEGER,
		  NumberMIN_SAFE_INTEGER: Number.MIN_SAFE_INTEGER,
		  NumberParseInt: Number.parseInt,
		  ObjectDefineProperties(self, props) {
		    return Object.defineProperties(self, props)
		  },
		  ObjectDefineProperty(self, name, prop) {
		    return Object.defineProperty(self, name, prop)
		  },
		  ObjectGetOwnPropertyDescriptor(self, name) {
		    return Object.getOwnPropertyDescriptor(self, name)
		  },
		  ObjectKeys(obj) {
		    return Object.keys(obj)
		  },
		  ObjectSetPrototypeOf(target, proto) {
		    return Object.setPrototypeOf(target, proto)
		  },
		  Promise,
		  PromisePrototypeCatch(self, fn) {
		    return self.catch(fn)
		  },
		  PromisePrototypeThen(self, thenFn, catchFn) {
		    return self.then(thenFn, catchFn)
		  },
		  PromiseReject(err) {
		    return Promise.reject(err)
		  },
		  PromiseResolve(val) {
		    return Promise.resolve(val)
		  },
		  ReflectApply: Reflect.apply,
		  RegExpPrototypeTest(self, value) {
		    return self.test(value)
		  },
		  SafeSet: Set,
		  String,
		  StringPrototypeSlice(self, start, end) {
		    return self.slice(start, end)
		  },
		  StringPrototypeToLowerCase(self) {
		    return self.toLowerCase()
		  },
		  StringPrototypeToUpperCase(self) {
		    return self.toUpperCase()
		  },
		  StringPrototypeTrim(self) {
		    return self.trim()
		  },
		  Symbol,
		  SymbolFor: Symbol.for,
		  SymbolAsyncIterator: Symbol.asyncIterator,
		  SymbolHasInstance: Symbol.hasInstance,
		  SymbolIterator: Symbol.iterator,
		  SymbolDispose: Symbol.dispose || Symbol('Symbol.dispose'),
		  SymbolAsyncDispose: Symbol.asyncDispose || Symbol('Symbol.asyncDispose'),
		  TypedArrayPrototypeSet(self, buf, len) {
		    return self.set(buf, len)
		  },
		  Boolean,
		  Uint8Array
		};
		return primordials;
	}

	var util$1 = {exports: {}};

	var inspect;
	var hasRequiredInspect;

	function requireInspect () {
		if (hasRequiredInspect) return inspect;
		hasRequiredInspect = 1;

		/*
		  This file is a reduced and adapted version of the main lib/internal/util/inspect.js file defined at

		  https://github.com/nodejs/node/blob/main/lib/internal/util/inspect.js

		  Don't try to replace with the original file and keep it up to date with the upstream file.
		*/
		inspect = {
		  format(format, ...args) {
		    // Simplified version of https://nodejs.org/api/util.html#utilformatformat-args
		    return format.replace(/%([sdifj])/g, function (...[_unused, type]) {
		      const replacement = args.shift();
		      if (type === 'f') {
		        return replacement.toFixed(6)
		      } else if (type === 'j') {
		        return JSON.stringify(replacement)
		      } else if (type === 's' && typeof replacement === 'object') {
		        const ctor = replacement.constructor !== Object ? replacement.constructor.name : '';
		        return `${ctor} {}`.trim()
		      } else {
		        return replacement.toString()
		      }
		    })
		  },
		  inspect(value) {
		    // Vastly simplified version of https://nodejs.org/api/util.html#utilinspectobject-options
		    switch (typeof value) {
		      case 'string':
		        if (value.includes("'")) {
		          if (!value.includes('"')) {
		            return `"${value}"`
		          } else if (!value.includes('`') && !value.includes('${')) {
		            return `\`${value}\``
		          }
		        }
		        return `'${value}'`
		      case 'number':
		        if (isNaN(value)) {
		          return 'NaN'
		        } else if (Object.is(value, -0)) {
		          return String(value)
		        }
		        return value
		      case 'bigint':
		        return `${String(value)}n`
		      case 'boolean':
		      case 'undefined':
		        return String(value)
		      case 'object':
		        return '{}'
		    }
		  }
		};
		return inspect;
	}

	var errors;
	var hasRequiredErrors;

	function requireErrors () {
		if (hasRequiredErrors) return errors;
		hasRequiredErrors = 1;

		const { format, inspect } = requireInspect();
		const { AggregateError: CustomAggregateError } = requirePrimordials();

		/*
		  This file is a reduced and adapted version of the main lib/internal/errors.js file defined at

		  https://github.com/nodejs/node/blob/main/lib/internal/errors.js

		  Don't try to replace with the original file and keep it up to date (starting from E(...) definitions)
		  with the upstream file.
		*/

		const AggregateError = globalThis.AggregateError || CustomAggregateError;
		const kIsNodeError = Symbol('kIsNodeError');
		const kTypes = [
		  'string',
		  'function',
		  'number',
		  'object',
		  // Accept 'Function' and 'Object' as alternative to the lower cased version.
		  'Function',
		  'Object',
		  'boolean',
		  'bigint',
		  'symbol'
		];
		const classRegExp = /^([A-Z][a-z0-9]*)+$/;
		const nodeInternalPrefix = '__node_internal_';
		const codes = {};
		function assert(value, message) {
		  if (!value) {
		    throw new codes.ERR_INTERNAL_ASSERTION(message)
		  }
		}

		// Only use this for integers! Decimal numbers do not work with this function.
		function addNumericalSeparator(val) {
		  let res = '';
		  let i = val.length;
		  const start = val[0] === '-' ? 1 : 0;
		  for (; i >= start + 4; i -= 3) {
		    res = `_${val.slice(i - 3, i)}${res}`;
		  }
		  return `${val.slice(0, i)}${res}`
		}
		function getMessage(key, msg, args) {
		  if (typeof msg === 'function') {
		    assert(
		      msg.length <= args.length,
		      // Default options do not count.
		      `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${msg.length}).`
		    );
		    return msg(...args)
		  }
		  const expectedLength = (msg.match(/%[dfijoOs]/g) || []).length;
		  assert(
		    expectedLength === args.length,
		    `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${expectedLength}).`
		  );
		  if (args.length === 0) {
		    return msg
		  }
		  return format(msg, ...args)
		}
		function E(code, message, Base) {
		  if (!Base) {
		    Base = Error;
		  }
		  class NodeError extends Base {
		    constructor(...args) {
		      super(getMessage(code, message, args));
		    }
		    toString() {
		      return `${this.name} [${code}]: ${this.message}`
		    }
		  }
		  Object.defineProperties(NodeError.prototype, {
		    name: {
		      value: Base.name,
		      writable: true,
		      enumerable: false,
		      configurable: true
		    },
		    toString: {
		      value() {
		        return `${this.name} [${code}]: ${this.message}`
		      },
		      writable: true,
		      enumerable: false,
		      configurable: true
		    }
		  });
		  NodeError.prototype.code = code;
		  NodeError.prototype[kIsNodeError] = true;
		  codes[code] = NodeError;
		}
		function hideStackFrames(fn) {
		  // We rename the functions that will be hidden to cut off the stacktrace
		  // at the outermost one
		  const hidden = nodeInternalPrefix + fn.name;
		  Object.defineProperty(fn, 'name', {
		    value: hidden
		  });
		  return fn
		}
		function aggregateTwoErrors(innerError, outerError) {
		  if (innerError && outerError && innerError !== outerError) {
		    if (Array.isArray(outerError.errors)) {
		      // If `outerError` is already an `AggregateError`.
		      outerError.errors.push(innerError);
		      return outerError
		    }
		    const err = new AggregateError([outerError, innerError], outerError.message);
		    err.code = outerError.code;
		    return err
		  }
		  return innerError || outerError
		}
		class AbortError extends Error {
		  constructor(message = 'The operation was aborted', options = undefined) {
		    if (options !== undefined && typeof options !== 'object') {
		      throw new codes.ERR_INVALID_ARG_TYPE('options', 'Object', options)
		    }
		    super(message, options);
		    this.code = 'ABORT_ERR';
		    this.name = 'AbortError';
		  }
		}
		E('ERR_ASSERTION', '%s', Error);
		E(
		  'ERR_INVALID_ARG_TYPE',
		  (name, expected, actual) => {
		    assert(typeof name === 'string', "'name' must be a string");
		    if (!Array.isArray(expected)) {
		      expected = [expected];
		    }
		    let msg = 'The ';
		    if (name.endsWith(' argument')) {
		      // For cases like 'first argument'
		      msg += `${name} `;
		    } else {
		      msg += `"${name}" ${name.includes('.') ? 'property' : 'argument'} `;
		    }
		    msg += 'must be ';
		    const types = [];
		    const instances = [];
		    const other = [];
		    for (const value of expected) {
		      assert(typeof value === 'string', 'All expected entries have to be of type string');
		      if (kTypes.includes(value)) {
		        types.push(value.toLowerCase());
		      } else if (classRegExp.test(value)) {
		        instances.push(value);
		      } else {
		        assert(value !== 'object', 'The value "object" should be written as "Object"');
		        other.push(value);
		      }
		    }

		    // Special handle `object` in case other instances are allowed to outline
		    // the differences between each other.
		    if (instances.length > 0) {
		      const pos = types.indexOf('object');
		      if (pos !== -1) {
		        types.splice(types, pos, 1);
		        instances.push('Object');
		      }
		    }
		    if (types.length > 0) {
		      switch (types.length) {
		        case 1:
		          msg += `of type ${types[0]}`;
		          break
		        case 2:
		          msg += `one of type ${types[0]} or ${types[1]}`;
		          break
		        default: {
		          const last = types.pop();
		          msg += `one of type ${types.join(', ')}, or ${last}`;
		        }
		      }
		      if (instances.length > 0 || other.length > 0) {
		        msg += ' or ';
		      }
		    }
		    if (instances.length > 0) {
		      switch (instances.length) {
		        case 1:
		          msg += `an instance of ${instances[0]}`;
		          break
		        case 2:
		          msg += `an instance of ${instances[0]} or ${instances[1]}`;
		          break
		        default: {
		          const last = instances.pop();
		          msg += `an instance of ${instances.join(', ')}, or ${last}`;
		        }
		      }
		      if (other.length > 0) {
		        msg += ' or ';
		      }
		    }
		    switch (other.length) {
		      case 0:
		        break
		      case 1:
		        if (other[0].toLowerCase() !== other[0]) {
		          msg += 'an ';
		        }
		        msg += `${other[0]}`;
		        break
		      case 2:
		        msg += `one of ${other[0]} or ${other[1]}`;
		        break
		      default: {
		        const last = other.pop();
		        msg += `one of ${other.join(', ')}, or ${last}`;
		      }
		    }
		    if (actual == null) {
		      msg += `. Received ${actual}`;
		    } else if (typeof actual === 'function' && actual.name) {
		      msg += `. Received function ${actual.name}`;
		    } else if (typeof actual === 'object') {
		      var _actual$constructor;
		      if (
		        (_actual$constructor = actual.constructor) !== null &&
		        _actual$constructor !== undefined &&
		        _actual$constructor.name
		      ) {
		        msg += `. Received an instance of ${actual.constructor.name}`;
		      } else {
		        const inspected = inspect(actual, {
		          depth: -1
		        });
		        msg += `. Received ${inspected}`;
		      }
		    } else {
		      let inspected = inspect(actual, {
		        colors: false
		      });
		      if (inspected.length > 25) {
		        inspected = `${inspected.slice(0, 25)}...`;
		      }
		      msg += `. Received type ${typeof actual} (${inspected})`;
		    }
		    return msg
		  },
		  TypeError
		);
		E(
		  'ERR_INVALID_ARG_VALUE',
		  (name, value, reason = 'is invalid') => {
		    let inspected = inspect(value);
		    if (inspected.length > 128) {
		      inspected = inspected.slice(0, 128) + '...';
		    }
		    const type = name.includes('.') ? 'property' : 'argument';
		    return `The ${type} '${name}' ${reason}. Received ${inspected}`
		  },
		  TypeError
		);
		E(
		  'ERR_INVALID_RETURN_VALUE',
		  (input, name, value) => {
		    var _value$constructor;
		    const type =
		      value !== null &&
		      value !== undefined &&
		      (_value$constructor = value.constructor) !== null &&
		      _value$constructor !== undefined &&
		      _value$constructor.name
		        ? `instance of ${value.constructor.name}`
		        : `type ${typeof value}`;
		    return `Expected ${input} to be returned from the "${name}"` + ` function but got ${type}.`
		  },
		  TypeError
		);
		E(
		  'ERR_MISSING_ARGS',
		  (...args) => {
		    assert(args.length > 0, 'At least one arg needs to be specified');
		    let msg;
		    const len = args.length;
		    args = (Array.isArray(args) ? args : [args]).map((a) => `"${a}"`).join(' or ');
		    switch (len) {
		      case 1:
		        msg += `The ${args[0]} argument`;
		        break
		      case 2:
		        msg += `The ${args[0]} and ${args[1]} arguments`;
		        break
		      default:
		        {
		          const last = args.pop();
		          msg += `The ${args.join(', ')}, and ${last} arguments`;
		        }
		        break
		    }
		    return `${msg} must be specified`
		  },
		  TypeError
		);
		E(
		  'ERR_OUT_OF_RANGE',
		  (str, range, input) => {
		    assert(range, 'Missing "range" argument');
		    let received;
		    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
		      received = addNumericalSeparator(String(input));
		    } else if (typeof input === 'bigint') {
		      received = String(input);
		      const limit = BigInt(2) ** BigInt(32);
		      if (input > limit || input < -limit) {
		        received = addNumericalSeparator(received);
		      }
		      received += 'n';
		    } else {
		      received = inspect(input);
		    }
		    return `The value of "${str}" is out of range. It must be ${range}. Received ${received}`
		  },
		  RangeError
		);
		E('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times', Error);
		E('ERR_METHOD_NOT_IMPLEMENTED', 'The %s method is not implemented', Error);
		E('ERR_STREAM_ALREADY_FINISHED', 'Cannot call %s after a stream was finished', Error);
		E('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable', Error);
		E('ERR_STREAM_DESTROYED', 'Cannot call %s after a stream was destroyed', Error);
		E('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);
		E('ERR_STREAM_PREMATURE_CLOSE', 'Premature close', Error);
		E('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF', Error);
		E('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event', Error);
		E('ERR_STREAM_WRITE_AFTER_END', 'write after end', Error);
		E('ERR_UNKNOWN_ENCODING', 'Unknown encoding: %s', TypeError);
		errors = {
		  AbortError,
		  aggregateTwoErrors: hideStackFrames(aggregateTwoErrors),
		  hideStackFrames,
		  codes
		};
		return errors;
	}

	var browser$1 = {exports: {}};

	/*globals self, window */

	var hasRequiredBrowser$2;

	function requireBrowser$2 () {
		if (hasRequiredBrowser$2) return browser$1.exports;
		hasRequiredBrowser$2 = 1;

		/*eslint-disable @mysticatea/prettier */
		const { AbortController, AbortSignal } =
		    typeof self !== "undefined" ? self :
		    typeof window !== "undefined" ? window :
		    /* otherwise */ undefined;
		/*eslint-enable @mysticatea/prettier */

		browser$1.exports = AbortController;
		browser$1.exports.AbortSignal = AbortSignal;
		browser$1.exports.default = AbortController;
		return browser$1.exports;
	}

	var events$1 = {exports: {}};

	var hasRequiredEvents$1;

	function requireEvents$1 () {
		if (hasRequiredEvents$1) return events$1.exports;
		hasRequiredEvents$1 = 1;

		var R = typeof Reflect === 'object' ? Reflect : null;
		var ReflectApply = R && typeof R.apply === 'function'
		  ? R.apply
		  : function ReflectApply(target, receiver, args) {
		    return Function.prototype.apply.call(target, receiver, args);
		  };

		var ReflectOwnKeys;
		if (R && typeof R.ownKeys === 'function') {
		  ReflectOwnKeys = R.ownKeys;
		} else if (Object.getOwnPropertySymbols) {
		  ReflectOwnKeys = function ReflectOwnKeys(target) {
		    return Object.getOwnPropertyNames(target)
		      .concat(Object.getOwnPropertySymbols(target));
		  };
		} else {
		  ReflectOwnKeys = function ReflectOwnKeys(target) {
		    return Object.getOwnPropertyNames(target);
		  };
		}

		function ProcessEmitWarning(warning) {
		  if (console && console.warn) console.warn(warning);
		}

		var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
		  return value !== value;
		};

		function EventEmitter() {
		  EventEmitter.init.call(this);
		}
		events$1.exports = EventEmitter;
		events$1.exports.once = once;

		// Backwards-compat with node 0.10.x
		EventEmitter.EventEmitter = EventEmitter;

		EventEmitter.prototype._events = undefined;
		EventEmitter.prototype._eventsCount = 0;
		EventEmitter.prototype._maxListeners = undefined;

		// By default EventEmitters will print a warning if more than 10 listeners are
		// added to it. This is a useful default which helps finding memory leaks.
		var defaultMaxListeners = 10;

		function checkListener(listener) {
		  if (typeof listener !== 'function') {
		    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
		  }
		}

		Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
		  enumerable: true,
		  get: function() {
		    return defaultMaxListeners;
		  },
		  set: function(arg) {
		    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
		      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
		    }
		    defaultMaxListeners = arg;
		  }
		});

		EventEmitter.init = function() {

		  if (this._events === undefined ||
		      this._events === Object.getPrototypeOf(this)._events) {
		    this._events = Object.create(null);
		    this._eventsCount = 0;
		  }

		  this._maxListeners = this._maxListeners || undefined;
		};

		// Obviously not all Emitters should be limited to 10. This function allows
		// that to be increased. Set to zero for unlimited.
		EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
		  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
		    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
		  }
		  this._maxListeners = n;
		  return this;
		};

		function _getMaxListeners(that) {
		  if (that._maxListeners === undefined)
		    return EventEmitter.defaultMaxListeners;
		  return that._maxListeners;
		}

		EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
		  return _getMaxListeners(this);
		};

		EventEmitter.prototype.emit = function emit(type) {
		  var args = [];
		  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
		  var doError = (type === 'error');

		  var events = this._events;
		  if (events !== undefined)
		    doError = (doError && events.error === undefined);
		  else if (!doError)
		    return false;

		  // If there is no 'error' event listener then throw.
		  if (doError) {
		    var er;
		    if (args.length > 0)
		      er = args[0];
		    if (er instanceof Error) {
		      // Note: The comments on the `throw` lines are intentional, they show
		      // up in Node's output if this results in an unhandled exception.
		      throw er; // Unhandled 'error' event
		    }
		    // At least give some kind of context to the user
		    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
		    err.context = er;
		    throw err; // Unhandled 'error' event
		  }

		  var handler = events[type];

		  if (handler === undefined)
		    return false;

		  if (typeof handler === 'function') {
		    ReflectApply(handler, this, args);
		  } else {
		    var len = handler.length;
		    var listeners = arrayClone(handler, len);
		    for (var i = 0; i < len; ++i)
		      ReflectApply(listeners[i], this, args);
		  }

		  return true;
		};

		function _addListener(target, type, listener, prepend) {
		  var m;
		  var events;
		  var existing;

		  checkListener(listener);

		  events = target._events;
		  if (events === undefined) {
		    events = target._events = Object.create(null);
		    target._eventsCount = 0;
		  } else {
		    // To avoid recursion in the case that type === "newListener"! Before
		    // adding it to the listeners, first emit "newListener".
		    if (events.newListener !== undefined) {
		      target.emit('newListener', type,
		                  listener.listener ? listener.listener : listener);

		      // Re-assign `events` because a newListener handler could have caused the
		      // this._events to be assigned to a new object
		      events = target._events;
		    }
		    existing = events[type];
		  }

		  if (existing === undefined) {
		    // Optimize the case of one listener. Don't need the extra array object.
		    existing = events[type] = listener;
		    ++target._eventsCount;
		  } else {
		    if (typeof existing === 'function') {
		      // Adding the second element, need to change to array.
		      existing = events[type] =
		        prepend ? [listener, existing] : [existing, listener];
		      // If we've already got an array, just append.
		    } else if (prepend) {
		      existing.unshift(listener);
		    } else {
		      existing.push(listener);
		    }

		    // Check for listener leak
		    m = _getMaxListeners(target);
		    if (m > 0 && existing.length > m && !existing.warned) {
		      existing.warned = true;
		      // No error code for this since it is a Warning
		      // eslint-disable-next-line no-restricted-syntax
		      var w = new Error('Possible EventEmitter memory leak detected. ' +
		                          existing.length + ' ' + String(type) + ' listeners ' +
		                          'added. Use emitter.setMaxListeners() to ' +
		                          'increase limit');
		      w.name = 'MaxListenersExceededWarning';
		      w.emitter = target;
		      w.type = type;
		      w.count = existing.length;
		      ProcessEmitWarning(w);
		    }
		  }

		  return target;
		}

		EventEmitter.prototype.addListener = function addListener(type, listener) {
		  return _addListener(this, type, listener, false);
		};

		EventEmitter.prototype.on = EventEmitter.prototype.addListener;

		EventEmitter.prototype.prependListener =
		    function prependListener(type, listener) {
		      return _addListener(this, type, listener, true);
		    };

		function onceWrapper() {
		  if (!this.fired) {
		    this.target.removeListener(this.type, this.wrapFn);
		    this.fired = true;
		    if (arguments.length === 0)
		      return this.listener.call(this.target);
		    return this.listener.apply(this.target, arguments);
		  }
		}

		function _onceWrap(target, type, listener) {
		  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
		  var wrapped = onceWrapper.bind(state);
		  wrapped.listener = listener;
		  state.wrapFn = wrapped;
		  return wrapped;
		}

		EventEmitter.prototype.once = function once(type, listener) {
		  checkListener(listener);
		  this.on(type, _onceWrap(this, type, listener));
		  return this;
		};

		EventEmitter.prototype.prependOnceListener =
		    function prependOnceListener(type, listener) {
		      checkListener(listener);
		      this.prependListener(type, _onceWrap(this, type, listener));
		      return this;
		    };

		// Emits a 'removeListener' event if and only if the listener was removed.
		EventEmitter.prototype.removeListener =
		    function removeListener(type, listener) {
		      var list, events, position, i, originalListener;

		      checkListener(listener);

		      events = this._events;
		      if (events === undefined)
		        return this;

		      list = events[type];
		      if (list === undefined)
		        return this;

		      if (list === listener || list.listener === listener) {
		        if (--this._eventsCount === 0)
		          this._events = Object.create(null);
		        else {
		          delete events[type];
		          if (events.removeListener)
		            this.emit('removeListener', type, list.listener || listener);
		        }
		      } else if (typeof list !== 'function') {
		        position = -1;

		        for (i = list.length - 1; i >= 0; i--) {
		          if (list[i] === listener || list[i].listener === listener) {
		            originalListener = list[i].listener;
		            position = i;
		            break;
		          }
		        }

		        if (position < 0)
		          return this;

		        if (position === 0)
		          list.shift();
		        else {
		          spliceOne(list, position);
		        }

		        if (list.length === 1)
		          events[type] = list[0];

		        if (events.removeListener !== undefined)
		          this.emit('removeListener', type, originalListener || listener);
		      }

		      return this;
		    };

		EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

		EventEmitter.prototype.removeAllListeners =
		    function removeAllListeners(type) {
		      var listeners, events, i;

		      events = this._events;
		      if (events === undefined)
		        return this;

		      // not listening for removeListener, no need to emit
		      if (events.removeListener === undefined) {
		        if (arguments.length === 0) {
		          this._events = Object.create(null);
		          this._eventsCount = 0;
		        } else if (events[type] !== undefined) {
		          if (--this._eventsCount === 0)
		            this._events = Object.create(null);
		          else
		            delete events[type];
		        }
		        return this;
		      }

		      // emit removeListener for all listeners on all events
		      if (arguments.length === 0) {
		        var keys = Object.keys(events);
		        var key;
		        for (i = 0; i < keys.length; ++i) {
		          key = keys[i];
		          if (key === 'removeListener') continue;
		          this.removeAllListeners(key);
		        }
		        this.removeAllListeners('removeListener');
		        this._events = Object.create(null);
		        this._eventsCount = 0;
		        return this;
		      }

		      listeners = events[type];

		      if (typeof listeners === 'function') {
		        this.removeListener(type, listeners);
		      } else if (listeners !== undefined) {
		        // LIFO order
		        for (i = listeners.length - 1; i >= 0; i--) {
		          this.removeListener(type, listeners[i]);
		        }
		      }

		      return this;
		    };

		function _listeners(target, type, unwrap) {
		  var events = target._events;

		  if (events === undefined)
		    return [];

		  var evlistener = events[type];
		  if (evlistener === undefined)
		    return [];

		  if (typeof evlistener === 'function')
		    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

		  return unwrap ?
		    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
		}

		EventEmitter.prototype.listeners = function listeners(type) {
		  return _listeners(this, type, true);
		};

		EventEmitter.prototype.rawListeners = function rawListeners(type) {
		  return _listeners(this, type, false);
		};

		EventEmitter.listenerCount = function(emitter, type) {
		  if (typeof emitter.listenerCount === 'function') {
		    return emitter.listenerCount(type);
		  } else {
		    return listenerCount.call(emitter, type);
		  }
		};

		EventEmitter.prototype.listenerCount = listenerCount;
		function listenerCount(type) {
		  var events = this._events;

		  if (events !== undefined) {
		    var evlistener = events[type];

		    if (typeof evlistener === 'function') {
		      return 1;
		    } else if (evlistener !== undefined) {
		      return evlistener.length;
		    }
		  }

		  return 0;
		}

		EventEmitter.prototype.eventNames = function eventNames() {
		  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
		};

		function arrayClone(arr, n) {
		  var copy = new Array(n);
		  for (var i = 0; i < n; ++i)
		    copy[i] = arr[i];
		  return copy;
		}

		function spliceOne(list, index) {
		  for (; index + 1 < list.length; index++)
		    list[index] = list[index + 1];
		  list.pop();
		}

		function unwrapListeners(arr) {
		  var ret = new Array(arr.length);
		  for (var i = 0; i < ret.length; ++i) {
		    ret[i] = arr[i].listener || arr[i];
		  }
		  return ret;
		}

		function once(emitter, name) {
		  return new Promise(function (resolve, reject) {
		    function errorListener(err) {
		      emitter.removeListener(name, resolver);
		      reject(err);
		    }

		    function resolver() {
		      if (typeof emitter.removeListener === 'function') {
		        emitter.removeListener('error', errorListener);
		      }
		      resolve([].slice.call(arguments));
		    }
		    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
		    if (name !== 'error') {
		      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
		    }
		  });
		}

		function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
		  if (typeof emitter.on === 'function') {
		    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
		  }
		}

		function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
		  if (typeof emitter.on === 'function') {
		    if (flags.once) {
		      emitter.once(name, listener);
		    } else {
		      emitter.on(name, listener);
		    }
		  } else if (typeof emitter.addEventListener === 'function') {
		    // EventTarget does not have `error` event semantics like Node
		    // EventEmitters, we do not listen for `error` events here.
		    emitter.addEventListener(name, function wrapListener(arg) {
		      // IE does not have builtin `{ once: true }` support so we
		      // have to do it manually.
		      if (flags.once) {
		        emitter.removeEventListener(name, wrapListener);
		      }
		      listener(arg);
		    });
		  } else {
		    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
		  }
		}
		return events$1.exports;
	}

	var hasRequiredUtil$1;

	function requireUtil$1 () {
		if (hasRequiredUtil$1) return util$1.exports;
		hasRequiredUtil$1 = 1;
		(function (module) {

			const bufferModule = requireBuffer();
			const { format, inspect } = requireInspect();
			const {
			  codes: { ERR_INVALID_ARG_TYPE }
			} = requireErrors();
			const { kResistStopPropagation, AggregateError, SymbolDispose } = requirePrimordials();
			const AbortSignal = globalThis.AbortSignal || requireBrowser$2().AbortSignal;
			const AbortController = globalThis.AbortController || requireBrowser$2().AbortController;
			const AsyncFunction = Object.getPrototypeOf(async function () {}).constructor;
			const Blob = globalThis.Blob || bufferModule.Blob;
			/* eslint-disable indent */
			const isBlob =
			  typeof Blob !== 'undefined'
			    ? function isBlob(b) {
			        // eslint-disable-next-line indent
			        return b instanceof Blob
			      }
			    : function isBlob(b) {
			        return false
			      };
			/* eslint-enable indent */

			const validateAbortSignal = (signal, name) => {
			  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {
			    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)
			  }
			};
			const validateFunction = (value, name) => {
			  if (typeof value !== 'function') {
			    throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)
			  }
			};
			module.exports = {
			  AggregateError,
			  kEmptyObject: Object.freeze({}),
			  once(callback) {
			    let called = false;
			    return function (...args) {
			      if (called) {
			        return
			      }
			      called = true;
			      callback.apply(this, args);
			    }
			  },
			  createDeferredPromise: function () {
			    let resolve;
			    let reject;

			    // eslint-disable-next-line promise/param-names
			    const promise = new Promise((res, rej) => {
			      resolve = res;
			      reject = rej;
			    });
			    return {
			      promise,
			      resolve,
			      reject
			    }
			  },
			  promisify(fn) {
			    return new Promise((resolve, reject) => {
			      fn((err, ...args) => {
			        if (err) {
			          return reject(err)
			        }
			        return resolve(...args)
			      });
			    })
			  },
			  debuglog() {
			    return function () {}
			  },
			  format,
			  inspect,
			  types: {
			    isAsyncFunction(fn) {
			      return fn instanceof AsyncFunction
			    },
			    isArrayBufferView(arr) {
			      return ArrayBuffer.isView(arr)
			    }
			  },
			  isBlob,
			  deprecate(fn, message) {
			    return fn
			  },
			  addAbortListener:
			    requireEvents$1().addAbortListener ||
			    function addAbortListener(signal, listener) {
			      if (signal === undefined) {
			        throw new ERR_INVALID_ARG_TYPE('signal', 'AbortSignal', signal)
			      }
			      validateAbortSignal(signal, 'signal');
			      validateFunction(listener, 'listener');
			      let removeEventListener;
			      if (signal.aborted) {
			        queueMicrotask(() => listener());
			      } else {
			        signal.addEventListener('abort', listener, {
			          __proto__: null,
			          once: true,
			          [kResistStopPropagation]: true
			        });
			        removeEventListener = () => {
			          signal.removeEventListener('abort', listener);
			        };
			      }
			      return {
			        __proto__: null,
			        [SymbolDispose]() {
			          var _removeEventListener
			          ;(_removeEventListener = removeEventListener) === null || _removeEventListener === undefined
			            ? undefined
			            : _removeEventListener();
			        }
			      }
			    },
			  AbortSignalAny:
			    AbortSignal.any ||
			    function AbortSignalAny(signals) {
			      // Fast path if there is only one signal.
			      if (signals.length === 1) {
			        return signals[0]
			      }
			      const ac = new AbortController();
			      const abort = () => ac.abort();
			      signals.forEach((signal) => {
			        validateAbortSignal(signal, 'signals');
			        signal.addEventListener('abort', abort, {
			          once: true
			        });
			      });
			      ac.signal.addEventListener(
			        'abort',
			        () => {
			          signals.forEach((signal) => signal.removeEventListener('abort', abort));
			        },
			        {
			          once: true
			        }
			      );
			      return ac.signal
			    }
			};
			module.exports.promisify.custom = Symbol.for('nodejs.util.promisify.custom'); 
		} (util$1));
		return util$1.exports;
	}

	var operators = {};

	/* eslint jsdoc/require-jsdoc: "error" */

	var validators;
	var hasRequiredValidators;

	function requireValidators () {
		if (hasRequiredValidators) return validators;
		hasRequiredValidators = 1;

		const {
		  ArrayIsArray,
		  ArrayPrototypeIncludes,
		  ArrayPrototypeJoin,
		  ArrayPrototypeMap,
		  NumberIsInteger,
		  NumberIsNaN,
		  NumberMAX_SAFE_INTEGER,
		  NumberMIN_SAFE_INTEGER,
		  NumberParseInt,
		  ObjectPrototypeHasOwnProperty,
		  RegExpPrototypeExec,
		  String,
		  StringPrototypeToUpperCase,
		  StringPrototypeTrim
		} = requirePrimordials();
		const {
		  hideStackFrames,
		  codes: { ERR_SOCKET_BAD_PORT, ERR_INVALID_ARG_TYPE, ERR_INVALID_ARG_VALUE, ERR_OUT_OF_RANGE, ERR_UNKNOWN_SIGNAL }
		} = requireErrors();
		const { normalizeEncoding } = requireUtil$1();
		const { isAsyncFunction, isArrayBufferView } = requireUtil$1().types;
		const signals = {};

		/**
		 * @param {*} value
		 * @returns {boolean}
		 */
		function isInt32(value) {
		  return value === (value | 0)
		}

		/**
		 * @param {*} value
		 * @returns {boolean}
		 */
		function isUint32(value) {
		  return value === value >>> 0
		}
		const octalReg = /^[0-7]+$/;
		const modeDesc = 'must be a 32-bit unsigned integer or an octal string';

		/**
		 * Parse and validate values that will be converted into mode_t (the S_*
		 * constants). Only valid numbers and octal strings are allowed. They could be
		 * converted to 32-bit unsigned integers or non-negative signed integers in the
		 * C++ land, but any value higher than 0o777 will result in platform-specific
		 * behaviors.
		 * @param {*} value Values to be validated
		 * @param {string} name Name of the argument
		 * @param {number} [def] If specified, will be returned for invalid values
		 * @returns {number}
		 */
		function parseFileMode(value, name, def) {
		  if (typeof value === 'undefined') {
		    value = def;
		  }
		  if (typeof value === 'string') {
		    if (RegExpPrototypeExec(octalReg, value) === null) {
		      throw new ERR_INVALID_ARG_VALUE(name, value, modeDesc)
		    }
		    value = NumberParseInt(value, 8);
		  }
		  validateUint32(value, name);
		  return value
		}

		/**
		 * @callback validateInteger
		 * @param {*} value
		 * @param {string} name
		 * @param {number} [min]
		 * @param {number} [max]
		 * @returns {asserts value is number}
		 */

		/** @type {validateInteger} */
		const validateInteger = hideStackFrames((value, name, min = NumberMIN_SAFE_INTEGER, max = NumberMAX_SAFE_INTEGER) => {
		  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)
		  if (!NumberIsInteger(value)) throw new ERR_OUT_OF_RANGE(name, 'an integer', value)
		  if (value < min || value > max) throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)
		});

		/**
		 * @callback validateInt32
		 * @param {*} value
		 * @param {string} name
		 * @param {number} [min]
		 * @param {number} [max]
		 * @returns {asserts value is number}
		 */

		/** @type {validateInt32} */
		const validateInt32 = hideStackFrames((value, name, min = -2147483648, max = 2147483647) => {
		  // The defaults for min and max correspond to the limits of 32-bit integers.
		  if (typeof value !== 'number') {
		    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)
		  }
		  if (!NumberIsInteger(value)) {
		    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)
		  }
		  if (value < min || value > max) {
		    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)
		  }
		});

		/**
		 * @callback validateUint32
		 * @param {*} value
		 * @param {string} name
		 * @param {number|boolean} [positive=false]
		 * @returns {asserts value is number}
		 */

		/** @type {validateUint32} */
		const validateUint32 = hideStackFrames((value, name, positive = false) => {
		  if (typeof value !== 'number') {
		    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)
		  }
		  if (!NumberIsInteger(value)) {
		    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)
		  }
		  const min = positive ? 1 : 0;
		  // 2 ** 32 === 4294967296
		  const max = 4294967295;
		  if (value < min || value > max) {
		    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)
		  }
		});

		/**
		 * @callback validateString
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is string}
		 */

		/** @type {validateString} */
		function validateString(value, name) {
		  if (typeof value !== 'string') throw new ERR_INVALID_ARG_TYPE(name, 'string', value)
		}

		/**
		 * @callback validateNumber
		 * @param {*} value
		 * @param {string} name
		 * @param {number} [min]
		 * @param {number} [max]
		 * @returns {asserts value is number}
		 */

		/** @type {validateNumber} */
		function validateNumber(value, name, min = undefined, max) {
		  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)
		  if (
		    (min != null && value < min) ||
		    (max != null && value > max) ||
		    ((min != null || max != null) && NumberIsNaN(value))
		  ) {
		    throw new ERR_OUT_OF_RANGE(
		      name,
		      `${min != null ? `>= ${min}` : ''}${min != null && max != null ? ' && ' : ''}${max != null ? `<= ${max}` : ''}`,
		      value
		    )
		  }
		}

		/**
		 * @callback validateOneOf
		 * @template T
		 * @param {T} value
		 * @param {string} name
		 * @param {T[]} oneOf
		 */

		/** @type {validateOneOf} */
		const validateOneOf = hideStackFrames((value, name, oneOf) => {
		  if (!ArrayPrototypeIncludes(oneOf, value)) {
		    const allowed = ArrayPrototypeJoin(
		      ArrayPrototypeMap(oneOf, (v) => (typeof v === 'string' ? `'${v}'` : String(v))),
		      ', '
		    );
		    const reason = 'must be one of: ' + allowed;
		    throw new ERR_INVALID_ARG_VALUE(name, value, reason)
		  }
		});

		/**
		 * @callback validateBoolean
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is boolean}
		 */

		/** @type {validateBoolean} */
		function validateBoolean(value, name) {
		  if (typeof value !== 'boolean') throw new ERR_INVALID_ARG_TYPE(name, 'boolean', value)
		}

		/**
		 * @param {any} options
		 * @param {string} key
		 * @param {boolean} defaultValue
		 * @returns {boolean}
		 */
		function getOwnPropertyValueOrDefault(options, key, defaultValue) {
		  return options == null || !ObjectPrototypeHasOwnProperty(options, key) ? defaultValue : options[key]
		}

		/**
		 * @callback validateObject
		 * @param {*} value
		 * @param {string} name
		 * @param {{
		 *   allowArray?: boolean,
		 *   allowFunction?: boolean,
		 *   nullable?: boolean
		 * }} [options]
		 */

		/** @type {validateObject} */
		const validateObject = hideStackFrames((value, name, options = null) => {
		  const allowArray = getOwnPropertyValueOrDefault(options, 'allowArray', false);
		  const allowFunction = getOwnPropertyValueOrDefault(options, 'allowFunction', false);
		  const nullable = getOwnPropertyValueOrDefault(options, 'nullable', false);
		  if (
		    (!nullable && value === null) ||
		    (!allowArray && ArrayIsArray(value)) ||
		    (typeof value !== 'object' && (!allowFunction || typeof value !== 'function'))
		  ) {
		    throw new ERR_INVALID_ARG_TYPE(name, 'Object', value)
		  }
		});

		/**
		 * @callback validateDictionary - We are using the Web IDL Standard definition
		 *                                of "dictionary" here, which means any value
		 *                                whose Type is either Undefined, Null, or
		 *                                Object (which includes functions).
		 * @param {*} value
		 * @param {string} name
		 * @see https://webidl.spec.whatwg.org/#es-dictionary
		 * @see https://tc39.es/ecma262/#table-typeof-operator-results
		 */

		/** @type {validateDictionary} */
		const validateDictionary = hideStackFrames((value, name) => {
		  if (value != null && typeof value !== 'object' && typeof value !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE(name, 'a dictionary', value)
		  }
		});

		/**
		 * @callback validateArray
		 * @param {*} value
		 * @param {string} name
		 * @param {number} [minLength]
		 * @returns {asserts value is any[]}
		 */

		/** @type {validateArray} */
		const validateArray = hideStackFrames((value, name, minLength = 0) => {
		  if (!ArrayIsArray(value)) {
		    throw new ERR_INVALID_ARG_TYPE(name, 'Array', value)
		  }
		  if (value.length < minLength) {
		    const reason = `must be longer than ${minLength}`;
		    throw new ERR_INVALID_ARG_VALUE(name, value, reason)
		  }
		});

		/**
		 * @callback validateStringArray
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is string[]}
		 */

		/** @type {validateStringArray} */
		function validateStringArray(value, name) {
		  validateArray(value, name);
		  for (let i = 0; i < value.length; i++) {
		    validateString(value[i], `${name}[${i}]`);
		  }
		}

		/**
		 * @callback validateBooleanArray
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is boolean[]}
		 */

		/** @type {validateBooleanArray} */
		function validateBooleanArray(value, name) {
		  validateArray(value, name);
		  for (let i = 0; i < value.length; i++) {
		    validateBoolean(value[i], `${name}[${i}]`);
		  }
		}

		/**
		 * @callback validateAbortSignalArray
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is AbortSignal[]}
		 */

		/** @type {validateAbortSignalArray} */
		function validateAbortSignalArray(value, name) {
		  validateArray(value, name);
		  for (let i = 0; i < value.length; i++) {
		    const signal = value[i];
		    const indexedName = `${name}[${i}]`;
		    if (signal == null) {
		      throw new ERR_INVALID_ARG_TYPE(indexedName, 'AbortSignal', signal)
		    }
		    validateAbortSignal(signal, indexedName);
		  }
		}

		/**
		 * @param {*} signal
		 * @param {string} [name='signal']
		 * @returns {asserts signal is keyof signals}
		 */
		function validateSignalName(signal, name = 'signal') {
		  validateString(signal, name);
		  if (signals[signal] === undefined) {
		    if (signals[StringPrototypeToUpperCase(signal)] !== undefined) {
		      throw new ERR_UNKNOWN_SIGNAL(signal + ' (signals must use all capital letters)')
		    }
		    throw new ERR_UNKNOWN_SIGNAL(signal)
		  }
		}

		/**
		 * @callback validateBuffer
		 * @param {*} buffer
		 * @param {string} [name='buffer']
		 * @returns {asserts buffer is ArrayBufferView}
		 */

		/** @type {validateBuffer} */
		const validateBuffer = hideStackFrames((buffer, name = 'buffer') => {
		  if (!isArrayBufferView(buffer)) {
		    throw new ERR_INVALID_ARG_TYPE(name, ['Buffer', 'TypedArray', 'DataView'], buffer)
		  }
		});

		/**
		 * @param {string} data
		 * @param {string} encoding
		 */
		function validateEncoding(data, encoding) {
		  const normalizedEncoding = normalizeEncoding(encoding);
		  const length = data.length;
		  if (normalizedEncoding === 'hex' && length % 2 !== 0) {
		    throw new ERR_INVALID_ARG_VALUE('encoding', encoding, `is invalid for data of length ${length}`)
		  }
		}

		/**
		 * Check that the port number is not NaN when coerced to a number,
		 * is an integer and that it falls within the legal range of port numbers.
		 * @param {*} port
		 * @param {string} [name='Port']
		 * @param {boolean} [allowZero=true]
		 * @returns {number}
		 */
		function validatePort(port, name = 'Port', allowZero = true) {
		  if (
		    (typeof port !== 'number' && typeof port !== 'string') ||
		    (typeof port === 'string' && StringPrototypeTrim(port).length === 0) ||
		    +port !== +port >>> 0 ||
		    port > 0xffff ||
		    (port === 0 && !allowZero)
		  ) {
		    throw new ERR_SOCKET_BAD_PORT(name, port, allowZero)
		  }
		  return port | 0
		}

		/**
		 * @callback validateAbortSignal
		 * @param {*} signal
		 * @param {string} name
		 */

		/** @type {validateAbortSignal} */
		const validateAbortSignal = hideStackFrames((signal, name) => {
		  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {
		    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)
		  }
		});

		/**
		 * @callback validateFunction
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is Function}
		 */

		/** @type {validateFunction} */
		const validateFunction = hideStackFrames((value, name) => {
		  if (typeof value !== 'function') throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)
		});

		/**
		 * @callback validatePlainFunction
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is Function}
		 */

		/** @type {validatePlainFunction} */
		const validatePlainFunction = hideStackFrames((value, name) => {
		  if (typeof value !== 'function' || isAsyncFunction(value)) throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)
		});

		/**
		 * @callback validateUndefined
		 * @param {*} value
		 * @param {string} name
		 * @returns {asserts value is undefined}
		 */

		/** @type {validateUndefined} */
		const validateUndefined = hideStackFrames((value, name) => {
		  if (value !== undefined) throw new ERR_INVALID_ARG_TYPE(name, 'undefined', value)
		});

		/**
		 * @template T
		 * @param {T} value
		 * @param {string} name
		 * @param {T[]} union
		 */
		function validateUnion(value, name, union) {
		  if (!ArrayPrototypeIncludes(union, value)) {
		    throw new ERR_INVALID_ARG_TYPE(name, `('${ArrayPrototypeJoin(union, '|')}')`, value)
		  }
		}

		/*
		  The rules for the Link header field are described here:
		  https://www.rfc-editor.org/rfc/rfc8288.html#section-3

		  This regex validates any string surrounded by angle brackets
		  (not necessarily a valid URI reference) followed by zero or more
		  link-params separated by semicolons.
		*/
		const linkValueRegExp = /^(?:<[^>]*>)(?:\s*;\s*[^;"\s]+(?:=(")?[^;"\s]*\1)?)*$/;

		/**
		 * @param {any} value
		 * @param {string} name
		 */
		function validateLinkHeaderFormat(value, name) {
		  if (typeof value === 'undefined' || !RegExpPrototypeExec(linkValueRegExp, value)) {
		    throw new ERR_INVALID_ARG_VALUE(
		      name,
		      value,
		      'must be an array or string of format "</styles.css>; rel=preload; as=style"'
		    )
		  }
		}

		/**
		 * @param {any} hints
		 * @return {string}
		 */
		function validateLinkHeaderValue(hints) {
		  if (typeof hints === 'string') {
		    validateLinkHeaderFormat(hints, 'hints');
		    return hints
		  } else if (ArrayIsArray(hints)) {
		    const hintsLength = hints.length;
		    let result = '';
		    if (hintsLength === 0) {
		      return result
		    }
		    for (let i = 0; i < hintsLength; i++) {
		      const link = hints[i];
		      validateLinkHeaderFormat(link, 'hints');
		      result += link;
		      if (i !== hintsLength - 1) {
		        result += ', ';
		      }
		    }
		    return result
		  }
		  throw new ERR_INVALID_ARG_VALUE(
		    'hints',
		    hints,
		    'must be an array or string of format "</styles.css>; rel=preload; as=style"'
		  )
		}
		validators = {
		  isInt32,
		  isUint32,
		  parseFileMode,
		  validateArray,
		  validateStringArray,
		  validateBooleanArray,
		  validateAbortSignalArray,
		  validateBoolean,
		  validateBuffer,
		  validateDictionary,
		  validateEncoding,
		  validateFunction,
		  validateInt32,
		  validateInteger,
		  validateNumber,
		  validateObject,
		  validateOneOf,
		  validatePlainFunction,
		  validatePort,
		  validateSignalName,
		  validateString,
		  validateUint32,
		  validateUndefined,
		  validateUnion,
		  validateAbortSignal,
		  validateLinkHeaderValue
		};
		return validators;
	}

	var endOfStream = {exports: {}};

	var browser = {exports: {}};

	var hasRequiredBrowser$1;

	function requireBrowser$1 () {
		if (hasRequiredBrowser$1) return browser.exports;
		hasRequiredBrowser$1 = 1;
		// shim for using process in browser
		var process = browser.exports = {};

		// cached from whatever global is present so that test runners that stub it
		// don't break things.  But we need to wrap it in a try catch in case it is
		// wrapped in strict mode code which doesn't define any globals.  It's inside a
		// function because try/catches deoptimize in certain engines.

		var cachedSetTimeout;
		var cachedClearTimeout;

		function defaultSetTimout() {
		    throw new Error('setTimeout has not been defined');
		}
		function defaultClearTimeout () {
		    throw new Error('clearTimeout has not been defined');
		}
		(function () {
		    try {
		        if (typeof setTimeout === 'function') {
		            cachedSetTimeout = setTimeout;
		        } else {
		            cachedSetTimeout = defaultSetTimout;
		        }
		    } catch (e) {
		        cachedSetTimeout = defaultSetTimout;
		    }
		    try {
		        if (typeof clearTimeout === 'function') {
		            cachedClearTimeout = clearTimeout;
		        } else {
		            cachedClearTimeout = defaultClearTimeout;
		        }
		    } catch (e) {
		        cachedClearTimeout = defaultClearTimeout;
		    }
		} ());
		function runTimeout(fun) {
		    if (cachedSetTimeout === setTimeout) {
		        //normal enviroments in sane situations
		        return setTimeout(fun, 0);
		    }
		    // if setTimeout wasn't available but was latter defined
		    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
		        cachedSetTimeout = setTimeout;
		        return setTimeout(fun, 0);
		    }
		    try {
		        // when when somebody has screwed with setTimeout but no I.E. maddness
		        return cachedSetTimeout(fun, 0);
		    } catch(e){
		        try {
		            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
		            return cachedSetTimeout.call(null, fun, 0);
		        } catch(e){
		            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
		            return cachedSetTimeout.call(this, fun, 0);
		        }
		    }


		}
		function runClearTimeout(marker) {
		    if (cachedClearTimeout === clearTimeout) {
		        //normal enviroments in sane situations
		        return clearTimeout(marker);
		    }
		    // if clearTimeout wasn't available but was latter defined
		    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
		        cachedClearTimeout = clearTimeout;
		        return clearTimeout(marker);
		    }
		    try {
		        // when when somebody has screwed with setTimeout but no I.E. maddness
		        return cachedClearTimeout(marker);
		    } catch (e){
		        try {
		            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
		            return cachedClearTimeout.call(null, marker);
		        } catch (e){
		            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
		            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
		            return cachedClearTimeout.call(this, marker);
		        }
		    }



		}
		var queue = [];
		var draining = false;
		var currentQueue;
		var queueIndex = -1;

		function cleanUpNextTick() {
		    if (!draining || !currentQueue) {
		        return;
		    }
		    draining = false;
		    if (currentQueue.length) {
		        queue = currentQueue.concat(queue);
		    } else {
		        queueIndex = -1;
		    }
		    if (queue.length) {
		        drainQueue();
		    }
		}

		function drainQueue() {
		    if (draining) {
		        return;
		    }
		    var timeout = runTimeout(cleanUpNextTick);
		    draining = true;

		    var len = queue.length;
		    while(len) {
		        currentQueue = queue;
		        queue = [];
		        while (++queueIndex < len) {
		            if (currentQueue) {
		                currentQueue[queueIndex].run();
		            }
		        }
		        queueIndex = -1;
		        len = queue.length;
		    }
		    currentQueue = null;
		    draining = false;
		    runClearTimeout(timeout);
		}

		process.nextTick = function (fun) {
		    var args = new Array(arguments.length - 1);
		    if (arguments.length > 1) {
		        for (var i = 1; i < arguments.length; i++) {
		            args[i - 1] = arguments[i];
		        }
		    }
		    queue.push(new Item(fun, args));
		    if (queue.length === 1 && !draining) {
		        runTimeout(drainQueue);
		    }
		};

		// v8 likes predictible objects
		function Item(fun, array) {
		    this.fun = fun;
		    this.array = array;
		}
		Item.prototype.run = function () {
		    this.fun.apply(null, this.array);
		};
		process.title = 'browser';
		process.browser = true;
		process.env = {};
		process.argv = [];
		process.version = ''; // empty string to avoid regexp issues
		process.versions = {};

		function noop() {}

		process.on = noop;
		process.addListener = noop;
		process.once = noop;
		process.off = noop;
		process.removeListener = noop;
		process.removeAllListeners = noop;
		process.emit = noop;
		process.prependListener = noop;
		process.prependOnceListener = noop;

		process.listeners = function (name) { return [] };

		process.binding = function (name) {
		    throw new Error('process.binding is not supported');
		};

		process.cwd = function () { return '/' };
		process.chdir = function (dir) {
		    throw new Error('process.chdir is not supported');
		};
		process.umask = function() { return 0; };
		return browser.exports;
	}

	var utils;
	var hasRequiredUtils;

	function requireUtils () {
		if (hasRequiredUtils) return utils;
		hasRequiredUtils = 1;

		const { SymbolAsyncIterator, SymbolIterator, SymbolFor } = requirePrimordials();

		// We need to use SymbolFor to make these globally available
		// for interopt with readable-stream, i.e. readable-stream
		// and node core needs to be able to read/write private state
		// from each other for proper interoperability.
		const kIsDestroyed = SymbolFor('nodejs.stream.destroyed');
		const kIsErrored = SymbolFor('nodejs.stream.errored');
		const kIsReadable = SymbolFor('nodejs.stream.readable');
		const kIsWritable = SymbolFor('nodejs.stream.writable');
		const kIsDisturbed = SymbolFor('nodejs.stream.disturbed');
		const kIsClosedPromise = SymbolFor('nodejs.webstream.isClosedPromise');
		const kControllerErrorFunction = SymbolFor('nodejs.webstream.controllerErrorFunction');
		function isReadableNodeStream(obj, strict = false) {
		  var _obj$_readableState;
		  return !!(
		    (
		      obj &&
		      typeof obj.pipe === 'function' &&
		      typeof obj.on === 'function' &&
		      (!strict || (typeof obj.pause === 'function' && typeof obj.resume === 'function')) &&
		      (!obj._writableState ||
		        ((_obj$_readableState = obj._readableState) === null || _obj$_readableState === undefined
		          ? undefined
		          : _obj$_readableState.readable) !== false) &&
		      // Duplex
		      (!obj._writableState || obj._readableState)
		    ) // Writable has .pipe.
		  )
		}
		function isWritableNodeStream(obj) {
		  var _obj$_writableState;
		  return !!(
		    (
		      obj &&
		      typeof obj.write === 'function' &&
		      typeof obj.on === 'function' &&
		      (!obj._readableState ||
		        ((_obj$_writableState = obj._writableState) === null || _obj$_writableState === undefined
		          ? undefined
		          : _obj$_writableState.writable) !== false)
		    ) // Duplex
		  )
		}
		function isDuplexNodeStream(obj) {
		  return !!(
		    obj &&
		    typeof obj.pipe === 'function' &&
		    obj._readableState &&
		    typeof obj.on === 'function' &&
		    typeof obj.write === 'function'
		  )
		}
		function isNodeStream(obj) {
		  return (
		    obj &&
		    (obj._readableState ||
		      obj._writableState ||
		      (typeof obj.write === 'function' && typeof obj.on === 'function') ||
		      (typeof obj.pipe === 'function' && typeof obj.on === 'function'))
		  )
		}
		function isReadableStream(obj) {
		  return !!(
		    obj &&
		    !isNodeStream(obj) &&
		    typeof obj.pipeThrough === 'function' &&
		    typeof obj.getReader === 'function' &&
		    typeof obj.cancel === 'function'
		  )
		}
		function isWritableStream(obj) {
		  return !!(obj && !isNodeStream(obj) && typeof obj.getWriter === 'function' && typeof obj.abort === 'function')
		}
		function isTransformStream(obj) {
		  return !!(obj && !isNodeStream(obj) && typeof obj.readable === 'object' && typeof obj.writable === 'object')
		}
		function isWebStream(obj) {
		  return isReadableStream(obj) || isWritableStream(obj) || isTransformStream(obj)
		}
		function isIterable(obj, isAsync) {
		  if (obj == null) return false
		  if (isAsync === true) return typeof obj[SymbolAsyncIterator] === 'function'
		  if (isAsync === false) return typeof obj[SymbolIterator] === 'function'
		  return typeof obj[SymbolAsyncIterator] === 'function' || typeof obj[SymbolIterator] === 'function'
		}
		function isDestroyed(stream) {
		  if (!isNodeStream(stream)) return null
		  const wState = stream._writableState;
		  const rState = stream._readableState;
		  const state = wState || rState;
		  return !!(stream.destroyed || stream[kIsDestroyed] || (state !== null && state !== undefined && state.destroyed))
		}

		// Have been end():d.
		function isWritableEnded(stream) {
		  if (!isWritableNodeStream(stream)) return null
		  if (stream.writableEnded === true) return true
		  const wState = stream._writableState;
		  if (wState !== null && wState !== undefined && wState.errored) return false
		  if (typeof (wState === null || wState === undefined ? undefined : wState.ended) !== 'boolean') return null
		  return wState.ended
		}

		// Have emitted 'finish'.
		function isWritableFinished(stream, strict) {
		  if (!isWritableNodeStream(stream)) return null
		  if (stream.writableFinished === true) return true
		  const wState = stream._writableState;
		  if (wState !== null && wState !== undefined && wState.errored) return false
		  if (typeof (wState === null || wState === undefined ? undefined : wState.finished) !== 'boolean') return null
		  return !!(wState.finished || (strict === false && wState.ended === true && wState.length === 0))
		}

		// Have been push(null):d.
		function isReadableEnded(stream) {
		  if (!isReadableNodeStream(stream)) return null
		  if (stream.readableEnded === true) return true
		  const rState = stream._readableState;
		  if (!rState || rState.errored) return false
		  if (typeof (rState === null || rState === undefined ? undefined : rState.ended) !== 'boolean') return null
		  return rState.ended
		}

		// Have emitted 'end'.
		function isReadableFinished(stream, strict) {
		  if (!isReadableNodeStream(stream)) return null
		  const rState = stream._readableState;
		  if (rState !== null && rState !== undefined && rState.errored) return false
		  if (typeof (rState === null || rState === undefined ? undefined : rState.endEmitted) !== 'boolean') return null
		  return !!(rState.endEmitted || (strict === false && rState.ended === true && rState.length === 0))
		}
		function isReadable(stream) {
		  if (stream && stream[kIsReadable] != null) return stream[kIsReadable]
		  if (typeof (stream === null || stream === undefined ? undefined : stream.readable) !== 'boolean') return null
		  if (isDestroyed(stream)) return false
		  return isReadableNodeStream(stream) && stream.readable && !isReadableFinished(stream)
		}
		function isWritable(stream) {
		  if (stream && stream[kIsWritable] != null) return stream[kIsWritable]
		  if (typeof (stream === null || stream === undefined ? undefined : stream.writable) !== 'boolean') return null
		  if (isDestroyed(stream)) return false
		  return isWritableNodeStream(stream) && stream.writable && !isWritableEnded(stream)
		}
		function isFinished(stream, opts) {
		  if (!isNodeStream(stream)) {
		    return null
		  }
		  if (isDestroyed(stream)) {
		    return true
		  }
		  if ((opts === null || opts === undefined ? undefined : opts.readable) !== false && isReadable(stream)) {
		    return false
		  }
		  if ((opts === null || opts === undefined ? undefined : opts.writable) !== false && isWritable(stream)) {
		    return false
		  }
		  return true
		}
		function isWritableErrored(stream) {
		  var _stream$_writableStat, _stream$_writableStat2;
		  if (!isNodeStream(stream)) {
		    return null
		  }
		  if (stream.writableErrored) {
		    return stream.writableErrored
		  }
		  return (_stream$_writableStat =
		    (_stream$_writableStat2 = stream._writableState) === null || _stream$_writableStat2 === undefined
		      ? undefined
		      : _stream$_writableStat2.errored) !== null && _stream$_writableStat !== undefined
		    ? _stream$_writableStat
		    : null
		}
		function isReadableErrored(stream) {
		  var _stream$_readableStat, _stream$_readableStat2;
		  if (!isNodeStream(stream)) {
		    return null
		  }
		  if (stream.readableErrored) {
		    return stream.readableErrored
		  }
		  return (_stream$_readableStat =
		    (_stream$_readableStat2 = stream._readableState) === null || _stream$_readableStat2 === undefined
		      ? undefined
		      : _stream$_readableStat2.errored) !== null && _stream$_readableStat !== undefined
		    ? _stream$_readableStat
		    : null
		}
		function isClosed(stream) {
		  if (!isNodeStream(stream)) {
		    return null
		  }
		  if (typeof stream.closed === 'boolean') {
		    return stream.closed
		  }
		  const wState = stream._writableState;
		  const rState = stream._readableState;
		  if (
		    typeof (wState === null || wState === undefined ? undefined : wState.closed) === 'boolean' ||
		    typeof (rState === null || rState === undefined ? undefined : rState.closed) === 'boolean'
		  ) {
		    return (
		      (wState === null || wState === undefined ? undefined : wState.closed) ||
		      (rState === null || rState === undefined ? undefined : rState.closed)
		    )
		  }
		  if (typeof stream._closed === 'boolean' && isOutgoingMessage(stream)) {
		    return stream._closed
		  }
		  return null
		}
		function isOutgoingMessage(stream) {
		  return (
		    typeof stream._closed === 'boolean' &&
		    typeof stream._defaultKeepAlive === 'boolean' &&
		    typeof stream._removedConnection === 'boolean' &&
		    typeof stream._removedContLen === 'boolean'
		  )
		}
		function isServerResponse(stream) {
		  return typeof stream._sent100 === 'boolean' && isOutgoingMessage(stream)
		}
		function isServerRequest(stream) {
		  var _stream$req;
		  return (
		    typeof stream._consuming === 'boolean' &&
		    typeof stream._dumped === 'boolean' &&
		    ((_stream$req = stream.req) === null || _stream$req === undefined ? undefined : _stream$req.upgradeOrConnect) ===
		      undefined
		  )
		}
		function willEmitClose(stream) {
		  if (!isNodeStream(stream)) return null
		  const wState = stream._writableState;
		  const rState = stream._readableState;
		  const state = wState || rState;
		  return (
		    (!state && isServerResponse(stream)) || !!(state && state.autoDestroy && state.emitClose && state.closed === false)
		  )
		}
		function isDisturbed(stream) {
		  var _stream$kIsDisturbed;
		  return !!(
		    stream &&
		    ((_stream$kIsDisturbed = stream[kIsDisturbed]) !== null && _stream$kIsDisturbed !== undefined
		      ? _stream$kIsDisturbed
		      : stream.readableDidRead || stream.readableAborted)
		  )
		}
		function isErrored(stream) {
		  var _ref,
		    _ref2,
		    _ref3,
		    _ref4,
		    _ref5,
		    _stream$kIsErrored,
		    _stream$_readableStat3,
		    _stream$_writableStat3,
		    _stream$_readableStat4,
		    _stream$_writableStat4;
		  return !!(
		    stream &&
		    ((_ref =
		      (_ref2 =
		        (_ref3 =
		          (_ref4 =
		            (_ref5 =
		              (_stream$kIsErrored = stream[kIsErrored]) !== null && _stream$kIsErrored !== undefined
		                ? _stream$kIsErrored
		                : stream.readableErrored) !== null && _ref5 !== undefined
		              ? _ref5
		              : stream.writableErrored) !== null && _ref4 !== undefined
		            ? _ref4
		            : (_stream$_readableStat3 = stream._readableState) === null || _stream$_readableStat3 === undefined
		            ? undefined
		            : _stream$_readableStat3.errorEmitted) !== null && _ref3 !== undefined
		          ? _ref3
		          : (_stream$_writableStat3 = stream._writableState) === null || _stream$_writableStat3 === undefined
		          ? undefined
		          : _stream$_writableStat3.errorEmitted) !== null && _ref2 !== undefined
		        ? _ref2
		        : (_stream$_readableStat4 = stream._readableState) === null || _stream$_readableStat4 === undefined
		        ? undefined
		        : _stream$_readableStat4.errored) !== null && _ref !== undefined
		      ? _ref
		      : (_stream$_writableStat4 = stream._writableState) === null || _stream$_writableStat4 === undefined
		      ? undefined
		      : _stream$_writableStat4.errored)
		  )
		}
		utils = {
		  isDestroyed,
		  kIsDestroyed,
		  isDisturbed,
		  kIsDisturbed,
		  isErrored,
		  kIsErrored,
		  isReadable,
		  kIsReadable,
		  kIsClosedPromise,
		  kControllerErrorFunction,
		  kIsWritable,
		  isClosed,
		  isDuplexNodeStream,
		  isFinished,
		  isIterable,
		  isReadableNodeStream,
		  isReadableStream,
		  isReadableEnded,
		  isReadableFinished,
		  isReadableErrored,
		  isNodeStream,
		  isWebStream,
		  isWritable,
		  isWritableNodeStream,
		  isWritableStream,
		  isWritableEnded,
		  isWritableFinished,
		  isWritableErrored,
		  isServerRequest,
		  isServerResponse,
		  willEmitClose,
		  isTransformStream
		};
		return utils;
	}

	var hasRequiredEndOfStream;

	function requireEndOfStream () {
		if (hasRequiredEndOfStream) return endOfStream.exports;
		hasRequiredEndOfStream = 1;

		/* replacement start */

		const process = requireBrowser$1();

		/* replacement end */

		const { AbortError, codes } = requireErrors();
		const { ERR_INVALID_ARG_TYPE, ERR_STREAM_PREMATURE_CLOSE } = codes;
		const { kEmptyObject, once } = requireUtil$1();
		const { validateAbortSignal, validateFunction, validateObject, validateBoolean } = requireValidators();
		const { Promise, PromisePrototypeThen, SymbolDispose } = requirePrimordials();
		const {
		  isClosed,
		  isReadable,
		  isReadableNodeStream,
		  isReadableStream,
		  isReadableFinished,
		  isReadableErrored,
		  isWritable,
		  isWritableNodeStream,
		  isWritableStream,
		  isWritableFinished,
		  isWritableErrored,
		  isNodeStream,
		  willEmitClose: _willEmitClose,
		  kIsClosedPromise
		} = requireUtils();
		let addAbortListener;
		function isRequest(stream) {
		  return stream.setHeader && typeof stream.abort === 'function'
		}
		const nop = () => {};
		function eos(stream, options, callback) {
		  var _options$readable, _options$writable;
		  if (arguments.length === 2) {
		    callback = options;
		    options = kEmptyObject;
		  } else if (options == null) {
		    options = kEmptyObject;
		  } else {
		    validateObject(options, 'options');
		  }
		  validateFunction(callback, 'callback');
		  validateAbortSignal(options.signal, 'options.signal');
		  callback = once(callback);
		  if (isReadableStream(stream) || isWritableStream(stream)) {
		    return eosWeb(stream, options, callback)
		  }
		  if (!isNodeStream(stream)) {
		    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)
		  }
		  const readable =
		    (_options$readable = options.readable) !== null && _options$readable !== undefined
		      ? _options$readable
		      : isReadableNodeStream(stream);
		  const writable =
		    (_options$writable = options.writable) !== null && _options$writable !== undefined
		      ? _options$writable
		      : isWritableNodeStream(stream);
		  const wState = stream._writableState;
		  const rState = stream._readableState;
		  const onlegacyfinish = () => {
		    if (!stream.writable) {
		      onfinish();
		    }
		  };

		  // TODO (ronag): Improve soft detection to include core modules and
		  // common ecosystem modules that do properly emit 'close' but fail
		  // this generic check.
		  let willEmitClose =
		    _willEmitClose(stream) && isReadableNodeStream(stream) === readable && isWritableNodeStream(stream) === writable;
		  let writableFinished = isWritableFinished(stream, false);
		  const onfinish = () => {
		    writableFinished = true;
		    // Stream should not be destroyed here. If it is that
		    // means that user space is doing something differently and
		    // we cannot trust willEmitClose.
		    if (stream.destroyed) {
		      willEmitClose = false;
		    }
		    if (willEmitClose && (!stream.readable || readable)) {
		      return
		    }
		    if (!readable || readableFinished) {
		      callback.call(stream);
		    }
		  };
		  let readableFinished = isReadableFinished(stream, false);
		  const onend = () => {
		    readableFinished = true;
		    // Stream should not be destroyed here. If it is that
		    // means that user space is doing something differently and
		    // we cannot trust willEmitClose.
		    if (stream.destroyed) {
		      willEmitClose = false;
		    }
		    if (willEmitClose && (!stream.writable || writable)) {
		      return
		    }
		    if (!writable || writableFinished) {
		      callback.call(stream);
		    }
		  };
		  const onerror = (err) => {
		    callback.call(stream, err);
		  };
		  let closed = isClosed(stream);
		  const onclose = () => {
		    closed = true;
		    const errored = isWritableErrored(stream) || isReadableErrored(stream);
		    if (errored && typeof errored !== 'boolean') {
		      return callback.call(stream, errored)
		    }
		    if (readable && !readableFinished && isReadableNodeStream(stream, true)) {
		      if (!isReadableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())
		    }
		    if (writable && !writableFinished) {
		      if (!isWritableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())
		    }
		    callback.call(stream);
		  };
		  const onclosed = () => {
		    closed = true;
		    const errored = isWritableErrored(stream) || isReadableErrored(stream);
		    if (errored && typeof errored !== 'boolean') {
		      return callback.call(stream, errored)
		    }
		    callback.call(stream);
		  };
		  const onrequest = () => {
		    stream.req.on('finish', onfinish);
		  };
		  if (isRequest(stream)) {
		    stream.on('complete', onfinish);
		    if (!willEmitClose) {
		      stream.on('abort', onclose);
		    }
		    if (stream.req) {
		      onrequest();
		    } else {
		      stream.on('request', onrequest);
		    }
		  } else if (writable && !wState) {
		    // legacy streams
		    stream.on('end', onlegacyfinish);
		    stream.on('close', onlegacyfinish);
		  }

		  // Not all streams will emit 'close' after 'aborted'.
		  if (!willEmitClose && typeof stream.aborted === 'boolean') {
		    stream.on('aborted', onclose);
		  }
		  stream.on('end', onend);
		  stream.on('finish', onfinish);
		  if (options.error !== false) {
		    stream.on('error', onerror);
		  }
		  stream.on('close', onclose);
		  if (closed) {
		    process.nextTick(onclose);
		  } else if (
		    (wState !== null && wState !== undefined && wState.errorEmitted) ||
		    (rState !== null && rState !== undefined && rState.errorEmitted)
		  ) {
		    if (!willEmitClose) {
		      process.nextTick(onclosed);
		    }
		  } else if (
		    !readable &&
		    (!willEmitClose || isReadable(stream)) &&
		    (writableFinished || isWritable(stream) === false)
		  ) {
		    process.nextTick(onclosed);
		  } else if (
		    !writable &&
		    (!willEmitClose || isWritable(stream)) &&
		    (readableFinished || isReadable(stream) === false)
		  ) {
		    process.nextTick(onclosed);
		  } else if (rState && stream.req && stream.aborted) {
		    process.nextTick(onclosed);
		  }
		  const cleanup = () => {
		    callback = nop;
		    stream.removeListener('aborted', onclose);
		    stream.removeListener('complete', onfinish);
		    stream.removeListener('abort', onclose);
		    stream.removeListener('request', onrequest);
		    if (stream.req) stream.req.removeListener('finish', onfinish);
		    stream.removeListener('end', onlegacyfinish);
		    stream.removeListener('close', onlegacyfinish);
		    stream.removeListener('finish', onfinish);
		    stream.removeListener('end', onend);
		    stream.removeListener('error', onerror);
		    stream.removeListener('close', onclose);
		  };
		  if (options.signal && !closed) {
		    const abort = () => {
		      // Keep it because cleanup removes it.
		      const endCallback = callback;
		      cleanup();
		      endCallback.call(
		        stream,
		        new AbortError(undefined, {
		          cause: options.signal.reason
		        })
		      );
		    };
		    if (options.signal.aborted) {
		      process.nextTick(abort);
		    } else {
		      addAbortListener = addAbortListener || requireUtil$1().addAbortListener;
		      const disposable = addAbortListener(options.signal, abort);
		      const originalCallback = callback;
		      callback = once((...args) => {
		        disposable[SymbolDispose]();
		        originalCallback.apply(stream, args);
		      });
		    }
		  }
		  return cleanup
		}
		function eosWeb(stream, options, callback) {
		  let isAborted = false;
		  let abort = nop;
		  if (options.signal) {
		    abort = () => {
		      isAborted = true;
		      callback.call(
		        stream,
		        new AbortError(undefined, {
		          cause: options.signal.reason
		        })
		      );
		    };
		    if (options.signal.aborted) {
		      process.nextTick(abort);
		    } else {
		      addAbortListener = addAbortListener || requireUtil$1().addAbortListener;
		      const disposable = addAbortListener(options.signal, abort);
		      const originalCallback = callback;
		      callback = once((...args) => {
		        disposable[SymbolDispose]();
		        originalCallback.apply(stream, args);
		      });
		    }
		  }
		  const resolverFn = (...args) => {
		    if (!isAborted) {
		      process.nextTick(() => callback.apply(stream, args));
		    }
		  };
		  PromisePrototypeThen(stream[kIsClosedPromise].promise, resolverFn, resolverFn);
		  return nop
		}
		function finished(stream, opts) {
		  var _opts;
		  let autoCleanup = false;
		  if (opts === null) {
		    opts = kEmptyObject;
		  }
		  if ((_opts = opts) !== null && _opts !== undefined && _opts.cleanup) {
		    validateBoolean(opts.cleanup, 'cleanup');
		    autoCleanup = opts.cleanup;
		  }
		  return new Promise((resolve, reject) => {
		    const cleanup = eos(stream, opts, (err) => {
		      if (autoCleanup) {
		        cleanup();
		      }
		      if (err) {
		        reject(err);
		      } else {
		        resolve();
		      }
		    });
		  })
		}
		endOfStream.exports = eos;
		endOfStream.exports.finished = finished;
		return endOfStream.exports;
	}

	var destroy_1;
	var hasRequiredDestroy;

	function requireDestroy () {
		if (hasRequiredDestroy) return destroy_1;
		hasRequiredDestroy = 1;

		/* replacement start */

		const process = requireBrowser$1();

		/* replacement end */

		const {
		  aggregateTwoErrors,
		  codes: { ERR_MULTIPLE_CALLBACK },
		  AbortError
		} = requireErrors();
		const { Symbol } = requirePrimordials();
		const { kIsDestroyed, isDestroyed, isFinished, isServerRequest } = requireUtils();
		const kDestroy = Symbol('kDestroy');
		const kConstruct = Symbol('kConstruct');
		function checkError(err, w, r) {
		  if (err) {
		    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
		    err.stack; // eslint-disable-line no-unused-expressions

		    if (w && !w.errored) {
		      w.errored = err;
		    }
		    if (r && !r.errored) {
		      r.errored = err;
		    }
		  }
		}

		// Backwards compat. cb() is undocumented and unused in core but
		// unfortunately might be used by modules.
		function destroy(err, cb) {
		  const r = this._readableState;
		  const w = this._writableState;
		  // With duplex streams we use the writable side for state.
		  const s = w || r;
		  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {
		    if (typeof cb === 'function') {
		      cb();
		    }
		    return this
		  }

		  // We set destroyed to true before firing error callbacks in order
		  // to make it re-entrance safe in case destroy() is called within callbacks
		  checkError(err, w, r);
		  if (w) {
		    w.destroyed = true;
		  }
		  if (r) {
		    r.destroyed = true;
		  }

		  // If still constructing then defer calling _destroy.
		  if (!s.constructed) {
		    this.once(kDestroy, function (er) {
		      _destroy(this, aggregateTwoErrors(er, err), cb);
		    });
		  } else {
		    _destroy(this, err, cb);
		  }
		  return this
		}
		function _destroy(self, err, cb) {
		  let called = false;
		  function onDestroy(err) {
		    if (called) {
		      return
		    }
		    called = true;
		    const r = self._readableState;
		    const w = self._writableState;
		    checkError(err, w, r);
		    if (w) {
		      w.closed = true;
		    }
		    if (r) {
		      r.closed = true;
		    }
		    if (typeof cb === 'function') {
		      cb(err);
		    }
		    if (err) {
		      process.nextTick(emitErrorCloseNT, self, err);
		    } else {
		      process.nextTick(emitCloseNT, self);
		    }
		  }
		  try {
		    self._destroy(err || null, onDestroy);
		  } catch (err) {
		    onDestroy(err);
		  }
		}
		function emitErrorCloseNT(self, err) {
		  emitErrorNT(self, err);
		  emitCloseNT(self);
		}
		function emitCloseNT(self) {
		  const r = self._readableState;
		  const w = self._writableState;
		  if (w) {
		    w.closeEmitted = true;
		  }
		  if (r) {
		    r.closeEmitted = true;
		  }
		  if ((w !== null && w !== undefined && w.emitClose) || (r !== null && r !== undefined && r.emitClose)) {
		    self.emit('close');
		  }
		}
		function emitErrorNT(self, err) {
		  const r = self._readableState;
		  const w = self._writableState;
		  if ((w !== null && w !== undefined && w.errorEmitted) || (r !== null && r !== undefined && r.errorEmitted)) {
		    return
		  }
		  if (w) {
		    w.errorEmitted = true;
		  }
		  if (r) {
		    r.errorEmitted = true;
		  }
		  self.emit('error', err);
		}
		function undestroy() {
		  const r = this._readableState;
		  const w = this._writableState;
		  if (r) {
		    r.constructed = true;
		    r.closed = false;
		    r.closeEmitted = false;
		    r.destroyed = false;
		    r.errored = null;
		    r.errorEmitted = false;
		    r.reading = false;
		    r.ended = r.readable === false;
		    r.endEmitted = r.readable === false;
		  }
		  if (w) {
		    w.constructed = true;
		    w.destroyed = false;
		    w.closed = false;
		    w.closeEmitted = false;
		    w.errored = null;
		    w.errorEmitted = false;
		    w.finalCalled = false;
		    w.prefinished = false;
		    w.ended = w.writable === false;
		    w.ending = w.writable === false;
		    w.finished = w.writable === false;
		  }
		}
		function errorOrDestroy(stream, err, sync) {
		  // We have tests that rely on errors being emitted
		  // in the same tick, so changing this is semver major.
		  // For now when you opt-in to autoDestroy we allow
		  // the error to be emitted nextTick. In a future
		  // semver major update we should change the default to this.

		  const r = stream._readableState;
		  const w = stream._writableState;
		  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {
		    return this
		  }
		  if ((r !== null && r !== undefined && r.autoDestroy) || (w !== null && w !== undefined && w.autoDestroy))
		    stream.destroy(err);
		  else if (err) {
		    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
		    err.stack; // eslint-disable-line no-unused-expressions

		    if (w && !w.errored) {
		      w.errored = err;
		    }
		    if (r && !r.errored) {
		      r.errored = err;
		    }
		    if (sync) {
		      process.nextTick(emitErrorNT, stream, err);
		    } else {
		      emitErrorNT(stream, err);
		    }
		  }
		}
		function construct(stream, cb) {
		  if (typeof stream._construct !== 'function') {
		    return
		  }
		  const r = stream._readableState;
		  const w = stream._writableState;
		  if (r) {
		    r.constructed = false;
		  }
		  if (w) {
		    w.constructed = false;
		  }
		  stream.once(kConstruct, cb);
		  if (stream.listenerCount(kConstruct) > 1) {
		    // Duplex
		    return
		  }
		  process.nextTick(constructNT, stream);
		}
		function constructNT(stream) {
		  let called = false;
		  function onConstruct(err) {
		    if (called) {
		      errorOrDestroy(stream, err !== null && err !== undefined ? err : new ERR_MULTIPLE_CALLBACK());
		      return
		    }
		    called = true;
		    const r = stream._readableState;
		    const w = stream._writableState;
		    const s = w || r;
		    if (r) {
		      r.constructed = true;
		    }
		    if (w) {
		      w.constructed = true;
		    }
		    if (s.destroyed) {
		      stream.emit(kDestroy, err);
		    } else if (err) {
		      errorOrDestroy(stream, err, true);
		    } else {
		      process.nextTick(emitConstructNT, stream);
		    }
		  }
		  try {
		    stream._construct((err) => {
		      process.nextTick(onConstruct, err);
		    });
		  } catch (err) {
		    process.nextTick(onConstruct, err);
		  }
		}
		function emitConstructNT(stream) {
		  stream.emit(kConstruct);
		}
		function isRequest(stream) {
		  return (stream === null || stream === undefined ? undefined : stream.setHeader) && typeof stream.abort === 'function'
		}
		function emitCloseLegacy(stream) {
		  stream.emit('close');
		}
		function emitErrorCloseLegacy(stream, err) {
		  stream.emit('error', err);
		  process.nextTick(emitCloseLegacy, stream);
		}

		// Normalize destroy for legacy.
		function destroyer(stream, err) {
		  if (!stream || isDestroyed(stream)) {
		    return
		  }
		  if (!err && !isFinished(stream)) {
		    err = new AbortError();
		  }

		  // TODO: Remove isRequest branches.
		  if (isServerRequest(stream)) {
		    stream.socket = null;
		    stream.destroy(err);
		  } else if (isRequest(stream)) {
		    stream.abort();
		  } else if (isRequest(stream.req)) {
		    stream.req.abort();
		  } else if (typeof stream.destroy === 'function') {
		    stream.destroy(err);
		  } else if (typeof stream.close === 'function') {
		    // TODO: Don't lose err?
		    stream.close();
		  } else if (err) {
		    process.nextTick(emitErrorCloseLegacy, stream, err);
		  } else {
		    process.nextTick(emitCloseLegacy, stream);
		  }
		  if (!stream.destroyed) {
		    stream[kIsDestroyed] = true;
		  }
		}
		destroy_1 = {
		  construct,
		  destroyer,
		  destroy,
		  undestroy,
		  errorOrDestroy
		};
		return destroy_1;
	}

	var legacy;
	var hasRequiredLegacy;

	function requireLegacy () {
		if (hasRequiredLegacy) return legacy;
		hasRequiredLegacy = 1;

		const { ArrayIsArray, ObjectSetPrototypeOf } = requirePrimordials();
		const { EventEmitter: EE } = requireEvents$1();
		function Stream(opts) {
		  EE.call(this, opts);
		}
		ObjectSetPrototypeOf(Stream.prototype, EE.prototype);
		ObjectSetPrototypeOf(Stream, EE);
		Stream.prototype.pipe = function (dest, options) {
		  const source = this;
		  function ondata(chunk) {
		    if (dest.writable && dest.write(chunk) === false && source.pause) {
		      source.pause();
		    }
		  }
		  source.on('data', ondata);
		  function ondrain() {
		    if (source.readable && source.resume) {
		      source.resume();
		    }
		  }
		  dest.on('drain', ondrain);

		  // If the 'end' option is not supplied, dest.end() will be called when
		  // source gets the 'end' or 'close' events.  Only dest.end() once.
		  if (!dest._isStdio && (!options || options.end !== false)) {
		    source.on('end', onend);
		    source.on('close', onclose);
		  }
		  let didOnEnd = false;
		  function onend() {
		    if (didOnEnd) return
		    didOnEnd = true;
		    dest.end();
		  }
		  function onclose() {
		    if (didOnEnd) return
		    didOnEnd = true;
		    if (typeof dest.destroy === 'function') dest.destroy();
		  }

		  // Don't leave dangling pipes when there are errors.
		  function onerror(er) {
		    cleanup();
		    if (EE.listenerCount(this, 'error') === 0) {
		      this.emit('error', er);
		    }
		  }
		  prependListener(source, 'error', onerror);
		  prependListener(dest, 'error', onerror);

		  // Remove all the event listeners that were added.
		  function cleanup() {
		    source.removeListener('data', ondata);
		    dest.removeListener('drain', ondrain);
		    source.removeListener('end', onend);
		    source.removeListener('close', onclose);
		    source.removeListener('error', onerror);
		    dest.removeListener('error', onerror);
		    source.removeListener('end', cleanup);
		    source.removeListener('close', cleanup);
		    dest.removeListener('close', cleanup);
		  }
		  source.on('end', cleanup);
		  source.on('close', cleanup);
		  dest.on('close', cleanup);
		  dest.emit('pipe', source);

		  // Allow for unix-like usage: A.pipe(B).pipe(C)
		  return dest
		};
		function prependListener(emitter, event, fn) {
		  // Sadly this is not cacheable as some libraries bundle their own
		  // event emitter implementation with them.
		  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn)

		  // This is a hack to make sure that our error handler is attached before any
		  // userland ones.  NEVER DO THIS. This is here only because this code needs
		  // to continue to work with older versions of Node.js that do not include
		  // the prependListener() method. The goal is to eventually remove this hack.
		  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);
		  else if (ArrayIsArray(emitter._events[event])) emitter._events[event].unshift(fn);
		  else emitter._events[event] = [fn, emitter._events[event]];
		}
		legacy = {
		  Stream,
		  prependListener
		};
		return legacy;
	}

	var addAbortSignal = {exports: {}};

	var hasRequiredAddAbortSignal;

	function requireAddAbortSignal () {
		if (hasRequiredAddAbortSignal) return addAbortSignal.exports;
		hasRequiredAddAbortSignal = 1;
		(function (module) {

			const { SymbolDispose } = requirePrimordials();
			const { AbortError, codes } = requireErrors();
			const { isNodeStream, isWebStream, kControllerErrorFunction } = requireUtils();
			const eos = requireEndOfStream();
			const { ERR_INVALID_ARG_TYPE } = codes;
			let addAbortListener;

			// This method is inlined here for readable-stream
			// It also does not allow for signal to not exist on the stream
			// https://github.com/nodejs/node/pull/36061#discussion_r533718029
			const validateAbortSignal = (signal, name) => {
			  if (typeof signal !== 'object' || !('aborted' in signal)) {
			    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)
			  }
			};
			module.exports.addAbortSignal = function addAbortSignal(signal, stream) {
			  validateAbortSignal(signal, 'signal');
			  if (!isNodeStream(stream) && !isWebStream(stream)) {
			    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)
			  }
			  return module.exports.addAbortSignalNoValidate(signal, stream)
			};
			module.exports.addAbortSignalNoValidate = function (signal, stream) {
			  if (typeof signal !== 'object' || !('aborted' in signal)) {
			    return stream
			  }
			  const onAbort = isNodeStream(stream)
			    ? () => {
			        stream.destroy(
			          new AbortError(undefined, {
			            cause: signal.reason
			          })
			        );
			      }
			    : () => {
			        stream[kControllerErrorFunction](
			          new AbortError(undefined, {
			            cause: signal.reason
			          })
			        );
			      };
			  if (signal.aborted) {
			    onAbort();
			  } else {
			    addAbortListener = addAbortListener || requireUtil$1().addAbortListener;
			    const disposable = addAbortListener(signal, onAbort);
			    eos(stream, disposable[SymbolDispose]);
			  }
			  return stream
			}; 
		} (addAbortSignal));
		return addAbortSignal.exports;
	}

	var buffer_list;
	var hasRequiredBuffer_list;

	function requireBuffer_list () {
		if (hasRequiredBuffer_list) return buffer_list;
		hasRequiredBuffer_list = 1;

		const { StringPrototypeSlice, SymbolIterator, TypedArrayPrototypeSet, Uint8Array } = requirePrimordials();
		const { Buffer } = requireBuffer();
		const { inspect } = requireUtil$1();
		buffer_list = class BufferList {
		  constructor() {
		    this.head = null;
		    this.tail = null;
		    this.length = 0;
		  }
		  push(v) {
		    const entry = {
		      data: v,
		      next: null
		    };
		    if (this.length > 0) this.tail.next = entry;
		    else this.head = entry;
		    this.tail = entry;
		    ++this.length;
		  }
		  unshift(v) {
		    const entry = {
		      data: v,
		      next: this.head
		    };
		    if (this.length === 0) this.tail = entry;
		    this.head = entry;
		    ++this.length;
		  }
		  shift() {
		    if (this.length === 0) return
		    const ret = this.head.data;
		    if (this.length === 1) this.head = this.tail = null;
		    else this.head = this.head.next;
		    --this.length;
		    return ret
		  }
		  clear() {
		    this.head = this.tail = null;
		    this.length = 0;
		  }
		  join(s) {
		    if (this.length === 0) return ''
		    let p = this.head;
		    let ret = '' + p.data;
		    while ((p = p.next) !== null) ret += s + p.data;
		    return ret
		  }
		  concat(n) {
		    if (this.length === 0) return Buffer.alloc(0)
		    const ret = Buffer.allocUnsafe(n >>> 0);
		    let p = this.head;
		    let i = 0;
		    while (p) {
		      TypedArrayPrototypeSet(ret, p.data, i);
		      i += p.data.length;
		      p = p.next;
		    }
		    return ret
		  }

		  // Consumes a specified amount of bytes or characters from the buffered data.
		  consume(n, hasStrings) {
		    const data = this.head.data;
		    if (n < data.length) {
		      // `slice` is the same for buffers and strings.
		      const slice = data.slice(0, n);
		      this.head.data = data.slice(n);
		      return slice
		    }
		    if (n === data.length) {
		      // First chunk is a perfect match.
		      return this.shift()
		    }
		    // Result spans more than one buffer.
		    return hasStrings ? this._getString(n) : this._getBuffer(n)
		  }
		  first() {
		    return this.head.data
		  }
		  *[SymbolIterator]() {
		    for (let p = this.head; p; p = p.next) {
		      yield p.data;
		    }
		  }

		  // Consumes a specified amount of characters from the buffered data.
		  _getString(n) {
		    let ret = '';
		    let p = this.head;
		    let c = 0;
		    do {
		      const str = p.data;
		      if (n > str.length) {
		        ret += str;
		        n -= str.length;
		      } else {
		        if (n === str.length) {
		          ret += str;
		          ++c;
		          if (p.next) this.head = p.next;
		          else this.head = this.tail = null;
		        } else {
		          ret += StringPrototypeSlice(str, 0, n);
		          this.head = p;
		          p.data = StringPrototypeSlice(str, n);
		        }
		        break
		      }
		      ++c;
		    } while ((p = p.next) !== null)
		    this.length -= c;
		    return ret
		  }

		  // Consumes a specified amount of bytes from the buffered data.
		  _getBuffer(n) {
		    const ret = Buffer.allocUnsafe(n);
		    const retLen = n;
		    let p = this.head;
		    let c = 0;
		    do {
		      const buf = p.data;
		      if (n > buf.length) {
		        TypedArrayPrototypeSet(ret, buf, retLen - n);
		        n -= buf.length;
		      } else {
		        if (n === buf.length) {
		          TypedArrayPrototypeSet(ret, buf, retLen - n);
		          ++c;
		          if (p.next) this.head = p.next;
		          else this.head = this.tail = null;
		        } else {
		          TypedArrayPrototypeSet(ret, new Uint8Array(buf.buffer, buf.byteOffset, n), retLen - n);
		          this.head = p;
		          p.data = buf.slice(n);
		        }
		        break
		      }
		      ++c;
		    } while ((p = p.next) !== null)
		    this.length -= c;
		    return ret
		  }

		  // Make sure the linked list only shows the minimal necessary information.
		  [Symbol.for('nodejs.util.inspect.custom')](_, options) {
		    return inspect(this, {
		      ...options,
		      // Only inspect one level.
		      depth: 0,
		      // It should not recurse.
		      customInspect: false
		    })
		  }
		};
		return buffer_list;
	}

	var state;
	var hasRequiredState;

	function requireState () {
		if (hasRequiredState) return state;
		hasRequiredState = 1;

		const { MathFloor, NumberIsInteger } = requirePrimordials();
		const { validateInteger } = requireValidators();
		const { ERR_INVALID_ARG_VALUE } = requireErrors().codes;
		let defaultHighWaterMarkBytes = 16 * 1024;
		let defaultHighWaterMarkObjectMode = 16;
		function highWaterMarkFrom(options, isDuplex, duplexKey) {
		  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null
		}
		function getDefaultHighWaterMark(objectMode) {
		  return objectMode ? defaultHighWaterMarkObjectMode : defaultHighWaterMarkBytes
		}
		function setDefaultHighWaterMark(objectMode, value) {
		  validateInteger(value, 'value', 0);
		  if (objectMode) {
		    defaultHighWaterMarkObjectMode = value;
		  } else {
		    defaultHighWaterMarkBytes = value;
		  }
		}
		function getHighWaterMark(state, options, duplexKey, isDuplex) {
		  const hwm = highWaterMarkFrom(options, isDuplex, duplexKey);
		  if (hwm != null) {
		    if (!NumberIsInteger(hwm) || hwm < 0) {
		      const name = isDuplex ? `options.${duplexKey}` : 'options.highWaterMark';
		      throw new ERR_INVALID_ARG_VALUE(name, hwm)
		    }
		    return MathFloor(hwm)
		  }

		  // Default value
		  return getDefaultHighWaterMark(state.objectMode)
		}
		state = {
		  getHighWaterMark,
		  getDefaultHighWaterMark,
		  setDefaultHighWaterMark
		};
		return state;
	}

	var string_decoder = {};

	var safeBuffer = {exports: {}};

	/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */

	var hasRequiredSafeBuffer;

	function requireSafeBuffer () {
		if (hasRequiredSafeBuffer) return safeBuffer.exports;
		hasRequiredSafeBuffer = 1;
		(function (module, exports) {
			/* eslint-disable node/no-deprecated-api */
			var buffer = requireBuffer();
			var Buffer = buffer.Buffer;

			// alternative to using Object.keys for old browsers
			function copyProps (src, dst) {
			  for (var key in src) {
			    dst[key] = src[key];
			  }
			}
			if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
			  module.exports = buffer;
			} else {
			  // Copy properties from require('buffer')
			  copyProps(buffer, exports);
			  exports.Buffer = SafeBuffer;
			}

			function SafeBuffer (arg, encodingOrOffset, length) {
			  return Buffer(arg, encodingOrOffset, length)
			}

			SafeBuffer.prototype = Object.create(Buffer.prototype);

			// Copy static methods from Buffer
			copyProps(Buffer, SafeBuffer);

			SafeBuffer.from = function (arg, encodingOrOffset, length) {
			  if (typeof arg === 'number') {
			    throw new TypeError('Argument must not be a number')
			  }
			  return Buffer(arg, encodingOrOffset, length)
			};

			SafeBuffer.alloc = function (size, fill, encoding) {
			  if (typeof size !== 'number') {
			    throw new TypeError('Argument must be a number')
			  }
			  var buf = Buffer(size);
			  if (fill !== undefined) {
			    if (typeof encoding === 'string') {
			      buf.fill(fill, encoding);
			    } else {
			      buf.fill(fill);
			    }
			  } else {
			    buf.fill(0);
			  }
			  return buf
			};

			SafeBuffer.allocUnsafe = function (size) {
			  if (typeof size !== 'number') {
			    throw new TypeError('Argument must be a number')
			  }
			  return Buffer(size)
			};

			SafeBuffer.allocUnsafeSlow = function (size) {
			  if (typeof size !== 'number') {
			    throw new TypeError('Argument must be a number')
			  }
			  return buffer.SlowBuffer(size)
			}; 
		} (safeBuffer, safeBuffer.exports));
		return safeBuffer.exports;
	}

	var hasRequiredString_decoder;

	function requireString_decoder () {
		if (hasRequiredString_decoder) return string_decoder;
		hasRequiredString_decoder = 1;

		/*<replacement>*/

		var Buffer = requireSafeBuffer().Buffer;
		/*</replacement>*/

		var isEncoding = Buffer.isEncoding || function (encoding) {
		  encoding = '' + encoding;
		  switch (encoding && encoding.toLowerCase()) {
		    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
		      return true;
		    default:
		      return false;
		  }
		};

		function _normalizeEncoding(enc) {
		  if (!enc) return 'utf8';
		  var retried;
		  while (true) {
		    switch (enc) {
		      case 'utf8':
		      case 'utf-8':
		        return 'utf8';
		      case 'ucs2':
		      case 'ucs-2':
		      case 'utf16le':
		      case 'utf-16le':
		        return 'utf16le';
		      case 'latin1':
		      case 'binary':
		        return 'latin1';
		      case 'base64':
		      case 'ascii':
		      case 'hex':
		        return enc;
		      default:
		        if (retried) return; // undefined
		        enc = ('' + enc).toLowerCase();
		        retried = true;
		    }
		  }
		}
		// Do not cache `Buffer.isEncoding` when checking encoding names as some
		// modules monkey-patch it to support additional encodings
		function normalizeEncoding(enc) {
		  var nenc = _normalizeEncoding(enc);
		  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
		  return nenc || enc;
		}

		// StringDecoder provides an interface for efficiently splitting a series of
		// buffers into a series of JS strings without breaking apart multi-byte
		// characters.
		string_decoder.StringDecoder = StringDecoder;
		function StringDecoder(encoding) {
		  this.encoding = normalizeEncoding(encoding);
		  var nb;
		  switch (this.encoding) {
		    case 'utf16le':
		      this.text = utf16Text;
		      this.end = utf16End;
		      nb = 4;
		      break;
		    case 'utf8':
		      this.fillLast = utf8FillLast;
		      nb = 4;
		      break;
		    case 'base64':
		      this.text = base64Text;
		      this.end = base64End;
		      nb = 3;
		      break;
		    default:
		      this.write = simpleWrite;
		      this.end = simpleEnd;
		      return;
		  }
		  this.lastNeed = 0;
		  this.lastTotal = 0;
		  this.lastChar = Buffer.allocUnsafe(nb);
		}

		StringDecoder.prototype.write = function (buf) {
		  if (buf.length === 0) return '';
		  var r;
		  var i;
		  if (this.lastNeed) {
		    r = this.fillLast(buf);
		    if (r === undefined) return '';
		    i = this.lastNeed;
		    this.lastNeed = 0;
		  } else {
		    i = 0;
		  }
		  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
		  return r || '';
		};

		StringDecoder.prototype.end = utf8End;

		// Returns only complete characters in a Buffer
		StringDecoder.prototype.text = utf8Text;

		// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
		StringDecoder.prototype.fillLast = function (buf) {
		  if (this.lastNeed <= buf.length) {
		    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
		    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
		  }
		  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
		  this.lastNeed -= buf.length;
		};

		// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
		// continuation byte. If an invalid byte is detected, -2 is returned.
		function utf8CheckByte(byte) {
		  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
		  return byte >> 6 === 0x02 ? -1 : -2;
		}

		// Checks at most 3 bytes at the end of a Buffer in order to detect an
		// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
		// needed to complete the UTF-8 character (if applicable) are returned.
		function utf8CheckIncomplete(self, buf, i) {
		  var j = buf.length - 1;
		  if (j < i) return 0;
		  var nb = utf8CheckByte(buf[j]);
		  if (nb >= 0) {
		    if (nb > 0) self.lastNeed = nb - 1;
		    return nb;
		  }
		  if (--j < i || nb === -2) return 0;
		  nb = utf8CheckByte(buf[j]);
		  if (nb >= 0) {
		    if (nb > 0) self.lastNeed = nb - 2;
		    return nb;
		  }
		  if (--j < i || nb === -2) return 0;
		  nb = utf8CheckByte(buf[j]);
		  if (nb >= 0) {
		    if (nb > 0) {
		      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
		    }
		    return nb;
		  }
		  return 0;
		}

		// Validates as many continuation bytes for a multi-byte UTF-8 character as
		// needed or are available. If we see a non-continuation byte where we expect
		// one, we "replace" the validated continuation bytes we've seen so far with
		// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
		// behavior. The continuation byte check is included three times in the case
		// where all of the continuation bytes for a character exist in the same buffer.
		// It is also done this way as a slight performance increase instead of using a
		// loop.
		function utf8CheckExtraBytes(self, buf, p) {
		  if ((buf[0] & 0xC0) !== 0x80) {
		    self.lastNeed = 0;
		    return '\ufffd';
		  }
		  if (self.lastNeed > 1 && buf.length > 1) {
		    if ((buf[1] & 0xC0) !== 0x80) {
		      self.lastNeed = 1;
		      return '\ufffd';
		    }
		    if (self.lastNeed > 2 && buf.length > 2) {
		      if ((buf[2] & 0xC0) !== 0x80) {
		        self.lastNeed = 2;
		        return '\ufffd';
		      }
		    }
		  }
		}

		// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
		function utf8FillLast(buf) {
		  var p = this.lastTotal - this.lastNeed;
		  var r = utf8CheckExtraBytes(this, buf);
		  if (r !== undefined) return r;
		  if (this.lastNeed <= buf.length) {
		    buf.copy(this.lastChar, p, 0, this.lastNeed);
		    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
		  }
		  buf.copy(this.lastChar, p, 0, buf.length);
		  this.lastNeed -= buf.length;
		}

		// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
		// partial character, the character's bytes are buffered until the required
		// number of bytes are available.
		function utf8Text(buf, i) {
		  var total = utf8CheckIncomplete(this, buf, i);
		  if (!this.lastNeed) return buf.toString('utf8', i);
		  this.lastTotal = total;
		  var end = buf.length - (total - this.lastNeed);
		  buf.copy(this.lastChar, 0, end);
		  return buf.toString('utf8', i, end);
		}

		// For UTF-8, a replacement character is added when ending on a partial
		// character.
		function utf8End(buf) {
		  var r = buf && buf.length ? this.write(buf) : '';
		  if (this.lastNeed) return r + '\ufffd';
		  return r;
		}

		// UTF-16LE typically needs two bytes per character, but even if we have an even
		// number of bytes available, we need to check if we end on a leading/high
		// surrogate. In that case, we need to wait for the next two bytes in order to
		// decode the last character properly.
		function utf16Text(buf, i) {
		  if ((buf.length - i) % 2 === 0) {
		    var r = buf.toString('utf16le', i);
		    if (r) {
		      var c = r.charCodeAt(r.length - 1);
		      if (c >= 0xD800 && c <= 0xDBFF) {
		        this.lastNeed = 2;
		        this.lastTotal = 4;
		        this.lastChar[0] = buf[buf.length - 2];
		        this.lastChar[1] = buf[buf.length - 1];
		        return r.slice(0, -1);
		      }
		    }
		    return r;
		  }
		  this.lastNeed = 1;
		  this.lastTotal = 2;
		  this.lastChar[0] = buf[buf.length - 1];
		  return buf.toString('utf16le', i, buf.length - 1);
		}

		// For UTF-16LE we do not explicitly append special replacement characters if we
		// end on a partial character, we simply let v8 handle that.
		function utf16End(buf) {
		  var r = buf && buf.length ? this.write(buf) : '';
		  if (this.lastNeed) {
		    var end = this.lastTotal - this.lastNeed;
		    return r + this.lastChar.toString('utf16le', 0, end);
		  }
		  return r;
		}

		function base64Text(buf, i) {
		  var n = (buf.length - i) % 3;
		  if (n === 0) return buf.toString('base64', i);
		  this.lastNeed = 3 - n;
		  this.lastTotal = 3;
		  if (n === 1) {
		    this.lastChar[0] = buf[buf.length - 1];
		  } else {
		    this.lastChar[0] = buf[buf.length - 2];
		    this.lastChar[1] = buf[buf.length - 1];
		  }
		  return buf.toString('base64', i, buf.length - n);
		}

		function base64End(buf) {
		  var r = buf && buf.length ? this.write(buf) : '';
		  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
		  return r;
		}

		// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
		function simpleWrite(buf) {
		  return buf.toString(this.encoding);
		}

		function simpleEnd(buf) {
		  return buf && buf.length ? this.write(buf) : '';
		}
		return string_decoder;
	}

	var from_1;
	var hasRequiredFrom;

	function requireFrom () {
		if (hasRequiredFrom) return from_1;
		hasRequiredFrom = 1;

		/* replacement start */

		const process = requireBrowser$1();

		/* replacement end */

		const { PromisePrototypeThen, SymbolAsyncIterator, SymbolIterator } = requirePrimordials();
		const { Buffer } = requireBuffer();
		const { ERR_INVALID_ARG_TYPE, ERR_STREAM_NULL_VALUES } = requireErrors().codes;
		function from(Readable, iterable, opts) {
		  let iterator;
		  if (typeof iterable === 'string' || iterable instanceof Buffer) {
		    return new Readable({
		      objectMode: true,
		      ...opts,
		      read() {
		        this.push(iterable);
		        this.push(null);
		      }
		    })
		  }
		  let isAsync;
		  if (iterable && iterable[SymbolAsyncIterator]) {
		    isAsync = true;
		    iterator = iterable[SymbolAsyncIterator]();
		  } else if (iterable && iterable[SymbolIterator]) {
		    isAsync = false;
		    iterator = iterable[SymbolIterator]();
		  } else {
		    throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable)
		  }
		  const readable = new Readable({
		    objectMode: true,
		    highWaterMark: 1,
		    // TODO(ronag): What options should be allowed?
		    ...opts
		  });

		  // Flag to protect against _read
		  // being called before last iteration completion.
		  let reading = false;
		  readable._read = function () {
		    if (!reading) {
		      reading = true;
		      next();
		    }
		  };
		  readable._destroy = function (error, cb) {
		    PromisePrototypeThen(
		      close(error),
		      () => process.nextTick(cb, error),
		      // nextTick is here in case cb throws
		      (e) => process.nextTick(cb, e || error)
		    );
		  };
		  async function close(error) {
		    const hadError = error !== undefined && error !== null;
		    const hasThrow = typeof iterator.throw === 'function';
		    if (hadError && hasThrow) {
		      const { value, done } = await iterator.throw(error);
		      await value;
		      if (done) {
		        return
		      }
		    }
		    if (typeof iterator.return === 'function') {
		      const { value } = await iterator.return();
		      await value;
		    }
		  }
		  async function next() {
		    for (;;) {
		      try {
		        const { value, done } = isAsync ? await iterator.next() : iterator.next();
		        if (done) {
		          readable.push(null);
		        } else {
		          const res = value && typeof value.then === 'function' ? await value : value;
		          if (res === null) {
		            reading = false;
		            throw new ERR_STREAM_NULL_VALUES()
		          } else if (readable.push(res)) {
		            continue
		          } else {
		            reading = false;
		          }
		        }
		      } catch (err) {
		        readable.destroy(err);
		      }
		      break
		    }
		  }
		  return readable
		}
		from_1 = from;
		return from_1;
	}

	var readable;
	var hasRequiredReadable;

	function requireReadable () {
		if (hasRequiredReadable) return readable;
		hasRequiredReadable = 1;

		/* replacement start */

		const process = requireBrowser$1();

		/* replacement end */

		const {
		  ArrayPrototypeIndexOf,
		  NumberIsInteger,
		  NumberIsNaN,
		  NumberParseInt,
		  ObjectDefineProperties,
		  ObjectKeys,
		  ObjectSetPrototypeOf,
		  Promise,
		  SafeSet,
		  SymbolAsyncDispose,
		  SymbolAsyncIterator,
		  Symbol
		} = requirePrimordials();
		readable = Readable;
		Readable.ReadableState = ReadableState;
		const { EventEmitter: EE } = requireEvents$1();
		const { Stream, prependListener } = requireLegacy();
		const { Buffer } = requireBuffer();
		const { addAbortSignal } = requireAddAbortSignal();
		const eos = requireEndOfStream();
		let debug = requireUtil$1().debuglog('stream', (fn) => {
		  debug = fn;
		});
		const BufferList = requireBuffer_list();
		const destroyImpl = requireDestroy();
		const { getHighWaterMark, getDefaultHighWaterMark } = requireState();
		const {
		  aggregateTwoErrors,
		  codes: {
		    ERR_INVALID_ARG_TYPE,
		    ERR_METHOD_NOT_IMPLEMENTED,
		    ERR_OUT_OF_RANGE,
		    ERR_STREAM_PUSH_AFTER_EOF,
		    ERR_STREAM_UNSHIFT_AFTER_END_EVENT
		  },
		  AbortError
		} = requireErrors();
		const { validateObject } = requireValidators();
		const kPaused = Symbol('kPaused');
		const { StringDecoder } = requireString_decoder();
		const from = requireFrom();
		ObjectSetPrototypeOf(Readable.prototype, Stream.prototype);
		ObjectSetPrototypeOf(Readable, Stream);
		const nop = () => {};
		const { errorOrDestroy } = destroyImpl;
		const kObjectMode = 1 << 0;
		const kEnded = 1 << 1;
		const kEndEmitted = 1 << 2;
		const kReading = 1 << 3;
		const kConstructed = 1 << 4;
		const kSync = 1 << 5;
		const kNeedReadable = 1 << 6;
		const kEmittedReadable = 1 << 7;
		const kReadableListening = 1 << 8;
		const kResumeScheduled = 1 << 9;
		const kErrorEmitted = 1 << 10;
		const kEmitClose = 1 << 11;
		const kAutoDestroy = 1 << 12;
		const kDestroyed = 1 << 13;
		const kClosed = 1 << 14;
		const kCloseEmitted = 1 << 15;
		const kMultiAwaitDrain = 1 << 16;
		const kReadingMore = 1 << 17;
		const kDataEmitted = 1 << 18;

		// TODO(benjamingr) it is likely slower to do it this way than with free functions
		function makeBitMapDescriptor(bit) {
		  return {
		    enumerable: false,
		    get() {
		      return (this.state & bit) !== 0
		    },
		    set(value) {
		      if (value) this.state |= bit;
		      else this.state &= ~bit;
		    }
		  }
		}
		ObjectDefineProperties(ReadableState.prototype, {
		  objectMode: makeBitMapDescriptor(kObjectMode),
		  ended: makeBitMapDescriptor(kEnded),
		  endEmitted: makeBitMapDescriptor(kEndEmitted),
		  reading: makeBitMapDescriptor(kReading),
		  // Stream is still being constructed and cannot be
		  // destroyed until construction finished or failed.
		  // Async construction is opt in, therefore we start as
		  // constructed.
		  constructed: makeBitMapDescriptor(kConstructed),
		  // A flag to be able to tell if the event 'readable'/'data' is emitted
		  // immediately, or on a later tick.  We set this to true at first, because
		  // any actions that shouldn't happen until "later" should generally also
		  // not happen before the first read call.
		  sync: makeBitMapDescriptor(kSync),
		  // Whenever we return null, then we set a flag to say
		  // that we're awaiting a 'readable' event emission.
		  needReadable: makeBitMapDescriptor(kNeedReadable),
		  emittedReadable: makeBitMapDescriptor(kEmittedReadable),
		  readableListening: makeBitMapDescriptor(kReadableListening),
		  resumeScheduled: makeBitMapDescriptor(kResumeScheduled),
		  // True if the error was already emitted and should not be thrown again.
		  errorEmitted: makeBitMapDescriptor(kErrorEmitted),
		  emitClose: makeBitMapDescriptor(kEmitClose),
		  autoDestroy: makeBitMapDescriptor(kAutoDestroy),
		  // Has it been destroyed.
		  destroyed: makeBitMapDescriptor(kDestroyed),
		  // Indicates whether the stream has finished destroying.
		  closed: makeBitMapDescriptor(kClosed),
		  // True if close has been emitted or would have been emitted
		  // depending on emitClose.
		  closeEmitted: makeBitMapDescriptor(kCloseEmitted),
		  multiAwaitDrain: makeBitMapDescriptor(kMultiAwaitDrain),
		  // If true, a maybeReadMore has been scheduled.
		  readingMore: makeBitMapDescriptor(kReadingMore),
		  dataEmitted: makeBitMapDescriptor(kDataEmitted)
		});
		function ReadableState(options, stream, isDuplex) {
		  // Duplex streams are both readable and writable, but share
		  // the same options object.
		  // However, some cases require setting options to different
		  // values for the readable and the writable sides of the duplex stream.
		  // These options can be provided separately as readableXXX and writableXXX.
		  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof requireDuplex();

		  // Bit map field to store ReadableState more effciently with 1 bit per field
		  // instead of a V8 slot per field.
		  this.state = kEmitClose | kAutoDestroy | kConstructed | kSync;
		  // Object stream flag. Used to make read(n) ignore n and to
		  // make all the buffer merging and length checks go away.
		  if (options && options.objectMode) this.state |= kObjectMode;
		  if (isDuplex && options && options.readableObjectMode) this.state |= kObjectMode;

		  // The point at which it stops calling _read() to fill the buffer
		  // Note: 0 is a valid value, means "don't call _read preemptively ever"
		  this.highWaterMark = options
		    ? getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex)
		    : getDefaultHighWaterMark(false);

		  // A linked list is used to store data chunks instead of an array because the
		  // linked list can remove elements from the beginning faster than
		  // array.shift().
		  this.buffer = new BufferList();
		  this.length = 0;
		  this.pipes = [];
		  this.flowing = null;
		  this[kPaused] = null;

		  // Should close be emitted on destroy. Defaults to true.
		  if (options && options.emitClose === false) this.state &= ~kEmitClose;

		  // Should .destroy() be called after 'end' (and potentially 'finish').
		  if (options && options.autoDestroy === false) this.state &= ~kAutoDestroy;

		  // Indicates whether the stream has errored. When true no further
		  // _read calls, 'data' or 'readable' events should occur. This is needed
		  // since when autoDestroy is disabled we need a way to tell whether the
		  // stream has failed.
		  this.errored = null;

		  // Crypto is kind of old and crusty.  Historically, its default string
		  // encoding is 'binary' so we have to make this configurable.
		  // Everything else in the universe uses 'utf8', though.
		  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8';

		  // Ref the piped dest which we need a drain event on it
		  // type: null | Writable | Set<Writable>.
		  this.awaitDrainWriters = null;
		  this.decoder = null;
		  this.encoding = null;
		  if (options && options.encoding) {
		    this.decoder = new StringDecoder(options.encoding);
		    this.encoding = options.encoding;
		  }
		}
		function Readable(options) {
		  if (!(this instanceof Readable)) return new Readable(options)

		  // Checking for a Stream.Duplex instance is faster here instead of inside
		  // the ReadableState constructor, at least with V8 6.5.
		  const isDuplex = this instanceof requireDuplex();
		  this._readableState = new ReadableState(options, this, isDuplex);
		  if (options) {
		    if (typeof options.read === 'function') this._read = options.read;
		    if (typeof options.destroy === 'function') this._destroy = options.destroy;
		    if (typeof options.construct === 'function') this._construct = options.construct;
		    if (options.signal && !isDuplex) addAbortSignal(options.signal, this);
		  }
		  Stream.call(this, options);
		  destroyImpl.construct(this, () => {
		    if (this._readableState.needReadable) {
		      maybeReadMore(this, this._readableState);
		    }
		  });
		}
		Readable.prototype.destroy = destroyImpl.destroy;
		Readable.prototype._undestroy = destroyImpl.undestroy;
		Readable.prototype._destroy = function (err, cb) {
		  cb(err);
		};
		Readable.prototype[EE.captureRejectionSymbol] = function (err) {
		  this.destroy(err);
		};
		Readable.prototype[SymbolAsyncDispose] = function () {
		  let error;
		  if (!this.destroyed) {
		    error = this.readableEnded ? null : new AbortError();
		    this.destroy(error);
		  }
		  return new Promise((resolve, reject) => eos(this, (err) => (err && err !== error ? reject(err) : resolve(null))))
		};

		// Manually shove something into the read() buffer.
		// This returns true if the highWaterMark has not been hit yet,
		// similar to how Writable.write() returns true if you should
		// write() some more.
		Readable.prototype.push = function (chunk, encoding) {
		  return readableAddChunk(this, chunk, encoding, false)
		};

		// Unshift should *always* be something directly out of read().
		Readable.prototype.unshift = function (chunk, encoding) {
		  return readableAddChunk(this, chunk, encoding, true)
		};
		function readableAddChunk(stream, chunk, encoding, addToFront) {
		  debug('readableAddChunk', chunk);
		  const state = stream._readableState;
		  let err;
		  if ((state.state & kObjectMode) === 0) {
		    if (typeof chunk === 'string') {
		      encoding = encoding || state.defaultEncoding;
		      if (state.encoding !== encoding) {
		        if (addToFront && state.encoding) {
		          // When unshifting, if state.encoding is set, we have to save
		          // the string in the BufferList with the state encoding.
		          chunk = Buffer.from(chunk, encoding).toString(state.encoding);
		        } else {
		          chunk = Buffer.from(chunk, encoding);
		          encoding = '';
		        }
		      }
		    } else if (chunk instanceof Buffer) {
		      encoding = '';
		    } else if (Stream._isUint8Array(chunk)) {
		      chunk = Stream._uint8ArrayToBuffer(chunk);
		      encoding = '';
		    } else if (chunk != null) {
		      err = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);
		    }
		  }
		  if (err) {
		    errorOrDestroy(stream, err);
		  } else if (chunk === null) {
		    state.state &= ~kReading;
		    onEofChunk(stream, state);
		  } else if ((state.state & kObjectMode) !== 0 || (chunk && chunk.length > 0)) {
		    if (addToFront) {
		      if ((state.state & kEndEmitted) !== 0) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());
		      else if (state.destroyed || state.errored) return false
		      else addChunk(stream, state, chunk, true);
		    } else if (state.ended) {
		      errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());
		    } else if (state.destroyed || state.errored) {
		      return false
		    } else {
		      state.state &= ~kReading;
		      if (state.decoder && !encoding) {
		        chunk = state.decoder.write(chunk);
		        if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);
		        else maybeReadMore(stream, state);
		      } else {
		        addChunk(stream, state, chunk, false);
		      }
		    }
		  } else if (!addToFront) {
		    state.state &= ~kReading;
		    maybeReadMore(stream, state);
		  }

		  // We can push more data if we are below the highWaterMark.
		  // Also, if we have no data yet, we can stand some more bytes.
		  // This is to work around cases where hwm=0, such as the repl.
		  return !state.ended && (state.length < state.highWaterMark || state.length === 0)
		}
		function addChunk(stream, state, chunk, addToFront) {
		  if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount('data') > 0) {
		    // Use the guard to avoid creating `Set()` repeatedly
		    // when we have multiple pipes.
		    if ((state.state & kMultiAwaitDrain) !== 0) {
		      state.awaitDrainWriters.clear();
		    } else {
		      state.awaitDrainWriters = null;
		    }
		    state.dataEmitted = true;
		    stream.emit('data', chunk);
		  } else {
		    // Update the buffer info.
		    state.length += state.objectMode ? 1 : chunk.length;
		    if (addToFront) state.buffer.unshift(chunk);
		    else state.buffer.push(chunk);
		    if ((state.state & kNeedReadable) !== 0) emitReadable(stream);
		  }
		  maybeReadMore(stream, state);
		}
		Readable.prototype.isPaused = function () {
		  const state = this._readableState;
		  return state[kPaused] === true || state.flowing === false
		};

		// Backwards compatibility.
		Readable.prototype.setEncoding = function (enc) {
		  const decoder = new StringDecoder(enc);
		  this._readableState.decoder = decoder;
		  // If setEncoding(null), decoder.encoding equals utf8.
		  this._readableState.encoding = this._readableState.decoder.encoding;
		  const buffer = this._readableState.buffer;
		  // Iterate over current buffer to convert already stored Buffers:
		  let content = '';
		  for (const data of buffer) {
		    content += decoder.write(data);
		  }
		  buffer.clear();
		  if (content !== '') buffer.push(content);
		  this._readableState.length = content.length;
		  return this
		};

		// Don't raise the hwm > 1GB.
		const MAX_HWM = 0x40000000;
		function computeNewHighWaterMark(n) {
		  if (n > MAX_HWM) {
		    throw new ERR_OUT_OF_RANGE('size', '<= 1GiB', n)
		  } else {
		    // Get the next highest power of 2 to prevent increasing hwm excessively in
		    // tiny amounts.
		    n--;
		    n |= n >>> 1;
		    n |= n >>> 2;
		    n |= n >>> 4;
		    n |= n >>> 8;
		    n |= n >>> 16;
		    n++;
		  }
		  return n
		}

		// This function is designed to be inlinable, so please take care when making
		// changes to the function body.
		function howMuchToRead(n, state) {
		  if (n <= 0 || (state.length === 0 && state.ended)) return 0
		  if ((state.state & kObjectMode) !== 0) return 1
		  if (NumberIsNaN(n)) {
		    // Only flow one buffer at a time.
		    if (state.flowing && state.length) return state.buffer.first().length
		    return state.length
		  }
		  if (n <= state.length) return n
		  return state.ended ? state.length : 0
		}

		// You can override either this method, or the async _read(n) below.
		Readable.prototype.read = function (n) {
		  debug('read', n);
		  // Same as parseInt(undefined, 10), however V8 7.3 performance regressed
		  // in this scenario, so we are doing it manually.
		  if (n === undefined) {
		    n = NaN;
		  } else if (!NumberIsInteger(n)) {
		    n = NumberParseInt(n, 10);
		  }
		  const state = this._readableState;
		  const nOrig = n;

		  // If we're asking for more than the current hwm, then raise the hwm.
		  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
		  if (n !== 0) state.state &= ~kEmittedReadable;

		  // If we're doing read(0) to trigger a readable event, but we
		  // already have a bunch of data in the buffer, then just trigger
		  // the 'readable' event and move on.
		  if (
		    n === 0 &&
		    state.needReadable &&
		    ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)
		  ) {
		    debug('read: emitReadable', state.length, state.ended);
		    if (state.length === 0 && state.ended) endReadable(this);
		    else emitReadable(this);
		    return null
		  }
		  n = howMuchToRead(n, state);

		  // If we've ended, and we're now clear, then finish it up.
		  if (n === 0 && state.ended) {
		    if (state.length === 0) endReadable(this);
		    return null
		  }

		  // All the actual chunk generation logic needs to be
		  // *below* the call to _read.  The reason is that in certain
		  // synthetic stream cases, such as passthrough streams, _read
		  // may be a completely synchronous operation which may change
		  // the state of the read buffer, providing enough data when
		  // before there was *not* enough.
		  //
		  // So, the steps are:
		  // 1. Figure out what the state of things will be after we do
		  // a read from the buffer.
		  //
		  // 2. If that resulting state will trigger a _read, then call _read.
		  // Note that this may be asynchronous, or synchronous.  Yes, it is
		  // deeply ugly to write APIs this way, but that still doesn't mean
		  // that the Readable class should behave improperly, as streams are
		  // designed to be sync/async agnostic.
		  // Take note if the _read call is sync or async (ie, if the read call
		  // has returned yet), so that we know whether or not it's safe to emit
		  // 'readable' etc.
		  //
		  // 3. Actually pull the requested chunks out of the buffer and return.

		  // if we need a readable event, then we need to do some reading.
		  let doRead = (state.state & kNeedReadable) !== 0;
		  debug('need readable', doRead);

		  // If we currently have less than the highWaterMark, then also read some.
		  if (state.length === 0 || state.length - n < state.highWaterMark) {
		    doRead = true;
		    debug('length less than watermark', doRead);
		  }

		  // However, if we've ended, then there's no point, if we're already
		  // reading, then it's unnecessary, if we're constructing we have to wait,
		  // and if we're destroyed or errored, then it's not allowed,
		  if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {
		    doRead = false;
		    debug('reading, ended or constructing', doRead);
		  } else if (doRead) {
		    debug('do read');
		    state.state |= kReading | kSync;
		    // If the length is currently zero, then we *need* a readable event.
		    if (state.length === 0) state.state |= kNeedReadable;

		    // Call internal read method
		    try {
		      this._read(state.highWaterMark);
		    } catch (err) {
		      errorOrDestroy(this, err);
		    }
		    state.state &= ~kSync;

		    // If _read pushed data synchronously, then `reading` will be false,
		    // and we need to re-evaluate how much data we can return to the user.
		    if (!state.reading) n = howMuchToRead(nOrig, state);
		  }
		  let ret;
		  if (n > 0) ret = fromList(n, state);
		  else ret = null;
		  if (ret === null) {
		    state.needReadable = state.length <= state.highWaterMark;
		    n = 0;
		  } else {
		    state.length -= n;
		    if (state.multiAwaitDrain) {
		      state.awaitDrainWriters.clear();
		    } else {
		      state.awaitDrainWriters = null;
		    }
		  }
		  if (state.length === 0) {
		    // If we have nothing in the buffer, then we want to know
		    // as soon as we *do* get something into the buffer.
		    if (!state.ended) state.needReadable = true;

		    // If we tried to read() past the EOF, then emit end on the next tick.
		    if (nOrig !== n && state.ended) endReadable(this);
		  }
		  if (ret !== null && !state.errorEmitted && !state.closeEmitted) {
		    state.dataEmitted = true;
		    this.emit('data', ret);
		  }
		  return ret
		};
		function onEofChunk(stream, state) {
		  debug('onEofChunk');
		  if (state.ended) return
		  if (state.decoder) {
		    const chunk = state.decoder.end();
		    if (chunk && chunk.length) {
		      state.buffer.push(chunk);
		      state.length += state.objectMode ? 1 : chunk.length;
		    }
		  }
		  state.ended = true;
		  if (state.sync) {
		    // If we are sync, wait until next tick to emit the data.
		    // Otherwise we risk emitting data in the flow()
		    // the readable code triggers during a read() call.
		    emitReadable(stream);
		  } else {
		    // Emit 'readable' now to make sure it gets picked up.
		    state.needReadable = false;
		    state.emittedReadable = true;
		    // We have to emit readable now that we are EOF. Modules
		    // in the ecosystem (e.g. dicer) rely on this event being sync.
		    emitReadable_(stream);
		  }
		}

		// Don't emit readable right away in sync mode, because this can trigger
		// another read() call => stack overflow.  This way, it might trigger
		// a nextTick recursion warning, but that's not so bad.
		function emitReadable(stream) {
		  const state = stream._readableState;
		  debug('emitReadable', state.needReadable, state.emittedReadable);
		  state.needReadable = false;
		  if (!state.emittedReadable) {
		    debug('emitReadable', state.flowing);
		    state.emittedReadable = true;
		    process.nextTick(emitReadable_, stream);
		  }
		}
		function emitReadable_(stream) {
		  const state = stream._readableState;
		  debug('emitReadable_', state.destroyed, state.length, state.ended);
		  if (!state.destroyed && !state.errored && (state.length || state.ended)) {
		    stream.emit('readable');
		    state.emittedReadable = false;
		  }

		  // The stream needs another readable event if:
		  // 1. It is not flowing, as the flow mechanism will take
		  //    care of it.
		  // 2. It is not ended.
		  // 3. It is below the highWaterMark, so we can schedule
		  //    another readable later.
		  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
		  flow(stream);
		}

		// At this point, the user has presumably seen the 'readable' event,
		// and called read() to consume some data.  that may have triggered
		// in turn another _read(n) call, in which case reading = true if
		// it's in progress.
		// However, if we're not ended, or reading, and the length < hwm,
		// then go ahead and try to read some more preemptively.
		function maybeReadMore(stream, state) {
		  if (!state.readingMore && state.constructed) {
		    state.readingMore = true;
		    process.nextTick(maybeReadMore_, stream, state);
		  }
		}
		function maybeReadMore_(stream, state) {
		  // Attempt to read more data if we should.
		  //
		  // The conditions for reading more data are (one of):
		  // - Not enough data buffered (state.length < state.highWaterMark). The loop
		  //   is responsible for filling the buffer with enough data if such data
		  //   is available. If highWaterMark is 0 and we are not in the flowing mode
		  //   we should _not_ attempt to buffer any extra data. We'll get more data
		  //   when the stream consumer calls read() instead.
		  // - No data in the buffer, and the stream is in flowing mode. In this mode
		  //   the loop below is responsible for ensuring read() is called. Failing to
		  //   call read here would abort the flow and there's no other mechanism for
		  //   continuing the flow if the stream consumer has just subscribed to the
		  //   'data' event.
		  //
		  // In addition to the above conditions to keep reading data, the following
		  // conditions prevent the data from being read:
		  // - The stream has ended (state.ended).
		  // - There is already a pending 'read' operation (state.reading). This is a
		  //   case where the stream has called the implementation defined _read()
		  //   method, but they are processing the call asynchronously and have _not_
		  //   called push() with new data. In this case we skip performing more
		  //   read()s. The execution ends in this method again after the _read() ends
		  //   up calling push() with more data.
		  while (
		    !state.reading &&
		    !state.ended &&
		    (state.length < state.highWaterMark || (state.flowing && state.length === 0))
		  ) {
		    const len = state.length;
		    debug('maybeReadMore read 0');
		    stream.read(0);
		    if (len === state.length)
		      // Didn't get any data, stop spinning.
		      break
		  }
		  state.readingMore = false;
		}

		// Abstract method.  to be overridden in specific implementation classes.
		// call cb(er, data) where data is <= n in length.
		// for virtual (non-string, non-buffer) streams, "length" is somewhat
		// arbitrary, and perhaps not very meaningful.
		Readable.prototype._read = function (n) {
		  throw new ERR_METHOD_NOT_IMPLEMENTED('_read()')
		};
		Readable.prototype.pipe = function (dest, pipeOpts) {
		  const src = this;
		  const state = this._readableState;
		  if (state.pipes.length === 1) {
		    if (!state.multiAwaitDrain) {
		      state.multiAwaitDrain = true;
		      state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : []);
		    }
		  }
		  state.pipes.push(dest);
		  debug('pipe count=%d opts=%j', state.pipes.length, pipeOpts);
		  const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;
		  const endFn = doEnd ? onend : unpipe;
		  if (state.endEmitted) process.nextTick(endFn);
		  else src.once('end', endFn);
		  dest.on('unpipe', onunpipe);
		  function onunpipe(readable, unpipeInfo) {
		    debug('onunpipe');
		    if (readable === src) {
		      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
		        unpipeInfo.hasUnpiped = true;
		        cleanup();
		      }
		    }
		  }
		  function onend() {
		    debug('onend');
		    dest.end();
		  }
		  let ondrain;
		  let cleanedUp = false;
		  function cleanup() {
		    debug('cleanup');
		    // Cleanup event handlers once the pipe is broken.
		    dest.removeListener('close', onclose);
		    dest.removeListener('finish', onfinish);
		    if (ondrain) {
		      dest.removeListener('drain', ondrain);
		    }
		    dest.removeListener('error', onerror);
		    dest.removeListener('unpipe', onunpipe);
		    src.removeListener('end', onend);
		    src.removeListener('end', unpipe);
		    src.removeListener('data', ondata);
		    cleanedUp = true;

		    // If the reader is waiting for a drain event from this
		    // specific writer, then it would cause it to never start
		    // flowing again.
		    // So, if this is awaiting a drain, then we just call it now.
		    // If we don't know, then assume that we are waiting for one.
		    if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain)) ondrain();
		  }
		  function pause() {
		    // If the user unpiped during `dest.write()`, it is possible
		    // to get stuck in a permanently paused state if that write
		    // also returned false.
		    // => Check whether `dest` is still a piping destination.
		    if (!cleanedUp) {
		      if (state.pipes.length === 1 && state.pipes[0] === dest) {
		        debug('false write response, pause', 0);
		        state.awaitDrainWriters = dest;
		        state.multiAwaitDrain = false;
		      } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {
		        debug('false write response, pause', state.awaitDrainWriters.size);
		        state.awaitDrainWriters.add(dest);
		      }
		      src.pause();
		    }
		    if (!ondrain) {
		      // When the dest drains, it reduces the awaitDrain counter
		      // on the source.  This would be more elegant with a .once()
		      // handler in flow(), but adding and removing repeatedly is
		      // too slow.
		      ondrain = pipeOnDrain(src, dest);
		      dest.on('drain', ondrain);
		    }
		  }
		  src.on('data', ondata);
		  function ondata(chunk) {
		    debug('ondata');
		    const ret = dest.write(chunk);
		    debug('dest.write', ret);
		    if (ret === false) {
		      pause();
		    }
		  }

		  // If the dest has an error, then stop piping into it.
		  // However, don't suppress the throwing behavior for this.
		  function onerror(er) {
		    debug('onerror', er);
		    unpipe();
		    dest.removeListener('error', onerror);
		    if (dest.listenerCount('error') === 0) {
		      const s = dest._writableState || dest._readableState;
		      if (s && !s.errorEmitted) {
		        // User incorrectly emitted 'error' directly on the stream.
		        errorOrDestroy(dest, er);
		      } else {
		        dest.emit('error', er);
		      }
		    }
		  }

		  // Make sure our error handler is attached before userland ones.
		  prependListener(dest, 'error', onerror);

		  // Both close and finish should trigger unpipe, but only once.
		  function onclose() {
		    dest.removeListener('finish', onfinish);
		    unpipe();
		  }
		  dest.once('close', onclose);
		  function onfinish() {
		    debug('onfinish');
		    dest.removeListener('close', onclose);
		    unpipe();
		  }
		  dest.once('finish', onfinish);
		  function unpipe() {
		    debug('unpipe');
		    src.unpipe(dest);
		  }

		  // Tell the dest that it's being piped to.
		  dest.emit('pipe', src);

		  // Start the flow if it hasn't been started already.

		  if (dest.writableNeedDrain === true) {
		    pause();
		  } else if (!state.flowing) {
		    debug('pipe resume');
		    src.resume();
		  }
		  return dest
		};
		function pipeOnDrain(src, dest) {
		  return function pipeOnDrainFunctionResult() {
		    const state = src._readableState;

		    // `ondrain` will call directly,
		    // `this` maybe not a reference to dest,
		    // so we use the real dest here.
		    if (state.awaitDrainWriters === dest) {
		      debug('pipeOnDrain', 1);
		      state.awaitDrainWriters = null;
		    } else if (state.multiAwaitDrain) {
		      debug('pipeOnDrain', state.awaitDrainWriters.size);
		      state.awaitDrainWriters.delete(dest);
		    }
		    if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount('data')) {
		      src.resume();
		    }
		  }
		}
		Readable.prototype.unpipe = function (dest) {
		  const state = this._readableState;
		  const unpipeInfo = {
		    hasUnpiped: false
		  };

		  // If we're not piping anywhere, then do nothing.
		  if (state.pipes.length === 0) return this
		  if (!dest) {
		    // remove all.
		    const dests = state.pipes;
		    state.pipes = [];
		    this.pause();
		    for (let i = 0; i < dests.length; i++)
		      dests[i].emit('unpipe', this, {
		        hasUnpiped: false
		      });
		    return this
		  }

		  // Try to find the right one.
		  const index = ArrayPrototypeIndexOf(state.pipes, dest);
		  if (index === -1) return this
		  state.pipes.splice(index, 1);
		  if (state.pipes.length === 0) this.pause();
		  dest.emit('unpipe', this, unpipeInfo);
		  return this
		};

		// Set up data events if they are asked for
		// Ensure readable listeners eventually get something.
		Readable.prototype.on = function (ev, fn) {
		  const res = Stream.prototype.on.call(this, ev, fn);
		  const state = this._readableState;
		  if (ev === 'data') {
		    // Update readableListening so that resume() may be a no-op
		    // a few lines down. This is needed to support once('readable').
		    state.readableListening = this.listenerCount('readable') > 0;

		    // Try start flowing on next tick if stream isn't explicitly paused.
		    if (state.flowing !== false) this.resume();
		  } else if (ev === 'readable') {
		    if (!state.endEmitted && !state.readableListening) {
		      state.readableListening = state.needReadable = true;
		      state.flowing = false;
		      state.emittedReadable = false;
		      debug('on readable', state.length, state.reading);
		      if (state.length) {
		        emitReadable(this);
		      } else if (!state.reading) {
		        process.nextTick(nReadingNextTick, this);
		      }
		    }
		  }
		  return res
		};
		Readable.prototype.addListener = Readable.prototype.on;
		Readable.prototype.removeListener = function (ev, fn) {
		  const res = Stream.prototype.removeListener.call(this, ev, fn);
		  if (ev === 'readable') {
		    // We need to check if there is someone still listening to
		    // readable and reset the state. However this needs to happen
		    // after readable has been emitted but before I/O (nextTick) to
		    // support once('readable', fn) cycles. This means that calling
		    // resume within the same tick will have no
		    // effect.
		    process.nextTick(updateReadableListening, this);
		  }
		  return res
		};
		Readable.prototype.off = Readable.prototype.removeListener;
		Readable.prototype.removeAllListeners = function (ev) {
		  const res = Stream.prototype.removeAllListeners.apply(this, arguments);
		  if (ev === 'readable' || ev === undefined) {
		    // We need to check if there is someone still listening to
		    // readable and reset the state. However this needs to happen
		    // after readable has been emitted but before I/O (nextTick) to
		    // support once('readable', fn) cycles. This means that calling
		    // resume within the same tick will have no
		    // effect.
		    process.nextTick(updateReadableListening, this);
		  }
		  return res
		};
		function updateReadableListening(self) {
		  const state = self._readableState;
		  state.readableListening = self.listenerCount('readable') > 0;
		  if (state.resumeScheduled && state[kPaused] === false) {
		    // Flowing needs to be set to true now, otherwise
		    // the upcoming resume will not flow.
		    state.flowing = true;

		    // Crude way to check if we should resume.
		  } else if (self.listenerCount('data') > 0) {
		    self.resume();
		  } else if (!state.readableListening) {
		    state.flowing = null;
		  }
		}
		function nReadingNextTick(self) {
		  debug('readable nexttick read 0');
		  self.read(0);
		}

		// pause() and resume() are remnants of the legacy readable stream API
		// If the user uses them, then switch into old mode.
		Readable.prototype.resume = function () {
		  const state = this._readableState;
		  if (!state.flowing) {
		    debug('resume');
		    // We flow only if there is no one listening
		    // for readable, but we still have to call
		    // resume().
		    state.flowing = !state.readableListening;
		    resume(this, state);
		  }
		  state[kPaused] = false;
		  return this
		};
		function resume(stream, state) {
		  if (!state.resumeScheduled) {
		    state.resumeScheduled = true;
		    process.nextTick(resume_, stream, state);
		  }
		}
		function resume_(stream, state) {
		  debug('resume', state.reading);
		  if (!state.reading) {
		    stream.read(0);
		  }
		  state.resumeScheduled = false;
		  stream.emit('resume');
		  flow(stream);
		  if (state.flowing && !state.reading) stream.read(0);
		}
		Readable.prototype.pause = function () {
		  debug('call pause flowing=%j', this._readableState.flowing);
		  if (this._readableState.flowing !== false) {
		    debug('pause');
		    this._readableState.flowing = false;
		    this.emit('pause');
		  }
		  this._readableState[kPaused] = true;
		  return this
		};
		function flow(stream) {
		  const state = stream._readableState;
		  debug('flow', state.flowing);
		  while (state.flowing && stream.read() !== null);
		}

		// Wrap an old-style stream as the async data source.
		// This is *not* part of the readable stream interface.
		// It is an ugly unfortunate mess of history.
		Readable.prototype.wrap = function (stream) {
		  let paused = false;

		  // TODO (ronag): Should this.destroy(err) emit
		  // 'error' on the wrapped stream? Would require
		  // a static factory method, e.g. Readable.wrap(stream).

		  stream.on('data', (chunk) => {
		    if (!this.push(chunk) && stream.pause) {
		      paused = true;
		      stream.pause();
		    }
		  });
		  stream.on('end', () => {
		    this.push(null);
		  });
		  stream.on('error', (err) => {
		    errorOrDestroy(this, err);
		  });
		  stream.on('close', () => {
		    this.destroy();
		  });
		  stream.on('destroy', () => {
		    this.destroy();
		  });
		  this._read = () => {
		    if (paused && stream.resume) {
		      paused = false;
		      stream.resume();
		    }
		  };

		  // Proxy all the other methods. Important when wrapping filters and duplexes.
		  const streamKeys = ObjectKeys(stream);
		  for (let j = 1; j < streamKeys.length; j++) {
		    const i = streamKeys[j];
		    if (this[i] === undefined && typeof stream[i] === 'function') {
		      this[i] = stream[i].bind(stream);
		    }
		  }
		  return this
		};
		Readable.prototype[SymbolAsyncIterator] = function () {
		  return streamToAsyncIterator(this)
		};
		Readable.prototype.iterator = function (options) {
		  if (options !== undefined) {
		    validateObject(options, 'options');
		  }
		  return streamToAsyncIterator(this, options)
		};
		function streamToAsyncIterator(stream, options) {
		  if (typeof stream.read !== 'function') {
		    stream = Readable.wrap(stream, {
		      objectMode: true
		    });
		  }
		  const iter = createAsyncIterator(stream, options);
		  iter.stream = stream;
		  return iter
		}
		async function* createAsyncIterator(stream, options) {
		  let callback = nop;
		  function next(resolve) {
		    if (this === stream) {
		      callback();
		      callback = nop;
		    } else {
		      callback = resolve;
		    }
		  }
		  stream.on('readable', next);
		  let error;
		  const cleanup = eos(
		    stream,
		    {
		      writable: false
		    },
		    (err) => {
		      error = err ? aggregateTwoErrors(error, err) : null;
		      callback();
		      callback = nop;
		    }
		  );
		  try {
		    while (true) {
		      const chunk = stream.destroyed ? null : stream.read();
		      if (chunk !== null) {
		        yield chunk;
		      } else if (error) {
		        throw error
		      } else if (error === null) {
		        return
		      } else {
		        await new Promise(next);
		      }
		    }
		  } catch (err) {
		    error = aggregateTwoErrors(error, err);
		    throw error
		  } finally {
		    if (
		      (error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) &&
		      (error === undefined || stream._readableState.autoDestroy)
		    ) {
		      destroyImpl.destroyer(stream, null);
		    } else {
		      stream.off('readable', next);
		      cleanup();
		    }
		  }
		}

		// Making it explicit these properties are not enumerable
		// because otherwise some prototype manipulation in
		// userland will fail.
		ObjectDefineProperties(Readable.prototype, {
		  readable: {
		    __proto__: null,
		    get() {
		      const r = this._readableState;
		      // r.readable === false means that this is part of a Duplex stream
		      // where the readable side was disabled upon construction.
		      // Compat. The user might manually disable readable side through
		      // deprecated setter.
		      return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted
		    },
		    set(val) {
		      // Backwards compat.
		      if (this._readableState) {
		        this._readableState.readable = !!val;
		      }
		    }
		  },
		  readableDidRead: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return this._readableState.dataEmitted
		    }
		  },
		  readableAborted: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return !!(
		        this._readableState.readable !== false &&
		        (this._readableState.destroyed || this._readableState.errored) &&
		        !this._readableState.endEmitted
		      )
		    }
		  },
		  readableHighWaterMark: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return this._readableState.highWaterMark
		    }
		  },
		  readableBuffer: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return this._readableState && this._readableState.buffer
		    }
		  },
		  readableFlowing: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return this._readableState.flowing
		    },
		    set: function (state) {
		      if (this._readableState) {
		        this._readableState.flowing = state;
		      }
		    }
		  },
		  readableLength: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState.length
		    }
		  },
		  readableObjectMode: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState ? this._readableState.objectMode : false
		    }
		  },
		  readableEncoding: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState ? this._readableState.encoding : null
		    }
		  },
		  errored: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState ? this._readableState.errored : null
		    }
		  },
		  closed: {
		    __proto__: null,
		    get() {
		      return this._readableState ? this._readableState.closed : false
		    }
		  },
		  destroyed: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState ? this._readableState.destroyed : false
		    },
		    set(value) {
		      // We ignore the value if the stream
		      // has not been initialized yet.
		      if (!this._readableState) {
		        return
		      }

		      // Backward compatibility, the user is explicitly
		      // managing destroyed.
		      this._readableState.destroyed = value;
		    }
		  },
		  readableEnded: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._readableState ? this._readableState.endEmitted : false
		    }
		  }
		});
		ObjectDefineProperties(ReadableState.prototype, {
		  // Legacy getter for `pipesCount`.
		  pipesCount: {
		    __proto__: null,
		    get() {
		      return this.pipes.length
		    }
		  },
		  // Legacy property for `paused`.
		  paused: {
		    __proto__: null,
		    get() {
		      return this[kPaused] !== false
		    },
		    set(value) {
		      this[kPaused] = !!value;
		    }
		  }
		});

		// Exposed for testing purposes only.
		Readable._fromList = fromList;

		// Pluck off n bytes from an array of buffers.
		// Length is the combined lengths of all the buffers in the list.
		// This function is designed to be inlinable, so please take care when making
		// changes to the function body.
		function fromList(n, state) {
		  // nothing buffered.
		  if (state.length === 0) return null
		  let ret;
		  if (state.objectMode) ret = state.buffer.shift();
		  else if (!n || n >= state.length) {
		    // Read it all, truncate the list.
		    if (state.decoder) ret = state.buffer.join('');
		    else if (state.buffer.length === 1) ret = state.buffer.first();
		    else ret = state.buffer.concat(state.length);
		    state.buffer.clear();
		  } else {
		    // read part of list.
		    ret = state.buffer.consume(n, state.decoder);
		  }
		  return ret
		}
		function endReadable(stream) {
		  const state = stream._readableState;
		  debug('endReadable', state.endEmitted);
		  if (!state.endEmitted) {
		    state.ended = true;
		    process.nextTick(endReadableNT, state, stream);
		  }
		}
		function endReadableNT(state, stream) {
		  debug('endReadableNT', state.endEmitted, state.length);

		  // Check that we didn't get one last unshift.
		  if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {
		    state.endEmitted = true;
		    stream.emit('end');
		    if (stream.writable && stream.allowHalfOpen === false) {
		      process.nextTick(endWritableNT, stream);
		    } else if (state.autoDestroy) {
		      // In case of duplex streams we need a way to detect
		      // if the writable side is ready for autoDestroy as well.
		      const wState = stream._writableState;
		      const autoDestroy =
		        !wState ||
		        (wState.autoDestroy &&
		          // We don't expect the writable to ever 'finish'
		          // if writable is explicitly set to false.
		          (wState.finished || wState.writable === false));
		      if (autoDestroy) {
		        stream.destroy();
		      }
		    }
		  }
		}
		function endWritableNT(stream) {
		  const writable = stream.writable && !stream.writableEnded && !stream.destroyed;
		  if (writable) {
		    stream.end();
		  }
		}
		Readable.from = function (iterable, opts) {
		  return from(Readable, iterable, opts)
		};
		let webStreamsAdapters;

		// Lazy to avoid circular references
		function lazyWebStreams() {
		  if (webStreamsAdapters === undefined) webStreamsAdapters = {};
		  return webStreamsAdapters
		}
		Readable.fromWeb = function (readableStream, options) {
		  return lazyWebStreams().newStreamReadableFromReadableStream(readableStream, options)
		};
		Readable.toWeb = function (streamReadable, options) {
		  return lazyWebStreams().newReadableStreamFromStreamReadable(streamReadable, options)
		};
		Readable.wrap = function (src, options) {
		  var _ref, _src$readableObjectMo;
		  return new Readable({
		    objectMode:
		      (_ref =
		        (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined
		          ? _src$readableObjectMo
		          : src.objectMode) !== null && _ref !== undefined
		        ? _ref
		        : true,
		    ...options,
		    destroy(err, callback) {
		      destroyImpl.destroyer(src, err);
		      callback(err);
		    }
		  }).wrap(src)
		};
		return readable;
	}

	var writable;
	var hasRequiredWritable;

	function requireWritable () {
		if (hasRequiredWritable) return writable;
		hasRequiredWritable = 1;

		/* replacement start */

		const process = requireBrowser$1();

		/* replacement end */

		const {
		  ArrayPrototypeSlice,
		  Error,
		  FunctionPrototypeSymbolHasInstance,
		  ObjectDefineProperty,
		  ObjectDefineProperties,
		  ObjectSetPrototypeOf,
		  StringPrototypeToLowerCase,
		  Symbol,
		  SymbolHasInstance
		} = requirePrimordials();
		writable = Writable;
		Writable.WritableState = WritableState;
		const { EventEmitter: EE } = requireEvents$1();
		const Stream = requireLegacy().Stream;
		const { Buffer } = requireBuffer();
		const destroyImpl = requireDestroy();
		const { addAbortSignal } = requireAddAbortSignal();
		const { getHighWaterMark, getDefaultHighWaterMark } = requireState();
		const {
		  ERR_INVALID_ARG_TYPE,
		  ERR_METHOD_NOT_IMPLEMENTED,
		  ERR_MULTIPLE_CALLBACK,
		  ERR_STREAM_CANNOT_PIPE,
		  ERR_STREAM_DESTROYED,
		  ERR_STREAM_ALREADY_FINISHED,
		  ERR_STREAM_NULL_VALUES,
		  ERR_STREAM_WRITE_AFTER_END,
		  ERR_UNKNOWN_ENCODING
		} = requireErrors().codes;
		const { errorOrDestroy } = destroyImpl;
		ObjectSetPrototypeOf(Writable.prototype, Stream.prototype);
		ObjectSetPrototypeOf(Writable, Stream);
		function nop() {}
		const kOnFinished = Symbol('kOnFinished');
		function WritableState(options, stream, isDuplex) {
		  // Duplex streams are both readable and writable, but share
		  // the same options object.
		  // However, some cases require setting options to different
		  // values for the readable and the writable sides of the duplex stream,
		  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.
		  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof requireDuplex();

		  // Object stream flag to indicate whether or not this stream
		  // contains buffers or objects.
		  this.objectMode = !!(options && options.objectMode);
		  if (isDuplex) this.objectMode = this.objectMode || !!(options && options.writableObjectMode);

		  // The point at which write() starts returning false
		  // Note: 0 is a valid value, means that we always return false if
		  // the entire buffer is not flushed immediately on write().
		  this.highWaterMark = options
		    ? getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex)
		    : getDefaultHighWaterMark(false);

		  // if _final has been called.
		  this.finalCalled = false;

		  // drain event flag.
		  this.needDrain = false;
		  // At the start of calling end()
		  this.ending = false;
		  // When end() has been called, and returned.
		  this.ended = false;
		  // When 'finish' is emitted.
		  this.finished = false;

		  // Has it been destroyed
		  this.destroyed = false;

		  // Should we decode strings into buffers before passing to _write?
		  // this is here so that some node-core streams can optimize string
		  // handling at a lower level.
		  const noDecode = !!(options && options.decodeStrings === false);
		  this.decodeStrings = !noDecode;

		  // Crypto is kind of old and crusty.  Historically, its default string
		  // encoding is 'binary' so we have to make this configurable.
		  // Everything else in the universe uses 'utf8', though.
		  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8';

		  // Not an actual buffer we keep track of, but a measurement
		  // of how much we're waiting to get pushed to some underlying
		  // socket or file.
		  this.length = 0;

		  // A flag to see when we're in the middle of a write.
		  this.writing = false;

		  // When true all writes will be buffered until .uncork() call.
		  this.corked = 0;

		  // A flag to be able to tell if the onwrite cb is called immediately,
		  // or on a later tick.  We set this to true at first, because any
		  // actions that shouldn't happen until "later" should generally also
		  // not happen before the first write call.
		  this.sync = true;

		  // A flag to know if we're processing previously buffered items, which
		  // may call the _write() callback in the same tick, so that we don't
		  // end up in an overlapped onwrite situation.
		  this.bufferProcessing = false;

		  // The callback that's passed to _write(chunk, cb).
		  this.onwrite = onwrite.bind(undefined, stream);

		  // The callback that the user supplies to write(chunk, encoding, cb).
		  this.writecb = null;

		  // The amount that is being written when _write is called.
		  this.writelen = 0;

		  // Storage for data passed to the afterWrite() callback in case of
		  // synchronous _write() completion.
		  this.afterWriteTickInfo = null;
		  resetBuffer(this);

		  // Number of pending user-supplied write callbacks
		  // this must be 0 before 'finish' can be emitted.
		  this.pendingcb = 0;

		  // Stream is still being constructed and cannot be
		  // destroyed until construction finished or failed.
		  // Async construction is opt in, therefore we start as
		  // constructed.
		  this.constructed = true;

		  // Emit prefinish if the only thing we're waiting for is _write cbs
		  // This is relevant for synchronous Transform streams.
		  this.prefinished = false;

		  // True if the error was already emitted and should not be thrown again.
		  this.errorEmitted = false;

		  // Should close be emitted on destroy. Defaults to true.
		  this.emitClose = !options || options.emitClose !== false;

		  // Should .destroy() be called after 'finish' (and potentially 'end').
		  this.autoDestroy = !options || options.autoDestroy !== false;

		  // Indicates whether the stream has errored. When true all write() calls
		  // should return false. This is needed since when autoDestroy
		  // is disabled we need a way to tell whether the stream has failed.
		  this.errored = null;

		  // Indicates whether the stream has finished destroying.
		  this.closed = false;

		  // True if close has been emitted or would have been emitted
		  // depending on emitClose.
		  this.closeEmitted = false;
		  this[kOnFinished] = [];
		}
		function resetBuffer(state) {
		  state.buffered = [];
		  state.bufferedIndex = 0;
		  state.allBuffers = true;
		  state.allNoop = true;
		}
		WritableState.prototype.getBuffer = function getBuffer() {
		  return ArrayPrototypeSlice(this.buffered, this.bufferedIndex)
		};
		ObjectDefineProperty(WritableState.prototype, 'bufferedRequestCount', {
		  __proto__: null,
		  get() {
		    return this.buffered.length - this.bufferedIndex
		  }
		});
		function Writable(options) {
		  // Writable ctor is applied to Duplexes, too.
		  // `realHasInstance` is necessary because using plain `instanceof`
		  // would return false, as no `_writableState` property is attached.

		  // Trying to use the custom `instanceof` for Writable here will also break the
		  // Node.js LazyTransform implementation, which has a non-trivial getter for
		  // `_writableState` that would lead to infinite recursion.

		  // Checking for a Stream.Duplex instance is faster here instead of inside
		  // the WritableState constructor, at least with V8 6.5.
		  const isDuplex = this instanceof requireDuplex();
		  if (!isDuplex && !FunctionPrototypeSymbolHasInstance(Writable, this)) return new Writable(options)
		  this._writableState = new WritableState(options, this, isDuplex);
		  if (options) {
		    if (typeof options.write === 'function') this._write = options.write;
		    if (typeof options.writev === 'function') this._writev = options.writev;
		    if (typeof options.destroy === 'function') this._destroy = options.destroy;
		    if (typeof options.final === 'function') this._final = options.final;
		    if (typeof options.construct === 'function') this._construct = options.construct;
		    if (options.signal) addAbortSignal(options.signal, this);
		  }
		  Stream.call(this, options);
		  destroyImpl.construct(this, () => {
		    const state = this._writableState;
		    if (!state.writing) {
		      clearBuffer(this, state);
		    }
		    finishMaybe(this, state);
		  });
		}
		ObjectDefineProperty(Writable, SymbolHasInstance, {
		  __proto__: null,
		  value: function (object) {
		    if (FunctionPrototypeSymbolHasInstance(this, object)) return true
		    if (this !== Writable) return false
		    return object && object._writableState instanceof WritableState
		  }
		});

		// Otherwise people can pipe Writable streams, which is just wrong.
		Writable.prototype.pipe = function () {
		  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());
		};
		function _write(stream, chunk, encoding, cb) {
		  const state = stream._writableState;
		  if (typeof encoding === 'function') {
		    cb = encoding;
		    encoding = state.defaultEncoding;
		  } else {
		    if (!encoding) encoding = state.defaultEncoding;
		    else if (encoding !== 'buffer' && !Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)
		    if (typeof cb !== 'function') cb = nop;
		  }
		  if (chunk === null) {
		    throw new ERR_STREAM_NULL_VALUES()
		  } else if (!state.objectMode) {
		    if (typeof chunk === 'string') {
		      if (state.decodeStrings !== false) {
		        chunk = Buffer.from(chunk, encoding);
		        encoding = 'buffer';
		      }
		    } else if (chunk instanceof Buffer) {
		      encoding = 'buffer';
		    } else if (Stream._isUint8Array(chunk)) {
		      chunk = Stream._uint8ArrayToBuffer(chunk);
		      encoding = 'buffer';
		    } else {
		      throw new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)
		    }
		  }
		  let err;
		  if (state.ending) {
		    err = new ERR_STREAM_WRITE_AFTER_END();
		  } else if (state.destroyed) {
		    err = new ERR_STREAM_DESTROYED('write');
		  }
		  if (err) {
		    process.nextTick(cb, err);
		    errorOrDestroy(stream, err, true);
		    return err
		  }
		  state.pendingcb++;
		  return writeOrBuffer(stream, state, chunk, encoding, cb)
		}
		Writable.prototype.write = function (chunk, encoding, cb) {
		  return _write(this, chunk, encoding, cb) === true
		};
		Writable.prototype.cork = function () {
		  this._writableState.corked++;
		};
		Writable.prototype.uncork = function () {
		  const state = this._writableState;
		  if (state.corked) {
		    state.corked--;
		    if (!state.writing) clearBuffer(this, state);
		  }
		};
		Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
		  // node::ParseEncoding() requires lower case.
		  if (typeof encoding === 'string') encoding = StringPrototypeToLowerCase(encoding);
		  if (!Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)
		  this._writableState.defaultEncoding = encoding;
		  return this
		};

		// If we're already writing something, then just put this
		// in the queue, and wait our turn.  Otherwise, call _write
		// If we return false, then we need a drain event, so set that flag.
		function writeOrBuffer(stream, state, chunk, encoding, callback) {
		  const len = state.objectMode ? 1 : chunk.length;
		  state.length += len;

		  // stream._write resets state.length
		  const ret = state.length < state.highWaterMark;
		  // We must ensure that previous needDrain will not be reset to false.
		  if (!ret) state.needDrain = true;
		  if (state.writing || state.corked || state.errored || !state.constructed) {
		    state.buffered.push({
		      chunk,
		      encoding,
		      callback
		    });
		    if (state.allBuffers && encoding !== 'buffer') {
		      state.allBuffers = false;
		    }
		    if (state.allNoop && callback !== nop) {
		      state.allNoop = false;
		    }
		  } else {
		    state.writelen = len;
		    state.writecb = callback;
		    state.writing = true;
		    state.sync = true;
		    stream._write(chunk, encoding, state.onwrite);
		    state.sync = false;
		  }

		  // Return false if errored or destroyed in order to break
		  // any synchronous while(stream.write(data)) loops.
		  return ret && !state.errored && !state.destroyed
		}
		function doWrite(stream, state, writev, len, chunk, encoding, cb) {
		  state.writelen = len;
		  state.writecb = cb;
		  state.writing = true;
		  state.sync = true;
		  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));
		  else if (writev) stream._writev(chunk, state.onwrite);
		  else stream._write(chunk, encoding, state.onwrite);
		  state.sync = false;
		}
		function onwriteError(stream, state, er, cb) {
		  --state.pendingcb;
		  cb(er);
		  // Ensure callbacks are invoked even when autoDestroy is
		  // not enabled. Passing `er` here doesn't make sense since
		  // it's related to one specific write, not to the buffered
		  // writes.
		  errorBuffer(state);
		  // This can emit error, but error must always follow cb.
		  errorOrDestroy(stream, er);
		}
		function onwrite(stream, er) {
		  const state = stream._writableState;
		  const sync = state.sync;
		  const cb = state.writecb;
		  if (typeof cb !== 'function') {
		    errorOrDestroy(stream, new ERR_MULTIPLE_CALLBACK());
		    return
		  }
		  state.writing = false;
		  state.writecb = null;
		  state.length -= state.writelen;
		  state.writelen = 0;
		  if (er) {
		    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
		    er.stack; // eslint-disable-line no-unused-expressions

		    if (!state.errored) {
		      state.errored = er;
		    }

		    // In case of duplex streams we need to notify the readable side of the
		    // error.
		    if (stream._readableState && !stream._readableState.errored) {
		      stream._readableState.errored = er;
		    }
		    if (sync) {
		      process.nextTick(onwriteError, stream, state, er, cb);
		    } else {
		      onwriteError(stream, state, er, cb);
		    }
		  } else {
		    if (state.buffered.length > state.bufferedIndex) {
		      clearBuffer(stream, state);
		    }
		    if (sync) {
		      // It is a common case that the callback passed to .write() is always
		      // the same. In that case, we do not schedule a new nextTick(), but
		      // rather just increase a counter, to improve performance and avoid
		      // memory allocations.
		      if (state.afterWriteTickInfo !== null && state.afterWriteTickInfo.cb === cb) {
		        state.afterWriteTickInfo.count++;
		      } else {
		        state.afterWriteTickInfo = {
		          count: 1,
		          cb,
		          stream,
		          state
		        };
		        process.nextTick(afterWriteTick, state.afterWriteTickInfo);
		      }
		    } else {
		      afterWrite(stream, state, 1, cb);
		    }
		  }
		}
		function afterWriteTick({ stream, state, count, cb }) {
		  state.afterWriteTickInfo = null;
		  return afterWrite(stream, state, count, cb)
		}
		function afterWrite(stream, state, count, cb) {
		  const needDrain = !state.ending && !stream.destroyed && state.length === 0 && state.needDrain;
		  if (needDrain) {
		    state.needDrain = false;
		    stream.emit('drain');
		  }
		  while (count-- > 0) {
		    state.pendingcb--;
		    cb();
		  }
		  if (state.destroyed) {
		    errorBuffer(state);
		  }
		  finishMaybe(stream, state);
		}

		// If there's something in the buffer waiting, then invoke callbacks.
		function errorBuffer(state) {
		  if (state.writing) {
		    return
		  }
		  for (let n = state.bufferedIndex; n < state.buffered.length; ++n) {
		    var _state$errored;
		    const { chunk, callback } = state.buffered[n];
		    const len = state.objectMode ? 1 : chunk.length;
		    state.length -= len;
		    callback(
		      (_state$errored = state.errored) !== null && _state$errored !== undefined
		        ? _state$errored
		        : new ERR_STREAM_DESTROYED('write')
		    );
		  }
		  const onfinishCallbacks = state[kOnFinished].splice(0);
		  for (let i = 0; i < onfinishCallbacks.length; i++) {
		    var _state$errored2;
		    onfinishCallbacks[i](
		      (_state$errored2 = state.errored) !== null && _state$errored2 !== undefined
		        ? _state$errored2
		        : new ERR_STREAM_DESTROYED('end')
		    );
		  }
		  resetBuffer(state);
		}

		// If there's something in the buffer waiting, then process it.
		function clearBuffer(stream, state) {
		  if (state.corked || state.bufferProcessing || state.destroyed || !state.constructed) {
		    return
		  }
		  const { buffered, bufferedIndex, objectMode } = state;
		  const bufferedLength = buffered.length - bufferedIndex;
		  if (!bufferedLength) {
		    return
		  }
		  let i = bufferedIndex;
		  state.bufferProcessing = true;
		  if (bufferedLength > 1 && stream._writev) {
		    state.pendingcb -= bufferedLength - 1;
		    const callback = state.allNoop
		      ? nop
		      : (err) => {
		          for (let n = i; n < buffered.length; ++n) {
		            buffered[n].callback(err);
		          }
		        };
		    // Make a copy of `buffered` if it's going to be used by `callback` above,
		    // since `doWrite` will mutate the array.
		    const chunks = state.allNoop && i === 0 ? buffered : ArrayPrototypeSlice(buffered, i);
		    chunks.allBuffers = state.allBuffers;
		    doWrite(stream, state, true, state.length, chunks, '', callback);
		    resetBuffer(state);
		  } else {
		    do {
		      const { chunk, encoding, callback } = buffered[i];
		      buffered[i++] = null;
		      const len = objectMode ? 1 : chunk.length;
		      doWrite(stream, state, false, len, chunk, encoding, callback);
		    } while (i < buffered.length && !state.writing)
		    if (i === buffered.length) {
		      resetBuffer(state);
		    } else if (i > 256) {
		      buffered.splice(0, i);
		      state.bufferedIndex = 0;
		    } else {
		      state.bufferedIndex = i;
		    }
		  }
		  state.bufferProcessing = false;
		}
		Writable.prototype._write = function (chunk, encoding, cb) {
		  if (this._writev) {
		    this._writev(
		      [
		        {
		          chunk,
		          encoding
		        }
		      ],
		      cb
		    );
		  } else {
		    throw new ERR_METHOD_NOT_IMPLEMENTED('_write()')
		  }
		};
		Writable.prototype._writev = null;
		Writable.prototype.end = function (chunk, encoding, cb) {
		  const state = this._writableState;
		  if (typeof chunk === 'function') {
		    cb = chunk;
		    chunk = null;
		    encoding = null;
		  } else if (typeof encoding === 'function') {
		    cb = encoding;
		    encoding = null;
		  }
		  let err;
		  if (chunk !== null && chunk !== undefined) {
		    const ret = _write(this, chunk, encoding);
		    if (ret instanceof Error) {
		      err = ret;
		    }
		  }

		  // .end() fully uncorks.
		  if (state.corked) {
		    state.corked = 1;
		    this.uncork();
		  }
		  if (err) ; else if (!state.errored && !state.ending) {
		    // This is forgiving in terms of unnecessary calls to end() and can hide
		    // logic errors. However, usually such errors are harmless and causing a
		    // hard error can be disproportionately destructive. It is not always
		    // trivial for the user to determine whether end() needs to be called
		    // or not.

		    state.ending = true;
		    finishMaybe(this, state, true);
		    state.ended = true;
		  } else if (state.finished) {
		    err = new ERR_STREAM_ALREADY_FINISHED('end');
		  } else if (state.destroyed) {
		    err = new ERR_STREAM_DESTROYED('end');
		  }
		  if (typeof cb === 'function') {
		    if (err || state.finished) {
		      process.nextTick(cb, err);
		    } else {
		      state[kOnFinished].push(cb);
		    }
		  }
		  return this
		};
		function needFinish(state) {
		  return (
		    state.ending &&
		    !state.destroyed &&
		    state.constructed &&
		    state.length === 0 &&
		    !state.errored &&
		    state.buffered.length === 0 &&
		    !state.finished &&
		    !state.writing &&
		    !state.errorEmitted &&
		    !state.closeEmitted
		  )
		}
		function callFinal(stream, state) {
		  let called = false;
		  function onFinish(err) {
		    if (called) {
		      errorOrDestroy(stream, err !== null && err !== undefined ? err : ERR_MULTIPLE_CALLBACK());
		      return
		    }
		    called = true;
		    state.pendingcb--;
		    if (err) {
		      const onfinishCallbacks = state[kOnFinished].splice(0);
		      for (let i = 0; i < onfinishCallbacks.length; i++) {
		        onfinishCallbacks[i](err);
		      }
		      errorOrDestroy(stream, err, state.sync);
		    } else if (needFinish(state)) {
		      state.prefinished = true;
		      stream.emit('prefinish');
		      // Backwards compat. Don't check state.sync here.
		      // Some streams assume 'finish' will be emitted
		      // asynchronously relative to _final callback.
		      state.pendingcb++;
		      process.nextTick(finish, stream, state);
		    }
		  }
		  state.sync = true;
		  state.pendingcb++;
		  try {
		    stream._final(onFinish);
		  } catch (err) {
		    onFinish(err);
		  }
		  state.sync = false;
		}
		function prefinish(stream, state) {
		  if (!state.prefinished && !state.finalCalled) {
		    if (typeof stream._final === 'function' && !state.destroyed) {
		      state.finalCalled = true;
		      callFinal(stream, state);
		    } else {
		      state.prefinished = true;
		      stream.emit('prefinish');
		    }
		  }
		}
		function finishMaybe(stream, state, sync) {
		  if (needFinish(state)) {
		    prefinish(stream, state);
		    if (state.pendingcb === 0) {
		      if (sync) {
		        state.pendingcb++;
		        process.nextTick(
		          (stream, state) => {
		            if (needFinish(state)) {
		              finish(stream, state);
		            } else {
		              state.pendingcb--;
		            }
		          },
		          stream,
		          state
		        );
		      } else if (needFinish(state)) {
		        state.pendingcb++;
		        finish(stream, state);
		      }
		    }
		  }
		}
		function finish(stream, state) {
		  state.pendingcb--;
		  state.finished = true;
		  const onfinishCallbacks = state[kOnFinished].splice(0);
		  for (let i = 0; i < onfinishCallbacks.length; i++) {
		    onfinishCallbacks[i]();
		  }
		  stream.emit('finish');
		  if (state.autoDestroy) {
		    // In case of duplex streams we need a way to detect
		    // if the readable side is ready for autoDestroy as well.
		    const rState = stream._readableState;
		    const autoDestroy =
		      !rState ||
		      (rState.autoDestroy &&
		        // We don't expect the readable to ever 'end'
		        // if readable is explicitly set to false.
		        (rState.endEmitted || rState.readable === false));
		    if (autoDestroy) {
		      stream.destroy();
		    }
		  }
		}
		ObjectDefineProperties(Writable.prototype, {
		  closed: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.closed : false
		    }
		  },
		  destroyed: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.destroyed : false
		    },
		    set(value) {
		      // Backward compatibility, the user is explicitly managing destroyed.
		      if (this._writableState) {
		        this._writableState.destroyed = value;
		      }
		    }
		  },
		  writable: {
		    __proto__: null,
		    get() {
		      const w = this._writableState;
		      // w.writable === false means that this is part of a Duplex stream
		      // where the writable side was disabled upon construction.
		      // Compat. The user might manually disable writable side through
		      // deprecated setter.
		      return !!w && w.writable !== false && !w.destroyed && !w.errored && !w.ending && !w.ended
		    },
		    set(val) {
		      // Backwards compatible.
		      if (this._writableState) {
		        this._writableState.writable = !!val;
		      }
		    }
		  },
		  writableFinished: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.finished : false
		    }
		  },
		  writableObjectMode: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.objectMode : false
		    }
		  },
		  writableBuffer: {
		    __proto__: null,
		    get() {
		      return this._writableState && this._writableState.getBuffer()
		    }
		  },
		  writableEnded: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.ending : false
		    }
		  },
		  writableNeedDrain: {
		    __proto__: null,
		    get() {
		      const wState = this._writableState;
		      if (!wState) return false
		      return !wState.destroyed && !wState.ending && wState.needDrain
		    }
		  },
		  writableHighWaterMark: {
		    __proto__: null,
		    get() {
		      return this._writableState && this._writableState.highWaterMark
		    }
		  },
		  writableCorked: {
		    __proto__: null,
		    get() {
		      return this._writableState ? this._writableState.corked : 0
		    }
		  },
		  writableLength: {
		    __proto__: null,
		    get() {
		      return this._writableState && this._writableState.length
		    }
		  },
		  errored: {
		    __proto__: null,
		    enumerable: false,
		    get() {
		      return this._writableState ? this._writableState.errored : null
		    }
		  },
		  writableAborted: {
		    __proto__: null,
		    enumerable: false,
		    get: function () {
		      return !!(
		        this._writableState.writable !== false &&
		        (this._writableState.destroyed || this._writableState.errored) &&
		        !this._writableState.finished
		      )
		    }
		  }
		});
		const destroy = destroyImpl.destroy;
		Writable.prototype.destroy = function (err, cb) {
		  const state = this._writableState;

		  // Invoke pending callbacks.
		  if (!state.destroyed && (state.bufferedIndex < state.buffered.length || state[kOnFinished].length)) {
		    process.nextTick(errorBuffer, state);
		  }
		  destroy.call(this, err, cb);
		  return this
		};
		Writable.prototype._undestroy = destroyImpl.undestroy;
		Writable.prototype._destroy = function (err, cb) {
		  cb(err);
		};
		Writable.prototype[EE.captureRejectionSymbol] = function (err) {
		  this.destroy(err);
		};
		let webStreamsAdapters;

		// Lazy to avoid circular references
		function lazyWebStreams() {
		  if (webStreamsAdapters === undefined) webStreamsAdapters = {};
		  return webStreamsAdapters
		}
		Writable.fromWeb = function (writableStream, options) {
		  return lazyWebStreams().newStreamWritableFromWritableStream(writableStream, options)
		};
		Writable.toWeb = function (streamWritable) {
		  return lazyWebStreams().newWritableStreamFromStreamWritable(streamWritable)
		};
		return writable;
	}

	/* replacement start */

	var duplexify;
	var hasRequiredDuplexify;

	function requireDuplexify () {
		if (hasRequiredDuplexify) return duplexify;
		hasRequiredDuplexify = 1;
		const process = requireBrowser$1()

		/* replacement end */

		;	const bufferModule = requireBuffer();
		const {
		  isReadable,
		  isWritable,
		  isIterable,
		  isNodeStream,
		  isReadableNodeStream,
		  isWritableNodeStream,
		  isDuplexNodeStream,
		  isReadableStream,
		  isWritableStream
		} = requireUtils();
		const eos = requireEndOfStream();
		const {
		  AbortError,
		  codes: { ERR_INVALID_ARG_TYPE, ERR_INVALID_RETURN_VALUE }
		} = requireErrors();
		const { destroyer } = requireDestroy();
		const Duplex = requireDuplex();
		const Readable = requireReadable();
		const Writable = requireWritable();
		const { createDeferredPromise } = requireUtil$1();
		const from = requireFrom();
		const Blob = globalThis.Blob || bufferModule.Blob;
		const isBlob =
		  typeof Blob !== 'undefined'
		    ? function isBlob(b) {
		        return b instanceof Blob
		      }
		    : function isBlob(b) {
		        return false
		      };
		const AbortController = globalThis.AbortController || requireBrowser$2().AbortController;
		const { FunctionPrototypeCall } = requirePrimordials();

		// This is needed for pre node 17.
		class Duplexify extends Duplex {
		  constructor(options) {
		    super(options);

		    // https://github.com/nodejs/node/pull/34385

		    if ((options === null || options === undefined ? undefined : options.readable) === false) {
		      this._readableState.readable = false;
		      this._readableState.ended = true;
		      this._readableState.endEmitted = true;
		    }
		    if ((options === null || options === undefined ? undefined : options.writable) === false) {
		      this._writableState.writable = false;
		      this._writableState.ending = true;
		      this._writableState.ended = true;
		      this._writableState.finished = true;
		    }
		  }
		}
		duplexify = function duplexify(body, name) {
		  if (isDuplexNodeStream(body)) {
		    return body
		  }
		  if (isReadableNodeStream(body)) {
		    return _duplexify({
		      readable: body
		    })
		  }
		  if (isWritableNodeStream(body)) {
		    return _duplexify({
		      writable: body
		    })
		  }
		  if (isNodeStream(body)) {
		    return _duplexify({
		      writable: false,
		      readable: false
		    })
		  }
		  if (isReadableStream(body)) {
		    return _duplexify({
		      readable: Readable.fromWeb(body)
		    })
		  }
		  if (isWritableStream(body)) {
		    return _duplexify({
		      writable: Writable.fromWeb(body)
		    })
		  }
		  if (typeof body === 'function') {
		    const { value, write, final, destroy } = fromAsyncGen(body);
		    if (isIterable(value)) {
		      return from(Duplexify, value, {
		        // TODO (ronag): highWaterMark?
		        objectMode: true,
		        write,
		        final,
		        destroy
		      })
		    }
		    const then = value === null || value === undefined ? undefined : value.then;
		    if (typeof then === 'function') {
		      let d;
		      const promise = FunctionPrototypeCall(
		        then,
		        value,
		        (val) => {
		          if (val != null) {
		            throw new ERR_INVALID_RETURN_VALUE('nully', 'body', val)
		          }
		        },
		        (err) => {
		          destroyer(d, err);
		        }
		      );
		      return (d = new Duplexify({
		        // TODO (ronag): highWaterMark?
		        objectMode: true,
		        readable: false,
		        write,
		        final(cb) {
		          final(async () => {
		            try {
		              await promise;
		              process.nextTick(cb, null);
		            } catch (err) {
		              process.nextTick(cb, err);
		            }
		          });
		        },
		        destroy
		      }))
		    }
		    throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or AsyncFunction', name, value)
		  }
		  if (isBlob(body)) {
		    return duplexify(body.arrayBuffer())
		  }
		  if (isIterable(body)) {
		    return from(Duplexify, body, {
		      // TODO (ronag): highWaterMark?
		      objectMode: true,
		      writable: false
		    })
		  }
		  if (
		    isReadableStream(body === null || body === undefined ? undefined : body.readable) &&
		    isWritableStream(body === null || body === undefined ? undefined : body.writable)
		  ) {
		    return Duplexify.fromWeb(body)
		  }
		  if (
		    typeof (body === null || body === undefined ? undefined : body.writable) === 'object' ||
		    typeof (body === null || body === undefined ? undefined : body.readable) === 'object'
		  ) {
		    const readable =
		      body !== null && body !== undefined && body.readable
		        ? isReadableNodeStream(body === null || body === undefined ? undefined : body.readable)
		          ? body === null || body === undefined
		            ? undefined
		            : body.readable
		          : duplexify(body.readable)
		        : undefined;
		    const writable =
		      body !== null && body !== undefined && body.writable
		        ? isWritableNodeStream(body === null || body === undefined ? undefined : body.writable)
		          ? body === null || body === undefined
		            ? undefined
		            : body.writable
		          : duplexify(body.writable)
		        : undefined;
		    return _duplexify({
		      readable,
		      writable
		    })
		  }
		  const then = body === null || body === undefined ? undefined : body.then;
		  if (typeof then === 'function') {
		    let d;
		    FunctionPrototypeCall(
		      then,
		      body,
		      (val) => {
		        if (val != null) {
		          d.push(val);
		        }
		        d.push(null);
		      },
		      (err) => {
		        destroyer(d, err);
		      }
		    );
		    return (d = new Duplexify({
		      objectMode: true,
		      writable: false,
		      read() {}
		    }))
		  }
		  throw new ERR_INVALID_ARG_TYPE(
		    name,
		    [
		      'Blob',
		      'ReadableStream',
		      'WritableStream',
		      'Stream',
		      'Iterable',
		      'AsyncIterable',
		      'Function',
		      '{ readable, writable } pair',
		      'Promise'
		    ],
		    body
		  )
		};
		function fromAsyncGen(fn) {
		  let { promise, resolve } = createDeferredPromise();
		  const ac = new AbortController();
		  const signal = ac.signal;
		  const value = fn(
		    (async function* () {
		      while (true) {
		        const _promise = promise;
		        promise = null;
		        const { chunk, done, cb } = await _promise;
		        process.nextTick(cb);
		        if (done) return
		        if (signal.aborted)
		          throw new AbortError(undefined, {
		            cause: signal.reason
		          })
		        ;({ promise, resolve } = createDeferredPromise());
		        yield chunk;
		      }
		    })(),
		    {
		      signal
		    }
		  );
		  return {
		    value,
		    write(chunk, encoding, cb) {
		      const _resolve = resolve;
		      resolve = null;
		      _resolve({
		        chunk,
		        done: false,
		        cb
		      });
		    },
		    final(cb) {
		      const _resolve = resolve;
		      resolve = null;
		      _resolve({
		        done: true,
		        cb
		      });
		    },
		    destroy(err, cb) {
		      ac.abort();
		      cb(err);
		    }
		  }
		}
		function _duplexify(pair) {
		  const r = pair.readable && typeof pair.readable.read !== 'function' ? Readable.wrap(pair.readable) : pair.readable;
		  const w = pair.writable;
		  let readable = !!isReadable(r);
		  let writable = !!isWritable(w);
		  let ondrain;
		  let onfinish;
		  let onreadable;
		  let onclose;
		  let d;
		  function onfinished(err) {
		    const cb = onclose;
		    onclose = null;
		    if (cb) {
		      cb(err);
		    } else if (err) {
		      d.destroy(err);
		    }
		  }

		  // TODO(ronag): Avoid double buffering.
		  // Implement Writable/Readable/Duplex traits.
		  // See, https://github.com/nodejs/node/pull/33515.
		  d = new Duplexify({
		    // TODO (ronag): highWaterMark?
		    readableObjectMode: !!(r !== null && r !== undefined && r.readableObjectMode),
		    writableObjectMode: !!(w !== null && w !== undefined && w.writableObjectMode),
		    readable,
		    writable
		  });
		  if (writable) {
		    eos(w, (err) => {
		      writable = false;
		      if (err) {
		        destroyer(r, err);
		      }
		      onfinished(err);
		    });
		    d._write = function (chunk, encoding, callback) {
		      if (w.write(chunk, encoding)) {
		        callback();
		      } else {
		        ondrain = callback;
		      }
		    };
		    d._final = function (callback) {
		      w.end();
		      onfinish = callback;
		    };
		    w.on('drain', function () {
		      if (ondrain) {
		        const cb = ondrain;
		        ondrain = null;
		        cb();
		      }
		    });
		    w.on('finish', function () {
		      if (onfinish) {
		        const cb = onfinish;
		        onfinish = null;
		        cb();
		      }
		    });
		  }
		  if (readable) {
		    eos(r, (err) => {
		      readable = false;
		      if (err) {
		        destroyer(r, err);
		      }
		      onfinished(err);
		    });
		    r.on('readable', function () {
		      if (onreadable) {
		        const cb = onreadable;
		        onreadable = null;
		        cb();
		      }
		    });
		    r.on('end', function () {
		      d.push(null);
		    });
		    d._read = function () {
		      while (true) {
		        const buf = r.read();
		        if (buf === null) {
		          onreadable = d._read;
		          return
		        }
		        if (!d.push(buf)) {
		          return
		        }
		      }
		    };
		  }
		  d._destroy = function (err, callback) {
		    if (!err && onclose !== null) {
		      err = new AbortError();
		    }
		    onreadable = null;
		    ondrain = null;
		    onfinish = null;
		    if (onclose === null) {
		      callback(err);
		    } else {
		      onclose = callback;
		      destroyer(w, err);
		      destroyer(r, err);
		    }
		  };
		  return d
		}
		return duplexify;
	}

	var duplex;
	var hasRequiredDuplex;

	function requireDuplex () {
		if (hasRequiredDuplex) return duplex;
		hasRequiredDuplex = 1;

		const {
		  ObjectDefineProperties,
		  ObjectGetOwnPropertyDescriptor,
		  ObjectKeys,
		  ObjectSetPrototypeOf
		} = requirePrimordials();
		duplex = Duplex;
		const Readable = requireReadable();
		const Writable = requireWritable();
		ObjectSetPrototypeOf(Duplex.prototype, Readable.prototype);
		ObjectSetPrototypeOf(Duplex, Readable);
		{
		  const keys = ObjectKeys(Writable.prototype);
		  // Allow the keys array to be GC'ed.
		  for (let i = 0; i < keys.length; i++) {
		    const method = keys[i];
		    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];
		  }
		}
		function Duplex(options) {
		  if (!(this instanceof Duplex)) return new Duplex(options)
		  Readable.call(this, options);
		  Writable.call(this, options);
		  if (options) {
		    this.allowHalfOpen = options.allowHalfOpen !== false;
		    if (options.readable === false) {
		      this._readableState.readable = false;
		      this._readableState.ended = true;
		      this._readableState.endEmitted = true;
		    }
		    if (options.writable === false) {
		      this._writableState.writable = false;
		      this._writableState.ending = true;
		      this._writableState.ended = true;
		      this._writableState.finished = true;
		    }
		  } else {
		    this.allowHalfOpen = true;
		  }
		}
		ObjectDefineProperties(Duplex.prototype, {
		  writable: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writable')
		  },
		  writableHighWaterMark: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableHighWaterMark')
		  },
		  writableObjectMode: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableObjectMode')
		  },
		  writableBuffer: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableBuffer')
		  },
		  writableLength: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableLength')
		  },
		  writableFinished: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableFinished')
		  },
		  writableCorked: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableCorked')
		  },
		  writableEnded: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableEnded')
		  },
		  writableNeedDrain: {
		    __proto__: null,
		    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableNeedDrain')
		  },
		  destroyed: {
		    __proto__: null,
		    get() {
		      if (this._readableState === undefined || this._writableState === undefined) {
		        return false
		      }
		      return this._readableState.destroyed && this._writableState.destroyed
		    },
		    set(value) {
		      // Backward compatibility, the user is explicitly
		      // managing destroyed.
		      if (this._readableState && this._writableState) {
		        this._readableState.destroyed = value;
		        this._writableState.destroyed = value;
		      }
		    }
		  }
		});
		let webStreamsAdapters;

		// Lazy to avoid circular references
		function lazyWebStreams() {
		  if (webStreamsAdapters === undefined) webStreamsAdapters = {};
		  return webStreamsAdapters
		}
		Duplex.fromWeb = function (pair, options) {
		  return lazyWebStreams().newStreamDuplexFromReadableWritablePair(pair, options)
		};
		Duplex.toWeb = function (duplex) {
		  return lazyWebStreams().newReadableWritablePairFromDuplex(duplex)
		};
		let duplexify;
		Duplex.from = function (body) {
		  if (!duplexify) {
		    duplexify = requireDuplexify();
		  }
		  return duplexify(body, 'body')
		};
		return duplex;
	}

	var transform;
	var hasRequiredTransform;

	function requireTransform () {
		if (hasRequiredTransform) return transform;
		hasRequiredTransform = 1;

		const { ObjectSetPrototypeOf, Symbol } = requirePrimordials();
		transform = Transform;
		const { ERR_METHOD_NOT_IMPLEMENTED } = requireErrors().codes;
		const Duplex = requireDuplex();
		const { getHighWaterMark } = requireState();
		ObjectSetPrototypeOf(Transform.prototype, Duplex.prototype);
		ObjectSetPrototypeOf(Transform, Duplex);
		const kCallback = Symbol('kCallback');
		function Transform(options) {
		  if (!(this instanceof Transform)) return new Transform(options)

		  // TODO (ronag): This should preferably always be
		  // applied but would be semver-major. Or even better;
		  // make Transform a Readable with the Writable interface.
		  const readableHighWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', true) : null;
		  if (readableHighWaterMark === 0) {
		    // A Duplex will buffer both on the writable and readable side while
		    // a Transform just wants to buffer hwm number of elements. To avoid
		    // buffering twice we disable buffering on the writable side.
		    options = {
		      ...options,
		      highWaterMark: null,
		      readableHighWaterMark,
		      // TODO (ronag): 0 is not optimal since we have
		      // a "bug" where we check needDrain before calling _write and not after.
		      // Refs: https://github.com/nodejs/node/pull/32887
		      // Refs: https://github.com/nodejs/node/pull/35941
		      writableHighWaterMark: options.writableHighWaterMark || 0
		    };
		  }
		  Duplex.call(this, options);

		  // We have implemented the _read method, and done the other things
		  // that Readable wants before the first _read call, so unset the
		  // sync guard flag.
		  this._readableState.sync = false;
		  this[kCallback] = null;
		  if (options) {
		    if (typeof options.transform === 'function') this._transform = options.transform;
		    if (typeof options.flush === 'function') this._flush = options.flush;
		  }

		  // When the writable side finishes, then flush out anything remaining.
		  // Backwards compat. Some Transform streams incorrectly implement _final
		  // instead of or in addition to _flush. By using 'prefinish' instead of
		  // implementing _final we continue supporting this unfortunate use case.
		  this.on('prefinish', prefinish);
		}
		function final(cb) {
		  if (typeof this._flush === 'function' && !this.destroyed) {
		    this._flush((er, data) => {
		      if (er) {
		        if (cb) {
		          cb(er);
		        } else {
		          this.destroy(er);
		        }
		        return
		      }
		      if (data != null) {
		        this.push(data);
		      }
		      this.push(null);
		      if (cb) {
		        cb();
		      }
		    });
		  } else {
		    this.push(null);
		    if (cb) {
		      cb();
		    }
		  }
		}
		function prefinish() {
		  if (this._final !== final) {
		    final.call(this);
		  }
		}
		Transform.prototype._final = final;
		Transform.prototype._transform = function (chunk, encoding, callback) {
		  throw new ERR_METHOD_NOT_IMPLEMENTED('_transform()')
		};
		Transform.prototype._write = function (chunk, encoding, callback) {
		  const rState = this._readableState;
		  const wState = this._writableState;
		  const length = rState.length;
		  this._transform(chunk, encoding, (err, val) => {
		    if (err) {
		      callback(err);
		      return
		    }
		    if (val != null) {
		      this.push(val);
		    }
		    if (
		      wState.ended ||
		      // Backwards compat.
		      length === rState.length ||
		      // Backwards compat.
		      rState.length < rState.highWaterMark
		    ) {
		      callback();
		    } else {
		      this[kCallback] = callback;
		    }
		  });
		};
		Transform.prototype._read = function () {
		  if (this[kCallback]) {
		    const callback = this[kCallback];
		    this[kCallback] = null;
		    callback();
		  }
		};
		return transform;
	}

	var passthrough;
	var hasRequiredPassthrough;

	function requirePassthrough () {
		if (hasRequiredPassthrough) return passthrough;
		hasRequiredPassthrough = 1;

		const { ObjectSetPrototypeOf } = requirePrimordials();
		passthrough = PassThrough;
		const Transform = requireTransform();
		ObjectSetPrototypeOf(PassThrough.prototype, Transform.prototype);
		ObjectSetPrototypeOf(PassThrough, Transform);
		function PassThrough(options) {
		  if (!(this instanceof PassThrough)) return new PassThrough(options)
		  Transform.call(this, options);
		}
		PassThrough.prototype._transform = function (chunk, encoding, cb) {
		  cb(null, chunk);
		};
		return passthrough;
	}

	/* replacement start */

	var pipeline_1;
	var hasRequiredPipeline;

	function requirePipeline () {
		if (hasRequiredPipeline) return pipeline_1;
		hasRequiredPipeline = 1;
		const process = requireBrowser$1()

		/* replacement end */
		// Ported from https://github.com/mafintosh/pump with
		// permission from the author, Mathias Buus (@mafintosh).

		;	const { ArrayIsArray, Promise, SymbolAsyncIterator, SymbolDispose } = requirePrimordials();
		const eos = requireEndOfStream();
		const { once } = requireUtil$1();
		const destroyImpl = requireDestroy();
		const Duplex = requireDuplex();
		const {
		  aggregateTwoErrors,
		  codes: {
		    ERR_INVALID_ARG_TYPE,
		    ERR_INVALID_RETURN_VALUE,
		    ERR_MISSING_ARGS,
		    ERR_STREAM_DESTROYED,
		    ERR_STREAM_PREMATURE_CLOSE
		  },
		  AbortError
		} = requireErrors();
		const { validateFunction, validateAbortSignal } = requireValidators();
		const {
		  isIterable,
		  isReadable,
		  isReadableNodeStream,
		  isNodeStream,
		  isTransformStream,
		  isWebStream,
		  isReadableStream,
		  isReadableFinished
		} = requireUtils();
		const AbortController = globalThis.AbortController || requireBrowser$2().AbortController;
		let PassThrough;
		let Readable;
		let addAbortListener;
		function destroyer(stream, reading, writing) {
		  let finished = false;
		  stream.on('close', () => {
		    finished = true;
		  });
		  const cleanup = eos(
		    stream,
		    {
		      readable: reading,
		      writable: writing
		    },
		    (err) => {
		      finished = !err;
		    }
		  );
		  return {
		    destroy: (err) => {
		      if (finished) return
		      finished = true;
		      destroyImpl.destroyer(stream, err || new ERR_STREAM_DESTROYED('pipe'));
		    },
		    cleanup
		  }
		}
		function popCallback(streams) {
		  // Streams should never be an empty array. It should always contain at least
		  // a single stream. Therefore optimize for the average case instead of
		  // checking for length === 0 as well.
		  validateFunction(streams[streams.length - 1], 'streams[stream.length - 1]');
		  return streams.pop()
		}
		function makeAsyncIterable(val) {
		  if (isIterable(val)) {
		    return val
		  } else if (isReadableNodeStream(val)) {
		    // Legacy streams are not Iterable.
		    return fromReadable(val)
		  }
		  throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable'], val)
		}
		async function* fromReadable(val) {
		  if (!Readable) {
		    Readable = requireReadable();
		  }
		  yield* Readable.prototype[SymbolAsyncIterator].call(val);
		}
		async function pumpToNode(iterable, writable, finish, { end }) {
		  let error;
		  let onresolve = null;
		  const resume = (err) => {
		    if (err) {
		      error = err;
		    }
		    if (onresolve) {
		      const callback = onresolve;
		      onresolve = null;
		      callback();
		    }
		  };
		  const wait = () =>
		    new Promise((resolve, reject) => {
		      if (error) {
		        reject(error);
		      } else {
		        onresolve = () => {
		          if (error) {
		            reject(error);
		          } else {
		            resolve();
		          }
		        };
		      }
		    });
		  writable.on('drain', resume);
		  const cleanup = eos(
		    writable,
		    {
		      readable: false
		    },
		    resume
		  );
		  try {
		    if (writable.writableNeedDrain) {
		      await wait();
		    }
		    for await (const chunk of iterable) {
		      if (!writable.write(chunk)) {
		        await wait();
		      }
		    }
		    if (end) {
		      writable.end();
		      await wait();
		    }
		    finish();
		  } catch (err) {
		    finish(error !== err ? aggregateTwoErrors(error, err) : err);
		  } finally {
		    cleanup();
		    writable.off('drain', resume);
		  }
		}
		async function pumpToWeb(readable, writable, finish, { end }) {
		  if (isTransformStream(writable)) {
		    writable = writable.writable;
		  }
		  // https://streams.spec.whatwg.org/#example-manual-write-with-backpressure
		  const writer = writable.getWriter();
		  try {
		    for await (const chunk of readable) {
		      await writer.ready;
		      writer.write(chunk).catch(() => {});
		    }
		    await writer.ready;
		    if (end) {
		      await writer.close();
		    }
		    finish();
		  } catch (err) {
		    try {
		      await writer.abort(err);
		      finish(err);
		    } catch (err) {
		      finish(err);
		    }
		  }
		}
		function pipeline(...streams) {
		  return pipelineImpl(streams, once(popCallback(streams)))
		}
		function pipelineImpl(streams, callback, opts) {
		  if (streams.length === 1 && ArrayIsArray(streams[0])) {
		    streams = streams[0];
		  }
		  if (streams.length < 2) {
		    throw new ERR_MISSING_ARGS('streams')
		  }
		  const ac = new AbortController();
		  const signal = ac.signal;
		  const outerSignal = opts === null || opts === undefined ? undefined : opts.signal;

		  // Need to cleanup event listeners if last stream is readable
		  // https://github.com/nodejs/node/issues/35452
		  const lastStreamCleanup = [];
		  validateAbortSignal(outerSignal, 'options.signal');
		  function abort() {
		    finishImpl(new AbortError());
		  }
		  addAbortListener = addAbortListener || requireUtil$1().addAbortListener;
		  let disposable;
		  if (outerSignal) {
		    disposable = addAbortListener(outerSignal, abort);
		  }
		  let error;
		  let value;
		  const destroys = [];
		  let finishCount = 0;
		  function finish(err) {
		    finishImpl(err, --finishCount === 0);
		  }
		  function finishImpl(err, final) {
		    var _disposable;
		    if (err && (!error || error.code === 'ERR_STREAM_PREMATURE_CLOSE')) {
		      error = err;
		    }
		    if (!error && !final) {
		      return
		    }
		    while (destroys.length) {
		      destroys.shift()(error);
		    }
	(_disposable = disposable) === null || _disposable === undefined ? undefined : _disposable[SymbolDispose]();
		    ac.abort();
		    if (final) {
		      if (!error) {
		        lastStreamCleanup.forEach((fn) => fn());
		      }
		      process.nextTick(callback, error, value);
		    }
		  }
		  let ret;
		  for (let i = 0; i < streams.length; i++) {
		    const stream = streams[i];
		    const reading = i < streams.length - 1;
		    const writing = i > 0;
		    const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false;
		    const isLastStream = i === streams.length - 1;
		    if (isNodeStream(stream)) {
		      if (end) {
		        const { destroy, cleanup } = destroyer(stream, reading, writing);
		        destroys.push(destroy);
		        if (isReadable(stream) && isLastStream) {
		          lastStreamCleanup.push(cleanup);
		        }
		      }

		      // Catch stream errors that occur after pipe/pump has completed.
		      function onError(err) {
		        if (err && err.name !== 'AbortError' && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
		          finish(err);
		        }
		      }
		      stream.on('error', onError);
		      if (isReadable(stream) && isLastStream) {
		        lastStreamCleanup.push(() => {
		          stream.removeListener('error', onError);
		        });
		      }
		    }
		    if (i === 0) {
		      if (typeof stream === 'function') {
		        ret = stream({
		          signal
		        });
		        if (!isIterable(ret)) {
		          throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or Stream', 'source', ret)
		        }
		      } else if (isIterable(stream) || isReadableNodeStream(stream) || isTransformStream(stream)) {
		        ret = stream;
		      } else {
		        ret = Duplex.from(stream);
		      }
		    } else if (typeof stream === 'function') {
		      if (isTransformStream(ret)) {
		        var _ret;
		        ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable);
		      } else {
		        ret = makeAsyncIterable(ret);
		      }
		      ret = stream(ret, {
		        signal
		      });
		      if (reading) {
		        if (!isIterable(ret, true)) {
		          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable', `transform[${i - 1}]`, ret)
		        }
		      } else {
		        var _ret2;
		        if (!PassThrough) {
		          PassThrough = requirePassthrough();
		        }

		        // If the last argument to pipeline is not a stream
		        // we must create a proxy stream so that pipeline(...)
		        // always returns a stream which can be further
		        // composed through `.pipe(stream)`.

		        const pt = new PassThrough({
		          objectMode: true
		        });

		        // Handle Promises/A+ spec, `then` could be a getter that throws on
		        // second use.
		        const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then;
		        if (typeof then === 'function') {
		          finishCount++;
		          then.call(
		            ret,
		            (val) => {
		              value = val;
		              if (val != null) {
		                pt.write(val);
		              }
		              if (end) {
		                pt.end();
		              }
		              process.nextTick(finish);
		            },
		            (err) => {
		              pt.destroy(err);
		              process.nextTick(finish, err);
		            }
		          );
		        } else if (isIterable(ret, true)) {
		          finishCount++;
		          pumpToNode(ret, pt, finish, {
		            end
		          });
		        } else if (isReadableStream(ret) || isTransformStream(ret)) {
		          const toRead = ret.readable || ret;
		          finishCount++;
		          pumpToNode(toRead, pt, finish, {
		            end
		          });
		        } else {
		          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable or Promise', 'destination', ret)
		        }
		        ret = pt;
		        const { destroy, cleanup } = destroyer(ret, false, true);
		        destroys.push(destroy);
		        if (isLastStream) {
		          lastStreamCleanup.push(cleanup);
		        }
		      }
		    } else if (isNodeStream(stream)) {
		      if (isReadableNodeStream(ret)) {
		        finishCount += 2;
		        const cleanup = pipe(ret, stream, finish, {
		          end
		        });
		        if (isReadable(stream) && isLastStream) {
		          lastStreamCleanup.push(cleanup);
		        }
		      } else if (isTransformStream(ret) || isReadableStream(ret)) {
		        const toRead = ret.readable || ret;
		        finishCount++;
		        pumpToNode(toRead, stream, finish, {
		          end
		        });
		      } else if (isIterable(ret)) {
		        finishCount++;
		        pumpToNode(ret, stream, finish, {
		          end
		        });
		      } else {
		        throw new ERR_INVALID_ARG_TYPE(
		          'val',
		          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],
		          ret
		        )
		      }
		      ret = stream;
		    } else if (isWebStream(stream)) {
		      if (isReadableNodeStream(ret)) {
		        finishCount++;
		        pumpToWeb(makeAsyncIterable(ret), stream, finish, {
		          end
		        });
		      } else if (isReadableStream(ret) || isIterable(ret)) {
		        finishCount++;
		        pumpToWeb(ret, stream, finish, {
		          end
		        });
		      } else if (isTransformStream(ret)) {
		        finishCount++;
		        pumpToWeb(ret.readable, stream, finish, {
		          end
		        });
		      } else {
		        throw new ERR_INVALID_ARG_TYPE(
		          'val',
		          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],
		          ret
		        )
		      }
		      ret = stream;
		    } else {
		      ret = Duplex.from(stream);
		    }
		  }
		  if (
		    (signal !== null && signal !== undefined && signal.aborted) ||
		    (outerSignal !== null && outerSignal !== undefined && outerSignal.aborted)
		  ) {
		    process.nextTick(abort);
		  }
		  return ret
		}
		function pipe(src, dst, finish, { end }) {
		  let ended = false;
		  dst.on('close', () => {
		    if (!ended) {
		      // Finish if the destination closes before the source has completed.
		      finish(new ERR_STREAM_PREMATURE_CLOSE());
		    }
		  });
		  src.pipe(dst, {
		    end: false
		  }); // If end is true we already will have a listener to end dst.

		  if (end) {
		    // Compat. Before node v10.12.0 stdio used to throw an error so
		    // pipe() did/does not end() stdio destinations.
		    // Now they allow it but "secretly" don't close the underlying fd.

		    function endFn() {
		      ended = true;
		      dst.end();
		    }
		    if (isReadableFinished(src)) {
		      // End the destination if the source has already ended.
		      process.nextTick(endFn);
		    } else {
		      src.once('end', endFn);
		    }
		  } else {
		    finish();
		  }
		  eos(
		    src,
		    {
		      readable: true,
		      writable: false
		    },
		    (err) => {
		      const rState = src._readableState;
		      if (
		        err &&
		        err.code === 'ERR_STREAM_PREMATURE_CLOSE' &&
		        rState &&
		        rState.ended &&
		        !rState.errored &&
		        !rState.errorEmitted
		      ) {
		        // Some readable streams will emit 'close' before 'end'. However, since
		        // this is on the readable side 'end' should still be emitted if the
		        // stream has been ended and no error emitted. This should be allowed in
		        // favor of backwards compatibility. Since the stream is piped to a
		        // destination this should not result in any observable difference.
		        // We don't need to check if this is a writable premature close since
		        // eos will only fail with premature close on the reading side for
		        // duplex streams.
		        src.once('end', finish).once('error', finish);
		      } else {
		        finish(err);
		      }
		    }
		  );
		  return eos(
		    dst,
		    {
		      readable: false,
		      writable: true
		    },
		    finish
		  )
		}
		pipeline_1 = {
		  pipelineImpl,
		  pipeline
		};
		return pipeline_1;
	}

	var compose;
	var hasRequiredCompose;

	function requireCompose () {
		if (hasRequiredCompose) return compose;
		hasRequiredCompose = 1;

		const { pipeline } = requirePipeline();
		const Duplex = requireDuplex();
		const { destroyer } = requireDestroy();
		const {
		  isNodeStream,
		  isReadable,
		  isWritable,
		  isWebStream,
		  isTransformStream,
		  isWritableStream,
		  isReadableStream
		} = requireUtils();
		const {
		  AbortError,
		  codes: { ERR_INVALID_ARG_VALUE, ERR_MISSING_ARGS }
		} = requireErrors();
		const eos = requireEndOfStream();
		compose = function compose(...streams) {
		  if (streams.length === 0) {
		    throw new ERR_MISSING_ARGS('streams')
		  }
		  if (streams.length === 1) {
		    return Duplex.from(streams[0])
		  }
		  const orgStreams = [...streams];
		  if (typeof streams[0] === 'function') {
		    streams[0] = Duplex.from(streams[0]);
		  }
		  if (typeof streams[streams.length - 1] === 'function') {
		    const idx = streams.length - 1;
		    streams[idx] = Duplex.from(streams[idx]);
		  }
		  for (let n = 0; n < streams.length; ++n) {
		    if (!isNodeStream(streams[n]) && !isWebStream(streams[n])) {
		      // TODO(ronag): Add checks for non streams.
		      continue
		    }
		    if (
		      n < streams.length - 1 &&
		      !(isReadable(streams[n]) || isReadableStream(streams[n]) || isTransformStream(streams[n]))
		    ) {
		      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be readable')
		    }
		    if (n > 0 && !(isWritable(streams[n]) || isWritableStream(streams[n]) || isTransformStream(streams[n]))) {
		      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be writable')
		    }
		  }
		  let ondrain;
		  let onfinish;
		  let onreadable;
		  let onclose;
		  let d;
		  function onfinished(err) {
		    const cb = onclose;
		    onclose = null;
		    if (cb) {
		      cb(err);
		    } else if (err) {
		      d.destroy(err);
		    } else if (!readable && !writable) {
		      d.destroy();
		    }
		  }
		  const head = streams[0];
		  const tail = pipeline(streams, onfinished);
		  const writable = !!(isWritable(head) || isWritableStream(head) || isTransformStream(head));
		  const readable = !!(isReadable(tail) || isReadableStream(tail) || isTransformStream(tail));

		  // TODO(ronag): Avoid double buffering.
		  // Implement Writable/Readable/Duplex traits.
		  // See, https://github.com/nodejs/node/pull/33515.
		  d = new Duplex({
		    // TODO (ronag): highWaterMark?
		    writableObjectMode: !!(head !== null && head !== undefined && head.writableObjectMode),
		    readableObjectMode: !!(tail !== null && tail !== undefined && tail.readableObjectMode),
		    writable,
		    readable
		  });
		  if (writable) {
		    if (isNodeStream(head)) {
		      d._write = function (chunk, encoding, callback) {
		        if (head.write(chunk, encoding)) {
		          callback();
		        } else {
		          ondrain = callback;
		        }
		      };
		      d._final = function (callback) {
		        head.end();
		        onfinish = callback;
		      };
		      head.on('drain', function () {
		        if (ondrain) {
		          const cb = ondrain;
		          ondrain = null;
		          cb();
		        }
		      });
		    } else if (isWebStream(head)) {
		      const writable = isTransformStream(head) ? head.writable : head;
		      const writer = writable.getWriter();
		      d._write = async function (chunk, encoding, callback) {
		        try {
		          await writer.ready;
		          writer.write(chunk).catch(() => {});
		          callback();
		        } catch (err) {
		          callback(err);
		        }
		      };
		      d._final = async function (callback) {
		        try {
		          await writer.ready;
		          writer.close().catch(() => {});
		          onfinish = callback;
		        } catch (err) {
		          callback(err);
		        }
		      };
		    }
		    const toRead = isTransformStream(tail) ? tail.readable : tail;
		    eos(toRead, () => {
		      if (onfinish) {
		        const cb = onfinish;
		        onfinish = null;
		        cb();
		      }
		    });
		  }
		  if (readable) {
		    if (isNodeStream(tail)) {
		      tail.on('readable', function () {
		        if (onreadable) {
		          const cb = onreadable;
		          onreadable = null;
		          cb();
		        }
		      });
		      tail.on('end', function () {
		        d.push(null);
		      });
		      d._read = function () {
		        while (true) {
		          const buf = tail.read();
		          if (buf === null) {
		            onreadable = d._read;
		            return
		          }
		          if (!d.push(buf)) {
		            return
		          }
		        }
		      };
		    } else if (isWebStream(tail)) {
		      const readable = isTransformStream(tail) ? tail.readable : tail;
		      const reader = readable.getReader();
		      d._read = async function () {
		        while (true) {
		          try {
		            const { value, done } = await reader.read();
		            if (!d.push(value)) {
		              return
		            }
		            if (done) {
		              d.push(null);
		              return
		            }
		          } catch {
		            return
		          }
		        }
		      };
		    }
		  }
		  d._destroy = function (err, callback) {
		    if (!err && onclose !== null) {
		      err = new AbortError();
		    }
		    onreadable = null;
		    ondrain = null;
		    onfinish = null;
		    if (onclose === null) {
		      callback(err);
		    } else {
		      onclose = callback;
		      if (isNodeStream(tail)) {
		        destroyer(tail, err);
		      }
		    }
		  };
		  return d
		};
		return compose;
	}

	var hasRequiredOperators;

	function requireOperators () {
		if (hasRequiredOperators) return operators;
		hasRequiredOperators = 1;

		const AbortController = globalThis.AbortController || requireBrowser$2().AbortController;
		const {
		  codes: { ERR_INVALID_ARG_VALUE, ERR_INVALID_ARG_TYPE, ERR_MISSING_ARGS, ERR_OUT_OF_RANGE },
		  AbortError
		} = requireErrors();
		const { validateAbortSignal, validateInteger, validateObject } = requireValidators();
		const kWeakHandler = requirePrimordials().Symbol('kWeak');
		const kResistStopPropagation = requirePrimordials().Symbol('kResistStopPropagation');
		const { finished } = requireEndOfStream();
		const staticCompose = requireCompose();
		const { addAbortSignalNoValidate } = requireAddAbortSignal();
		const { isWritable, isNodeStream } = requireUtils();
		const { deprecate } = requireUtil$1();
		const {
		  ArrayPrototypePush,
		  Boolean,
		  MathFloor,
		  Number,
		  NumberIsNaN,
		  Promise,
		  PromiseReject,
		  PromiseResolve,
		  PromisePrototypeThen,
		  Symbol
		} = requirePrimordials();
		const kEmpty = Symbol('kEmpty');
		const kEof = Symbol('kEof');
		function compose(stream, options) {
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  if (isNodeStream(stream) && !isWritable(stream)) {
		    throw new ERR_INVALID_ARG_VALUE('stream', stream, 'must be writable')
		  }
		  const composedStream = staticCompose(this, stream);
		  if (options !== null && options !== undefined && options.signal) {
		    // Not validating as we already validated before
		    addAbortSignalNoValidate(options.signal, composedStream);
		  }
		  return composedStream
		}
		function map(fn, options) {
		  if (typeof fn !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
		  }
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  let concurrency = 1;
		  if ((options === null || options === undefined ? undefined : options.concurrency) != null) {
		    concurrency = MathFloor(options.concurrency);
		  }
		  let highWaterMark = concurrency - 1;
		  if ((options === null || options === undefined ? undefined : options.highWaterMark) != null) {
		    highWaterMark = MathFloor(options.highWaterMark);
		  }
		  validateInteger(concurrency, 'options.concurrency', 1);
		  validateInteger(highWaterMark, 'options.highWaterMark', 0);
		  highWaterMark += concurrency;
		  return async function* map() {
		    const signal = requireUtil$1().AbortSignalAny(
		      [options === null || options === undefined ? undefined : options.signal].filter(Boolean)
		    );
		    const stream = this;
		    const queue = [];
		    const signalOpt = {
		      signal
		    };
		    let next;
		    let resume;
		    let done = false;
		    let cnt = 0;
		    function onCatch() {
		      done = true;
		      afterItemProcessed();
		    }
		    function afterItemProcessed() {
		      cnt -= 1;
		      maybeResume();
		    }
		    function maybeResume() {
		      if (resume && !done && cnt < concurrency && queue.length < highWaterMark) {
		        resume();
		        resume = null;
		      }
		    }
		    async function pump() {
		      try {
		        for await (let val of stream) {
		          if (done) {
		            return
		          }
		          if (signal.aborted) {
		            throw new AbortError()
		          }
		          try {
		            val = fn(val, signalOpt);
		            if (val === kEmpty) {
		              continue
		            }
		            val = PromiseResolve(val);
		          } catch (err) {
		            val = PromiseReject(err);
		          }
		          cnt += 1;
		          PromisePrototypeThen(val, afterItemProcessed, onCatch);
		          queue.push(val);
		          if (next) {
		            next();
		            next = null;
		          }
		          if (!done && (queue.length >= highWaterMark || cnt >= concurrency)) {
		            await new Promise((resolve) => {
		              resume = resolve;
		            });
		          }
		        }
		        queue.push(kEof);
		      } catch (err) {
		        const val = PromiseReject(err);
		        PromisePrototypeThen(val, afterItemProcessed, onCatch);
		        queue.push(val);
		      } finally {
		        done = true;
		        if (next) {
		          next();
		          next = null;
		        }
		      }
		    }
		    pump();
		    try {
		      while (true) {
		        while (queue.length > 0) {
		          const val = await queue[0];
		          if (val === kEof) {
		            return
		          }
		          if (signal.aborted) {
		            throw new AbortError()
		          }
		          if (val !== kEmpty) {
		            yield val;
		          }
		          queue.shift();
		          maybeResume();
		        }
		        await new Promise((resolve) => {
		          next = resolve;
		        });
		      }
		    } finally {
		      done = true;
		      if (resume) {
		        resume();
		        resume = null;
		      }
		    }
		  }.call(this)
		}
		function asIndexedPairs(options = undefined) {
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  return async function* asIndexedPairs() {
		    let index = 0;
		    for await (const val of this) {
		      var _options$signal;
		      if (
		        options !== null &&
		        options !== undefined &&
		        (_options$signal = options.signal) !== null &&
		        _options$signal !== undefined &&
		        _options$signal.aborted
		      ) {
		        throw new AbortError({
		          cause: options.signal.reason
		        })
		      }
		      yield [index++, val];
		    }
		  }.call(this)
		}
		async function some(fn, options = undefined) {
		  for await (const unused of filter.call(this, fn, options)) {
		    return true
		  }
		  return false
		}
		async function every(fn, options = undefined) {
		  if (typeof fn !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
		  }
		  // https://en.wikipedia.org/wiki/De_Morgan%27s_laws
		  return !(await some.call(
		    this,
		    async (...args) => {
		      return !(await fn(...args))
		    },
		    options
		  ))
		}
		async function find(fn, options) {
		  for await (const result of filter.call(this, fn, options)) {
		    return result
		  }
		  return undefined
		}
		async function forEach(fn, options) {
		  if (typeof fn !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
		  }
		  async function forEachFn(value, options) {
		    await fn(value, options);
		    return kEmpty
		  }
		  // eslint-disable-next-line no-unused-vars
		  for await (const unused of map.call(this, forEachFn, options));
		}
		function filter(fn, options) {
		  if (typeof fn !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
		  }
		  async function filterFn(value, options) {
		    if (await fn(value, options)) {
		      return value
		    }
		    return kEmpty
		  }
		  return map.call(this, filterFn, options)
		}

		// Specific to provide better error to reduce since the argument is only
		// missing if the stream has no items in it - but the code is still appropriate
		class ReduceAwareErrMissingArgs extends ERR_MISSING_ARGS {
		  constructor() {
		    super('reduce');
		    this.message = 'Reduce of an empty stream requires an initial value';
		  }
		}
		async function reduce(reducer, initialValue, options) {
		  var _options$signal2;
		  if (typeof reducer !== 'function') {
		    throw new ERR_INVALID_ARG_TYPE('reducer', ['Function', 'AsyncFunction'], reducer)
		  }
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  let hasInitialValue = arguments.length > 1;
		  if (
		    options !== null &&
		    options !== undefined &&
		    (_options$signal2 = options.signal) !== null &&
		    _options$signal2 !== undefined &&
		    _options$signal2.aborted
		  ) {
		    const err = new AbortError(undefined, {
		      cause: options.signal.reason
		    });
		    this.once('error', () => {}); // The error is already propagated
		    await finished(this.destroy(err));
		    throw err
		  }
		  const ac = new AbortController();
		  const signal = ac.signal;
		  if (options !== null && options !== undefined && options.signal) {
		    const opts = {
		      once: true,
		      [kWeakHandler]: this,
		      [kResistStopPropagation]: true
		    };
		    options.signal.addEventListener('abort', () => ac.abort(), opts);
		  }
		  let gotAnyItemFromStream = false;
		  try {
		    for await (const value of this) {
		      var _options$signal3;
		      gotAnyItemFromStream = true;
		      if (
		        options !== null &&
		        options !== undefined &&
		        (_options$signal3 = options.signal) !== null &&
		        _options$signal3 !== undefined &&
		        _options$signal3.aborted
		      ) {
		        throw new AbortError()
		      }
		      if (!hasInitialValue) {
		        initialValue = value;
		        hasInitialValue = true;
		      } else {
		        initialValue = await reducer(initialValue, value, {
		          signal
		        });
		      }
		    }
		    if (!gotAnyItemFromStream && !hasInitialValue) {
		      throw new ReduceAwareErrMissingArgs()
		    }
		  } finally {
		    ac.abort();
		  }
		  return initialValue
		}
		async function toArray(options) {
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  const result = [];
		  for await (const val of this) {
		    var _options$signal4;
		    if (
		      options !== null &&
		      options !== undefined &&
		      (_options$signal4 = options.signal) !== null &&
		      _options$signal4 !== undefined &&
		      _options$signal4.aborted
		    ) {
		      throw new AbortError(undefined, {
		        cause: options.signal.reason
		      })
		    }
		    ArrayPrototypePush(result, val);
		  }
		  return result
		}
		function flatMap(fn, options) {
		  const values = map.call(this, fn, options);
		  return async function* flatMap() {
		    for await (const val of values) {
		      yield* val;
		    }
		  }.call(this)
		}
		function toIntegerOrInfinity(number) {
		  // We coerce here to align with the spec
		  // https://github.com/tc39/proposal-iterator-helpers/issues/169
		  number = Number(number);
		  if (NumberIsNaN(number)) {
		    return 0
		  }
		  if (number < 0) {
		    throw new ERR_OUT_OF_RANGE('number', '>= 0', number)
		  }
		  return number
		}
		function drop(number, options = undefined) {
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  number = toIntegerOrInfinity(number);
		  return async function* drop() {
		    var _options$signal5;
		    if (
		      options !== null &&
		      options !== undefined &&
		      (_options$signal5 = options.signal) !== null &&
		      _options$signal5 !== undefined &&
		      _options$signal5.aborted
		    ) {
		      throw new AbortError()
		    }
		    for await (const val of this) {
		      var _options$signal6;
		      if (
		        options !== null &&
		        options !== undefined &&
		        (_options$signal6 = options.signal) !== null &&
		        _options$signal6 !== undefined &&
		        _options$signal6.aborted
		      ) {
		        throw new AbortError()
		      }
		      if (number-- <= 0) {
		        yield val;
		      }
		    }
		  }.call(this)
		}
		function take(number, options = undefined) {
		  if (options != null) {
		    validateObject(options, 'options');
		  }
		  if ((options === null || options === undefined ? undefined : options.signal) != null) {
		    validateAbortSignal(options.signal, 'options.signal');
		  }
		  number = toIntegerOrInfinity(number);
		  return async function* take() {
		    var _options$signal7;
		    if (
		      options !== null &&
		      options !== undefined &&
		      (_options$signal7 = options.signal) !== null &&
		      _options$signal7 !== undefined &&
		      _options$signal7.aborted
		    ) {
		      throw new AbortError()
		    }
		    for await (const val of this) {
		      var _options$signal8;
		      if (
		        options !== null &&
		        options !== undefined &&
		        (_options$signal8 = options.signal) !== null &&
		        _options$signal8 !== undefined &&
		        _options$signal8.aborted
		      ) {
		        throw new AbortError()
		      }
		      if (number-- > 0) {
		        yield val;
		      }

		      // Don't get another item from iterator in case we reached the end
		      if (number <= 0) {
		        return
		      }
		    }
		  }.call(this)
		}
		operators.streamReturningOperators = {
		  asIndexedPairs: deprecate(asIndexedPairs, 'readable.asIndexedPairs will be removed in a future version.'),
		  drop,
		  filter,
		  flatMap,
		  map,
		  take,
		  compose
		};
		operators.promiseReturningOperators = {
		  every,
		  forEach,
		  reduce,
		  toArray,
		  some,
		  find
		};
		return operators;
	}

	var promises;
	var hasRequiredPromises;

	function requirePromises () {
		if (hasRequiredPromises) return promises;
		hasRequiredPromises = 1;

		const { ArrayPrototypePop, Promise } = requirePrimordials();
		const { isIterable, isNodeStream, isWebStream } = requireUtils();
		const { pipelineImpl: pl } = requirePipeline();
		const { finished } = requireEndOfStream();
		requireStream();
		function pipeline(...streams) {
		  return new Promise((resolve, reject) => {
		    let signal;
		    let end;
		    const lastArg = streams[streams.length - 1];
		    if (
		      lastArg &&
		      typeof lastArg === 'object' &&
		      !isNodeStream(lastArg) &&
		      !isIterable(lastArg) &&
		      !isWebStream(lastArg)
		    ) {
		      const options = ArrayPrototypePop(streams);
		      signal = options.signal;
		      end = options.end;
		    }
		    pl(
		      streams,
		      (err, value) => {
		        if (err) {
		          reject(err);
		        } else {
		          resolve(value);
		        }
		      },
		      {
		        signal,
		        end
		      }
		    );
		  })
		}
		promises = {
		  finished,
		  pipeline
		};
		return promises;
	}

	var hasRequiredStream;

	function requireStream () {
		if (hasRequiredStream) return stream.exports;
		hasRequiredStream = 1;

		/* replacement start */

		const { Buffer } = requireBuffer();

		/* replacement end */

		const { ObjectDefineProperty, ObjectKeys, ReflectApply } = requirePrimordials();
		const {
		  promisify: { custom: customPromisify }
		} = requireUtil$1();
		const { streamReturningOperators, promiseReturningOperators } = requireOperators();
		const {
		  codes: { ERR_ILLEGAL_CONSTRUCTOR }
		} = requireErrors();
		const compose = requireCompose();
		const { setDefaultHighWaterMark, getDefaultHighWaterMark } = requireState();
		const { pipeline } = requirePipeline();
		const { destroyer } = requireDestroy();
		const eos = requireEndOfStream();
		const promises = requirePromises();
		const utils = requireUtils();
		const Stream = (stream.exports = requireLegacy().Stream);
		Stream.isDestroyed = utils.isDestroyed;
		Stream.isDisturbed = utils.isDisturbed;
		Stream.isErrored = utils.isErrored;
		Stream.isReadable = utils.isReadable;
		Stream.isWritable = utils.isWritable;
		Stream.Readable = requireReadable();
		for (const key of ObjectKeys(streamReturningOperators)) {
		  const op = streamReturningOperators[key];
		  function fn(...args) {
		    if (new.target) {
		      throw ERR_ILLEGAL_CONSTRUCTOR()
		    }
		    return Stream.Readable.from(ReflectApply(op, this, args))
		  }
		  ObjectDefineProperty(fn, 'name', {
		    __proto__: null,
		    value: op.name
		  });
		  ObjectDefineProperty(fn, 'length', {
		    __proto__: null,
		    value: op.length
		  });
		  ObjectDefineProperty(Stream.Readable.prototype, key, {
		    __proto__: null,
		    value: fn,
		    enumerable: false,
		    configurable: true,
		    writable: true
		  });
		}
		for (const key of ObjectKeys(promiseReturningOperators)) {
		  const op = promiseReturningOperators[key];
		  function fn(...args) {
		    if (new.target) {
		      throw ERR_ILLEGAL_CONSTRUCTOR()
		    }
		    return ReflectApply(op, this, args)
		  }
		  ObjectDefineProperty(fn, 'name', {
		    __proto__: null,
		    value: op.name
		  });
		  ObjectDefineProperty(fn, 'length', {
		    __proto__: null,
		    value: op.length
		  });
		  ObjectDefineProperty(Stream.Readable.prototype, key, {
		    __proto__: null,
		    value: fn,
		    enumerable: false,
		    configurable: true,
		    writable: true
		  });
		}
		Stream.Writable = requireWritable();
		Stream.Duplex = requireDuplex();
		Stream.Transform = requireTransform();
		Stream.PassThrough = requirePassthrough();
		Stream.pipeline = pipeline;
		const { addAbortSignal } = requireAddAbortSignal();
		Stream.addAbortSignal = addAbortSignal;
		Stream.finished = eos;
		Stream.destroy = destroyer;
		Stream.compose = compose;
		Stream.setDefaultHighWaterMark = setDefaultHighWaterMark;
		Stream.getDefaultHighWaterMark = getDefaultHighWaterMark;
		ObjectDefineProperty(Stream, 'promises', {
		  __proto__: null,
		  configurable: true,
		  enumerable: true,
		  get() {
		    return promises
		  }
		});
		ObjectDefineProperty(pipeline, customPromisify, {
		  __proto__: null,
		  enumerable: true,
		  get() {
		    return promises.pipeline
		  }
		});
		ObjectDefineProperty(eos, customPromisify, {
		  __proto__: null,
		  enumerable: true,
		  get() {
		    return promises.finished
		  }
		});

		// Backwards-compat with node 0.4.x
		Stream.Stream = Stream;
		Stream._isUint8Array = function isUint8Array(value) {
		  return value instanceof Uint8Array
		};
		Stream._uint8ArrayToBuffer = function _uint8ArrayToBuffer(chunk) {
		  return Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)
		};
		return stream.exports;
	}

	var hasRequiredBrowser;

	function requireBrowser () {
		if (hasRequiredBrowser) return browser$2.exports;
		hasRequiredBrowser = 1;
		(function (module) {

			const CustomStream = requireStream();
			const promises = requirePromises();
			const originalDestroy = CustomStream.Readable.destroy;
			module.exports = CustomStream.Readable;

			// Explicit export naming is needed for ESM
			module.exports._uint8ArrayToBuffer = CustomStream._uint8ArrayToBuffer;
			module.exports._isUint8Array = CustomStream._isUint8Array;
			module.exports.isDisturbed = CustomStream.isDisturbed;
			module.exports.isErrored = CustomStream.isErrored;
			module.exports.isReadable = CustomStream.isReadable;
			module.exports.Readable = CustomStream.Readable;
			module.exports.Writable = CustomStream.Writable;
			module.exports.Duplex = CustomStream.Duplex;
			module.exports.Transform = CustomStream.Transform;
			module.exports.PassThrough = CustomStream.PassThrough;
			module.exports.addAbortSignal = CustomStream.addAbortSignal;
			module.exports.finished = CustomStream.finished;
			module.exports.destroy = CustomStream.destroy;
			module.exports.destroy = originalDestroy;
			module.exports.pipeline = CustomStream.pipeline;
			module.exports.compose = CustomStream.compose;
			Object.defineProperty(CustomStream, 'promises', {
			  configurable: true,
			  enumerable: true,
			  get() {
			    return promises
			  }
			});
			module.exports.Stream = CustomStream.Stream;

			// Allow default importing
			module.exports.default = module.exports; 
		} (browser$2));
		return browser$2.exports;
	}

	var browserExports = requireBrowser();

	// **N3Store** objects store N3 quads by graph in memory.

	const ITERATOR = Symbol('iter');

	function merge(target, source, depth = 4) {
	  if (depth === 0)
	    return Object.assign(target, source);

	  for (const key in source)
	    target[key] = merge(target[key] || Object.create(null), source[key], depth - 1);

	  return target;
	}

	/**
	 * Determines the intersection of the `_graphs` index s1 and s2.
	 * s1 and s2 *must* belong to Stores that share an `_entityIndex`.
	 *
	 * False is returned when there is no intersection; this should
	 * *not* be set as the value for an index.
	 */
	function intersect(s1, s2, depth = 4) {
	  let target = false;

	  for (const key in s1) {
	    if (key in s2) {
	      const intersection = depth === 0 ? null : intersect(s1[key], s2[key], depth - 1);
	      if (intersection !== false) {
	        target = target || Object.create(null);
	        target[key] = intersection;
	      }
	      // Depth 3 is the 'subjects', 'predicates' and 'objects' keys.
	      // If the 'subjects' index is empty, so will the 'predicates' and 'objects' index.
	      else if (depth === 3) {
	        return false;
	      }
	    }
	  }

	  return target;
	}

	/**
	 * Determines the difference of the `_graphs` index s1 and s2.
	 * s1 and s2 *must* belong to Stores that share an `_entityIndex`.
	 *
	 * False is returned when there is no difference; this should
	 * *not* be set as the value for an index.
	 */
	function difference(s1, s2, depth = 4) {
	  let target = false;

	  for (const key in s1) {
	    // When the key is not in the index, then none of the triples defined by s1[key] are
	    // in s2 and so we want to copy them over to the resultant store.
	    if (!(key in s2)) {
	      target = target || Object.create(null);
	      target[key] = depth === 0 ? null : merge({}, s1[key], depth - 1);
	    }
	    else if (depth !== 0) {
	      const diff = difference(s1[key], s2[key], depth - 1);
	      if (diff !== false) {
	        target = target || Object.create(null);
	        target[key] = diff;
	      }
	      // Depth 3 is the 'subjects', 'predicates' and 'objects' keys.
	      // If the 'subjects' index is empty, so will the 'predicates' and 'objects' index.
	      else if (depth === 3) {
	        return false;
	      }
	    }
	  }

	  return target;
	}

	// ## Constructor
	class N3EntityIndex {
	  constructor(options = {}) {
	    this._id = 1;
	    // `_ids` maps entities such as `http://xmlns.com/foaf/0.1/name` to numbers,
	    // saving memory by using only numbers as keys in `_graphs`
	    this._ids = Object.create(null);
	    this._ids[''] = 1;
	     // inverse of `_ids`
	    this._entities = Object.create(null);
	    this._entities[1] = '';
	    // `_blankNodeIndex` is the index of the last automatically named blank node
	    this._blankNodeIndex = 0;
	    this._factory = options.factory || DataFactory;
	  }

	  _termFromId(id) {
	    if (id[0] === '.') {
	      const entities = this._entities;
	      const terms = id.split('.');
	      const q = this._factory.quad(
	        this._termFromId(entities[terms[1]]),
	        this._termFromId(entities[terms[2]]),
	        this._termFromId(entities[terms[3]]),
	        terms[4] && this._termFromId(entities[terms[4]]),
	      );
	      return q;
	    }
	    return termFromId(id, this._factory);
	  }

	  _termToNumericId(term) {
	    if (term.termType === 'Quad') {
	      const s = this._termToNumericId(term.subject),
	          p = this._termToNumericId(term.predicate),
	          o = this._termToNumericId(term.object);
	      let g;

	      return s && p && o && (isDefaultGraph(term.graph) || (g = this._termToNumericId(term.graph))) &&
	        this._ids[g ? `.${s}.${p}.${o}.${g}` : `.${s}.${p}.${o}`];
	    }
	    return this._ids[termToId(term)];
	  }

	  _termToNewNumericId(term) {
	    // This assumes that no graph term is present - we may wish to error if there is one
	    const str = term && term.termType === 'Quad' ?
	      `.${this._termToNewNumericId(term.subject)}.${this._termToNewNumericId(term.predicate)}.${this._termToNewNumericId(term.object)}${
        isDefaultGraph(term.graph) ? '' : `.${this._termToNewNumericId(term.graph)}`
      }`
	      : termToId(term);

	    return this._ids[str] || (this._ids[this._entities[++this._id] = str] = this._id);
	  }

	  createBlankNode(suggestedName) {
	    let name, index;
	    // Generate a name based on the suggested name
	    if (suggestedName) {
	      name = suggestedName = `_:${suggestedName}`, index = 1;
	      while (this._ids[name])
	        name = suggestedName + index++;
	    }
	    // Generate a generic blank node name
	    else {
	      do { name = `_:b${this._blankNodeIndex++}`; }
	      while (this._ids[name]);
	    }
	    // Add the blank node to the entities, avoiding the generation of duplicates
	    this._ids[name] = ++this._id;
	    this._entities[this._id] = name;
	    return this._factory.blankNode(name.substr(2));
	  }
	}

	// ## Constructor
	class N3Store {
	  constructor(quads, options) {
	    // The number of quads is initially zero
	    this._size = 0;
	    // `_graphs` contains subject, predicate, and object indexes per graph
	    this._graphs = Object.create(null);

	    // Shift parameters if `quads` is not given
	    if (!options && quads && !quads[0] && !(typeof quads.match === 'function'))
	      options = quads, quads = null;
	    options = options || {};
	    this._factory = options.factory || DataFactory;
	    this._entityIndex = options.entityIndex || new N3EntityIndex({ factory: this._factory });
	    this._entities = this._entityIndex._entities;
	    this._termFromId = this._entityIndex._termFromId.bind(this._entityIndex);
	    this._termToNumericId = this._entityIndex._termToNumericId.bind(this._entityIndex);
	    this._termToNewNumericId = this._entityIndex._termToNewNumericId.bind(this._entityIndex);

	    // Add quads if passed
	    if (quads)
	      this.addAll(quads);
	  }

	  // ## Public properties

	  // ### `size` returns the number of quads in the store
	  get size() {
	    // Return the quad count if if was cached
	    let size = this._size;
	    if (size !== null)
	      return size;

	    // Calculate the number of quads by counting to the deepest level
	    size = 0;
	    const graphs = this._graphs;
	    let subjects, subject;
	    for (const graphKey in graphs)
	      for (const subjectKey in (subjects = graphs[graphKey].subjects))
	        for (const predicateKey in (subject = subjects[subjectKey]))
	          size += Object.keys(subject[predicateKey]).length;
	    return this._size = size;
	  }

	  // ## Private methods

	  // ### `_addToIndex` adds a quad to a three-layered index.
	  // Returns if the index has changed, if the entry did not already exist.
	  _addToIndex(index0, key0, key1, key2) {
	    // Create layers as necessary
	    const index1 = index0[key0] || (index0[key0] = {});
	    const index2 = index1[key1] || (index1[key1] = {});
	    // Setting the key to _any_ value signals the presence of the quad
	    const existed = key2 in index2;
	    if (!existed)
	      index2[key2] = null;
	    return !existed;
	  }

	  // ### `_removeFromIndex` removes a quad from a three-layered index
	  _removeFromIndex(index0, key0, key1, key2) {
	    // Remove the quad from the index
	    const index1 = index0[key0], index2 = index1[key1];
	    delete index2[key2];

	    // Remove intermediary index layers if they are empty
	    for (const key in index2) return;
	    delete index1[key1];
	    for (const key in index1) return;
	    delete index0[key0];
	  }

	  // ### `_findInIndex` finds a set of quads in a three-layered index.
	  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.
	  // Any of these keys can be undefined, which is interpreted as a wildcard.
	  // `name0`, `name1`, and `name2` are the names of the keys at each level,
	  // used when reconstructing the resulting quad
	  // (for instance: _subject_, _predicate_, and _object_).
	  // Finally, `graphId` will be the graph of the created quads.
	  *_findInIndex(index0, key0, key1, key2, name0, name1, name2, graphId) {
	    let tmp, index1, index2;
	    const entityKeys = this._entities;
	    const graph = this._termFromId(entityKeys[graphId]);
	    const parts = { subject: null, predicate: null, object: null };

	    // If a key is specified, use only that part of index 0.
	    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];
	    for (const value0 in index0) {
	      if (index1 = index0[value0]) {
	        parts[name0] = this._termFromId(entityKeys[value0]);
	        // If a key is specified, use only that part of index 1.
	        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];
	        for (const value1 in index1) {
	          if (index2 = index1[value1]) {
	            parts[name1] = this._termFromId(entityKeys[value1]);
	            // If a key is specified, use only that part of index 2, if it exists.
	            const values = key2 ? (key2 in index2 ? [key2] : []) : Object.keys(index2);
	            // Create quads for all items found in index 2.
	            for (let l = 0; l < values.length; l++) {
	              parts[name2] = this._termFromId(entityKeys[values[l]]);
	              yield this._factory.quad(parts.subject, parts.predicate, parts.object, graph);
	            }
	          }
	        }
	      }
	    }
	  }

	  // ### `_loop` executes the callback on all keys of index 0
	  _loop(index0, callback) {
	    for (const key0 in index0)
	      callback(key0);
	  }

	  // ### `_loopByKey0` executes the callback on all keys of a certain entry in index 0
	  _loopByKey0(index0, key0, callback) {
	    let index1, key1;
	    if (index1 = index0[key0]) {
	      for (key1 in index1)
	        callback(key1);
	    }
	  }

	  // ### `_loopByKey1` executes the callback on given keys of all entries in index 0
	  _loopByKey1(index0, key1, callback) {
	    let key0, index1;
	    for (key0 in index0) {
	      index1 = index0[key0];
	      if (index1[key1])
	        callback(key0);
	    }
	  }

	  // ### `_loopBy2Keys` executes the callback on given keys of certain entries in index 2
	  _loopBy2Keys(index0, key0, key1, callback) {
	    let index1, index2, key2;
	    if ((index1 = index0[key0]) && (index2 = index1[key1])) {
	      for (key2 in index2)
	        callback(key2);
	    }
	  }

	  // ### `_countInIndex` counts matching quads in a three-layered index.
	  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.
	  // Any of these keys can be undefined, which is interpreted as a wildcard.
	  _countInIndex(index0, key0, key1, key2) {
	    let count = 0, tmp, index1, index2;

	    // If a key is specified, count only that part of index 0
	    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];
	    for (const value0 in index0) {
	      if (index1 = index0[value0]) {
	        // If a key is specified, count only that part of index 1
	        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];
	        for (const value1 in index1) {
	          if (index2 = index1[value1]) {
	            // If a key is specified, count the quad if it exists
	            if (key2) (key2 in index2) && count++;
	            // Otherwise, count all quads
	            else count += Object.keys(index2).length;
	          }
	        }
	      }
	    }
	    return count;
	  }

	  // ### `_getGraphs` returns an array with the given graph,
	  // or all graphs if the argument is null or undefined.
	  _getGraphs(graph) {
	    graph = graph === '' ? 1 : (graph && (this._termToNumericId(graph) || -1));
	    return typeof graph !== 'number' ? this._graphs : { [graph]: this._graphs[graph] };
	  }

	  // ### `_uniqueEntities` returns a function that accepts an entity ID
	  // and passes the corresponding entity to callback if it hasn't occurred before.
	  _uniqueEntities(callback) {
	    const uniqueIds = Object.create(null);
	    return id => {
	      if (!(id in uniqueIds)) {
	        uniqueIds[id] = true;
	        callback(this._termFromId(this._entities[id], this._factory));
	      }
	    };
	  }

	  // ## Public methods

	  // ### `add` adds the specified quad to the dataset.
	  // Returns the dataset instance it was called on.
	  // Existing quads, as defined in Quad.equals, will be ignored.
	  add(quad) {
	    this.addQuad(quad);
	    return this;
	  }

	  // ### `addQuad` adds a new quad to the store.
	  // Returns if the quad index has changed, if the quad did not already exist.
	  addQuad(subject, predicate, object, graph) {
	    // Shift arguments if a quad object is given instead of components
	    if (!predicate)
	      graph = subject.graph, object = subject.object,
	        predicate = subject.predicate, subject = subject.subject;

	    // Convert terms to internal string representation
	    graph = graph ? this._termToNewNumericId(graph) : 1;

	    // Find the graph that will contain the triple
	    let graphItem = this._graphs[graph];
	    // Create the graph if it doesn't exist yet
	    if (!graphItem) {
	      graphItem = this._graphs[graph] = { subjects: {}, predicates: {}, objects: {} };
	      // Freezing a graph helps subsequent `add` performance,
	      // and properties will never be modified anyway
	      Object.freeze(graphItem);
	    }

	    // Since entities can often be long IRIs, we avoid storing them in every index.
	    // Instead, we have a separate index that maps entities to numbers,
	    // which are then used as keys in the other indexes.
	    subject   = this._termToNewNumericId(subject);
	    predicate = this._termToNewNumericId(predicate);
	    object    = this._termToNewNumericId(object);

	    if (!this._addToIndex(graphItem.subjects,   subject,   predicate, object))
	      return false;
	    this._addToIndex(graphItem.predicates, predicate, object,    subject);
	    this._addToIndex(graphItem.objects,    object,    subject,   predicate);

	    // The cached quad count is now invalid
	    this._size = null;
	    return true;
	  }

	  // ### `addQuads` adds multiple quads to the store
	  addQuads(quads) {
	    for (let i = 0; i < quads.length; i++)
	      this.addQuad(quads[i]);
	  }

	  // ### `delete` removes the specified quad from the dataset.
	  // Returns the dataset instance it was called on.
	  delete(quad) {
	    this.removeQuad(quad);
	    return this;
	  }

	  // ### `has` determines whether a dataset includes a certain quad or quad pattern.
	  has(subjectOrQuad, predicate, object, graph) {
	    if (subjectOrQuad && subjectOrQuad.subject)
	      ({ subject: subjectOrQuad, predicate, object, graph } = subjectOrQuad);
	    return !this.readQuads(subjectOrQuad, predicate, object, graph).next().done;
	  }

	  // ### `import` adds a stream of quads to the store
	  import(stream) {
	    stream.on('data', quad => { this.addQuad(quad); });
	    return stream;
	  }

	  // ### `removeQuad` removes a quad from the store if it exists
	  removeQuad(subject, predicate, object, graph) {
	    // Shift arguments if a quad object is given instead of components
	    if (!predicate)
	      ({ subject, predicate, object, graph } = subject);
	    // Convert terms to internal string representation
	    graph = graph ? this._termToNumericId(graph) : 1;

	    // Find internal identifiers for all components
	    // and verify the quad exists.
	    const graphs = this._graphs;
	    let graphItem, subjects, predicates;
	    if (!(subject    = subject && this._termToNumericId(subject)) || !(predicate = predicate && this._termToNumericId(predicate)) ||
	        !(object     = object && this._termToNumericId(object))  || !(graphItem = graphs[graph])  ||
	        !(subjects   = graphItem.subjects[subject]) ||
	        !(predicates = subjects[predicate]) ||
	        !(object in predicates))
	      return false;

	    // Remove it from all indexes
	    this._removeFromIndex(graphItem.subjects,   subject,   predicate, object);
	    this._removeFromIndex(graphItem.predicates, predicate, object,    subject);
	    this._removeFromIndex(graphItem.objects,    object,    subject,   predicate);
	    if (this._size !== null) this._size--;

	    // Remove the graph if it is empty
	    for (subject in graphItem.subjects) return true;
	    delete graphs[graph];
	    return true;
	  }

	  // ### `removeQuads` removes multiple quads from the store
	  removeQuads(quads) {
	    for (let i = 0; i < quads.length; i++)
	      this.removeQuad(quads[i]);
	  }

	  // ### `remove` removes a stream of quads from the store
	  remove(stream) {
	    stream.on('data', quad => { this.removeQuad(quad); });
	    return stream;
	  }

	  // ### `removeMatches` removes all matching quads from the store
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  removeMatches(subject, predicate, object, graph) {
	    const stream = new browserExports.Readable({ objectMode: true });

	    const iterable = this.readQuads(subject, predicate, object, graph);
	    stream._read = size => {
	      while (--size >= 0) {
	        const { done, value } = iterable.next();
	        if (done) {
	          stream.push(null);
	          return;
	        }
	        stream.push(value);
	      }
	    };

	    return this.remove(stream);
	  }

	  // ### `deleteGraph` removes all triples with the given graph from the store
	  deleteGraph(graph) {
	    return this.removeMatches(null, null, null, graph);
	  }

	  // ### `getQuads` returns an array of quads matching a pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  getQuads(subject, predicate, object, graph) {
	    return [...this.readQuads(subject, predicate, object, graph)];
	  }

	  /**
	   * `readQuads` returns a generator of quads matching a pattern.
	   * Setting any field to `undefined` or `null` indicates a wildcard.
	   * @deprecated Use `match` instead.
	   */
	  *readQuads(subject, predicate, object, graph) {
	    const graphs = this._getGraphs(graph);
	    let content, subjectId, predicateId, objectId;

	    // Translate IRIs to internal index keys.
	    if (subject   && !(subjectId   = this._termToNumericId(subject))   ||
	        predicate && !(predicateId = this._termToNumericId(predicate)) ||
	        object    && !(objectId    = this._termToNumericId(object)))
	      return;

	    for (const graphId in graphs) {
	      // Only if the specified graph contains triples, there can be results
	      if (content = graphs[graphId]) {
	        // Choose the optimal index, based on what fields are present
	        if (subjectId) {
	          if (objectId)
	            // If subject and object are given, the object index will be the fastest
	            yield* this._findInIndex(content.objects, objectId, subjectId, predicateId,
	                              'object', 'subject', 'predicate', graphId);
	          else
	            // If only subject and possibly predicate are given, the subject index will be the fastest
	            yield* this._findInIndex(content.subjects, subjectId, predicateId, null,
	                              'subject', 'predicate', 'object', graphId);
	        }
	        else if (predicateId)
	          // If only predicate and possibly object are given, the predicate index will be the fastest
	          yield* this._findInIndex(content.predicates, predicateId, objectId, null,
	                            'predicate', 'object', 'subject', graphId);
	        else if (objectId)
	          // If only object is given, the object index will be the fastest
	          yield* this._findInIndex(content.objects, objectId, null, null,
	                            'object', 'subject', 'predicate', graphId);
	        else
	          // If nothing is given, iterate subjects and predicates first
	          yield* this._findInIndex(content.subjects, null, null, null,
	                            'subject', 'predicate', 'object', graphId);
	      }
	    }
	  }

	  // ### `match` returns a new dataset that is comprised of all quads in the current instance matching the given arguments.
	  // The logic described in Quad Matching is applied for each quad in this dataset to check if it should be included in the output dataset.
	  // Note: This method always returns a new DatasetCore, even if that dataset contains no quads.
	  // Note: Since a DatasetCore is an unordered set, the order of the quads within the returned sequence is arbitrary.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  // For backwards compatibility, the object return also implements the Readable stream interface.
	  match(subject, predicate, object, graph) {
	    return new DatasetCoreAndReadableStream(this, subject, predicate, object, graph, { entityIndex: this._entityIndex });
	  }

	  // ### `countQuads` returns the number of quads matching a pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  countQuads(subject, predicate, object, graph) {
	    const graphs = this._getGraphs(graph);
	    let count = 0, content, subjectId, predicateId, objectId;

	    // Translate IRIs to internal index keys.
	    if (subject   && !(subjectId   = this._termToNumericId(subject))   ||
	        predicate && !(predicateId = this._termToNumericId(predicate)) ||
	        object    && !(objectId    = this._termToNumericId(object)))
	      return 0;

	    for (const graphId in graphs) {
	      // Only if the specified graph contains triples, there can be results
	      if (content = graphs[graphId]) {
	        // Choose the optimal index, based on what fields are present
	        if (subject) {
	          if (object)
	            // If subject and object are given, the object index will be the fastest
	            count += this._countInIndex(content.objects, objectId, subjectId, predicateId);
	          else
	            // If only subject and possibly predicate are given, the subject index will be the fastest
	            count += this._countInIndex(content.subjects, subjectId, predicateId, objectId);
	        }
	        else if (predicate) {
	          // If only predicate and possibly object are given, the predicate index will be the fastest
	          count += this._countInIndex(content.predicates, predicateId, objectId, subjectId);
	        }
	        else {
	          // If only object is possibly given, the object index will be the fastest
	          count += this._countInIndex(content.objects, objectId, subjectId, predicateId);
	        }
	      }
	    }
	    return count;
	  }

	  // ### `forEach` executes the callback on all quads.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  forEach(callback, subject, predicate, object, graph) {
	    this.some(quad => {
	      callback(quad, this);
	      return false;
	    }, subject, predicate, object, graph);
	  }

	  // ### `every` executes the callback on all quads,
	  // and returns `true` if it returns truthy for all them.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  every(callback, subject, predicate, object, graph) {
	    return !this.some(quad => !callback(quad, this), subject, predicate, object, graph);
	  }

	  // ### `some` executes the callback on all quads,
	  // and returns `true` if it returns truthy for any of them.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  some(callback, subject, predicate, object, graph) {
	    for (const quad of this.readQuads(subject, predicate, object, graph))
	      if (callback(quad, this))
	        return true;
	    return false;
	  }

	  // ### `getSubjects` returns all subjects that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  getSubjects(predicate, object, graph) {
	    const results = [];
	    this.forSubjects(s => { results.push(s); }, predicate, object, graph);
	    return results;
	  }

	  // ### `forSubjects` executes the callback on all subjects that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  forSubjects(callback, predicate, object, graph) {
	    const graphs = this._getGraphs(graph);
	    let content, predicateId, objectId;
	    callback = this._uniqueEntities(callback);

	    // Translate IRIs to internal index keys.
	    if (predicate && !(predicateId = this._termToNumericId(predicate)) ||
	        object    && !(objectId    = this._termToNumericId(object)))
	      return;

	    for (graph in graphs) {
	      // Only if the specified graph contains triples, there can be results
	      if (content = graphs[graph]) {
	        // Choose optimal index based on which fields are wildcards
	        if (predicateId) {
	          if (objectId)
	            // If predicate and object are given, the POS index is best.
	            this._loopBy2Keys(content.predicates, predicateId, objectId, callback);
	          else
	            // If only predicate is given, the SPO index is best.
	            this._loopByKey1(content.subjects, predicateId, callback);
	        }
	        else if (objectId)
	          // If only object is given, the OSP index is best.
	          this._loopByKey0(content.objects, objectId, callback);
	        else
	          // If no params given, iterate all the subjects
	          this._loop(content.subjects, callback);
	      }
	    }
	  }

	  // ### `getPredicates` returns all predicates that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  getPredicates(subject, object, graph) {
	    const results = [];
	    this.forPredicates(p => { results.push(p); }, subject, object, graph);
	    return results;
	  }

	  // ### `forPredicates` executes the callback on all predicates that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  forPredicates(callback, subject, object, graph) {
	    const graphs = this._getGraphs(graph);
	    let content, subjectId, objectId;
	    callback = this._uniqueEntities(callback);

	    // Translate IRIs to internal index keys.
	    if (subject   && !(subjectId   = this._termToNumericId(subject))   ||
	        object    && !(objectId    = this._termToNumericId(object)))
	      return;

	    for (graph in graphs) {
	      // Only if the specified graph contains triples, there can be results
	      if (content = graphs[graph]) {
	        // Choose optimal index based on which fields are wildcards
	        if (subjectId) {
	          if (objectId)
	            // If subject and object are given, the OSP index is best.
	            this._loopBy2Keys(content.objects, objectId, subjectId, callback);
	          else
	            // If only subject is given, the SPO index is best.
	            this._loopByKey0(content.subjects, subjectId, callback);
	        }
	        else if (objectId)
	          // If only object is given, the POS index is best.
	          this._loopByKey1(content.predicates, objectId, callback);
	        else
	          // If no params given, iterate all the predicates.
	          this._loop(content.predicates, callback);
	      }
	    }
	  }

	  // ### `getObjects` returns all objects that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  getObjects(subject, predicate, graph) {
	    const results = [];
	    this.forObjects(o => { results.push(o); }, subject, predicate, graph);
	    return results;
	  }

	  // ### `forObjects` executes the callback on all objects that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  forObjects(callback, subject, predicate, graph) {
	    const graphs = this._getGraphs(graph);
	    let content, subjectId, predicateId;
	    callback = this._uniqueEntities(callback);

	    // Translate IRIs to internal index keys.
	    if (subject   && !(subjectId   = this._termToNumericId(subject))   ||
	        predicate && !(predicateId = this._termToNumericId(predicate)))
	      return;

	    for (graph in graphs) {
	      // Only if the specified graph contains triples, there can be results
	      if (content = graphs[graph]) {
	        // Choose optimal index based on which fields are wildcards
	        if (subjectId) {
	          if (predicateId)
	            // If subject and predicate are given, the SPO index is best.
	            this._loopBy2Keys(content.subjects, subjectId, predicateId, callback);
	          else
	            // If only subject is given, the OSP index is best.
	            this._loopByKey1(content.objects, subjectId, callback);
	        }
	        else if (predicateId)
	          // If only predicate is given, the POS index is best.
	          this._loopByKey0(content.predicates, predicateId, callback);
	        else
	          // If no params given, iterate all the objects.
	          this._loop(content.objects, callback);
	      }
	    }
	  }

	  // ### `getGraphs` returns all graphs that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  getGraphs(subject, predicate, object) {
	    const results = [];
	    this.forGraphs(g => { results.push(g); }, subject, predicate, object);
	    return results;
	  }

	  // ### `forGraphs` executes the callback on all graphs that match the pattern.
	  // Setting any field to `undefined` or `null` indicates a wildcard.
	  forGraphs(callback, subject, predicate, object) {
	    for (const graph in this._graphs) {
	      this.some(quad => {
	        callback(quad.graph);
	        return true; // Halt iteration of some()
	      }, subject, predicate, object, this._termFromId(this._entities[graph]));
	    }
	  }

	  // ### `createBlankNode` creates a new blank node, returning its name
	  createBlankNode(suggestedName) {
	    return this._entityIndex.createBlankNode(suggestedName);
	  }

	  // ### `extractLists` finds and removes all list triples
	  // and returns the items per list.
	  extractLists({ remove = false, ignoreErrors = false } = {}) {
	    const lists = {}; // has scalar keys so could be a simple Object
	    const onError = ignoreErrors ? (() => true) :
	                  ((node, message) => { throw new Error(`${node.value} ${message}`); });

	    // Traverse each list from its tail
	    const tails = this.getQuads(null, namespaces.rdf.rest, namespaces.rdf.nil, null);
	    const toRemove = remove ? [...tails] : [];
	    tails.forEach(tailQuad => {
	      const items = [];             // the members found as objects of rdf:first quads
	      let malformed = false;      // signals whether the current list is malformed
	      let head;                   // the head of the list (_:b1 in above example)
	      let headPos;                // set to subject or object when head is set
	      const graph = tailQuad.graph; // make sure list is in exactly one graph

	      // Traverse the list from tail to end
	      let current = tailQuad.subject;
	      while (current && !malformed) {
	        const objectQuads = this.getQuads(null, null, current, null);
	        const subjectQuads = this.getQuads(current, null, null, null);
	        let quad, first = null, rest = null, parent = null;

	        // Find the first and rest of this list node
	        for (let i = 0; i < subjectQuads.length && !malformed; i++) {
	          quad = subjectQuads[i];
	          if (!quad.graph.equals(graph))
	            malformed = onError(current, 'not confined to single graph');
	          else if (head)
	            malformed = onError(current, 'has non-list arcs out');

	          // one rdf:first
	          else if (quad.predicate.value === namespaces.rdf.first) {
	            if (first)
	              malformed = onError(current, 'has multiple rdf:first arcs');
	            else
	              toRemove.push(first = quad);
	          }

	          // one rdf:rest
	          else if (quad.predicate.value === namespaces.rdf.rest) {
	            if (rest)
	              malformed = onError(current, 'has multiple rdf:rest arcs');
	            else
	              toRemove.push(rest = quad);
	          }

	          // alien triple
	          else if (objectQuads.length)
	            malformed = onError(current, 'can\'t be subject and object');
	          else {
	            head = quad; // e.g. { (1 2 3) :p :o }
	            headPos = 'subject';
	          }
	        }

	        // { :s :p (1 2) } arrives here with no head
	        // { (1 2) :p :o } arrives here with head set to the list.
	        for (let i = 0; i < objectQuads.length && !malformed; ++i) {
	          quad = objectQuads[i];
	          if (head)
	            malformed = onError(current, 'can\'t have coreferences');
	          // one rdf:rest
	          else if (quad.predicate.value === namespaces.rdf.rest) {
	            if (parent)
	              malformed = onError(current, 'has incoming rdf:rest arcs');
	            else
	              parent = quad;
	          }
	          else {
	            head = quad; // e.g. { :s :p (1 2) }
	            headPos = 'object';
	          }
	        }

	        // Store the list item and continue with parent
	        if (!first)
	          malformed = onError(current, 'has no list head');
	        else
	          items.unshift(first.object);
	        current = parent && parent.subject;
	      }

	      // Don't remove any quads if the list is malformed
	      if (malformed)
	        remove = false;
	      // Store the list under the value of its head
	      else if (head)
	        lists[head[headPos].value] = items;
	    });

	    // Remove list quads if requested
	    if (remove)
	      this.removeQuads(toRemove);
	    return lists;
	  }

	  /**
	   * Returns `true` if the current dataset is a superset of the given dataset; in other words, returns `true` if
	   * the given dataset is a subset of, i.e., is contained within, the current dataset.
	   *
	   * Blank Nodes will be normalized.
	   */
	  addAll(quads) {
	    if (quads instanceof DatasetCoreAndReadableStream)
	      quads = quads.filtered;

	    if (Array.isArray(quads))
	      this.addQuads(quads);
	    else if (quads instanceof N3Store && quads._entityIndex === this._entityIndex) {
	      if (quads._size !== 0) {
	        this._graphs = merge(this._graphs, quads._graphs);
	        this._size = null; // Invalidate the cached size
	      }
	    }
	    else {
	      for (const quad of quads)
	        this.add(quad);
	    }
	    return this;
	  }

	  /**
	   * Returns `true` if the current dataset is a superset of the given dataset; in other words, returns `true` if
	   * the given dataset is a subset of, i.e., is contained within, the current dataset.
	   *
	   * Blank Nodes will be normalized.
	   */
	  contains(other) {
	    if (other instanceof DatasetCoreAndReadableStream)
	      other = other.filtered;

	    if (other === this)
	      return true;

	    if (!(other instanceof N3Store) || this._entityIndex !== other._entityIndex)
	      return other.every(quad => this.has(quad));

	    const g1 = this._graphs, g2 = other._graphs;
	    let s1, s2, p1, p2, o1;
	    for (const graph in g2) {
	      if (!(s1 = g1[graph])) return false;
	      s1 = s1.subjects;
	      for (const subject in (s2 = g2[graph].subjects)) {
	        if (!(p1 = s1[subject])) return false;
	        for (const predicate in (p2 = s2[subject])) {
	          if (!(o1 = p1[predicate])) return false;
	          for (const object in p2[predicate])
	            if (!(object in o1)) return false;
	        }
	      }
	    }
	    return true;
	  }

	  /**
	   * This method removes the quads in the current dataset that match the given arguments.
	   *
	   * The logic described in {@link https://rdf.js.org/dataset-spec/#quad-matching|Quad Matching} is applied for each
	   * quad in this dataset, to select the quads which will be deleted.
	   *
	   * @param subject   The optional exact subject to match.
	   * @param predicate The optional exact predicate to match.
	   * @param object    The optional exact object to match.
	   * @param graph     The optional exact graph to match.
	   */
	  deleteMatches(subject, predicate, object, graph) {
	    for (const quad of this.match(subject, predicate, object, graph))
	      this.removeQuad(quad);
	    return this;
	  }

	  /**
	   * Returns a new dataset that contains all quads from the current dataset that are not included in the given dataset.
	   */
	  difference(other) {
	    if (other && other instanceof DatasetCoreAndReadableStream)
	      other = other.filtered;

	    if (other === this)
	      return new N3Store({ entityIndex: this._entityIndex });

	    if ((other instanceof N3Store) && other._entityIndex === this._entityIndex) {
	      const store = new N3Store({ entityIndex: this._entityIndex });
	      const graphs = difference(this._graphs, other._graphs);
	      if (graphs) {
	        store._graphs = graphs;
	        store._size = null;
	      }
	      return store;
	    }

	    return this.filter(quad => !other.has(quad));
	  }

	  /**
	   * Returns true if the current dataset contains the same graph structure as the given dataset.
	   *
	   * Blank Nodes will be normalized.
	   */
	  equals(other) {
	    if (other instanceof DatasetCoreAndReadableStream)
	      other = other.filtered;

	    return other === this || (this.size === other.size && this.contains(other));
	  }

	  /**
	   * Creates a new dataset with all the quads that pass the test implemented by the provided `iteratee`.
	   *
	   * This method is aligned with Array.prototype.filter() in ECMAScript-262.
	   */
	  filter(iteratee) {
	    const store = new N3Store({ entityIndex: this._entityIndex });
	    for (const quad of this)
	      if (iteratee(quad, this))
	        store.add(quad);
	    return store;
	  }

	  /**
	   * Returns a new dataset containing all quads from the current dataset that are also included in the given dataset.
	   */
	  intersection(other) {
	    if (other instanceof DatasetCoreAndReadableStream)
	      other = other.filtered;

	    if (other === this) {
	      const store = new N3Store({ entityIndex: this._entityIndex });
	      store._graphs = merge(Object.create(null), this._graphs);
	      store._size = this._size;
	      return store;
	    }
	    else if ((other instanceof N3Store) && this._entityIndex === other._entityIndex) {
	      const store = new N3Store({ entityIndex: this._entityIndex });
	      const graphs = intersect(other._graphs, this._graphs);
	      if (graphs) {
	        store._graphs = graphs;
	        store._size = null;
	      }
	      return store;
	    }

	    return this.filter(quad => other.has(quad));
	  }

	  /**
	   * Returns a new dataset containing all quads returned by applying `iteratee` to each quad in the current dataset.
	   */
	  map(iteratee) {
	    const store = new N3Store({ entityIndex: this._entityIndex });
	    for (const quad of this)
	      store.add(iteratee(quad, this));
	    return store;
	  }

	  /**
	   * This method calls the `iteratee` method on each `quad` of the `Dataset`. The first time the `iteratee` method
	   * is called, the `accumulator` value is the `initialValue`, or, if not given, equals the first quad of the `Dataset`.
	   * The return value of each call to the `iteratee` method is used as the `accumulator` value for the next call.
	   *
	   * This method returns the return value of the last `iteratee` call.
	   *
	   * This method is aligned with `Array.prototype.reduce()` in ECMAScript-262.
	   */
	  reduce(callback, initialValue) {
	    const iter = this.readQuads();
	    let accumulator = initialValue === undefined ? iter.next().value : initialValue;
	    for (const quad of iter)
	      accumulator = callback(accumulator, quad, this);
	    return accumulator;
	  }

	  /**
	   * Returns the set of quads within the dataset as a host-language-native sequence, for example an `Array` in
	   * ECMAScript-262.
	   *
	   * Since a `Dataset` is an unordered set, the order of the quads within the returned sequence is arbitrary.
	   */
	  toArray() {
	    return this.getQuads();
	  }

	  /**
	   * Returns an N-Quads string representation of the dataset, preprocessed with the
	   * {@link https://json-ld.github.io/normalization/spec/|RDF Dataset Normalization} algorithm.
	   */
	  toCanonical() {
	    throw new Error('not implemented');
	  }

	  /**
	   * Returns a stream that contains all quads of the dataset.
	   */
	  toStream() {
	    return this.match();
	  }

	  /**
	   * Returns an N-Quads string representation of the dataset.
	   *
	   * No prior normalization is required, therefore the results for the same quads may vary depending on the `Dataset`
	   * implementation.
	   */
	  toString() {
	    return (new N3Writer()).quadsToString(this);
	  }

	  /**
	   * Returns a new `Dataset` that is a concatenation of this dataset and the quads given as an argument.
	   */
	  union(quads) {
	    const store = new N3Store({ entityIndex: this._entityIndex });
	    store._graphs = merge(Object.create(null), this._graphs);
	    store._size = this._size;

	    store.addAll(quads);
	    return store;
	  }

	  // ### Store is an iterable.
	  // Can be used where iterables are expected: for...of loops, array spread operator,
	  // `yield*`, and destructuring assignment (order is not guaranteed).
	  *[Symbol.iterator]() {
	    yield* this.readQuads();
	  }
	}

	/**
	 * Returns a subset of the `index` with that part of the index
	 * matching the `ids` array. `ids` contains 3 elements that are
	 * either numerical ids; or `null`.
	 *
	 * `false` is returned when there are no matching indices; this should
	 * *not* be set as the value for an index.
	 */
	function indexMatch(index, ids, depth = 0) {
	  const ind = ids[depth];
	  if (ind && !(ind in index))
	    return false;

	  let target = false;
	  for (const key in (ind ? { [ind]: index[ind] } : index)) {
	    const result = depth === 2 ? null : indexMatch(index[key], ids, depth + 1);

	    if (result !== false) {
	      target = target || Object.create(null);
	      target[key] = result;
	    }
	  }
	  return target;
	}

	/**
	 * A class that implements both DatasetCore and Readable.
	 */
	class DatasetCoreAndReadableStream extends browserExports.Readable {
	  constructor(n3Store, subject, predicate, object, graph, options) {
	    super({ objectMode: true });
	    Object.assign(this, { n3Store, subject, predicate, object, graph, options });
	  }

	  get filtered() {
	    if (!this._filtered) {
	      const { n3Store, graph, object, predicate, subject } = this;
	      const newStore = this._filtered = new N3Store({ factory: n3Store._factory, entityIndex: this.options.entityIndex });

	      let subjectId, predicateId, objectId;

	      // Translate IRIs to internal index keys.
	      if (subject   && !(subjectId   = newStore._termToNumericId(subject))   ||
	          predicate && !(predicateId = newStore._termToNumericId(predicate)) ||
	          object    && !(objectId    = newStore._termToNumericId(object)))
	        return newStore;

	      const graphs = n3Store._getGraphs(graph);
	      for (const graphKey in graphs) {
	        let subjects, predicates, objects, content;
	        if (content = graphs[graphKey]) {
	          if (!subjectId && predicateId) {
	            if (predicates = indexMatch(content.predicates, [predicateId, objectId, subjectId])) {
	              subjects = indexMatch(content.subjects, [subjectId, predicateId, objectId]);
	              objects = indexMatch(content.objects, [objectId, subjectId, predicateId]);
	            }
	          }
	          else if (objectId) {
	            if (objects = indexMatch(content.objects, [objectId, subjectId, predicateId])) {
	              subjects = indexMatch(content.subjects, [subjectId, predicateId, objectId]);
	              predicates = indexMatch(content.predicates, [predicateId, objectId, subjectId]);
	            }
	          }
	          else if (subjects = indexMatch(content.subjects, [subjectId, predicateId, objectId])) {
	            predicates = indexMatch(content.predicates, [predicateId, objectId, subjectId]);
	            objects = indexMatch(content.objects, [objectId, subjectId, predicateId]);
	          }

	          if (subjects)
	            newStore._graphs[graphKey] = { subjects, predicates, objects };
	        }
	      }
	      newStore._size = null;
	    }
	    return this._filtered;
	  }

	  get size() {
	    return this.filtered.size;
	  }

	  _read(size) {
	    if (size > 0 && !this[ITERATOR])
	      this[ITERATOR] = this[Symbol.iterator]();
	    const iterable = this[ITERATOR];
	    while (--size >= 0) {
	      const { done, value } = iterable.next();
	      if (done) {
	        this.push(null);
	        return;
	      }
	      this.push(value);
	    }
	  }

	  addAll(quads) {
	    return this.filtered.addAll(quads);
	  }

	  contains(other) {
	    return this.filtered.contains(other);
	  }

	  deleteMatches(subject, predicate, object, graph) {
	    return this.filtered.deleteMatches(subject, predicate, object, graph);
	  }

	  difference(other) {
	    return this.filtered.difference(other);
	  }

	  equals(other) {
	    return this.filtered.equals(other);
	  }

	  every(callback, subject, predicate, object, graph) {
	    return this.filtered.every(callback, subject, predicate, object, graph);
	  }

	  filter(iteratee) {
	    return this.filtered.filter(iteratee);
	  }

	  forEach(callback, subject, predicate, object, graph) {
	    return this.filtered.forEach(callback, subject, predicate, object, graph);
	  }

	  import(stream) {
	    return this.filtered.import(stream);
	  }

	  intersection(other) {
	    return this.filtered.intersection(other);
	  }

	  map(iteratee) {
	    return this.filtered.map(iteratee);
	  }

	  some(callback, subject, predicate, object, graph) {
	    return this.filtered.some(callback, subject, predicate, object, graph);
	  }

	  toCanonical() {
	    return this.filtered.toCanonical();
	  }

	  toStream() {
	    return this._filtered ?
	      this._filtered.toStream()
	      : this.n3Store.match(this.subject, this.predicate, this.object, this.graph);
	  }

	  union(quads) {
	    return this._filtered ?
	      this._filtered.union(quads)
	      : this.n3Store.match(this.subject, this.predicate, this.object, this.graph).addAll(quads);
	  }

	  toArray() {
	    return this._filtered ? this._filtered.toArray() : this.n3Store.getQuads(this.subject, this.predicate, this.object, this.graph);
	  }

	  reduce(callback, initialValue) {
	    return this.filtered.reduce(callback, initialValue);
	  }

	  toString() {
	    return (new N3Writer()).quadsToString(this);
	  }

	  add(quad) {
	    return this.filtered.add(quad);
	  }

	  delete(quad) {
	    return this.filtered.delete(quad);
	  }

	  has(quad) {
	    return this.filtered.has(quad);
	  }

	  match(subject, predicate, object, graph) {
	    return new DatasetCoreAndReadableStream(this.filtered, subject, predicate, object, graph, this.options);
	  }

	  *[Symbol.iterator]() {
	    yield* this._filtered || this.n3Store.readQuads(this.subject, this.predicate, this.object, this.graph);
	  }
	}

	// Export all named exports as a default object for backward compatibility
	var N3 = {
	  Parser: N3Parser,
	  Writer: N3Writer,
	  Store: N3Store};

	/**
	 * Throw a given error.
	 *
	 * @param {Error|null|undefined} [error]
	 *   Maybe error.
	 * @returns {asserts error is null|undefined}
	 */
	function bail(error) {
	  if (error) {
	    throw error
	  }
	}

	var extend$1;
	var hasRequiredExtend;

	function requireExtend () {
		if (hasRequiredExtend) return extend$1;
		hasRequiredExtend = 1;

		var hasOwn = Object.prototype.hasOwnProperty;
		var toStr = Object.prototype.toString;
		var defineProperty = Object.defineProperty;
		var gOPD = Object.getOwnPropertyDescriptor;

		var isArray = function isArray(arr) {
			if (typeof Array.isArray === 'function') {
				return Array.isArray(arr);
			}

			return toStr.call(arr) === '[object Array]';
		};

		var isPlainObject = function isPlainObject(obj) {
			if (!obj || toStr.call(obj) !== '[object Object]') {
				return false;
			}

			var hasOwnConstructor = hasOwn.call(obj, 'constructor');
			var hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');
			// Not own constructor property must be Object
			if (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {
				return false;
			}

			// Own properties are enumerated firstly, so to speed up,
			// if last one is own, then all properties are own.
			var key;
			for (key in obj) { /**/ }

			return typeof key === 'undefined' || hasOwn.call(obj, key);
		};

		// If name is '__proto__', and Object.defineProperty is available, define __proto__ as an own property on target
		var setProperty = function setProperty(target, options) {
			if (defineProperty && options.name === '__proto__') {
				defineProperty(target, options.name, {
					enumerable: true,
					configurable: true,
					value: options.newValue,
					writable: true
				});
			} else {
				target[options.name] = options.newValue;
			}
		};

		// Return undefined instead of __proto__ if '__proto__' is not an own property
		var getProperty = function getProperty(obj, name) {
			if (name === '__proto__') {
				if (!hasOwn.call(obj, name)) {
					return void 0;
				} else if (gOPD) {
					// In early versions of node, obj['__proto__'] is buggy when obj has
					// __proto__ as an own property. Object.getOwnPropertyDescriptor() works.
					return gOPD(obj, name).value;
				}
			}

			return obj[name];
		};

		extend$1 = function extend() {
			var options, name, src, copy, copyIsArray, clone;
			var target = arguments[0];
			var i = 1;
			var length = arguments.length;
			var deep = false;

			// Handle a deep copy situation
			if (typeof target === 'boolean') {
				deep = target;
				target = arguments[1] || {};
				// skip the boolean and the target
				i = 2;
			}
			if (target == null || (typeof target !== 'object' && typeof target !== 'function')) {
				target = {};
			}

			for (; i < length; ++i) {
				options = arguments[i];
				// Only deal with non-null/undefined values
				if (options != null) {
					// Extend the base object
					for (name in options) {
						src = getProperty(target, name);
						copy = getProperty(options, name);

						// Prevent never-ending loop
						if (target !== copy) {
							// Recurse if we're merging plain objects or arrays
							if (deep && copy && (isPlainObject(copy) || (copyIsArray = isArray(copy)))) {
								if (copyIsArray) {
									copyIsArray = false;
									clone = src && isArray(src) ? src : [];
								} else {
									clone = src && isPlainObject(src) ? src : {};
								}

								// Never move original objects, clone them
								setProperty(target, { name: name, newValue: extend(deep, clone, copy) });

							// Don't bring in undefined values
							} else if (typeof copy !== 'undefined') {
								setProperty(target, { name: name, newValue: copy });
							}
						}
					}
				}
			}

			// Return the modified object
			return target;
		};
		return extend$1;
	}

	var extendExports = requireExtend();
	var extend = /*@__PURE__*/getDefaultExportFromCjs(extendExports);

	function isPlainObject(value) {
		if (typeof value !== 'object' || value === null) {
			return false;
		}

		const prototype = Object.getPrototypeOf(value);
		return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);
	}

	// To do: remove `void`s
	// To do: remove `null` from output of our APIs, allow it as user APIs.

	/**
	 * @typedef {(error?: Error | null | undefined, ...output: Array<any>) => void} Callback
	 *   Callback.
	 *
	 * @typedef {(...input: Array<any>) => any} Middleware
	 *   Ware.
	 *
	 * @typedef Pipeline
	 *   Pipeline.
	 * @property {Run} run
	 *   Run the pipeline.
	 * @property {Use} use
	 *   Add middleware.
	 *
	 * @typedef {(...input: Array<any>) => void} Run
	 *   Call all middleware.
	 *
	 *   Calls `done` on completion with either an error or the output of the
	 *   last middleware.
	 *
	 *   >  **Note**: as the length of input defines whether async functions get a
	 *   > `next` function,
	 *   > its recommended to keep `input` at one value normally.

	 *
	 * @typedef {(fn: Middleware) => Pipeline} Use
	 *   Add middleware.
	 */

	/**
	 * Create new middleware.
	 *
	 * @returns {Pipeline}
	 *   Pipeline.
	 */
	function trough() {
	  /** @type {Array<Middleware>} */
	  const fns = [];
	  /** @type {Pipeline} */
	  const pipeline = {run, use};

	  return pipeline

	  /** @type {Run} */
	  function run(...values) {
	    let middlewareIndex = -1;
	    /** @type {Callback} */
	    const callback = values.pop();

	    if (typeof callback !== 'function') {
	      throw new TypeError('Expected function as last argument, not ' + callback)
	    }

	    next(null, ...values);

	    /**
	     * Run the next `fn`, or were done.
	     *
	     * @param {Error | null | undefined} error
	     * @param {Array<any>} output
	     */
	    function next(error, ...output) {
	      const fn = fns[++middlewareIndex];
	      let index = -1;

	      if (error) {
	        callback(error);
	        return
	      }

	      // Copy non-nullish input into values.
	      while (++index < values.length) {
	        if (output[index] === null || output[index] === undefined) {
	          output[index] = values[index];
	        }
	      }

	      // Save the newly created `output` for the next call.
	      values = output;

	      // Next or done.
	      if (fn) {
	        wrap(fn, next)(...output);
	      } else {
	        callback(null, ...output);
	      }
	    }
	  }

	  /** @type {Use} */
	  function use(middelware) {
	    if (typeof middelware !== 'function') {
	      throw new TypeError(
	        'Expected `middelware` to be a function, not ' + middelware
	      )
	    }

	    fns.push(middelware);
	    return pipeline
	  }
	}

	/**
	 * Wrap `middleware` into a uniform interface.
	 *
	 * You can pass all input to the resulting function.
	 * `callback` is then called with the output of `middleware`.
	 *
	 * If `middleware` accepts more arguments than the later given in input,
	 * an extra `done` function is passed to it after that input,
	 * which must be called by `middleware`.
	 *
	 * The first value in `input` is the main input value.
	 * All other input values are the rest input values.
	 * The values given to `callback` are the input values,
	 * merged with every non-nullish output value.
	 *
	 * * if `middleware` throws an error,
	 *   returns a promise that is rejected,
	 *   or calls the given `done` function with an error,
	 *   `callback` is called with that error
	 * * if `middleware` returns a value or returns a promise that is resolved,
	 *   that value is the main output value
	 * * if `middleware` calls `done`,
	 *   all non-nullish values except for the first one (the error) overwrite the
	 *   output values
	 *
	 * @param {Middleware} middleware
	 *   Function to wrap.
	 * @param {Callback} callback
	 *   Callback called with the output of `middleware`.
	 * @returns {Run}
	 *   Wrapped middleware.
	 */
	function wrap(middleware, callback) {
	  /** @type {boolean} */
	  let called;

	  return wrapped

	  /**
	   * Call `middleware`.
	   * @this {any}
	   * @param {Array<any>} parameters
	   * @returns {void}
	   */
	  function wrapped(...parameters) {
	    const fnExpectsCallback = middleware.length > parameters.length;
	    /** @type {any} */
	    let result;

	    if (fnExpectsCallback) {
	      parameters.push(done);
	    }

	    try {
	      result = middleware.apply(this, parameters);
	    } catch (error) {
	      const exception = /** @type {Error} */ (error);

	      // Well, this is quite the pickle.
	      // `middleware` received a callback and called it synchronously, but that
	      // threw an error.
	      // The only thing left to do is to throw the thing instead.
	      if (fnExpectsCallback && called) {
	        throw exception
	      }

	      return done(exception)
	    }

	    if (!fnExpectsCallback) {
	      if (result && result.then && typeof result.then === 'function') {
	        result.then(then, done);
	      } else if (result instanceof Error) {
	        done(result);
	      } else {
	        then(result);
	      }
	    }
	  }

	  /**
	   * Call `callback`, only once.
	   *
	   * @type {Callback}
	   */
	  function done(error, ...output) {
	    if (!called) {
	      called = true;
	      callback(error, ...output);
	    }
	  }

	  /**
	   * Call `done` with one value.
	   *
	   * @param {any} [value]
	   */
	  function then(value) {
	    done(null, value);
	  }
	}

	/**
	 * @typedef {import('unist').Node} Node
	 * @typedef {import('unist').Point} Point
	 * @typedef {import('unist').Position} Position
	 */

	/**
	 * @typedef NodeLike
	 * @property {string} type
	 * @property {PositionLike | null | undefined} [position]
	 *
	 * @typedef PointLike
	 * @property {number | null | undefined} [line]
	 * @property {number | null | undefined} [column]
	 * @property {number | null | undefined} [offset]
	 *
	 * @typedef PositionLike
	 * @property {PointLike | null | undefined} [start]
	 * @property {PointLike | null | undefined} [end]
	 */

	/**
	 * Serialize the positional info of a point, position (start and end points),
	 * or node.
	 *
	 * @param {Node | NodeLike | Point | PointLike | Position | PositionLike | null | undefined} [value]
	 *   Node, position, or point.
	 * @returns {string}
	 *   Pretty printed positional info of a node (`string`).
	 *
	 *   In the format of a range `ls:cs-le:ce` (when given `node` or `position`)
	 *   or a point `l:c` (when given `point`), where `l` stands for line, `c` for
	 *   column, `s` for `start`, and `e` for end.
	 *   An empty string (`''`) is returned if the given value is neither `node`,
	 *   `position`, nor `point`.
	 */
	function stringifyPosition(value) {
	  // Nothing.
	  if (!value || typeof value !== 'object') {
	    return ''
	  }

	  // Node.
	  if ('position' in value || 'type' in value) {
	    return position(value.position)
	  }

	  // Position.
	  if ('start' in value || 'end' in value) {
	    return position(value)
	  }

	  // Point.
	  if ('line' in value || 'column' in value) {
	    return point$1(value)
	  }

	  // ?
	  return ''
	}

	/**
	 * @param {Point | PointLike | null | undefined} point
	 * @returns {string}
	 */
	function point$1(point) {
	  return index$1(point && point.line) + ':' + index$1(point && point.column)
	}

	/**
	 * @param {Position | PositionLike | null | undefined} pos
	 * @returns {string}
	 */
	function position(pos) {
	  return point$1(pos && pos.start) + '-' + point$1(pos && pos.end)
	}

	/**
	 * @param {number | null | undefined} value
	 * @returns {number}
	 */
	function index$1(value) {
	  return value && typeof value === 'number' ? value : 1
	}

	/**
	 * @typedef {import('unist').Node} Node
	 * @typedef {import('unist').Point} Point
	 * @typedef {import('unist').Position} Position
	 */


	/**
	 * Message.
	 */
	class VFileMessage extends Error {
	  /**
	   * Create a message for `reason`.
	   *
	   * >  **Note**: also has obsolete signatures.
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Options | null | undefined} [options]
	   * @returns
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @overload
	   * @param {string} reason
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {string | null | undefined} [origin]
	   * @returns
	   *
	   * @param {Error | VFileMessage | string} causeOrReason
	   *   Reason for message, should use markdown.
	   * @param {Node | NodeLike | Options | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
	   *   Configuration (optional).
	   * @param {string | null | undefined} [origin]
	   *   Place in code where the message originates (example:
	   *   `'my-package:my-rule'` or `'my-rule'`).
	   * @returns
	   *   Instance of `VFileMessage`.
	   */
	  // eslint-disable-next-line complexity
	  constructor(causeOrReason, optionsOrParentOrPlace, origin) {
	    super();

	    if (typeof optionsOrParentOrPlace === 'string') {
	      origin = optionsOrParentOrPlace;
	      optionsOrParentOrPlace = undefined;
	    }

	    /** @type {string} */
	    let reason = '';
	    /** @type {Options} */
	    let options = {};
	    let legacyCause = false;

	    if (optionsOrParentOrPlace) {
	      // Point.
	      if (
	        'line' in optionsOrParentOrPlace &&
	        'column' in optionsOrParentOrPlace
	      ) {
	        options = {place: optionsOrParentOrPlace};
	      }
	      // Position.
	      else if (
	        'start' in optionsOrParentOrPlace &&
	        'end' in optionsOrParentOrPlace
	      ) {
	        options = {place: optionsOrParentOrPlace};
	      }
	      // Node.
	      else if ('type' in optionsOrParentOrPlace) {
	        options = {
	          ancestors: [optionsOrParentOrPlace],
	          place: optionsOrParentOrPlace.position
	        };
	      }
	      // Options.
	      else {
	        options = {...optionsOrParentOrPlace};
	      }
	    }

	    if (typeof causeOrReason === 'string') {
	      reason = causeOrReason;
	    }
	    // Error.
	    else if (!options.cause && causeOrReason) {
	      legacyCause = true;
	      reason = causeOrReason.message;
	      options.cause = causeOrReason;
	    }

	    if (!options.ruleId && !options.source && typeof origin === 'string') {
	      const index = origin.indexOf(':');

	      if (index === -1) {
	        options.ruleId = origin;
	      } else {
	        options.source = origin.slice(0, index);
	        options.ruleId = origin.slice(index + 1);
	      }
	    }

	    if (!options.place && options.ancestors && options.ancestors) {
	      const parent = options.ancestors[options.ancestors.length - 1];

	      if (parent) {
	        options.place = parent.position;
	      }
	    }

	    const start =
	      options.place && 'start' in options.place
	        ? options.place.start
	        : options.place;

	    /* eslint-disable no-unused-expressions */
	    /**
	     * Stack of ancestor nodes surrounding the message.
	     *
	     * @type {Array<Node> | undefined}
	     */
	    this.ancestors = options.ancestors || undefined;

	    /**
	     * Original error cause of the message.
	     *
	     * @type {Error | undefined}
	     */
	    this.cause = options.cause || undefined;

	    /**
	     * Starting column of message.
	     *
	     * @type {number | undefined}
	     */
	    this.column = start ? start.column : undefined;

	    /**
	     * State of problem.
	     *
	     * * `true`  error, file not usable
	     * * `false`  warning, change may be needed
	     * * `undefined`  change likely not needed
	     *
	     * @type {boolean | null | undefined}
	     */
	    this.fatal = undefined;

	    /**
	     * Path of a file (used throughout the `VFile` ecosystem).
	     *
	     * @type {string | undefined}
	     */
	    this.file;

	    // Field from `Error`.
	    /**
	     * Reason for message.
	     *
	     * @type {string}
	     */
	    this.message = reason;

	    /**
	     * Starting line of error.
	     *
	     * @type {number | undefined}
	     */
	    this.line = start ? start.line : undefined;

	    // Field from `Error`.
	    /**
	     * Serialized positional info of message.
	     *
	     * On normal errors, this would be something like `ParseError`, buit in
	     * `VFile` messages we use this space to show where an error happened.
	     */
	    this.name = stringifyPosition(options.place) || '1:1';

	    /**
	     * Place of message.
	     *
	     * @type {Point | Position | undefined}
	     */
	    this.place = options.place || undefined;

	    /**
	     * Reason for message, should use markdown.
	     *
	     * @type {string}
	     */
	    this.reason = this.message;

	    /**
	     * Category of message (example: `'my-rule'`).
	     *
	     * @type {string | undefined}
	     */
	    this.ruleId = options.ruleId || undefined;

	    /**
	     * Namespace of message (example: `'my-package'`).
	     *
	     * @type {string | undefined}
	     */
	    this.source = options.source || undefined;

	    // Field from `Error`.
	    /**
	     * Stack of message.
	     *
	     * This is used by normal errors to show where something happened in
	     * programming code, irrelevant for `VFile` messages,
	     *
	     * @type {string}
	     */
	    this.stack =
	      legacyCause && options.cause && typeof options.cause.stack === 'string'
	        ? options.cause.stack
	        : '';

	    // The following fields are well known.
	    // Not standard.
	    // Feel free to add other non-standard fields to your messages.

	    /**
	     * Specify the source value thats being reported, which is deemed
	     * incorrect.
	     *
	     * @type {string | undefined}
	     */
	    this.actual;

	    /**
	     * Suggest acceptable values that can be used instead of `actual`.
	     *
	     * @type {Array<string> | undefined}
	     */
	    this.expected;

	    /**
	     * Long form description of the message (you should use markdown).
	     *
	     * @type {string | undefined}
	     */
	    this.note;

	    /**
	     * Link to docs for the message.
	     *
	     * >  **Note**: this must be an absolute URL that can be passed as `x`
	     * > to `new URL(x)`.
	     *
	     * @type {string | undefined}
	     */
	    this.url;
	    /* eslint-enable no-unused-expressions */
	  }
	}

	VFileMessage.prototype.file = '';
	VFileMessage.prototype.name = '';
	VFileMessage.prototype.reason = '';
	VFileMessage.prototype.message = '';
	VFileMessage.prototype.stack = '';
	VFileMessage.prototype.column = undefined;
	VFileMessage.prototype.line = undefined;
	VFileMessage.prototype.ancestors = undefined;
	VFileMessage.prototype.cause = undefined;
	VFileMessage.prototype.fatal = undefined;
	VFileMessage.prototype.place = undefined;
	VFileMessage.prototype.ruleId = undefined;
	VFileMessage.prototype.source = undefined;

	// A derivative work based on:
	// <https://github.com/browserify/path-browserify>.
	// Which is licensed:
	//
	// MIT License
	//
	// Copyright (c) 2013 James Halliday
	//
	// Permission is hereby granted, free of charge, to any person obtaining a copy of
	// this software and associated documentation files (the "Software"), to deal in
	// the Software without restriction, including without limitation the rights to
	// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
	// the Software, and to permit persons to whom the Software is furnished to do so,
	// subject to the following conditions:
	//
	// The above copyright notice and this permission notice shall be included in all
	// copies or substantial portions of the Software.
	//
	// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
	// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
	// FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
	// COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
	// IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
	// CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
	// A derivative work based on:
	//
	// Parts of that are extracted from Nodes internal `path` module:
	// <https://github.com/nodejs/node/blob/master/lib/path.js>.
	// Which is licensed:
	//
	// Copyright Joyent, Inc. and other Node contributors.
	//
	// Permission is hereby granted, free of charge, to any person obtaining a
	// copy of this software and associated documentation files (the
	// "Software"), to deal in the Software without restriction, including
	// without limitation the rights to use, copy, modify, merge, publish,
	// distribute, sublicense, and/or sell copies of the Software, and to permit
	// persons to whom the Software is furnished to do so, subject to the
	// following conditions:
	//
	// The above copyright notice and this permission notice shall be included
	// in all copies or substantial portions of the Software.
	//
	// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
	// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
	// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
	// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
	// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
	// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
	// USE OR OTHER DEALINGS IN THE SOFTWARE.

	const minpath = {basename, dirname, extname, join: join$1, sep: '/'};

	/* eslint-disable max-depth, complexity */

	/**
	 * Get the basename from a path.
	 *
	 * @param {string} path
	 *   File path.
	 * @param {string | null | undefined} [extname]
	 *   Extension to strip.
	 * @returns {string}
	 *   Stem or basename.
	 */
	function basename(path, extname) {
	  if (extname !== undefined && typeof extname !== 'string') {
	    throw new TypeError('"ext" argument must be a string')
	  }

	  assertPath$1(path);
	  let start = 0;
	  let end = -1;
	  let index = path.length;
	  /** @type {boolean | undefined} */
	  let seenNonSlash;

	  if (
	    extname === undefined ||
	    extname.length === 0 ||
	    extname.length > path.length
	  ) {
	    while (index--) {
	      if (path.codePointAt(index) === 47 /* `/` */) {
	        // If we reached a path separator that was not part of a set of path
	        // separators at the end of the string, stop now.
	        if (seenNonSlash) {
	          start = index + 1;
	          break
	        }
	      } else if (end < 0) {
	        // We saw the first non-path separator, mark this as the end of our
	        // path component.
	        seenNonSlash = true;
	        end = index + 1;
	      }
	    }

	    return end < 0 ? '' : path.slice(start, end)
	  }

	  if (extname === path) {
	    return ''
	  }

	  let firstNonSlashEnd = -1;
	  let extnameIndex = extname.length - 1;

	  while (index--) {
	    if (path.codePointAt(index) === 47 /* `/` */) {
	      // If we reached a path separator that was not part of a set of path
	      // separators at the end of the string, stop now.
	      if (seenNonSlash) {
	        start = index + 1;
	        break
	      }
	    } else {
	      if (firstNonSlashEnd < 0) {
	        // We saw the first non-path separator, remember this index in case
	        // we need it if the extension ends up not matching.
	        seenNonSlash = true;
	        firstNonSlashEnd = index + 1;
	      }

	      if (extnameIndex > -1) {
	        // Try to match the explicit extension.
	        if (path.codePointAt(index) === extname.codePointAt(extnameIndex--)) {
	          if (extnameIndex < 0) {
	            // We matched the extension, so mark this as the end of our path
	            // component
	            end = index;
	          }
	        } else {
	          // Extension does not match, so our result is the entire path
	          // component
	          extnameIndex = -1;
	          end = firstNonSlashEnd;
	        }
	      }
	    }
	  }

	  if (start === end) {
	    end = firstNonSlashEnd;
	  } else if (end < 0) {
	    end = path.length;
	  }

	  return path.slice(start, end)
	}

	/**
	 * Get the dirname from a path.
	 *
	 * @param {string} path
	 *   File path.
	 * @returns {string}
	 *   File path.
	 */
	function dirname(path) {
	  assertPath$1(path);

	  if (path.length === 0) {
	    return '.'
	  }

	  let end = -1;
	  let index = path.length;
	  /** @type {boolean | undefined} */
	  let unmatchedSlash;

	  // Prefix `--` is important to not run on `0`.
	  while (--index) {
	    if (path.codePointAt(index) === 47 /* `/` */) {
	      if (unmatchedSlash) {
	        end = index;
	        break
	      }
	    } else if (!unmatchedSlash) {
	      // We saw the first non-path separator
	      unmatchedSlash = true;
	    }
	  }

	  return end < 0
	    ? path.codePointAt(0) === 47 /* `/` */
	      ? '/'
	      : '.'
	    : end === 1 && path.codePointAt(0) === 47 /* `/` */
	      ? '//'
	      : path.slice(0, end)
	}

	/**
	 * Get an extname from a path.
	 *
	 * @param {string} path
	 *   File path.
	 * @returns {string}
	 *   Extname.
	 */
	function extname(path) {
	  assertPath$1(path);

	  let index = path.length;

	  let end = -1;
	  let startPart = 0;
	  let startDot = -1;
	  // Track the state of characters (if any) we see before our first dot and
	  // after any path separator we find.
	  let preDotState = 0;
	  /** @type {boolean | undefined} */
	  let unmatchedSlash;

	  while (index--) {
	    const code = path.codePointAt(index);

	    if (code === 47 /* `/` */) {
	      // If we reached a path separator that was not part of a set of path
	      // separators at the end of the string, stop now.
	      if (unmatchedSlash) {
	        startPart = index + 1;
	        break
	      }

	      continue
	    }

	    if (end < 0) {
	      // We saw the first non-path separator, mark this as the end of our
	      // extension.
	      unmatchedSlash = true;
	      end = index + 1;
	    }

	    if (code === 46 /* `.` */) {
	      // If this is our first dot, mark it as the start of our extension.
	      if (startDot < 0) {
	        startDot = index;
	      } else if (preDotState !== 1) {
	        preDotState = 1;
	      }
	    } else if (startDot > -1) {
	      // We saw a non-dot and non-path separator before our dot, so we should
	      // have a good chance at having a non-empty extension.
	      preDotState = -1;
	    }
	  }

	  if (
	    startDot < 0 ||
	    end < 0 ||
	    // We saw a non-dot character immediately before the dot.
	    preDotState === 0 ||
	    // The (right-most) trimmed path component is exactly `..`.
	    (preDotState === 1 && startDot === end - 1 && startDot === startPart + 1)
	  ) {
	    return ''
	  }

	  return path.slice(startDot, end)
	}

	/**
	 * Join segments from a path.
	 *
	 * @param {Array<string>} segments
	 *   Path segments.
	 * @returns {string}
	 *   File path.
	 */
	function join$1(...segments) {
	  let index = -1;
	  /** @type {string | undefined} */
	  let joined;

	  while (++index < segments.length) {
	    assertPath$1(segments[index]);

	    if (segments[index]) {
	      joined =
	        joined === undefined ? segments[index] : joined + '/' + segments[index];
	    }
	  }

	  return joined === undefined ? '.' : normalize(joined)
	}

	/**
	 * Normalize a basic file path.
	 *
	 * @param {string} path
	 *   File path.
	 * @returns {string}
	 *   File path.
	 */
	// Note: `normalize` is not exposed as `path.normalize`, so some code is
	// manually removed from it.
	function normalize(path) {
	  assertPath$1(path);

	  const absolute = path.codePointAt(0) === 47; /* `/` */

	  // Normalize the path according to POSIX rules.
	  let value = normalizeString(path, !absolute);

	  if (value.length === 0 && !absolute) {
	    value = '.';
	  }

	  if (value.length > 0 && path.codePointAt(path.length - 1) === 47 /* / */) {
	    value += '/';
	  }

	  return absolute ? '/' + value : value
	}

	/**
	 * Resolve `.` and `..` elements in a path with directory names.
	 *
	 * @param {string} path
	 *   File path.
	 * @param {boolean} allowAboveRoot
	 *   Whether `..` can move above root.
	 * @returns {string}
	 *   File path.
	 */
	function normalizeString(path, allowAboveRoot) {
	  let result = '';
	  let lastSegmentLength = 0;
	  let lastSlash = -1;
	  let dots = 0;
	  let index = -1;
	  /** @type {number | undefined} */
	  let code;
	  /** @type {number} */
	  let lastSlashIndex;

	  while (++index <= path.length) {
	    if (index < path.length) {
	      code = path.codePointAt(index);
	    } else if (code === 47 /* `/` */) {
	      break
	    } else {
	      code = 47; /* `/` */
	    }

	    if (code === 47 /* `/` */) {
	      if (lastSlash === index - 1 || dots === 1) ; else if (lastSlash !== index - 1 && dots === 2) {
	        if (
	          result.length < 2 ||
	          lastSegmentLength !== 2 ||
	          result.codePointAt(result.length - 1) !== 46 /* `.` */ ||
	          result.codePointAt(result.length - 2) !== 46 /* `.` */
	        ) {
	          if (result.length > 2) {
	            lastSlashIndex = result.lastIndexOf('/');

	            if (lastSlashIndex !== result.length - 1) {
	              if (lastSlashIndex < 0) {
	                result = '';
	                lastSegmentLength = 0;
	              } else {
	                result = result.slice(0, lastSlashIndex);
	                lastSegmentLength = result.length - 1 - result.lastIndexOf('/');
	              }

	              lastSlash = index;
	              dots = 0;
	              continue
	            }
	          } else if (result.length > 0) {
	            result = '';
	            lastSegmentLength = 0;
	            lastSlash = index;
	            dots = 0;
	            continue
	          }
	        }

	        if (allowAboveRoot) {
	          result = result.length > 0 ? result + '/..' : '..';
	          lastSegmentLength = 2;
	        }
	      } else {
	        if (result.length > 0) {
	          result += '/' + path.slice(lastSlash + 1, index);
	        } else {
	          result = path.slice(lastSlash + 1, index);
	        }

	        lastSegmentLength = index - lastSlash - 1;
	      }

	      lastSlash = index;
	      dots = 0;
	    } else if (code === 46 /* `.` */ && dots > -1) {
	      dots++;
	    } else {
	      dots = -1;
	    }
	  }

	  return result
	}

	/**
	 * Make sure `path` is a string.
	 *
	 * @param {string} path
	 *   File path.
	 * @returns {asserts path is string}
	 *   Nothing.
	 */
	function assertPath$1(path) {
	  if (typeof path !== 'string') {
	    throw new TypeError(
	      'Path must be a string. Received ' + JSON.stringify(path)
	    )
	  }
	}

	/* eslint-enable max-depth, complexity */

	// Somewhat based on:
	// <https://github.com/defunctzombie/node-process/blob/master/browser.js>.
	// But I dont think one tiny line of code can be copyrighted. 
	const minproc = {cwd};

	function cwd() {
	  return '/'
	}

	/**
	 * Checks if a value has the shape of a WHATWG URL object.
	 *
	 * Using a symbol or instanceof would not be able to recognize URL objects
	 * coming from other implementations (e.g. in Electron), so instead we are
	 * checking some well known properties for a lack of a better test.
	 *
	 * We use `href` and `protocol` as they are the only properties that are
	 * easy to retrieve and calculate due to the lazy nature of the getters.
	 *
	 * We check for auth attribute to distinguish legacy url instance with
	 * WHATWG URL instance.
	 *
	 * @param {unknown} fileUrlOrPath
	 *   File path or URL.
	 * @returns {fileUrlOrPath is URL}
	 *   Whether its a URL.
	 */
	// From: <https://github.com/nodejs/node/blob/6a3403c/lib/internal/url.js#L720>
	function isUrl(fileUrlOrPath) {
	  return Boolean(
	    fileUrlOrPath !== null &&
	      typeof fileUrlOrPath === 'object' &&
	      'href' in fileUrlOrPath &&
	      fileUrlOrPath.href &&
	      'protocol' in fileUrlOrPath &&
	      fileUrlOrPath.protocol &&
	      // @ts-expect-error: indexing is fine.
	      fileUrlOrPath.auth === undefined
	  )
	}

	// See: <https://github.com/nodejs/node/blob/6a3403c/lib/internal/url.js>

	/**
	 * @param {URL | string} path
	 *   File URL.
	 * @returns {string}
	 *   File URL.
	 */
	function urlToPath(path) {
	  if (typeof path === 'string') {
	    path = new URL(path);
	  } else if (!isUrl(path)) {
	    /** @type {NodeJS.ErrnoException} */
	    const error = new TypeError(
	      'The "path" argument must be of type string or an instance of URL. Received `' +
	        path +
	        '`'
	    );
	    error.code = 'ERR_INVALID_ARG_TYPE';
	    throw error
	  }

	  if (path.protocol !== 'file:') {
	    /** @type {NodeJS.ErrnoException} */
	    const error = new TypeError('The URL must be of scheme file');
	    error.code = 'ERR_INVALID_URL_SCHEME';
	    throw error
	  }

	  return getPathFromURLPosix(path)
	}

	/**
	 * Get a path from a POSIX URL.
	 *
	 * @param {URL} url
	 *   URL.
	 * @returns {string}
	 *   File path.
	 */
	function getPathFromURLPosix(url) {
	  if (url.hostname !== '') {
	    /** @type {NodeJS.ErrnoException} */
	    const error = new TypeError(
	      'File URL host must be "localhost" or empty on darwin'
	    );
	    error.code = 'ERR_INVALID_FILE_URL_HOST';
	    throw error
	  }

	  const pathname = url.pathname;
	  let index = -1;

	  while (++index < pathname.length) {
	    if (
	      pathname.codePointAt(index) === 37 /* `%` */ &&
	      pathname.codePointAt(index + 1) === 50 /* `2` */
	    ) {
	      const third = pathname.codePointAt(index + 2);
	      if (third === 70 /* `F` */ || third === 102 /* `f` */) {
	        /** @type {NodeJS.ErrnoException} */
	        const error = new TypeError(
	          'File URL path must not include encoded / characters'
	        );
	        error.code = 'ERR_INVALID_FILE_URL_PATH';
	        throw error
	      }
	    }
	  }

	  return decodeURIComponent(pathname)
	}

	/**
	 * @import {Node, Point, Position} from 'unist'
	 * @import {Options as MessageOptions} from 'vfile-message'
	 * @import {Compatible, Data, Map, Options, Value} from 'vfile'
	 */


	/**
	 * Order of setting (least specific to most), we need this because otherwise
	 * `{stem: 'a', path: '~/b.js'}` would throw, as a path is needed before a
	 * stem can be set.
	 */
	const order = /** @type {const} */ ([
	  'history',
	  'path',
	  'basename',
	  'stem',
	  'extname',
	  'dirname'
	]);

	class VFile {
	  /**
	   * Create a new virtual file.
	   *
	   * `options` is treated as:
	   *
	   * *   `string` or `Uint8Array`  `{value: options}`
	   * *   `URL`  `{path: options}`
	   * *   `VFile`  shallow copies its data over to the new file
	   * *   `object`  all fields are shallow copied over to the new file
	   *
	   * Path related fields are set in the following order (least specific to
	   * most specific): `history`, `path`, `basename`, `stem`, `extname`,
	   * `dirname`.
	   *
	   * You cannot set `dirname` or `extname` without setting either `history`,
	   * `path`, `basename`, or `stem` too.
	   *
	   * @param {Compatible | null | undefined} [value]
	   *   File value.
	   * @returns
	   *   New instance.
	   */
	  constructor(value) {
	    /** @type {Options | VFile} */
	    let options;

	    if (!value) {
	      options = {};
	    } else if (isUrl(value)) {
	      options = {path: value};
	    } else if (typeof value === 'string' || isUint8Array$1(value)) {
	      options = {value};
	    } else {
	      options = value;
	    }

	    /* eslint-disable no-unused-expressions */

	    /**
	     * Base of `path` (default: `process.cwd()` or `'/'` in browsers).
	     *
	     * @type {string}
	     */
	    // Prevent calling `cwd` (which could be expensive) if its not needed;
	    // the empty string will be overridden in the next block.
	    this.cwd = 'cwd' in options ? '' : minproc.cwd();

	    /**
	     * Place to store custom info (default: `{}`).
	     *
	     * Its OK to store custom data directly on the file but moving it to
	     * `data` is recommended.
	     *
	     * @type {Data}
	     */
	    this.data = {};

	    /**
	     * List of file paths the file moved between.
	     *
	     * The first is the original path and the last is the current path.
	     *
	     * @type {Array<string>}
	     */
	    this.history = [];

	    /**
	     * List of messages associated with the file.
	     *
	     * @type {Array<VFileMessage>}
	     */
	    this.messages = [];

	    /**
	     * Raw value.
	     *
	     * @type {Value}
	     */
	    this.value;

	    // The below are non-standard, they are well-known.
	    // As in, used in several tools.
	    /**
	     * Source map.
	     *
	     * This type is equivalent to the `RawSourceMap` type from the `source-map`
	     * module.
	     *
	     * @type {Map | null | undefined}
	     */
	    this.map;

	    /**
	     * Custom, non-string, compiled, representation.
	     *
	     * This is used by unified to store non-string results.
	     * One example is when turning markdown into React nodes.
	     *
	     * @type {unknown}
	     */
	    this.result;

	    /**
	     * Whether a file was saved to disk.
	     *
	     * This is used by vfile reporters.
	     *
	     * @type {boolean}
	     */
	    this.stored;
	    /* eslint-enable no-unused-expressions */

	    // Set path related properties in the correct order.
	    let index = -1;

	    while (++index < order.length) {
	      const field = order[index];

	      // Note: we specifically use `in` instead of `hasOwnProperty` to accept
	      // `vfile`s too.
	      if (
	        field in options &&
	        options[field] !== undefined &&
	        options[field] !== null
	      ) {
	        // @ts-expect-error: TS doesnt understand basic reality.
	        this[field] = field === 'history' ? [...options[field]] : options[field];
	      }
	    }

	    /** @type {string} */
	    let field;

	    // Set non-path related properties.
	    for (field in options) {
	      // @ts-expect-error: fine to set other things.
	      if (!order.includes(field)) {
	        // @ts-expect-error: fine to set other things.
	        this[field] = options[field];
	      }
	    }
	  }

	  /**
	   * Get the basename (including extname) (example: `'index.min.js'`).
	   *
	   * @returns {string | undefined}
	   *   Basename.
	   */
	  get basename() {
	    return typeof this.path === 'string'
	      ? minpath.basename(this.path)
	      : undefined
	  }

	  /**
	   * Set basename (including extname) (`'index.min.js'`).
	   *
	   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
	   * on windows).
	   * Cannot be nullified (use `file.path = file.dirname` instead).
	   *
	   * @param {string} basename
	   *   Basename.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  set basename(basename) {
	    assertNonEmpty(basename, 'basename');
	    assertPart(basename, 'basename');
	    this.path = minpath.join(this.dirname || '', basename);
	  }

	  /**
	   * Get the parent path (example: `'~'`).
	   *
	   * @returns {string | undefined}
	   *   Dirname.
	   */
	  get dirname() {
	    return typeof this.path === 'string'
	      ? minpath.dirname(this.path)
	      : undefined
	  }

	  /**
	   * Set the parent path (example: `'~'`).
	   *
	   * Cannot be set if theres no `path` yet.
	   *
	   * @param {string | undefined} dirname
	   *   Dirname.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  set dirname(dirname) {
	    assertPath(this.basename, 'dirname');
	    this.path = minpath.join(dirname || '', this.basename);
	  }

	  /**
	   * Get the extname (including dot) (example: `'.js'`).
	   *
	   * @returns {string | undefined}
	   *   Extname.
	   */
	  get extname() {
	    return typeof this.path === 'string'
	      ? minpath.extname(this.path)
	      : undefined
	  }

	  /**
	   * Set the extname (including dot) (example: `'.js'`).
	   *
	   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
	   * on windows).
	   * Cannot be set if theres no `path` yet.
	   *
	   * @param {string | undefined} extname
	   *   Extname.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  set extname(extname) {
	    assertPart(extname, 'extname');
	    assertPath(this.dirname, 'extname');

	    if (extname) {
	      if (extname.codePointAt(0) !== 46 /* `.` */) {
	        throw new Error('`extname` must start with `.`')
	      }

	      if (extname.includes('.', 1)) {
	        throw new Error('`extname` cannot contain multiple dots')
	      }
	    }

	    this.path = minpath.join(this.dirname, this.stem + (extname || ''));
	  }

	  /**
	   * Get the full path (example: `'~/index.min.js'`).
	   *
	   * @returns {string}
	   *   Path.
	   */
	  get path() {
	    return this.history[this.history.length - 1]
	  }

	  /**
	   * Set the full path (example: `'~/index.min.js'`).
	   *
	   * Cannot be nullified.
	   * You can set a file URL (a `URL` object with a `file:` protocol) which will
	   * be turned into a path with `url.fileURLToPath`.
	   *
	   * @param {URL | string} path
	   *   Path.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  set path(path) {
	    if (isUrl(path)) {
	      path = urlToPath(path);
	    }

	    assertNonEmpty(path, 'path');

	    if (this.path !== path) {
	      this.history.push(path);
	    }
	  }

	  /**
	   * Get the stem (basename w/o extname) (example: `'index.min'`).
	   *
	   * @returns {string | undefined}
	   *   Stem.
	   */
	  get stem() {
	    return typeof this.path === 'string'
	      ? minpath.basename(this.path, this.extname)
	      : undefined
	  }

	  /**
	   * Set the stem (basename w/o extname) (example: `'index.min'`).
	   *
	   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
	   * on windows).
	   * Cannot be nullified (use `file.path = file.dirname` instead).
	   *
	   * @param {string} stem
	   *   Stem.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  set stem(stem) {
	    assertNonEmpty(stem, 'stem');
	    assertPart(stem, 'stem');
	    this.path = minpath.join(this.dirname || '', stem + (this.extname || ''));
	  }

	  // Normal prototypal methods.
	  /**
	   * Create a fatal message for `reason` associated with the file.
	   *
	   * The `fatal` field of the message is set to `true` (error; file not usable)
	   * and the `file` field is set to the current file path.
	   * The message is added to the `messages` field on `file`.
	   *
	   * >  **Note**: also has obsolete signatures.
	   *
	   * @overload
	   * @param {string} reason
	   * @param {MessageOptions | null | undefined} [options]
	   * @returns {never}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {string | null | undefined} [origin]
	   * @returns {never}
	   *
	   * @param {Error | VFileMessage | string} causeOrReason
	   *   Reason for message, should use markdown.
	   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
	   *   Configuration (optional).
	   * @param {string | null | undefined} [origin]
	   *   Place in code where the message originates (example:
	   *   `'my-package:my-rule'` or `'my-rule'`).
	   * @returns {never}
	   *   Never.
	   * @throws {VFileMessage}
	   *   Message.
	   */
	  fail(causeOrReason, optionsOrParentOrPlace, origin) {
	    // @ts-expect-error: the overloads are fine.
	    const message = this.message(causeOrReason, optionsOrParentOrPlace, origin);

	    message.fatal = true;

	    throw message
	  }

	  /**
	   * Create an info message for `reason` associated with the file.
	   *
	   * The `fatal` field of the message is set to `undefined` (info; change
	   * likely not needed) and the `file` field is set to the current file path.
	   * The message is added to the `messages` field on `file`.
	   *
	   * >  **Note**: also has obsolete signatures.
	   *
	   * @overload
	   * @param {string} reason
	   * @param {MessageOptions | null | undefined} [options]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @param {Error | VFileMessage | string} causeOrReason
	   *   Reason for message, should use markdown.
	   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
	   *   Configuration (optional).
	   * @param {string | null | undefined} [origin]
	   *   Place in code where the message originates (example:
	   *   `'my-package:my-rule'` or `'my-rule'`).
	   * @returns {VFileMessage}
	   *   Message.
	   */
	  info(causeOrReason, optionsOrParentOrPlace, origin) {
	    // @ts-expect-error: the overloads are fine.
	    const message = this.message(causeOrReason, optionsOrParentOrPlace, origin);

	    message.fatal = undefined;

	    return message
	  }

	  /**
	   * Create a message for `reason` associated with the file.
	   *
	   * The `fatal` field of the message is set to `false` (warning; change may be
	   * needed) and the `file` field is set to the current file path.
	   * The message is added to the `messages` field on `file`.
	   *
	   * >  **Note**: also has obsolete signatures.
	   *
	   * @overload
	   * @param {string} reason
	   * @param {MessageOptions | null | undefined} [options]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {string} reason
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Node | NodeLike | null | undefined} parent
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {Point | Position | null | undefined} place
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @overload
	   * @param {Error | VFileMessage} cause
	   * @param {string | null | undefined} [origin]
	   * @returns {VFileMessage}
	   *
	   * @param {Error | VFileMessage | string} causeOrReason
	   *   Reason for message, should use markdown.
	   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
	   *   Configuration (optional).
	   * @param {string | null | undefined} [origin]
	   *   Place in code where the message originates (example:
	   *   `'my-package:my-rule'` or `'my-rule'`).
	   * @returns {VFileMessage}
	   *   Message.
	   */
	  message(causeOrReason, optionsOrParentOrPlace, origin) {
	    const message = new VFileMessage(
	      // @ts-expect-error: the overloads are fine.
	      causeOrReason,
	      optionsOrParentOrPlace,
	      origin
	    );

	    if (this.path) {
	      message.name = this.path + ':' + message.name;
	      message.file = this.path;
	    }

	    message.fatal = false;

	    this.messages.push(message);

	    return message
	  }

	  /**
	   * Serialize the file.
	   *
	   * > **Note**: which encodings are supported depends on the engine.
	   * > For info on Node.js, see:
	   * > <https://nodejs.org/api/util.html#whatwg-supported-encodings>.
	   *
	   * @param {string | null | undefined} [encoding='utf8']
	   *   Character encoding to understand `value` as when its a `Uint8Array`
	   *   (default: `'utf-8'`).
	   * @returns {string}
	   *   Serialized file.
	   */
	  toString(encoding) {
	    if (this.value === undefined) {
	      return ''
	    }

	    if (typeof this.value === 'string') {
	      return this.value
	    }

	    const decoder = new TextDecoder(encoding || undefined);
	    return decoder.decode(this.value)
	  }
	}

	/**
	 * Assert that `part` is not a path (as in, does not contain `path.sep`).
	 *
	 * @param {string | null | undefined} part
	 *   File path part.
	 * @param {string} name
	 *   Part name.
	 * @returns {undefined}
	 *   Nothing.
	 */
	function assertPart(part, name) {
	  if (part && part.includes(minpath.sep)) {
	    throw new Error(
	      '`' + name + '` cannot be a path: did not expect `' + minpath.sep + '`'
	    )
	  }
	}

	/**
	 * Assert that `part` is not empty.
	 *
	 * @param {string | undefined} part
	 *   Thing.
	 * @param {string} name
	 *   Part name.
	 * @returns {asserts part is string}
	 *   Nothing.
	 */
	function assertNonEmpty(part, name) {
	  if (!part) {
	    throw new Error('`' + name + '` cannot be empty')
	  }
	}

	/**
	 * Assert `path` exists.
	 *
	 * @param {string | undefined} path
	 *   Path.
	 * @param {string} name
	 *   Dependency name.
	 * @returns {asserts path is string}
	 *   Nothing.
	 */
	function assertPath(path, name) {
	  if (!path) {
	    throw new Error('Setting `' + name + '` requires `path` to be set too')
	  }
	}

	/**
	 * Assert `value` is an `Uint8Array`.
	 *
	 * @param {unknown} value
	 *   thing.
	 * @returns {value is Uint8Array}
	 *   Whether `value` is an `Uint8Array`.
	 */
	function isUint8Array$1(value) {
	  return Boolean(
	    value &&
	      typeof value === 'object' &&
	      'byteLength' in value &&
	      'byteOffset' in value
	  )
	}

	const CallableInstance =
	  /**
	   * @type {new <Parameters extends Array<unknown>, Result>(property: string | symbol) => (...parameters: Parameters) => Result}
	   */
	  (
	    /** @type {unknown} */
	    (
	      /**
	       * @this {Function}
	       * @param {string | symbol} property
	       * @returns {(...parameters: Array<unknown>) => unknown}
	       */
	      function (property) {
	        const self = this;
	        const constr = self.constructor;
	        const proto = /** @type {Record<string | symbol, Function>} */ (
	          // Prototypes do exist.
	          // type-coverage:ignore-next-line
	          constr.prototype
	        );
	        const value = proto[property];
	        /** @type {(...parameters: Array<unknown>) => unknown} */
	        const apply = function () {
	          return value.apply(apply, arguments)
	        };

	        Object.setPrototypeOf(apply, proto);

	        // Not needed for us in `unified`: we only call this on the `copy`
	        // function,
	        // and we don't need to add its fields (`length`, `name`)
	        // over.
	        // See also: GH-246.
	        // const names = Object.getOwnPropertyNames(value)
	        //
	        // for (const p of names) {
	        //   const descriptor = Object.getOwnPropertyDescriptor(value, p)
	        //   if (descriptor) Object.defineProperty(apply, p, descriptor)
	        // }

	        return apply
	      }
	    )
	  );

	/**
	 * @typedef {import('trough').Pipeline} Pipeline
	 *
	 * @typedef {import('unist').Node} Node
	 *
	 * @typedef {import('vfile').Compatible} Compatible
	 * @typedef {import('vfile').Value} Value
	 *
	 * @typedef {import('../index.js').CompileResultMap} CompileResultMap
	 * @typedef {import('../index.js').Data} Data
	 * @typedef {import('../index.js').Settings} Settings
	 */


	// To do: next major: drop `Compiler`, `Parser`: prefer lowercase.

	// To do: we could start yielding `never` in TS when a parser is missing and
	// `parse` is called.
	// Currently, we allow directly setting `processor.parser`, which is untyped.

	const own$3 = {}.hasOwnProperty;

	/**
	 * @template {Node | undefined} [ParseTree=undefined]
	 *   Output of `parse` (optional).
	 * @template {Node | undefined} [HeadTree=undefined]
	 *   Input for `run` (optional).
	 * @template {Node | undefined} [TailTree=undefined]
	 *   Output for `run` (optional).
	 * @template {Node | undefined} [CompileTree=undefined]
	 *   Input of `stringify` (optional).
	 * @template {CompileResults | undefined} [CompileResult=undefined]
	 *   Output of `stringify` (optional).
	 * @extends {CallableInstance<[], Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>>}
	 */
	class Processor extends CallableInstance {
	  /**
	   * Create a processor.
	   */
	  constructor() {
	    // If `Processor()` is called (w/o new), `copy` is called instead.
	    super('copy');

	    /**
	     * Compiler to use (deprecated).
	     *
	     * @deprecated
	     *   Use `compiler` instead.
	     * @type {(
	     *   Compiler<
	     *     CompileTree extends undefined ? Node : CompileTree,
	     *     CompileResult extends undefined ? CompileResults : CompileResult
	     *   > |
	     *   undefined
	     * )}
	     */
	    this.Compiler = undefined;

	    /**
	     * Parser to use (deprecated).
	     *
	     * @deprecated
	     *   Use `parser` instead.
	     * @type {(
	     *   Parser<ParseTree extends undefined ? Node : ParseTree> |
	     *   undefined
	     * )}
	     */
	    this.Parser = undefined;

	    // Note: the following fields are considered private.
	    // However, they are needed for tests, and TSC generates an untyped
	    // `private freezeIndex` field for, which trips `type-coverage` up.
	    // Instead, we use `@deprecated` to visualize that they shouldnt be used.
	    /**
	     * Internal list of configured plugins.
	     *
	     * @deprecated
	     *   This is a private internal property and should not be used.
	     * @type {Array<PluginTuple<Array<unknown>>>}
	     */
	    this.attachers = [];

	    /**
	     * Compiler to use.
	     *
	     * @type {(
	     *   Compiler<
	     *     CompileTree extends undefined ? Node : CompileTree,
	     *     CompileResult extends undefined ? CompileResults : CompileResult
	     *   > |
	     *   undefined
	     * )}
	     */
	    this.compiler = undefined;

	    /**
	     * Internal state to track where we are while freezing.
	     *
	     * @deprecated
	     *   This is a private internal property and should not be used.
	     * @type {number}
	     */
	    this.freezeIndex = -1;

	    /**
	     * Internal state to track whether were frozen.
	     *
	     * @deprecated
	     *   This is a private internal property and should not be used.
	     * @type {boolean | undefined}
	     */
	    this.frozen = undefined;

	    /**
	     * Internal state.
	     *
	     * @deprecated
	     *   This is a private internal property and should not be used.
	     * @type {Data}
	     */
	    this.namespace = {};

	    /**
	     * Parser to use.
	     *
	     * @type {(
	     *   Parser<ParseTree extends undefined ? Node : ParseTree> |
	     *   undefined
	     * )}
	     */
	    this.parser = undefined;

	    /**
	     * Internal list of configured transformers.
	     *
	     * @deprecated
	     *   This is a private internal property and should not be used.
	     * @type {Pipeline}
	     */
	    this.transformers = trough();
	  }

	  /**
	   * Copy a processor.
	   *
	   * @deprecated
	   *   This is a private internal method and should not be used.
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *   New *unfrozen* processor ({@linkcode Processor}) that is
	   *   configured to work the same as its ancestor.
	   *   When the descendant processor is configured in the future it does not
	   *   affect the ancestral processor.
	   */
	  copy() {
	    // Cast as the type parameters will be the same after attaching.
	    const destination =
	      /** @type {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>} */ (
	        new Processor()
	      );
	    let index = -1;

	    while (++index < this.attachers.length) {
	      const attacher = this.attachers[index];
	      destination.use(...attacher);
	    }

	    destination.data(extend(true, {}, this.namespace));

	    return destination
	  }

	  /**
	   * Configure the processor with info available to all plugins.
	   * Information is stored in an object.
	   *
	   * Typically, options can be given to a specific plugin, but sometimes it
	   * makes sense to have information shared with several plugins.
	   * For example, a list of HTML elements that are self-closing, which is
	   * needed during all phases.
	   *
	   * > **Note**: setting information cannot occur on *frozen* processors.
	   * > Call the processor first to create a new unfrozen processor.
	   *
	   * > **Note**: to register custom data in TypeScript, augment the
	   * > {@linkcode Data} interface.
	   *
	   * @example
	   *   This example show how to get and set info:
	   *
	   *   ```js
	   *   import {unified} from 'unified'
	   *
	   *   const processor = unified().data('alpha', 'bravo')
	   *
	   *   processor.data('alpha') // => 'bravo'
	   *
	   *   processor.data() // => {alpha: 'bravo'}
	   *
	   *   processor.data({charlie: 'delta'})
	   *
	   *   processor.data() // => {charlie: 'delta'}
	   *   ```
	   *
	   * @template {keyof Data} Key
	   *
	   * @overload
	   * @returns {Data}
	   *
	   * @overload
	   * @param {Data} dataset
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *
	   * @overload
	   * @param {Key} key
	   * @returns {Data[Key]}
	   *
	   * @overload
	   * @param {Key} key
	   * @param {Data[Key]} value
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *
	   * @param {Data | Key} [key]
	   *   Key to get or set, or entire dataset to set, or nothing to get the
	   *   entire dataset (optional).
	   * @param {Data[Key]} [value]
	   *   Value to set (optional).
	   * @returns {unknown}
	   *   The current processor when setting, the value at `key` when getting, or
	   *   the entire dataset when getting without key.
	   */
	  data(key, value) {
	    if (typeof key === 'string') {
	      // Set `key`.
	      if (arguments.length === 2) {
	        assertUnfrozen('data', this.frozen);
	        this.namespace[key] = value;
	        return this
	      }

	      // Get `key`.
	      return (own$3.call(this.namespace, key) && this.namespace[key]) || undefined
	    }

	    // Set space.
	    if (key) {
	      assertUnfrozen('data', this.frozen);
	      this.namespace = key;
	      return this
	    }

	    // Get space.
	    return this.namespace
	  }

	  /**
	   * Freeze a processor.
	   *
	   * Frozen processors are meant to be extended and not to be configured
	   * directly.
	   *
	   * When a processor is frozen it cannot be unfrozen.
	   * New processors working the same way can be created by calling the
	   * processor.
	   *
	   * Its possible to freeze processors explicitly by calling `.freeze()`.
	   * Processors freeze automatically when `.parse()`, `.run()`, `.runSync()`,
	   * `.stringify()`, `.process()`, or `.processSync()` are called.
	   *
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *   The current processor.
	   */
	  freeze() {
	    if (this.frozen) {
	      return this
	    }

	    // Cast so that we can type plugins easier.
	    // Plugins are supposed to be usable on different processors, not just on
	    // this exact processor.
	    const self = /** @type {Processor} */ (/** @type {unknown} */ (this));

	    while (++this.freezeIndex < this.attachers.length) {
	      const [attacher, ...options] = this.attachers[this.freezeIndex];

	      if (options[0] === false) {
	        continue
	      }

	      if (options[0] === true) {
	        options[0] = undefined;
	      }

	      const transformer = attacher.call(self, ...options);

	      if (typeof transformer === 'function') {
	        this.transformers.use(transformer);
	      }
	    }

	    this.frozen = true;
	    this.freezeIndex = Number.POSITIVE_INFINITY;

	    return this
	  }

	  /**
	   * Parse text to a syntax tree.
	   *
	   * > **Note**: `parse` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `parse` performs the parse phase, not the run phase or other
	   * > phases.
	   *
	   * @param {Compatible | undefined} [file]
	   *   file to parse (optional); typically `string` or `VFile`; any value
	   *   accepted as `x` in `new VFile(x)`.
	   * @returns {ParseTree extends undefined ? Node : ParseTree}
	   *   Syntax tree representing `file`.
	   */
	  parse(file) {
	    this.freeze();
	    const realFile = vfile(file);
	    const parser = this.parser || this.Parser;
	    assertParser('parse', parser);
	    return parser(String(realFile), realFile)
	  }

	  /**
	   * Process the given file as configured on the processor.
	   *
	   * > **Note**: `process` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `process` performs the parse, run, and stringify phases.
	   *
	   * @overload
	   * @param {Compatible | undefined} file
	   * @param {ProcessCallback<VFileWithOutput<CompileResult>>} done
	   * @returns {undefined}
	   *
	   * @overload
	   * @param {Compatible | undefined} [file]
	   * @returns {Promise<VFileWithOutput<CompileResult>>}
	   *
	   * @param {Compatible | undefined} [file]
	   *   File (optional); typically `string` or `VFile`]; any value accepted as
	   *   `x` in `new VFile(x)`.
	   * @param {ProcessCallback<VFileWithOutput<CompileResult>> | undefined} [done]
	   *   Callback (optional).
	   * @returns {Promise<VFile> | undefined}
	   *   Nothing if `done` is given.
	   *   Otherwise a promise, rejected with a fatal error or resolved with the
	   *   processed file.
	   *
	   *   The parsed, transformed, and compiled value is available at
	   *   `file.value` (see note).
	   *
	   *   > **Note**: unified typically compiles by serializing: most
	   *   > compilers return `string` (or `Uint8Array`).
	   *   > Some compilers, such as the one configured with
	   *   > [`rehype-react`][rehype-react], return other values (in this case, a
	   *   > React tree).
	   *   > If youre using a compiler that doesnt serialize, expect different
	   *   > result values.
	   *   >
	   *   > To register custom results in TypeScript, add them to
	   *   > {@linkcode CompileResultMap}.
	   *
	   *   [rehype-react]: https://github.com/rehypejs/rehype-react
	   */
	  process(file, done) {
	    const self = this;

	    this.freeze();
	    assertParser('process', this.parser || this.Parser);
	    assertCompiler('process', this.compiler || this.Compiler);

	    return done ? executor(undefined, done) : new Promise(executor)

	    // Note: `void`s needed for TS.
	    /**
	     * @param {((file: VFileWithOutput<CompileResult>) => undefined | void) | undefined} resolve
	     * @param {(error: Error | undefined) => undefined | void} reject
	     * @returns {undefined}
	     */
	    function executor(resolve, reject) {
	      const realFile = vfile(file);
	      // Assume `ParseTree` (the result of the parser) matches `HeadTree` (the
	      // input of the first transform).
	      const parseTree =
	        /** @type {HeadTree extends undefined ? Node : HeadTree} */ (
	          /** @type {unknown} */ (self.parse(realFile))
	        );

	      self.run(parseTree, realFile, function (error, tree, file) {
	        if (error || !tree || !file) {
	          return realDone(error)
	        }

	        // Assume `TailTree` (the output of the last transform) matches
	        // `CompileTree` (the input of the compiler).
	        const compileTree =
	          /** @type {CompileTree extends undefined ? Node : CompileTree} */ (
	            /** @type {unknown} */ (tree)
	          );

	        const compileResult = self.stringify(compileTree, file);

	        if (looksLikeAValue(compileResult)) {
	          file.value = compileResult;
	        } else {
	          file.result = compileResult;
	        }

	        realDone(error, /** @type {VFileWithOutput<CompileResult>} */ (file));
	      });

	      /**
	       * @param {Error | undefined} error
	       * @param {VFileWithOutput<CompileResult> | undefined} [file]
	       * @returns {undefined}
	       */
	      function realDone(error, file) {
	        if (error || !file) {
	          reject(error);
	        } else if (resolve) {
	          resolve(file);
	        } else {
	          done(undefined, file);
	        }
	      }
	    }
	  }

	  /**
	   * Process the given file as configured on the processor.
	   *
	   * An error is thrown if asynchronous transforms are configured.
	   *
	   * > **Note**: `processSync` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `processSync` performs the parse, run, and stringify phases.
	   *
	   * @param {Compatible | undefined} [file]
	   *   File (optional); typically `string` or `VFile`; any value accepted as
	   *   `x` in `new VFile(x)`.
	   * @returns {VFileWithOutput<CompileResult>}
	   *   The processed file.
	   *
	   *   The parsed, transformed, and compiled value is available at
	   *   `file.value` (see note).
	   *
	   *   > **Note**: unified typically compiles by serializing: most
	   *   > compilers return `string` (or `Uint8Array`).
	   *   > Some compilers, such as the one configured with
	   *   > [`rehype-react`][rehype-react], return other values (in this case, a
	   *   > React tree).
	   *   > If youre using a compiler that doesnt serialize, expect different
	   *   > result values.
	   *   >
	   *   > To register custom results in TypeScript, add them to
	   *   > {@linkcode CompileResultMap}.
	   *
	   *   [rehype-react]: https://github.com/rehypejs/rehype-react
	   */
	  processSync(file) {
	    /** @type {boolean} */
	    let complete = false;
	    /** @type {VFileWithOutput<CompileResult> | undefined} */
	    let result;

	    this.freeze();
	    assertParser('processSync', this.parser || this.Parser);
	    assertCompiler('processSync', this.compiler || this.Compiler);

	    this.process(file, realDone);
	    assertDone('processSync', 'process', complete);

	    return result

	    /**
	     * @type {ProcessCallback<VFileWithOutput<CompileResult>>}
	     */
	    function realDone(error, file) {
	      complete = true;
	      bail(error);
	      result = file;
	    }
	  }

	  /**
	   * Run *transformers* on a syntax tree.
	   *
	   * > **Note**: `run` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `run` performs the run phase, not other phases.
	   *
	   * @overload
	   * @param {HeadTree extends undefined ? Node : HeadTree} tree
	   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} done
	   * @returns {undefined}
	   *
	   * @overload
	   * @param {HeadTree extends undefined ? Node : HeadTree} tree
	   * @param {Compatible | undefined} file
	   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} done
	   * @returns {undefined}
	   *
	   * @overload
	   * @param {HeadTree extends undefined ? Node : HeadTree} tree
	   * @param {Compatible | undefined} [file]
	   * @returns {Promise<TailTree extends undefined ? Node : TailTree>}
	   *
	   * @param {HeadTree extends undefined ? Node : HeadTree} tree
	   *   Tree to transform and inspect.
	   * @param {(
	   *   RunCallback<TailTree extends undefined ? Node : TailTree> |
	   *   Compatible
	   * )} [file]
	   *   File associated with `node` (optional); any value accepted as `x` in
	   *   `new VFile(x)`.
	   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} [done]
	   *   Callback (optional).
	   * @returns {Promise<TailTree extends undefined ? Node : TailTree> | undefined}
	   *   Nothing if `done` is given.
	   *   Otherwise, a promise rejected with a fatal error or resolved with the
	   *   transformed tree.
	   */
	  run(tree, file, done) {
	    assertNode(tree);
	    this.freeze();

	    const transformers = this.transformers;

	    if (!done && typeof file === 'function') {
	      done = file;
	      file = undefined;
	    }

	    return done ? executor(undefined, done) : new Promise(executor)

	    // Note: `void`s needed for TS.
	    /**
	     * @param {(
	     *   ((tree: TailTree extends undefined ? Node : TailTree) => undefined | void) |
	     *   undefined
	     * )} resolve
	     * @param {(error: Error) => undefined | void} reject
	     * @returns {undefined}
	     */
	    function executor(resolve, reject) {
	      const realFile = vfile(file);
	      transformers.run(tree, realFile, realDone);

	      /**
	       * @param {Error | undefined} error
	       * @param {Node} outputTree
	       * @param {VFile} file
	       * @returns {undefined}
	       */
	      function realDone(error, outputTree, file) {
	        const resultingTree =
	          /** @type {TailTree extends undefined ? Node : TailTree} */ (
	            outputTree || tree
	          );

	        if (error) {
	          reject(error);
	        } else if (resolve) {
	          resolve(resultingTree);
	        } else {
	          done(undefined, resultingTree, file);
	        }
	      }
	    }
	  }

	  /**
	   * Run *transformers* on a syntax tree.
	   *
	   * An error is thrown if asynchronous transforms are configured.
	   *
	   * > **Note**: `runSync` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `runSync` performs the run phase, not other phases.
	   *
	   * @param {HeadTree extends undefined ? Node : HeadTree} tree
	   *   Tree to transform and inspect.
	   * @param {Compatible | undefined} [file]
	   *   File associated with `node` (optional); any value accepted as `x` in
	   *   `new VFile(x)`.
	   * @returns {TailTree extends undefined ? Node : TailTree}
	   *   Transformed tree.
	   */
	  runSync(tree, file) {
	    /** @type {boolean} */
	    let complete = false;
	    /** @type {(TailTree extends undefined ? Node : TailTree) | undefined} */
	    let result;

	    this.run(tree, file, realDone);

	    assertDone('runSync', 'run', complete);
	    return result

	    /**
	     * @type {RunCallback<TailTree extends undefined ? Node : TailTree>}
	     */
	    function realDone(error, tree) {
	      bail(error);
	      result = tree;
	      complete = true;
	    }
	  }

	  /**
	   * Compile a syntax tree.
	   *
	   * > **Note**: `stringify` freezes the processor if not already *frozen*.
	   *
	   * > **Note**: `stringify` performs the stringify phase, not the run phase
	   * > or other phases.
	   *
	   * @param {CompileTree extends undefined ? Node : CompileTree} tree
	   *   Tree to compile.
	   * @param {Compatible | undefined} [file]
	   *   File associated with `node` (optional); any value accepted as `x` in
	   *   `new VFile(x)`.
	   * @returns {CompileResult extends undefined ? Value : CompileResult}
	   *   Textual representation of the tree (see note).
	   *
	   *   > **Note**: unified typically compiles by serializing: most compilers
	   *   > return `string` (or `Uint8Array`).
	   *   > Some compilers, such as the one configured with
	   *   > [`rehype-react`][rehype-react], return other values (in this case, a
	   *   > React tree).
	   *   > If youre using a compiler that doesnt serialize, expect different
	   *   > result values.
	   *   >
	   *   > To register custom results in TypeScript, add them to
	   *   > {@linkcode CompileResultMap}.
	   *
	   *   [rehype-react]: https://github.com/rehypejs/rehype-react
	   */
	  stringify(tree, file) {
	    this.freeze();
	    const realFile = vfile(file);
	    const compiler = this.compiler || this.Compiler;
	    assertCompiler('stringify', compiler);
	    assertNode(tree);

	    return compiler(tree, realFile)
	  }

	  /**
	   * Configure the processor to use a plugin, a list of usable values, or a
	   * preset.
	   *
	   * If the processor is already using a plugin, the previous plugin
	   * configuration is changed based on the options that are passed in.
	   * In other words, the plugin is not added a second time.
	   *
	   * > **Note**: `use` cannot be called on *frozen* processors.
	   * > Call the processor first to create a new unfrozen processor.
	   *
	   * @example
	   *   There are many ways to pass plugins to `.use()`.
	   *   This example gives an overview:
	   *
	   *   ```js
	   *   import {unified} from 'unified'
	   *
	   *   unified()
	   *     // Plugin with options:
	   *     .use(pluginA, {x: true, y: true})
	   *     // Passing the same plugin again merges configuration (to `{x: true, y: false, z: true}`):
	   *     .use(pluginA, {y: false, z: true})
	   *     // Plugins:
	   *     .use([pluginB, pluginC])
	   *     // Two plugins, the second with options:
	   *     .use([pluginD, [pluginE, {}]])
	   *     // Preset with plugins and settings:
	   *     .use({plugins: [pluginF, [pluginG, {}]], settings: {position: false}})
	   *     // Settings only:
	   *     .use({settings: {position: false}})
	   *   ```
	   *
	   * @template {Array<unknown>} [Parameters=[]]
	   * @template {Node | string | undefined} [Input=undefined]
	   * @template [Output=Input]
	   *
	   * @overload
	   * @param {Preset | null | undefined} [preset]
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *
	   * @overload
	   * @param {PluggableList} list
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *
	   * @overload
	   * @param {Plugin<Parameters, Input, Output>} plugin
	   * @param {...(Parameters | [boolean])} parameters
	   * @returns {UsePlugin<ParseTree, HeadTree, TailTree, CompileTree, CompileResult, Input, Output>}
	   *
	   * @param {PluggableList | Plugin | Preset | null | undefined} value
	   *   Usable value.
	   * @param {...unknown} parameters
	   *   Parameters, when a plugin is given as a usable value.
	   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
	   *   Current processor.
	   */
	  use(value, ...parameters) {
	    const attachers = this.attachers;
	    const namespace = this.namespace;

	    assertUnfrozen('use', this.frozen);

	    if (value === null || value === undefined) ; else if (typeof value === 'function') {
	      addPlugin(value, parameters);
	    } else if (typeof value === 'object') {
	      if (Array.isArray(value)) {
	        addList(value);
	      } else {
	        addPreset(value);
	      }
	    } else {
	      throw new TypeError('Expected usable value, not `' + value + '`')
	    }

	    return this

	    /**
	     * @param {Pluggable} value
	     * @returns {undefined}
	     */
	    function add(value) {
	      if (typeof value === 'function') {
	        addPlugin(value, []);
	      } else if (typeof value === 'object') {
	        if (Array.isArray(value)) {
	          const [plugin, ...parameters] =
	            /** @type {PluginTuple<Array<unknown>>} */ (value);
	          addPlugin(plugin, parameters);
	        } else {
	          addPreset(value);
	        }
	      } else {
	        throw new TypeError('Expected usable value, not `' + value + '`')
	      }
	    }

	    /**
	     * @param {Preset} result
	     * @returns {undefined}
	     */
	    function addPreset(result) {
	      if (!('plugins' in result) && !('settings' in result)) {
	        throw new Error(
	          'Expected usable value but received an empty preset, which is probably a mistake: presets typically come with `plugins` and sometimes with `settings`, but this has neither'
	        )
	      }

	      addList(result.plugins);

	      if (result.settings) {
	        namespace.settings = extend(true, namespace.settings, result.settings);
	      }
	    }

	    /**
	     * @param {PluggableList | null | undefined} plugins
	     * @returns {undefined}
	     */
	    function addList(plugins) {
	      let index = -1;

	      if (plugins === null || plugins === undefined) ; else if (Array.isArray(plugins)) {
	        while (++index < plugins.length) {
	          const thing = plugins[index];
	          add(thing);
	        }
	      } else {
	        throw new TypeError('Expected a list of plugins, not `' + plugins + '`')
	      }
	    }

	    /**
	     * @param {Plugin} plugin
	     * @param {Array<unknown>} parameters
	     * @returns {undefined}
	     */
	    function addPlugin(plugin, parameters) {
	      let index = -1;
	      let entryIndex = -1;

	      while (++index < attachers.length) {
	        if (attachers[index][0] === plugin) {
	          entryIndex = index;
	          break
	        }
	      }

	      if (entryIndex === -1) {
	        attachers.push([plugin, ...parameters]);
	      }
	      // Only set if there was at least a `primary` value, otherwise wed change
	      // `arguments.length`.
	      else if (parameters.length > 0) {
	        let [primary, ...rest] = parameters;
	        const currentPrimary = attachers[entryIndex][1];
	        if (isPlainObject(currentPrimary) && isPlainObject(primary)) {
	          primary = extend(true, currentPrimary, primary);
	        }

	        attachers[entryIndex] = [plugin, primary, ...rest];
	      }
	    }
	  }
	}

	// Note: this returns a *callable* instance.
	// Thats why its documented as a function.
	/**
	 * Create a new processor.
	 *
	 * @example
	 *   This example shows how a new processor can be created (from `remark`) and linked
	 *   to **stdin**(4) and **stdout**(4).
	 *
	 *   ```js
	 *   import process from 'node:process'
	 *   import concatStream from 'concat-stream'
	 *   import {remark} from 'remark'
	 *
	 *   process.stdin.pipe(
	 *     concatStream(function (buf) {
	 *       process.stdout.write(String(remark().processSync(buf)))
	 *     })
	 *   )
	 *   ```
	 *
	 * @returns
	 *   New *unfrozen* processor (`processor`).
	 *
	 *   This processor is configured to work the same as its ancestor.
	 *   When the descendant processor is configured in the future it does not
	 *   affect the ancestral processor.
	 */
	const unified = new Processor().freeze();

	/**
	 * Assert a parser is available.
	 *
	 * @param {string} name
	 * @param {unknown} value
	 * @returns {asserts value is Parser}
	 */
	function assertParser(name, value) {
	  if (typeof value !== 'function') {
	    throw new TypeError('Cannot `' + name + '` without `parser`')
	  }
	}

	/**
	 * Assert a compiler is available.
	 *
	 * @param {string} name
	 * @param {unknown} value
	 * @returns {asserts value is Compiler}
	 */
	function assertCompiler(name, value) {
	  if (typeof value !== 'function') {
	    throw new TypeError('Cannot `' + name + '` without `compiler`')
	  }
	}

	/**
	 * Assert the processor is not frozen.
	 *
	 * @param {string} name
	 * @param {unknown} frozen
	 * @returns {asserts frozen is false}
	 */
	function assertUnfrozen(name, frozen) {
	  if (frozen) {
	    throw new Error(
	      'Cannot call `' +
	        name +
	        '` on a frozen processor.\nCreate a new processor first, by calling it: use `processor()` instead of `processor`.'
	    )
	  }
	}

	/**
	 * Assert `node` is a unist node.
	 *
	 * @param {unknown} node
	 * @returns {asserts node is Node}
	 */
	function assertNode(node) {
	  // `isPlainObj` unfortunately uses `any` instead of `unknown`.
	  // type-coverage:ignore-next-line
	  if (!isPlainObject(node) || typeof node.type !== 'string') {
	    throw new TypeError('Expected node, got `' + node + '`')
	    // Fine.
	  }
	}

	/**
	 * Assert that `complete` is `true`.
	 *
	 * @param {string} name
	 * @param {string} asyncName
	 * @param {unknown} complete
	 * @returns {asserts complete is true}
	 */
	function assertDone(name, asyncName, complete) {
	  if (!complete) {
	    throw new Error(
	      '`' + name + '` finished async. Use `' + asyncName + '` instead'
	    )
	  }
	}

	/**
	 * @param {Compatible | undefined} [value]
	 * @returns {VFile}
	 */
	function vfile(value) {
	  return looksLikeAVFile(value) ? value : new VFile(value)
	}

	/**
	 * @param {Compatible | undefined} [value]
	 * @returns {value is VFile}
	 */
	function looksLikeAVFile(value) {
	  return Boolean(
	    value &&
	      typeof value === 'object' &&
	      'message' in value &&
	      'messages' in value
	  )
	}

	/**
	 * @param {unknown} [value]
	 * @returns {value is Value}
	 */
	function looksLikeAValue(value) {
	  return typeof value === 'string' || isUint8Array(value)
	}

	/**
	 * Assert `value` is an `Uint8Array`.
	 *
	 * @param {unknown} value
	 *   thing.
	 * @returns {value is Uint8Array}
	 *   Whether `value` is an `Uint8Array`.
	 */
	function isUint8Array(value) {
	  return Boolean(
	    value &&
	      typeof value === 'object' &&
	      'byteLength' in value &&
	      'byteOffset' in value
	  )
	}

	/**
	 * @typedef {import('mdast').Nodes} Nodes
	 *
	 * @typedef Options
	 *   Configuration (optional).
	 * @property {boolean | null | undefined} [includeImageAlt=true]
	 *   Whether to use `alt` for `image`s (default: `true`).
	 * @property {boolean | null | undefined} [includeHtml=true]
	 *   Whether to use `value` of HTML (default: `true`).
	 */

	/** @type {Options} */
	const emptyOptions = {};

	/**
	 * Get the text content of a node or list of nodes.
	 *
	 * Prefers the nodes plain-text fields, otherwise serializes its children,
	 * and if the given value is an array, serialize the nodes in it.
	 *
	 * @param {unknown} [value]
	 *   Thing to serialize, typically `Node`.
	 * @param {Options | null | undefined} [options]
	 *   Configuration (optional).
	 * @returns {string}
	 *   Serialized `value`.
	 */
	function toString(value, options) {
	  const settings = emptyOptions;
	  const includeImageAlt =
	    typeof settings.includeImageAlt === 'boolean'
	      ? settings.includeImageAlt
	      : true;
	  const includeHtml =
	    typeof settings.includeHtml === 'boolean' ? settings.includeHtml : true;

	  return one(value, includeImageAlt, includeHtml)
	}

	/**
	 * One node or several nodes.
	 *
	 * @param {unknown} value
	 *   Thing to serialize.
	 * @param {boolean} includeImageAlt
	 *   Include image `alt`s.
	 * @param {boolean} includeHtml
	 *   Include HTML.
	 * @returns {string}
	 *   Serialized node.
	 */
	function one(value, includeImageAlt, includeHtml) {
	  if (node(value)) {
	    if ('value' in value) {
	      return value.type === 'html' && !includeHtml ? '' : value.value
	    }

	    if (includeImageAlt && 'alt' in value && value.alt) {
	      return value.alt
	    }

	    if ('children' in value) {
	      return all(value.children, includeImageAlt, includeHtml)
	    }
	  }

	  if (Array.isArray(value)) {
	    return all(value, includeImageAlt, includeHtml)
	  }

	  return ''
	}

	/**
	 * Serialize a list of nodes.
	 *
	 * @param {Array<unknown>} values
	 *   Thing to serialize.
	 * @param {boolean} includeImageAlt
	 *   Include image `alt`s.
	 * @param {boolean} includeHtml
	 *   Include HTML.
	 * @returns {string}
	 *   Serialized nodes.
	 */
	function all(values, includeImageAlt, includeHtml) {
	  /** @type {Array<string>} */
	  const result = [];
	  let index = -1;

	  while (++index < values.length) {
	    result[index] = one(values[index], includeImageAlt, includeHtml);
	  }

	  return result.join('')
	}

	/**
	 * Check if `value` looks like a node.
	 *
	 * @param {unknown} value
	 *   Thing.
	 * @returns {value is Nodes}
	 *   Whether `value` is a node.
	 */
	function node(value) {
	  return Boolean(value && typeof value === 'object')
	}

	/// <reference lib="dom" />

	/* global document */

	const element = document.createElement('i');

	/**
	 * @param {string} value
	 * @returns {string | false}
	 */
	function decodeNamedCharacterReference(value) {
	  const characterReference = '&' + value + ';';
	  element.innerHTML = characterReference;
	  const character = element.textContent;

	  // Some named character references do not require the closing semicolon
	  // (`&not`, for instance), which leads to situations where parsing the assumed
	  // named reference of `&notit;` will result in the string `it;`.
	  // When we encounter a trailing semicolon after parsing, and the character
	  // reference to decode was not a semicolon (`&semi;`), we can assume that the
	  // matching was not complete.
	  if (
	    // @ts-expect-error: TypeScript is wrong that `textContent` on elements can
	    // yield `null`.
	    character.charCodeAt(character.length - 1) === 59 /* `;` */ &&
	    value !== 'semi'
	  ) {
	    return false
	  }

	  // If the decoded string is equal to the input, the character reference was
	  // not valid.
	  // @ts-expect-error: TypeScript is wrong that `textContent` on elements can
	  // yield `null`.
	  return character === characterReference ? false : character
	}

	/**
	 * Like `Array#splice`, but smarter for giant arrays.
	 *
	 * `Array#splice` takes all items to be inserted as individual argument which
	 * causes a stack overflow in V8 when trying to insert 100k items for instance.
	 *
	 * Otherwise, this does not return the removed items, and takes `items` as an
	 * array instead of rest parameters.
	 *
	 * @template {unknown} T
	 *   Item type.
	 * @param {Array<T>} list
	 *   List to operate on.
	 * @param {number} start
	 *   Index to remove/insert at (can be negative).
	 * @param {number} remove
	 *   Number of items to remove.
	 * @param {Array<T>} items
	 *   Items to inject into `list`.
	 * @returns {undefined}
	 *   Nothing.
	 */
	function splice(list, start, remove, items) {
	  const end = list.length;
	  let chunkStart = 0;
	  /** @type {Array<unknown>} */
	  let parameters;

	  // Make start between zero and `end` (included).
	  if (start < 0) {
	    start = -start > end ? 0 : end + start;
	  } else {
	    start = start > end ? end : start;
	  }
	  remove = remove > 0 ? remove : 0;

	  // No need to chunk the items if theres only a couple (10k) items.
	  if (items.length < 10000) {
	    parameters = Array.from(items);
	    parameters.unshift(start, remove);
	    // @ts-expect-error Hush, its fine.
	    list.splice(...parameters);
	  } else {
	    // Delete `remove` items starting from `start`
	    if (remove) list.splice(start, remove);

	    // Insert the items in chunks to not cause stack overflows.
	    while (chunkStart < items.length) {
	      parameters = items.slice(chunkStart, chunkStart + 10000);
	      parameters.unshift(start, 0);
	      // @ts-expect-error Hush, its fine.
	      list.splice(...parameters);
	      chunkStart += 10000;
	      start += 10000;
	    }
	  }
	}

	/**
	 * Append `items` (an array) at the end of `list` (another array).
	 * When `list` was empty, returns `items` instead.
	 *
	 * This prevents a potentially expensive operation when `list` is empty,
	 * and adds items in batches to prevent V8 from hanging.
	 *
	 * @template {unknown} T
	 *   Item type.
	 * @param {Array<T>} list
	 *   List to operate on.
	 * @param {Array<T>} items
	 *   Items to add to `list`.
	 * @returns {Array<T>}
	 *   Either `list` or `items`.
	 */
	function push(list, items) {
	  if (list.length > 0) {
	    splice(list, list.length, 0, items);
	    return list;
	  }
	  return items;
	}

	/**
	 * @import {
	 *   Extension,
	 *   Handles,
	 *   HtmlExtension,
	 *   NormalizedExtension
	 * } from 'micromark-util-types'
	 */


	const hasOwnProperty = {}.hasOwnProperty;

	/**
	 * Combine multiple syntax extensions into one.
	 *
	 * @param {ReadonlyArray<Extension>} extensions
	 *   List of syntax extensions.
	 * @returns {NormalizedExtension}
	 *   A single combined extension.
	 */
	function combineExtensions(extensions) {
	  /** @type {NormalizedExtension} */
	  const all = {};
	  let index = -1;

	  while (++index < extensions.length) {
	    syntaxExtension(all, extensions[index]);
	  }

	  return all
	}

	/**
	 * Merge `extension` into `all`.
	 *
	 * @param {NormalizedExtension} all
	 *   Extension to merge into.
	 * @param {Extension} extension
	 *   Extension to merge.
	 * @returns {undefined}
	 *   Nothing.
	 */
	function syntaxExtension(all, extension) {
	  /** @type {keyof Extension} */
	  let hook;

	  for (hook in extension) {
	    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;
	    /** @type {Record<string, unknown>} */
	    const left = maybe || (all[hook] = {});
	    /** @type {Record<string, unknown> | undefined} */
	    const right = extension[hook];
	    /** @type {string} */
	    let code;

	    if (right) {
	      for (code in right) {
	        if (!hasOwnProperty.call(left, code)) left[code] = [];
	        const value = right[code];
	        constructs(
	          // @ts-expect-error Looks like a list.
	          left[code],
	          Array.isArray(value) ? value : value ? [value] : []
	        );
	      }
	    }
	  }
	}

	/**
	 * Merge `list` into `existing` (both lists of constructs).
	 * Mutates `existing`.
	 *
	 * @param {Array<unknown>} existing
	 *   List of constructs to merge into.
	 * @param {Array<unknown>} list
	 *   List of constructs to merge.
	 * @returns {undefined}
	 *   Nothing.
	 */
	function constructs(existing, list) {
	  let index = -1;
	  /** @type {Array<unknown>} */
	  const before = [];

	  while (++index < list.length) {
	(list[index].add === 'after' ? existing : before).push(list[index]);
	  }

	  splice(existing, 0, 0, before);
	}

	/**
	 * Turn the number (in string form as either hexa- or plain decimal) coming from
	 * a numeric character reference into a character.
	 *
	 * Sort of like `String.fromCodePoint(Number.parseInt(value, base))`, but makes
	 * non-characters and control characters safe.
	 *
	 * @param {string} value
	 *   Value to decode.
	 * @param {number} base
	 *   Numeric base.
	 * @returns {string}
	 *   Character.
	 */
	function decodeNumericCharacterReference(value, base) {
	  const code = Number.parseInt(value, base);
	  if (
	  // C0 except for HT, LF, FF, CR, space.
	  code < 9 || code === 11 || code > 13 && code < 32 ||
	  // Control character (DEL) of C0, and C1 controls.
	  code > 126 && code < 160 ||
	  // Lone high surrogates and low surrogates.
	  code > 55_295 && code < 57_344 ||
	  // Noncharacters.
	  code > 64_975 && code < 65_008 || /* eslint-disable no-bitwise */
	  (code & 65_535) === 65_535 || (code & 65_535) === 65_534 || /* eslint-enable no-bitwise */
	  // Out of range
	  code > 1_114_111) {
	    return "\uFFFD";
	  }
	  return String.fromCodePoint(code);
	}

	/**
	 * Normalize an identifier (as found in references, definitions).
	 *
	 * Collapses markdown whitespace, trim, and then lower- and uppercase.
	 *
	 * Some characters are considered uppercase, such as U+03F4 (``), but if their
	 * lowercase counterpart (U+03B8 (``)) is uppercased will result in a different
	 * uppercase character (U+0398 (``)).
	 * So, to get a canonical form, we perform both lower- and uppercase.
	 *
	 * Using uppercase last makes sure keys will never interact with default
	 * prototypal values (such as `constructor`): nothing in the prototype of
	 * `Object` is uppercase.
	 *
	 * @param {string} value
	 *   Identifier to normalize.
	 * @returns {string}
	 *   Normalized identifier.
	 */
	function normalizeIdentifier(value) {
	  return value
	  // Collapse markdown whitespace.
	  .replace(/[\t\n\r ]+/g, " ")
	  // Trim.
	  .replace(/^ | $/g, '')
	  // Some characters are considered uppercase, but if their lowercase
	  // counterpart is uppercased will result in a different uppercase
	  // character.
	  // Hence, to get that form, we perform both lower- and uppercase.
	  // Upper case makes sure keys will not interact with default prototypal
	  // methods: no method is uppercase.
	  .toLowerCase().toUpperCase();
	}

	/**
	 * @import {Code} from 'micromark-util-types'
	 */

	/**
	 * Check whether the character code represents an ASCII alpha (`a` through `z`,
	 * case insensitive).
	 *
	 * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.
	 *
	 * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)
	 * to U+005A (`Z`).
	 *
	 * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)
	 * to U+007A (`z`).
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiAlpha = regexCheck(/[A-Za-z]/);

	/**
	 * Check whether the character code represents an ASCII alphanumeric (`a`
	 * through `z`, case insensitive, or `0` through `9`).
	 *
	 * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha
	 * (see `asciiAlpha`).
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiAlphanumeric = regexCheck(/[\dA-Za-z]/);

	/**
	 * Check whether the character code represents an ASCII atext.
	 *
	 * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in
	 * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),
	 * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F
	 * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E
	 * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE
	 * (`{`) to U+007E TILDE (`~`).
	 *
	 * See:
	 * **\[RFC5322]**:
	 * [Internet Message Format](https://tools.ietf.org/html/rfc5322).
	 * P. Resnick.
	 * IETF.
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiAtext = regexCheck(/[#-'*+\--9=?A-Z^-~]/);

	/**
	 * Check whether a character code is an ASCII control character.
	 *
	 * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)
	 * to U+001F (US), or U+007F (DEL).
	 *
	 * @param {Code} code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	function asciiControl(code) {
	  return (
	    // Special whitespace codes (which have negative values), C0 and Control
	    // character DEL
	    code !== null && (code < 32 || code === 127)
	  );
	}

	/**
	 * Check whether the character code represents an ASCII digit (`0` through `9`).
	 *
	 * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to
	 * U+0039 (`9`).
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiDigit = regexCheck(/\d/);

	/**
	 * Check whether the character code represents an ASCII hex digit (`a` through
	 * `f`, case insensitive, or `0` through `9`).
	 *
	 * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex
	 * digit, or an ASCII lower hex digit.
	 *
	 * An **ASCII upper hex digit** is a character in the inclusive range U+0041
	 * (`A`) to U+0046 (`F`).
	 *
	 * An **ASCII lower hex digit** is a character in the inclusive range U+0061
	 * (`a`) to U+0066 (`f`).
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiHexDigit = regexCheck(/[\dA-Fa-f]/);

	/**
	 * Check whether the character code represents ASCII punctuation.
	 *
	 * An **ASCII punctuation** is a character in the inclusive ranges U+0021
	 * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT
	 * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT
	 * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).
	 *
	 * @param code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/);

	/**
	 * Check whether a character code is a markdown line ending.
	 *
	 * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN
	 * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).
	 *
	 * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE
	 * RETURN (CR) are replaced by these virtual characters depending on whether
	 * they occurred together.
	 *
	 * @param {Code} code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	function markdownLineEnding(code) {
	  return code !== null && code < -2;
	}

	/**
	 * Check whether a character code is a markdown line ending (see
	 * `markdownLineEnding`) or markdown space (see `markdownSpace`).
	 *
	 * @param {Code} code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	function markdownLineEndingOrSpace(code) {
	  return code !== null && (code < 0 || code === 32);
	}

	/**
	 * Check whether a character code is a markdown space.
	 *
	 * A **markdown space** is the concrete character U+0020 SPACE (SP) and the
	 * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).
	 *
	 * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is
	 * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL
	 * SPACE (VS) characters, depending on the column at which the tab occurred.
	 *
	 * @param {Code} code
	 *   Code.
	 * @returns {boolean}
	 *   Whether it matches.
	 */
	function markdownSpace(code) {
	  return code === -2 || code === -1 || code === 32;
	}

	// Size note: removing ASCII from the regex and using `asciiPunctuation` here
	// In fact adds to the bundle size.
	/**
	 * Check whether the character code represents Unicode punctuation.
	 *
	 * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,
	 * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`
	 * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`
	 * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII
	 * punctuation (see `asciiPunctuation`).
	 *
	 * See:
	 * **\[UNICODE]**:
	 * [The Unicode Standard](https://www.unicode.org/versions/).
	 * Unicode Consortium.
	 *
	 * @param code
	 *   Code.
	 * @returns
	 *   Whether it matches.
	 */
	const unicodePunctuation = regexCheck(/\p{P}|\p{S}/u);

	/**
	 * Check whether the character code represents Unicode whitespace.
	 *
	 * Note that this does handle micromark specific markdown whitespace characters.
	 * See `markdownLineEndingOrSpace` to check that.
	 *
	 * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,
	 * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),
	 * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\[UNICODE]**).
	 *
	 * See:
	 * **\[UNICODE]**:
	 * [The Unicode Standard](https://www.unicode.org/versions/).
	 * Unicode Consortium.
	 *
	 * @param code
	 *   Code.
	 * @returns
	 *   Whether it matches.
	 */
	const unicodeWhitespace = regexCheck(/\s/);

	/**
	 * Create a code check from a regex.
	 *
	 * @param {RegExp} regex
	 *   Expression.
	 * @returns {(code: Code) => boolean}
	 *   Check.
	 */
	function regexCheck(regex) {
	  return check;

	  /**
	   * Check whether a code matches the bound regex.
	   *
	   * @param {Code} code
	   *   Character code.
	   * @returns {boolean}
	   *   Whether the character code matches the bound regex.
	   */
	  function check(code) {
	    return code !== null && code > -1 && regex.test(String.fromCharCode(code));
	  }
	}

	/**
	 * @import {Effects, State, TokenType} from 'micromark-util-types'
	 */


	// To do: implement `spaceOrTab`, `spaceOrTabMinMax`, `spaceOrTabWithOptions`.

	/**
	 * Parse spaces and tabs.
	 *
	 * There is no `nok` parameter:
	 *
	 * *   spaces in markdown are often optional, in which case this factory can be
	 *     used and `ok` will be switched to whether spaces were found or not
	 * *   one line ending or space can be detected with `markdownSpace(code)` right
	 *     before using `factorySpace`
	 *
	 * ###### Examples
	 *
	 * Where `` represents a tab (plus how much it expands) and `` represents a
	 * single space.
	 *
	 * ```markdown
	 * 
	 * 
	 * 
	 * ```
	 *
	 * @param {Effects} effects
	 *   Context.
	 * @param {State} ok
	 *   State switched to when successful.
	 * @param {TokenType} type
	 *   Type (`' \t'`).
	 * @param {number | undefined} [max=Infinity]
	 *   Max (exclusive).
	 * @returns {State}
	 *   Start state.
	 */
	function factorySpace(effects, ok, type, max) {
	  const limit = max ? max - 1 : Number.POSITIVE_INFINITY;
	  let size = 0;
	  return start;

	  /** @type {State} */
	  function start(code) {
	    if (markdownSpace(code)) {
	      effects.enter(type);
	      return prefix(code);
	    }
	    return ok(code);
	  }

	  /** @type {State} */
	  function prefix(code) {
	    if (markdownSpace(code) && size++ < limit) {
	      effects.consume(code);
	      return prefix;
	    }
	    effects.exit(type);
	    return ok(code);
	  }
	}

	/**
	 * @import {
	 *   InitialConstruct,
	 *   Initializer,
	 *   State,
	 *   TokenizeContext,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {InitialConstruct} */
	const content$1 = {
	  tokenize: initializeContent
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Initializer}
	 *   Content.
	 */
	function initializeContent(effects) {
	  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);
	  /** @type {Token} */
	  let previous;
	  return contentStart;

	  /** @type {State} */
	  function afterContentStartConstruct(code) {
	    if (code === null) {
	      effects.consume(code);
	      return;
	    }
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return factorySpace(effects, contentStart, "linePrefix");
	  }

	  /** @type {State} */
	  function paragraphInitial(code) {
	    effects.enter("paragraph");
	    return lineStart(code);
	  }

	  /** @type {State} */
	  function lineStart(code) {
	    const token = effects.enter("chunkText", {
	      contentType: "text",
	      previous
	    });
	    if (previous) {
	      previous.next = token;
	    }
	    previous = token;
	    return data(code);
	  }

	  /** @type {State} */
	  function data(code) {
	    if (code === null) {
	      effects.exit("chunkText");
	      effects.exit("paragraph");
	      effects.consume(code);
	      return;
	    }
	    if (markdownLineEnding(code)) {
	      effects.consume(code);
	      effects.exit("chunkText");
	      return lineStart;
	    }

	    // Data.
	    effects.consume(code);
	    return data;
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   ContainerState,
	 *   InitialConstruct,
	 *   Initializer,
	 *   Point,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {InitialConstruct} */
	const document$2 = {
	  tokenize: initializeDocument
	};

	/** @type {Construct} */
	const containerConstruct = {
	  tokenize: tokenizeContainer
	};

	/**
	 * @this {TokenizeContext}
	 *   Self.
	 * @type {Initializer}
	 *   Initializer.
	 */
	function initializeDocument(effects) {
	  const self = this;
	  /** @type {Array<StackItem>} */
	  const stack = [];
	  let continued = 0;
	  /** @type {TokenizeContext | undefined} */
	  let childFlow;
	  /** @type {Token | undefined} */
	  let childToken;
	  /** @type {number} */
	  let lineStartOffset;
	  return start;

	  /** @type {State} */
	  function start(code) {
	    // First we iterate through the open blocks, starting with the root
	    // document, and descending through last children down to the last open
	    // block.
	    // Each block imposes a condition that the line must satisfy if the block is
	    // to remain open.
	    // For example, a block quote requires a `>` character.
	    // A paragraph requires a non-blank line.
	    // In this phase we may match all or just some of the open blocks.
	    // But we cannot close unmatched blocks yet, because we may have a lazy
	    // continuation line.
	    if (continued < stack.length) {
	      const item = stack[continued];
	      self.containerState = item[1];
	      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);
	    }

	    // Done.
	    return checkNewContainers(code);
	  }

	  /** @type {State} */
	  function documentContinue(code) {
	    continued++;

	    // Note: this field is called `_closeFlow` but it also closes containers.
	    // Perhaps a good idea to rename it but its already used in the wild by
	    // extensions.
	    if (self.containerState._closeFlow) {
	      self.containerState._closeFlow = undefined;
	      if (childFlow) {
	        closeFlow();
	      }

	      // Note: this algorithm for moving events around is similar to the
	      // algorithm when dealing with lazy lines in `writeToChild`.
	      const indexBeforeExits = self.events.length;
	      let indexBeforeFlow = indexBeforeExits;
	      /** @type {Point | undefined} */
	      let point;

	      // Find the flow chunk.
	      while (indexBeforeFlow--) {
	        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === "chunkFlow") {
	          point = self.events[indexBeforeFlow][1].end;
	          break;
	        }
	      }
	      exitContainers(continued);

	      // Fix positions.
	      let index = indexBeforeExits;
	      while (index < self.events.length) {
	        self.events[index][1].end = {
	          ...point
	        };
	        index++;
	      }

	      // Inject the exits earlier (theyre still also at the end).
	      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));

	      // Discard the duplicate exits.
	      self.events.length = index;
	      return checkNewContainers(code);
	    }
	    return start(code);
	  }

	  /** @type {State} */
	  function checkNewContainers(code) {
	    // Next, after consuming the continuation markers for existing blocks, we
	    // look for new block starts (e.g. `>` for a block quote).
	    // If we encounter a new block start, we close any blocks unmatched in
	    // step 1 before creating the new block as a child of the last matched
	    // block.
	    if (continued === stack.length) {
	      // No need to `check` whether theres a container, of `exitContainers`
	      // would be moot.
	      // We can instead immediately `attempt` to parse one.
	      if (!childFlow) {
	        return documentContinued(code);
	      }

	      // If we have concrete content, such as block HTML or fenced code,
	      // we cant have containers pierce into them, so we can immediately
	      // start.
	      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {
	        return flowStart(code);
	      }

	      // If we do have flow, it could still be a blank line,
	      // but wed be interrupting it w/ a new container if theres a current
	      // construct.
	      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer
	      // needed in micromark-extension-gfm-table@1.0.6).
	      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);
	    }

	    // Check if there is a new container.
	    self.containerState = {};
	    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);
	  }

	  /** @type {State} */
	  function thereIsANewContainer(code) {
	    if (childFlow) closeFlow();
	    exitContainers(continued);
	    return documentContinued(code);
	  }

	  /** @type {State} */
	  function thereIsNoNewContainer(code) {
	    self.parser.lazy[self.now().line] = continued !== stack.length;
	    lineStartOffset = self.now().offset;
	    return flowStart(code);
	  }

	  /** @type {State} */
	  function documentContinued(code) {
	    // Try new containers.
	    self.containerState = {};
	    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);
	  }

	  /** @type {State} */
	  function containerContinue(code) {
	    continued++;
	    stack.push([self.currentConstruct, self.containerState]);
	    // Try another.
	    return documentContinued(code);
	  }

	  /** @type {State} */
	  function flowStart(code) {
	    if (code === null) {
	      if (childFlow) closeFlow();
	      exitContainers(0);
	      effects.consume(code);
	      return;
	    }
	    childFlow = childFlow || self.parser.flow(self.now());
	    effects.enter("chunkFlow", {
	      _tokenizer: childFlow,
	      contentType: "flow",
	      previous: childToken
	    });
	    return flowContinue(code);
	  }

	  /** @type {State} */
	  function flowContinue(code) {
	    if (code === null) {
	      writeToChild(effects.exit("chunkFlow"), true);
	      exitContainers(0);
	      effects.consume(code);
	      return;
	    }
	    if (markdownLineEnding(code)) {
	      effects.consume(code);
	      writeToChild(effects.exit("chunkFlow"));
	      // Get ready for the next line.
	      continued = 0;
	      self.interrupt = undefined;
	      return start;
	    }
	    effects.consume(code);
	    return flowContinue;
	  }

	  /**
	   * @param {Token} token
	   *   Token.
	   * @param {boolean | undefined} [endOfFile]
	   *   Whether the token is at the end of the file (default: `false`).
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function writeToChild(token, endOfFile) {
	    const stream = self.sliceStream(token);
	    if (endOfFile) stream.push(null);
	    token.previous = childToken;
	    if (childToken) childToken.next = token;
	    childToken = token;
	    childFlow.defineSkip(token.start);
	    childFlow.write(stream);

	    // Alright, so we just added a lazy line:
	    //
	    // ```markdown
	    // > a
	    // b.
	    //
	    // Or:
	    //
	    // > ~~~c
	    // d
	    //
	    // Or:
	    //
	    // > | e |
	    // f
	    // ```
	    //
	    // The construct in the second example (fenced code) does not accept lazy
	    // lines, so it marked itself as done at the end of its first line, and
	    // then the content construct parses `d`.
	    // Most constructs in markdown match on the first line: if the first line
	    // forms a construct, a non-lazy line cant unmake it.
	    //
	    // The construct in the third example is potentially a GFM table, and
	    // those are *weird*.
	    // It *could* be a table, from the first line, if the following line
	    // matches a condition.
	    // In this case, that second line is lazy, which unmakes the first line
	    // and turns the whole into one content block.
	    //
	    // Weve now parsed the non-lazy and the lazy line, and can figure out
	    // whether the lazy line started a new flow block.
	    // If it did, we exit the current containers between the two flow blocks.
	    if (self.parser.lazy[token.start.line]) {
	      let index = childFlow.events.length;
	      while (index--) {
	        if (
	        // The token starts before the line ending
	        childFlow.events[index][1].start.offset < lineStartOffset && (
	        // and either is not ended yet
	        !childFlow.events[index][1].end ||
	        // or ends after it.
	        childFlow.events[index][1].end.offset > lineStartOffset)) {
	          // Exit: theres still something open, which means its a lazy line
	          // part of something.
	          return;
	        }
	      }

	      // Note: this algorithm for moving events around is similar to the
	      // algorithm when closing flow in `documentContinue`.
	      const indexBeforeExits = self.events.length;
	      let indexBeforeFlow = indexBeforeExits;
	      /** @type {boolean | undefined} */
	      let seen;
	      /** @type {Point | undefined} */
	      let point;

	      // Find the previous chunk (the one before the lazy line).
	      while (indexBeforeFlow--) {
	        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === "chunkFlow") {
	          if (seen) {
	            point = self.events[indexBeforeFlow][1].end;
	            break;
	          }
	          seen = true;
	        }
	      }
	      exitContainers(continued);

	      // Fix positions.
	      index = indexBeforeExits;
	      while (index < self.events.length) {
	        self.events[index][1].end = {
	          ...point
	        };
	        index++;
	      }

	      // Inject the exits earlier (theyre still also at the end).
	      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));

	      // Discard the duplicate exits.
	      self.events.length = index;
	    }
	  }

	  /**
	   * @param {number} size
	   *   Size.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function exitContainers(size) {
	    let index = stack.length;

	    // Exit open containers.
	    while (index-- > size) {
	      const entry = stack[index];
	      self.containerState = entry[1];
	      entry[0].exit.call(self, effects);
	    }
	    stack.length = size;
	  }
	  function closeFlow() {
	    childFlow.write([null]);
	    childToken = undefined;
	    childFlow = undefined;
	    self.containerState._closeFlow = undefined;
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 *   Tokenizer.
	 */
	function tokenizeContainer(effects, ok, nok) {
	  // Always populated by defaults.

	  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), "linePrefix", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);
	}

	/**
	 * @import {Code} from 'micromark-util-types'
	 */

	/**
	 * Classify whether a code represents whitespace, punctuation, or something
	 * else.
	 *
	 * Used for attention (emphasis, strong), whose sequences can open or close
	 * based on the class of surrounding characters.
	 *
	 * >  **Note**: eof (`null`) is seen as whitespace.
	 *
	 * @param {Code} code
	 *   Code.
	 * @returns {typeof constants.characterGroupWhitespace | typeof constants.characterGroupPunctuation | undefined}
	 *   Group.
	 */
	function classifyCharacter(code) {
	  if (code === null || markdownLineEndingOrSpace(code) || unicodeWhitespace(code)) {
	    return 1;
	  }
	  if (unicodePunctuation(code)) {
	    return 2;
	  }
	}

	/**
	 * @import {Event, Resolver, TokenizeContext} from 'micromark-util-types'
	 */

	/**
	 * Call all `resolveAll`s.
	 *
	 * @param {ReadonlyArray<{resolveAll?: Resolver | undefined}>} constructs
	 *   List of constructs, optionally with `resolveAll`s.
	 * @param {Array<Event>} events
	 *   List of events.
	 * @param {TokenizeContext} context
	 *   Context used by `tokenize`.
	 * @returns {Array<Event>}
	 *   Changed events.
	 */
	function resolveAll(constructs, events, context) {
	  /** @type {Array<Resolver>} */
	  const called = [];
	  let index = -1;

	  while (++index < constructs.length) {
	    const resolve = constructs[index].resolveAll;

	    if (resolve && !called.includes(resolve)) {
	      events = resolve(events, context);
	      called.push(resolve);
	    }
	  }

	  return events
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   Event,
	 *   Point,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const attention = {
	  name: 'attention',
	  resolveAll: resolveAllAttention,
	  tokenize: tokenizeAttention
	};

	/**
	 * Take all events and resolve attention to emphasis or strong.
	 *
	 * @type {Resolver}
	 */
	// eslint-disable-next-line complexity
	function resolveAllAttention(events, context) {
	  let index = -1;
	  /** @type {number} */
	  let open;
	  /** @type {Token} */
	  let group;
	  /** @type {Token} */
	  let text;
	  /** @type {Token} */
	  let openingSequence;
	  /** @type {Token} */
	  let closingSequence;
	  /** @type {number} */
	  let use;
	  /** @type {Array<Event>} */
	  let nextEvents;
	  /** @type {number} */
	  let offset;

	  // Walk through all events.
	  //
	  // Note: performance of this is fine on an mb of normal markdown, but its
	  // a bottleneck for malicious stuff.
	  while (++index < events.length) {
	    // Find a token that can close.
	    if (events[index][0] === 'enter' && events[index][1].type === 'attentionSequence' && events[index][1]._close) {
	      open = index;

	      // Now walk back to find an opener.
	      while (open--) {
	        // Find a token that can open the closer.
	        if (events[open][0] === 'exit' && events[open][1].type === 'attentionSequence' && events[open][1]._open &&
	        // If the markers are the same:
	        context.sliceSerialize(events[open][1]).charCodeAt(0) === context.sliceSerialize(events[index][1]).charCodeAt(0)) {
	          // If the opening can close or the closing can open,
	          // and the close size *is not* a multiple of three,
	          // but the sum of the opening and closing size *is* multiple of three,
	          // then dont match.
	          if ((events[open][1]._close || events[index][1]._open) && (events[index][1].end.offset - events[index][1].start.offset) % 3 && !((events[open][1].end.offset - events[open][1].start.offset + events[index][1].end.offset - events[index][1].start.offset) % 3)) {
	            continue;
	          }

	          // Number of markers to use from the sequence.
	          use = events[open][1].end.offset - events[open][1].start.offset > 1 && events[index][1].end.offset - events[index][1].start.offset > 1 ? 2 : 1;
	          const start = {
	            ...events[open][1].end
	          };
	          const end = {
	            ...events[index][1].start
	          };
	          movePoint(start, -use);
	          movePoint(end, use);
	          openingSequence = {
	            type: use > 1 ? "strongSequence" : "emphasisSequence",
	            start,
	            end: {
	              ...events[open][1].end
	            }
	          };
	          closingSequence = {
	            type: use > 1 ? "strongSequence" : "emphasisSequence",
	            start: {
	              ...events[index][1].start
	            },
	            end
	          };
	          text = {
	            type: use > 1 ? "strongText" : "emphasisText",
	            start: {
	              ...events[open][1].end
	            },
	            end: {
	              ...events[index][1].start
	            }
	          };
	          group = {
	            type: use > 1 ? "strong" : "emphasis",
	            start: {
	              ...openingSequence.start
	            },
	            end: {
	              ...closingSequence.end
	            }
	          };
	          events[open][1].end = {
	            ...openingSequence.start
	          };
	          events[index][1].start = {
	            ...closingSequence.end
	          };
	          nextEvents = [];

	          // If there are more markers in the opening, add them before.
	          if (events[open][1].end.offset - events[open][1].start.offset) {
	            nextEvents = push(nextEvents, [['enter', events[open][1], context], ['exit', events[open][1], context]]);
	          }

	          // Opening.
	          nextEvents = push(nextEvents, [['enter', group, context], ['enter', openingSequence, context], ['exit', openingSequence, context], ['enter', text, context]]);

	          // Always populated by defaults.

	          // Between.
	          nextEvents = push(nextEvents, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + 1, index), context));

	          // Closing.
	          nextEvents = push(nextEvents, [['exit', text, context], ['enter', closingSequence, context], ['exit', closingSequence, context], ['exit', group, context]]);

	          // If there are more markers in the closing, add them after.
	          if (events[index][1].end.offset - events[index][1].start.offset) {
	            offset = 2;
	            nextEvents = push(nextEvents, [['enter', events[index][1], context], ['exit', events[index][1], context]]);
	          } else {
	            offset = 0;
	          }
	          splice(events, open - 1, index - open + 3, nextEvents);
	          index = open + nextEvents.length - offset - 2;
	          break;
	        }
	      }
	    }
	  }

	  // Remove remaining sequences.
	  index = -1;
	  while (++index < events.length) {
	    if (events[index][1].type === 'attentionSequence') {
	      events[index][1].type = 'data';
	    }
	  }
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeAttention(effects, ok) {
	  const attentionMarkers = this.parser.constructs.attentionMarkers.null;
	  const previous = this.previous;
	  const before = classifyCharacter(previous);

	  /** @type {NonNullable<Code>} */
	  let marker;
	  return start;

	  /**
	   * Before a sequence.
	   *
	   * ```markdown
	   * > | **
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    marker = code;
	    effects.enter('attentionSequence');
	    return inside(code);
	  }

	  /**
	   * In a sequence.
	   *
	   * ```markdown
	   * > | **
	   *     ^^
	   * ```
	   *
	   * @type {State}
	   */
	  function inside(code) {
	    if (code === marker) {
	      effects.consume(code);
	      return inside;
	    }
	    const token = effects.exit('attentionSequence');

	    // To do: next major: move this to resolver, just like `markdown-rs`.
	    const after = classifyCharacter(code);

	    // Always populated by defaults.

	    const open = !after || after === 2 && before || attentionMarkers.includes(code);
	    const close = !before || before === 2 && after || attentionMarkers.includes(previous);
	    token._open = Boolean(marker === 42 ? open : open && (before || !close));
	    token._close = Boolean(marker === 42 ? close : close && (after || !open));
	    return ok(code);
	  }
	}

	/**
	 * Move a point a bit.
	 *
	 * Note: `move` only works inside lines! Its not possible to move past other
	 * chunks (replacement characters, tabs, or line endings).
	 *
	 * @param {Point} point
	 *   Point.
	 * @param {number} offset
	 *   Amount to move.
	 * @returns {undefined}
	 *   Nothing.
	 */
	function movePoint(point, offset) {
	  point.column += offset;
	  point.offset += offset;
	  point._bufferIndex += offset;
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const autolink = {
	  name: 'autolink',
	  tokenize: tokenizeAutolink
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeAutolink(effects, ok, nok) {
	  let size = 0;
	  return start;

	  /**
	   * Start of an autolink.
	   *
	   * ```markdown
	   * > | a<https://example.com>b
	   *      ^
	   * > | a<user@example.com>b
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("autolink");
	    effects.enter("autolinkMarker");
	    effects.consume(code);
	    effects.exit("autolinkMarker");
	    effects.enter("autolinkProtocol");
	    return open;
	  }

	  /**
	   * After `<`, at protocol or atext.
	   *
	   * ```markdown
	   * > | a<https://example.com>b
	   *       ^
	   * > | a<user@example.com>b
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function open(code) {
	    if (asciiAlpha(code)) {
	      effects.consume(code);
	      return schemeOrEmailAtext;
	    }
	    if (code === 64) {
	      return nok(code);
	    }
	    return emailAtext(code);
	  }

	  /**
	   * At second byte of protocol or atext.
	   *
	   * ```markdown
	   * > | a<https://example.com>b
	   *        ^
	   * > | a<user@example.com>b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function schemeOrEmailAtext(code) {
	    // ASCII alphanumeric and `+`, `-`, and `.`.
	    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {
	      // Count the previous alphabetical from `open` too.
	      size = 1;
	      return schemeInsideOrEmailAtext(code);
	    }
	    return emailAtext(code);
	  }

	  /**
	   * In ambiguous protocol or atext.
	   *
	   * ```markdown
	   * > | a<https://example.com>b
	   *        ^
	   * > | a<user@example.com>b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function schemeInsideOrEmailAtext(code) {
	    if (code === 58) {
	      effects.consume(code);
	      size = 0;
	      return urlInside;
	    }

	    // ASCII alphanumeric and `+`, `-`, and `.`.
	    if ((code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) && size++ < 32) {
	      effects.consume(code);
	      return schemeInsideOrEmailAtext;
	    }
	    size = 0;
	    return emailAtext(code);
	  }

	  /**
	   * After protocol, in URL.
	   *
	   * ```markdown
	   * > | a<https://example.com>b
	   *             ^
	   * ```
	   *
	   * @type {State}
	   */
	  function urlInside(code) {
	    if (code === 62) {
	      effects.exit("autolinkProtocol");
	      effects.enter("autolinkMarker");
	      effects.consume(code);
	      effects.exit("autolinkMarker");
	      effects.exit("autolink");
	      return ok;
	    }

	    // ASCII control, space, or `<`.
	    if (code === null || code === 32 || code === 60 || asciiControl(code)) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return urlInside;
	  }

	  /**
	   * In email atext.
	   *
	   * ```markdown
	   * > | a<user.name@example.com>b
	   *              ^
	   * ```
	   *
	   * @type {State}
	   */
	  function emailAtext(code) {
	    if (code === 64) {
	      effects.consume(code);
	      return emailAtSignOrDot;
	    }
	    if (asciiAtext(code)) {
	      effects.consume(code);
	      return emailAtext;
	    }
	    return nok(code);
	  }

	  /**
	   * In label, after at-sign or dot.
	   *
	   * ```markdown
	   * > | a<user.name@example.com>b
	   *                 ^       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function emailAtSignOrDot(code) {
	    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code);
	  }

	  /**
	   * In label, where `.` and `>` are allowed.
	   *
	   * ```markdown
	   * > | a<user.name@example.com>b
	   *                   ^
	   * ```
	   *
	   * @type {State}
	   */
	  function emailLabel(code) {
	    if (code === 46) {
	      effects.consume(code);
	      size = 0;
	      return emailAtSignOrDot;
	    }
	    if (code === 62) {
	      // Exit, then change the token type.
	      effects.exit("autolinkProtocol").type = "autolinkEmail";
	      effects.enter("autolinkMarker");
	      effects.consume(code);
	      effects.exit("autolinkMarker");
	      effects.exit("autolink");
	      return ok;
	    }
	    return emailValue(code);
	  }

	  /**
	   * In label, where `.` and `>` are *not* allowed.
	   *
	   * Though, this is also used in `emailLabel` to parse other values.
	   *
	   * ```markdown
	   * > | a<user.name@ex-ample.com>b
	   *                    ^
	   * ```
	   *
	   * @type {State}
	   */
	  function emailValue(code) {
	    // ASCII alphanumeric or `-`.
	    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {
	      const next = code === 45 ? emailValue : emailLabel;
	      effects.consume(code);
	      return next;
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const blankLine = {
	  partial: true,
	  tokenize: tokenizeBlankLine
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeBlankLine(effects, ok, nok) {
	  return start;

	  /**
	   * Start of blank line.
	   *
	   * >  **Note**: `` represents a space character.
	   *
	   * ```markdown
	   * > | 
	   *     ^
	   * > | 
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    return markdownSpace(code) ? factorySpace(effects, after, "linePrefix")(code) : after(code);
	  }

	  /**
	   * At eof/eol, after optional whitespace.
	   *
	   * >  **Note**: `` represents a space character.
	   *
	   * ```markdown
	   * > | 
	   *       ^
	   * > | 
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   Exiter,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const blockQuote = {
	  continuation: {
	    tokenize: tokenizeBlockQuoteContinuation
	  },
	  exit,
	  name: 'blockQuote',
	  tokenize: tokenizeBlockQuoteStart
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeBlockQuoteStart(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   * Start of block quote.
	   *
	   * ```markdown
	   * > | > a
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    if (code === 62) {
	      const state = self.containerState;
	      if (!state.open) {
	        effects.enter("blockQuote", {
	          _container: true
	        });
	        state.open = true;
	      }
	      effects.enter("blockQuotePrefix");
	      effects.enter("blockQuoteMarker");
	      effects.consume(code);
	      effects.exit("blockQuoteMarker");
	      return after;
	    }
	    return nok(code);
	  }

	  /**
	   * After `>`, before optional whitespace.
	   *
	   * ```markdown
	   * > | > a
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    if (markdownSpace(code)) {
	      effects.enter("blockQuotePrefixWhitespace");
	      effects.consume(code);
	      effects.exit("blockQuotePrefixWhitespace");
	      effects.exit("blockQuotePrefix");
	      return ok;
	    }
	    effects.exit("blockQuotePrefix");
	    return ok(code);
	  }
	}

	/**
	 * Start of block quote continuation.
	 *
	 * ```markdown
	 *   | > a
	 * > | > b
	 *     ^
	 * ```
	 *
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeBlockQuoteContinuation(effects, ok, nok) {
	  const self = this;
	  return contStart;

	  /**
	   * Start of block quote continuation.
	   *
	   * Also used to parse the first block quote opening.
	   *
	   * ```markdown
	   *   | > a
	   * > | > b
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function contStart(code) {
	    if (markdownSpace(code)) {
	      // Always populated by defaults.

	      return factorySpace(effects, contBefore, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);
	    }
	    return contBefore(code);
	  }

	  /**
	   * At `>`, after optional whitespace.
	   *
	   * Also used to parse the first block quote opening.
	   *
	   * ```markdown
	   *   | > a
	   * > | > b
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function contBefore(code) {
	    return effects.attempt(blockQuote, ok, nok)(code);
	  }
	}

	/** @type {Exiter} */
	function exit(effects) {
	  effects.exit("blockQuote");
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const characterEscape = {
	  name: 'characterEscape',
	  tokenize: tokenizeCharacterEscape
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeCharacterEscape(effects, ok, nok) {
	  return start;

	  /**
	   * Start of character escape.
	   *
	   * ```markdown
	   * > | a\*b
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("characterEscape");
	    effects.enter("escapeMarker");
	    effects.consume(code);
	    effects.exit("escapeMarker");
	    return inside;
	  }

	  /**
	   * After `\`, at punctuation.
	   *
	   * ```markdown
	   * > | a\*b
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function inside(code) {
	    // ASCII punctuation.
	    if (asciiPunctuation(code)) {
	      effects.enter("characterEscapeValue");
	      effects.consume(code);
	      effects.exit("characterEscapeValue");
	      effects.exit("characterEscape");
	      return ok;
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const characterReference = {
	  name: 'characterReference',
	  tokenize: tokenizeCharacterReference
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeCharacterReference(effects, ok, nok) {
	  const self = this;
	  let size = 0;
	  /** @type {number} */
	  let max;
	  /** @type {(code: Code) => boolean} */
	  let test;
	  return start;

	  /**
	   * Start of character reference.
	   *
	   * ```markdown
	   * > | a&amp;b
	   *      ^
	   * > | a&#123;b
	   *      ^
	   * > | a&#x9;b
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("characterReference");
	    effects.enter("characterReferenceMarker");
	    effects.consume(code);
	    effects.exit("characterReferenceMarker");
	    return open;
	  }

	  /**
	   * After `&`, at `#` for numeric references or alphanumeric for named
	   * references.
	   *
	   * ```markdown
	   * > | a&amp;b
	   *       ^
	   * > | a&#123;b
	   *       ^
	   * > | a&#x9;b
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function open(code) {
	    if (code === 35) {
	      effects.enter("characterReferenceMarkerNumeric");
	      effects.consume(code);
	      effects.exit("characterReferenceMarkerNumeric");
	      return numeric;
	    }
	    effects.enter("characterReferenceValue");
	    max = 31;
	    test = asciiAlphanumeric;
	    return value(code);
	  }

	  /**
	   * After `#`, at `x` for hexadecimals or digit for decimals.
	   *
	   * ```markdown
	   * > | a&#123;b
	   *        ^
	   * > | a&#x9;b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function numeric(code) {
	    if (code === 88 || code === 120) {
	      effects.enter("characterReferenceMarkerHexadecimal");
	      effects.consume(code);
	      effects.exit("characterReferenceMarkerHexadecimal");
	      effects.enter("characterReferenceValue");
	      max = 6;
	      test = asciiHexDigit;
	      return value;
	    }
	    effects.enter("characterReferenceValue");
	    max = 7;
	    test = asciiDigit;
	    return value(code);
	  }

	  /**
	   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.
	   *
	   * The character reference kind defines what and how many characters are
	   * allowed.
	   *
	   * ```markdown
	   * > | a&amp;b
	   *       ^^^
	   * > | a&#123;b
	   *        ^^^
	   * > | a&#x9;b
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function value(code) {
	    if (code === 59 && size) {
	      const token = effects.exit("characterReferenceValue");
	      if (test === asciiAlphanumeric && !decodeNamedCharacterReference(self.sliceSerialize(token))) {
	        return nok(code);
	      }

	      // To do: `markdown-rs` uses a different name:
	      // `CharacterReferenceMarkerSemi`.
	      effects.enter("characterReferenceMarker");
	      effects.consume(code);
	      effects.exit("characterReferenceMarker");
	      effects.exit("characterReference");
	      return ok;
	    }
	    if (test(code) && size++ < max) {
	      effects.consume(code);
	      return value;
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const nonLazyContinuation = {
	  partial: true,
	  tokenize: tokenizeNonLazyContinuation
	};

	/** @type {Construct} */
	const codeFenced = {
	  concrete: true,
	  name: 'codeFenced',
	  tokenize: tokenizeCodeFenced
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeCodeFenced(effects, ok, nok) {
	  const self = this;
	  /** @type {Construct} */
	  const closeStart = {
	    partial: true,
	    tokenize: tokenizeCloseStart
	  };
	  let initialPrefix = 0;
	  let sizeOpen = 0;
	  /** @type {NonNullable<Code>} */
	  let marker;
	  return start;

	  /**
	   * Start of code.
	   *
	   * ```markdown
	   * > | ~~~js
	   *     ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // To do: parse whitespace like `markdown-rs`.
	    return beforeSequenceOpen(code);
	  }

	  /**
	   * In opening fence, after prefix, at sequence.
	   *
	   * ```markdown
	   * > | ~~~js
	   *     ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function beforeSequenceOpen(code) {
	    const tail = self.events[self.events.length - 1];
	    initialPrefix = tail && tail[1].type === "linePrefix" ? tail[2].sliceSerialize(tail[1], true).length : 0;
	    marker = code;
	    effects.enter("codeFenced");
	    effects.enter("codeFencedFence");
	    effects.enter("codeFencedFenceSequence");
	    return sequenceOpen(code);
	  }

	  /**
	   * In opening fence sequence.
	   *
	   * ```markdown
	   * > | ~~~js
	   *      ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function sequenceOpen(code) {
	    if (code === marker) {
	      sizeOpen++;
	      effects.consume(code);
	      return sequenceOpen;
	    }
	    if (sizeOpen < 3) {
	      return nok(code);
	    }
	    effects.exit("codeFencedFenceSequence");
	    return markdownSpace(code) ? factorySpace(effects, infoBefore, "whitespace")(code) : infoBefore(code);
	  }

	  /**
	   * In opening fence, after the sequence (and optional whitespace), before info.
	   *
	   * ```markdown
	   * > | ~~~js
	   *        ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function infoBefore(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("codeFencedFence");
	      return self.interrupt ? ok(code) : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);
	    }
	    effects.enter("codeFencedFenceInfo");
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return info(code);
	  }

	  /**
	   * In info.
	   *
	   * ```markdown
	   * > | ~~~js
	   *        ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function info(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("chunkString");
	      effects.exit("codeFencedFenceInfo");
	      return infoBefore(code);
	    }
	    if (markdownSpace(code)) {
	      effects.exit("chunkString");
	      effects.exit("codeFencedFenceInfo");
	      return factorySpace(effects, metaBefore, "whitespace")(code);
	    }
	    if (code === 96 && code === marker) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return info;
	  }

	  /**
	   * In opening fence, after info and whitespace, before meta.
	   *
	   * ```markdown
	   * > | ~~~js eval
	   *           ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function metaBefore(code) {
	    if (code === null || markdownLineEnding(code)) {
	      return infoBefore(code);
	    }
	    effects.enter("codeFencedFenceMeta");
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return meta(code);
	  }

	  /**
	   * In meta.
	   *
	   * ```markdown
	   * > | ~~~js eval
	   *           ^
	   *   | alert(1)
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function meta(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("chunkString");
	      effects.exit("codeFencedFenceMeta");
	      return infoBefore(code);
	    }
	    if (code === 96 && code === marker) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return meta;
	  }

	  /**
	   * At eol/eof in code, before a non-lazy closing fence or content.
	   *
	   * ```markdown
	   * > | ~~~js
	   *          ^
	   * > | alert(1)
	   *             ^
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function atNonLazyBreak(code) {
	    return effects.attempt(closeStart, after, contentBefore)(code);
	  }

	  /**
	   * Before code content, not a closing fence, at eol.
	   *
	   * ```markdown
	   *   | ~~~js
	   * > | alert(1)
	   *             ^
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function contentBefore(code) {
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return contentStart;
	  }

	  /**
	   * Before code content, not a closing fence.
	   *
	   * ```markdown
	   *   | ~~~js
	   * > | alert(1)
	   *     ^
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function contentStart(code) {
	    return initialPrefix > 0 && markdownSpace(code) ? factorySpace(effects, beforeContentChunk, "linePrefix", initialPrefix + 1)(code) : beforeContentChunk(code);
	  }

	  /**
	   * Before code content, after optional prefix.
	   *
	   * ```markdown
	   *   | ~~~js
	   * > | alert(1)
	   *     ^
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function beforeContentChunk(code) {
	    if (code === null || markdownLineEnding(code)) {
	      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);
	    }
	    effects.enter("codeFlowValue");
	    return contentChunk(code);
	  }

	  /**
	   * In code content.
	   *
	   * ```markdown
	   *   | ~~~js
	   * > | alert(1)
	   *     ^^^^^^^^
	   *   | ~~~
	   * ```
	   *
	   * @type {State}
	   */
	  function contentChunk(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("codeFlowValue");
	      return beforeContentChunk(code);
	    }
	    effects.consume(code);
	    return contentChunk;
	  }

	  /**
	   * After code.
	   *
	   * ```markdown
	   *   | ~~~js
	   *   | alert(1)
	   * > | ~~~
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    effects.exit("codeFenced");
	    return ok(code);
	  }

	  /**
	   * @this {TokenizeContext}
	   *   Context.
	   * @type {Tokenizer}
	   */
	  function tokenizeCloseStart(effects, ok, nok) {
	    let size = 0;
	    return startBefore;

	    /**
	     *
	     *
	     * @type {State}
	     */
	    function startBefore(code) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return start;
	    }

	    /**
	     * Before closing fence, at optional whitespace.
	     *
	     * ```markdown
	     *   | ~~~js
	     *   | alert(1)
	     * > | ~~~
	     *     ^
	     * ```
	     *
	     * @type {State}
	     */
	    function start(code) {
	      // Always populated by defaults.

	      // To do: `enter` here or in next state?
	      effects.enter("codeFencedFence");
	      return markdownSpace(code) ? factorySpace(effects, beforeSequenceClose, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : beforeSequenceClose(code);
	    }

	    /**
	     * In closing fence, after optional whitespace, at sequence.
	     *
	     * ```markdown
	     *   | ~~~js
	     *   | alert(1)
	     * > | ~~~
	     *     ^
	     * ```
	     *
	     * @type {State}
	     */
	    function beforeSequenceClose(code) {
	      if (code === marker) {
	        effects.enter("codeFencedFenceSequence");
	        return sequenceClose(code);
	      }
	      return nok(code);
	    }

	    /**
	     * In closing fence sequence.
	     *
	     * ```markdown
	     *   | ~~~js
	     *   | alert(1)
	     * > | ~~~
	     *     ^
	     * ```
	     *
	     * @type {State}
	     */
	    function sequenceClose(code) {
	      if (code === marker) {
	        size++;
	        effects.consume(code);
	        return sequenceClose;
	      }
	      if (size >= sizeOpen) {
	        effects.exit("codeFencedFenceSequence");
	        return markdownSpace(code) ? factorySpace(effects, sequenceCloseAfter, "whitespace")(code) : sequenceCloseAfter(code);
	      }
	      return nok(code);
	    }

	    /**
	     * After closing fence sequence, after optional whitespace.
	     *
	     * ```markdown
	     *   | ~~~js
	     *   | alert(1)
	     * > | ~~~
	     *        ^
	     * ```
	     *
	     * @type {State}
	     */
	    function sequenceCloseAfter(code) {
	      if (code === null || markdownLineEnding(code)) {
	        effects.exit("codeFencedFence");
	        return ok(code);
	      }
	      return nok(code);
	    }
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeNonLazyContinuation(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function start(code) {
	    if (code === null) {
	      return nok(code);
	    }
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return lineStart;
	  }

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function lineStart(code) {
	    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const codeIndented = {
	  name: 'codeIndented',
	  tokenize: tokenizeCodeIndented
	};

	/** @type {Construct} */
	const furtherStart = {
	  partial: true,
	  tokenize: tokenizeFurtherStart
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeCodeIndented(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   * Start of code (indented).
	   *
	   * > **Parsing note**: it is not needed to check if this first line is a
	   * > filled line (that it has a non-whitespace character), because blank lines
	   * > are parsed already, so we never run into that.
	   *
	   * ```markdown
	   * > |     aaa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // To do: manually check if interrupting like `markdown-rs`.

	    effects.enter("codeIndented");
	    // To do: use an improved `space_or_tab` function like `markdown-rs`,
	    // so that we can drop the next state.
	    return factorySpace(effects, afterPrefix, "linePrefix", 4 + 1)(code);
	  }

	  /**
	   * At start, after 1 or 4 spaces.
	   *
	   * ```markdown
	   * > |     aaa
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function afterPrefix(code) {
	    const tail = self.events[self.events.length - 1];
	    return tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? atBreak(code) : nok(code);
	  }

	  /**
	   * At a break.
	   *
	   * ```markdown
	   * > |     aaa
	   *         ^  ^
	   * ```
	   *
	   * @type {State}
	   */
	  function atBreak(code) {
	    if (code === null) {
	      return after(code);
	    }
	    if (markdownLineEnding(code)) {
	      return effects.attempt(furtherStart, atBreak, after)(code);
	    }
	    effects.enter("codeFlowValue");
	    return inside(code);
	  }

	  /**
	   * In code content.
	   *
	   * ```markdown
	   * > |     aaa
	   *         ^^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function inside(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("codeFlowValue");
	      return atBreak(code);
	    }
	    effects.consume(code);
	    return inside;
	  }

	  /** @type {State} */
	  function after(code) {
	    effects.exit("codeIndented");
	    // To do: allow interrupting like `markdown-rs`.
	    // Feel free to interrupt.
	    // tokenizer.interrupt = false
	    return ok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeFurtherStart(effects, ok, nok) {
	  const self = this;
	  return furtherStart;

	  /**
	   * At eol, trying to parse another indent.
	   *
	   * ```markdown
	   * > |     aaa
	   *            ^
	   *   |     bbb
	   * ```
	   *
	   * @type {State}
	   */
	  function furtherStart(code) {
	    // To do: improve `lazy` / `pierce` handling.
	    // If this is a lazy line, it cant be code.
	    if (self.parser.lazy[self.now().line]) {
	      return nok(code);
	    }
	    if (markdownLineEnding(code)) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return furtherStart;
	    }

	    // To do: the code here in `micromark-js` is a bit different from
	    // `markdown-rs` because there it can attempt spaces.
	    // We cant yet.
	    //
	    // To do: use an improved `space_or_tab` function like `markdown-rs`,
	    // so that we can drop the next state.
	    return factorySpace(effects, afterPrefix, "linePrefix", 4 + 1)(code);
	  }

	  /**
	   * At start, after 1 or 4 spaces.
	   *
	   * ```markdown
	   * > |     aaa
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function afterPrefix(code) {
	    const tail = self.events[self.events.length - 1];
	    return tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? ok(code) : markdownLineEnding(code) ? furtherStart(code) : nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   Previous,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const codeText = {
	  name: 'codeText',
	  previous,
	  resolve: resolveCodeText,
	  tokenize: tokenizeCodeText
	};

	// To do: next major: dont resolve, like `markdown-rs`.
	/** @type {Resolver} */
	function resolveCodeText(events) {
	  let tailExitIndex = events.length - 4;
	  let headEnterIndex = 3;
	  /** @type {number} */
	  let index;
	  /** @type {number | undefined} */
	  let enter;

	  // If we start and end with an EOL or a space.
	  if ((events[headEnterIndex][1].type === "lineEnding" || events[headEnterIndex][1].type === 'space') && (events[tailExitIndex][1].type === "lineEnding" || events[tailExitIndex][1].type === 'space')) {
	    index = headEnterIndex;

	    // And we have data.
	    while (++index < tailExitIndex) {
	      if (events[index][1].type === "codeTextData") {
	        // Then we have padding.
	        events[headEnterIndex][1].type = "codeTextPadding";
	        events[tailExitIndex][1].type = "codeTextPadding";
	        headEnterIndex += 2;
	        tailExitIndex -= 2;
	        break;
	      }
	    }
	  }

	  // Merge adjacent spaces and data.
	  index = headEnterIndex - 1;
	  tailExitIndex++;
	  while (++index <= tailExitIndex) {
	    if (enter === undefined) {
	      if (index !== tailExitIndex && events[index][1].type !== "lineEnding") {
	        enter = index;
	      }
	    } else if (index === tailExitIndex || events[index][1].type === "lineEnding") {
	      events[enter][1].type = "codeTextData";
	      if (index !== enter + 2) {
	        events[enter][1].end = events[index - 1][1].end;
	        events.splice(enter + 2, index - enter - 2);
	        tailExitIndex -= index - enter - 2;
	        index = enter + 2;
	      }
	      enter = undefined;
	    }
	  }
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Previous}
	 */
	function previous(code) {
	  // If there is a previous code, there will always be a tail.
	  return code !== 96 || this.events[this.events.length - 1][1].type === "characterEscape";
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeCodeText(effects, ok, nok) {
	  let sizeOpen = 0;
	  /** @type {number} */
	  let size;
	  /** @type {Token} */
	  let token;
	  return start;

	  /**
	   * Start of code (text).
	   *
	   * ```markdown
	   * > | `a`
	   *     ^
	   * > | \`a`
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("codeText");
	    effects.enter("codeTextSequence");
	    return sequenceOpen(code);
	  }

	  /**
	   * In opening sequence.
	   *
	   * ```markdown
	   * > | `a`
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function sequenceOpen(code) {
	    if (code === 96) {
	      effects.consume(code);
	      sizeOpen++;
	      return sequenceOpen;
	    }
	    effects.exit("codeTextSequence");
	    return between(code);
	  }

	  /**
	   * Between something and something else.
	   *
	   * ```markdown
	   * > | `a`
	   *      ^^
	   * ```
	   *
	   * @type {State}
	   */
	  function between(code) {
	    // EOF.
	    if (code === null) {
	      return nok(code);
	    }

	    // To do: next major: dont do spaces in resolve, but when compiling,
	    // like `markdown-rs`.
	    // Tabs dont work, and virtual spaces dont make sense.
	    if (code === 32) {
	      effects.enter('space');
	      effects.consume(code);
	      effects.exit('space');
	      return between;
	    }

	    // Closing fence? Could also be data.
	    if (code === 96) {
	      token = effects.enter("codeTextSequence");
	      size = 0;
	      return sequenceClose(code);
	    }
	    if (markdownLineEnding(code)) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return between;
	    }

	    // Data.
	    effects.enter("codeTextData");
	    return data(code);
	  }

	  /**
	   * In data.
	   *
	   * ```markdown
	   * > | `a`
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function data(code) {
	    if (code === null || code === 32 || code === 96 || markdownLineEnding(code)) {
	      effects.exit("codeTextData");
	      return between(code);
	    }
	    effects.consume(code);
	    return data;
	  }

	  /**
	   * In closing sequence.
	   *
	   * ```markdown
	   * > | `a`
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function sequenceClose(code) {
	    // More.
	    if (code === 96) {
	      effects.consume(code);
	      size++;
	      return sequenceClose;
	    }

	    // Done!
	    if (size === sizeOpen) {
	      effects.exit("codeTextSequence");
	      effects.exit("codeText");
	      return ok(code);
	    }

	    // More or less accents: mark as data.
	    token.type = "codeTextData";
	    return data(code);
	  }
	}

	/**
	 * Some of the internal operations of micromark do lots of editing
	 * operations on very large arrays. This runs into problems with two
	 * properties of most circa-2020 JavaScript interpreters:
	 *
	 *  - Array-length modifications at the high end of an array (push/pop) are
	 *    expected to be common and are implemented in (amortized) time
	 *    proportional to the number of elements added or removed, whereas
	 *    other operations (shift/unshift and splice) are much less efficient.
	 *  - Function arguments are passed on the stack, so adding tens of thousands
	 *    of elements to an array with `arr.push(...newElements)` will frequently
	 *    cause stack overflows. (see <https://stackoverflow.com/questions/22123769/rangeerror-maximum-call-stack-size-exceeded-why>)
	 *
	 * SpliceBuffers are an implementation of gap buffers, which are a
	 * generalization of the "queue made of two stacks" idea. The splice buffer
	 * maintains a cursor, and moving the cursor has cost proportional to the
	 * distance the cursor moves, but inserting, deleting, or splicing in
	 * new information at the cursor is as efficient as the push/pop operation.
	 * This allows for an efficient sequence of splices (or pushes, pops, shifts,
	 * or unshifts) as long such edits happen at the same part of the array or
	 * generally sweep through the array from the beginning to the end.
	 *
	 * The interface for splice buffers also supports large numbers of inputs by
	 * passing a single array argument rather passing multiple arguments on the
	 * function call stack.
	 *
	 * @template T
	 *   Item type.
	 */
	class SpliceBuffer {
	  /**
	   * @param {ReadonlyArray<T> | null | undefined} [initial]
	   *   Initial items (optional).
	   * @returns
	   *   Splice buffer.
	   */
	  constructor(initial) {
	    /** @type {Array<T>} */
	    this.left = initial ? [...initial] : [];
	    /** @type {Array<T>} */
	    this.right = [];
	  }

	  /**
	   * Array access;
	   * does not move the cursor.
	   *
	   * @param {number} index
	   *   Index.
	   * @return {T}
	   *   Item.
	   */
	  get(index) {
	    if (index < 0 || index >= this.left.length + this.right.length) {
	      throw new RangeError('Cannot access index `' + index + '` in a splice buffer of size `' + (this.left.length + this.right.length) + '`');
	    }
	    if (index < this.left.length) return this.left[index];
	    return this.right[this.right.length - index + this.left.length - 1];
	  }

	  /**
	   * The length of the splice buffer, one greater than the largest index in the
	   * array.
	   */
	  get length() {
	    return this.left.length + this.right.length;
	  }

	  /**
	   * Remove and return `list[0]`;
	   * moves the cursor to `0`.
	   *
	   * @returns {T | undefined}
	   *   Item, optional.
	   */
	  shift() {
	    this.setCursor(0);
	    return this.right.pop();
	  }

	  /**
	   * Slice the buffer to get an array;
	   * does not move the cursor.
	   *
	   * @param {number} start
	   *   Start.
	   * @param {number | null | undefined} [end]
	   *   End (optional).
	   * @returns {Array<T>}
	   *   Array of items.
	   */
	  slice(start, end) {
	    /** @type {number} */
	    const stop = end === null || end === undefined ? Number.POSITIVE_INFINITY : end;
	    if (stop < this.left.length) {
	      return this.left.slice(start, stop);
	    }
	    if (start > this.left.length) {
	      return this.right.slice(this.right.length - stop + this.left.length, this.right.length - start + this.left.length).reverse();
	    }
	    return this.left.slice(start).concat(this.right.slice(this.right.length - stop + this.left.length).reverse());
	  }

	  /**
	   * Mimics the behavior of Array.prototype.splice() except for the change of
	   * interface necessary to avoid segfaults when patching in very large arrays.
	   *
	   * This operation moves cursor is moved to `start` and results in the cursor
	   * placed after any inserted items.
	   *
	   * @param {number} start
	   *   Start;
	   *   zero-based index at which to start changing the array;
	   *   negative numbers count backwards from the end of the array and values
	   *   that are out-of bounds are clamped to the appropriate end of the array.
	   * @param {number | null | undefined} [deleteCount=0]
	   *   Delete count (default: `0`);
	   *   maximum number of elements to delete, starting from start.
	   * @param {Array<T> | null | undefined} [items=[]]
	   *   Items to include in place of the deleted items (default: `[]`).
	   * @return {Array<T>}
	   *   Any removed items.
	   */
	  splice(start, deleteCount, items) {
	    /** @type {number} */
	    const count = deleteCount || 0;
	    this.setCursor(Math.trunc(start));
	    const removed = this.right.splice(this.right.length - count, Number.POSITIVE_INFINITY);
	    if (items) chunkedPush(this.left, items);
	    return removed.reverse();
	  }

	  /**
	   * Remove and return the highest-numbered item in the array, so
	   * `list[list.length - 1]`;
	   * Moves the cursor to `length`.
	   *
	   * @returns {T | undefined}
	   *   Item, optional.
	   */
	  pop() {
	    this.setCursor(Number.POSITIVE_INFINITY);
	    return this.left.pop();
	  }

	  /**
	   * Inserts a single item to the high-numbered side of the array;
	   * moves the cursor to `length`.
	   *
	   * @param {T} item
	   *   Item.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  push(item) {
	    this.setCursor(Number.POSITIVE_INFINITY);
	    this.left.push(item);
	  }

	  /**
	   * Inserts many items to the high-numbered side of the array.
	   * Moves the cursor to `length`.
	   *
	   * @param {Array<T>} items
	   *   Items.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  pushMany(items) {
	    this.setCursor(Number.POSITIVE_INFINITY);
	    chunkedPush(this.left, items);
	  }

	  /**
	   * Inserts a single item to the low-numbered side of the array;
	   * Moves the cursor to `0`.
	   *
	   * @param {T} item
	   *   Item.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  unshift(item) {
	    this.setCursor(0);
	    this.right.push(item);
	  }

	  /**
	   * Inserts many items to the low-numbered side of the array;
	   * moves the cursor to `0`.
	   *
	   * @param {Array<T>} items
	   *   Items.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  unshiftMany(items) {
	    this.setCursor(0);
	    chunkedPush(this.right, items.reverse());
	  }

	  /**
	   * Move the cursor to a specific position in the array. Requires
	   * time proportional to the distance moved.
	   *
	   * If `n < 0`, the cursor will end up at the beginning.
	   * If `n > length`, the cursor will end up at the end.
	   *
	   * @param {number} n
	   *   Position.
	   * @return {undefined}
	   *   Nothing.
	   */
	  setCursor(n) {
	    if (n === this.left.length || n > this.left.length && this.right.length === 0 || n < 0 && this.left.length === 0) return;
	    if (n < this.left.length) {
	      // Move cursor to the this.left
	      const removed = this.left.splice(n, Number.POSITIVE_INFINITY);
	      chunkedPush(this.right, removed.reverse());
	    } else {
	      // Move cursor to the this.right
	      const removed = this.right.splice(this.left.length + this.right.length - n, Number.POSITIVE_INFINITY);
	      chunkedPush(this.left, removed.reverse());
	    }
	  }
	}

	/**
	 * Avoid stack overflow by pushing items onto the stack in segments
	 *
	 * @template T
	 *   Item type.
	 * @param {Array<T>} list
	 *   List to inject into.
	 * @param {ReadonlyArray<T>} right
	 *   Items to inject.
	 * @return {undefined}
	 *   Nothing.
	 */
	function chunkedPush(list, right) {
	  /** @type {number} */
	  let chunkStart = 0;
	  if (right.length < 10000) {
	    list.push(...right);
	  } else {
	    while (chunkStart < right.length) {
	      list.push(...right.slice(chunkStart, chunkStart + 10000));
	      chunkStart += 10000;
	    }
	  }
	}

	/**
	 * @import {Chunk, Event, Token} from 'micromark-util-types'
	 */


	/**
	 * Tokenize subcontent.
	 *
	 * @param {Array<Event>} eventsArray
	 *   List of events.
	 * @returns {boolean}
	 *   Whether subtokens were found.
	 */
	// eslint-disable-next-line complexity
	function subtokenize(eventsArray) {
	  /** @type {Record<string, number>} */
	  const jumps = {};
	  let index = -1;
	  /** @type {Event} */
	  let event;
	  /** @type {number | undefined} */
	  let lineIndex;
	  /** @type {number} */
	  let otherIndex;
	  /** @type {Event} */
	  let otherEvent;
	  /** @type {Array<Event>} */
	  let parameters;
	  /** @type {Array<Event>} */
	  let subevents;
	  /** @type {boolean | undefined} */
	  let more;
	  const events = new SpliceBuffer(eventsArray);
	  while (++index < events.length) {
	    while (index in jumps) {
	      index = jumps[index];
	    }
	    event = events.get(index);

	    // Add a hook for the GFM tasklist extension, which needs to know if text
	    // is in the first content of a list item.
	    if (index && event[1].type === "chunkFlow" && events.get(index - 1)[1].type === "listItemPrefix") {
	      subevents = event[1]._tokenizer.events;
	      otherIndex = 0;
	      if (otherIndex < subevents.length && subevents[otherIndex][1].type === "lineEndingBlank") {
	        otherIndex += 2;
	      }
	      if (otherIndex < subevents.length && subevents[otherIndex][1].type === "content") {
	        while (++otherIndex < subevents.length) {
	          if (subevents[otherIndex][1].type === "content") {
	            break;
	          }
	          if (subevents[otherIndex][1].type === "chunkText") {
	            subevents[otherIndex][1]._isInFirstContentOfListItem = true;
	            otherIndex++;
	          }
	        }
	      }
	    }

	    // Enter.
	    if (event[0] === 'enter') {
	      if (event[1].contentType) {
	        Object.assign(jumps, subcontent(events, index));
	        index = jumps[index];
	        more = true;
	      }
	    }
	    // Exit.
	    else if (event[1]._container) {
	      otherIndex = index;
	      lineIndex = undefined;
	      while (otherIndex--) {
	        otherEvent = events.get(otherIndex);
	        if (otherEvent[1].type === "lineEnding" || otherEvent[1].type === "lineEndingBlank") {
	          if (otherEvent[0] === 'enter') {
	            if (lineIndex) {
	              events.get(lineIndex)[1].type = "lineEndingBlank";
	            }
	            otherEvent[1].type = "lineEnding";
	            lineIndex = otherIndex;
	          }
	        } else if (otherEvent[1].type === "linePrefix" || otherEvent[1].type === "listItemIndent") ; else {
	          break;
	        }
	      }
	      if (lineIndex) {
	        // Fix position.
	        event[1].end = {
	          ...events.get(lineIndex)[1].start
	        };

	        // Switch container exit w/ line endings.
	        parameters = events.slice(lineIndex, index);
	        parameters.unshift(event);
	        events.splice(lineIndex, index - lineIndex + 1, parameters);
	      }
	    }
	  }

	  // The changes to the `events` buffer must be copied back into the eventsArray
	  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0));
	  return !more;
	}

	/**
	 * Tokenize embedded tokens.
	 *
	 * @param {SpliceBuffer<Event>} events
	 *   Events.
	 * @param {number} eventIndex
	 *   Index.
	 * @returns {Record<string, number>}
	 *   Gaps.
	 */
	function subcontent(events, eventIndex) {
	  const token = events.get(eventIndex)[1];
	  const context = events.get(eventIndex)[2];
	  let startPosition = eventIndex - 1;
	  /** @type {Array<number>} */
	  const startPositions = [];
	  let tokenizer = token._tokenizer;
	  if (!tokenizer) {
	    tokenizer = context.parser[token.contentType](token.start);
	    if (token._contentTypeTextTrailing) {
	      tokenizer._contentTypeTextTrailing = true;
	    }
	  }
	  const childEvents = tokenizer.events;
	  /** @type {Array<[number, number]>} */
	  const jumps = [];
	  /** @type {Record<string, number>} */
	  const gaps = {};
	  /** @type {Array<Chunk>} */
	  let stream;
	  /** @type {Token | undefined} */
	  let previous;
	  let index = -1;
	  /** @type {Token | undefined} */
	  let current = token;
	  let adjust = 0;
	  let start = 0;
	  const breaks = [start];

	  // Loop forward through the linked tokens to pass them in order to the
	  // subtokenizer.
	  while (current) {
	    // Find the position of the event for this token.
	    while (events.get(++startPosition)[1] !== current) {
	      // Empty.
	    }
	    startPositions.push(startPosition);
	    if (!current._tokenizer) {
	      stream = context.sliceStream(current);
	      if (!current.next) {
	        stream.push(null);
	      }
	      if (previous) {
	        tokenizer.defineSkip(current.start);
	      }
	      if (current._isInFirstContentOfListItem) {
	        tokenizer._gfmTasklistFirstContentOfListItem = true;
	      }
	      tokenizer.write(stream);
	      if (current._isInFirstContentOfListItem) {
	        tokenizer._gfmTasklistFirstContentOfListItem = undefined;
	      }
	    }

	    // Unravel the next token.
	    previous = current;
	    current = current.next;
	  }

	  // Now, loop back through all events (and linked tokens), to figure out which
	  // parts belong where.
	  current = token;
	  while (++index < childEvents.length) {
	    if (
	    // Find a void token that includes a break.
	    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {
	      start = index + 1;
	      breaks.push(start);
	      // Help GC.
	      current._tokenizer = undefined;
	      current.previous = undefined;
	      current = current.next;
	    }
	  }

	  // Help GC.
	  tokenizer.events = [];

	  // If theres one more token (which is the cases for lines that end in an
	  // EOF), thats perfect: the last point we found starts it.
	  // If there isnt then make sure any remaining content is added to it.
	  if (current) {
	    // Help GC.
	    current._tokenizer = undefined;
	    current.previous = undefined;
	  } else {
	    breaks.pop();
	  }

	  // Now splice the events from the subtokenizer into the current events,
	  // moving back to front so that splice indices arent affected.
	  index = breaks.length;
	  while (index--) {
	    const slice = childEvents.slice(breaks[index], breaks[index + 1]);
	    const start = startPositions.pop();
	    jumps.push([start, start + slice.length - 1]);
	    events.splice(start, 2, slice);
	  }
	  jumps.reverse();
	  index = -1;
	  while (++index < jumps.length) {
	    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];
	    adjust += jumps[index][1] - jumps[index][0] - 1;
	  }
	  return gaps;
	}

	/**
	 * @import {
	 *   Construct,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/**
	 * No name because it must not be turned off.
	 * @type {Construct}
	 */
	const content = {
	  resolve: resolveContent,
	  tokenize: tokenizeContent
	};

	/** @type {Construct} */
	const continuationConstruct = {
	  partial: true,
	  tokenize: tokenizeContinuation
	};

	/**
	 * Content is transparent: its parsed right now. That way, definitions are also
	 * parsed right now: before text in paragraphs (specifically, media) are parsed.
	 *
	 * @type {Resolver}
	 */
	function resolveContent(events) {
	  subtokenize(events);
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeContent(effects, ok) {
	  /** @type {Token | undefined} */
	  let previous;
	  return chunkStart;

	  /**
	   * Before a content chunk.
	   *
	   * ```markdown
	   * > | abc
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function chunkStart(code) {
	    effects.enter("content");
	    previous = effects.enter("chunkContent", {
	      contentType: "content"
	    });
	    return chunkInside(code);
	  }

	  /**
	   * In a content chunk.
	   *
	   * ```markdown
	   * > | abc
	   *     ^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function chunkInside(code) {
	    if (code === null) {
	      return contentEnd(code);
	    }

	    // To do: in `markdown-rs`, each line is parsed on its own, and everything
	    // is stitched together resolving.
	    if (markdownLineEnding(code)) {
	      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);
	    }

	    // Data.
	    effects.consume(code);
	    return chunkInside;
	  }

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function contentEnd(code) {
	    effects.exit("chunkContent");
	    effects.exit("content");
	    return ok(code);
	  }

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function contentContinue(code) {
	    effects.consume(code);
	    effects.exit("chunkContent");
	    previous.next = effects.enter("chunkContent", {
	      contentType: "content",
	      previous
	    });
	    previous = previous.next;
	    return chunkInside;
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeContinuation(effects, ok, nok) {
	  const self = this;
	  return startLookahead;

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function startLookahead(code) {
	    effects.exit("chunkContent");
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return factorySpace(effects, prefixed, "linePrefix");
	  }

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function prefixed(code) {
	    if (code === null || markdownLineEnding(code)) {
	      return nok(code);
	    }

	    // Always populated by defaults.

	    const tail = self.events[self.events.length - 1];
	    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4) {
	      return ok(code);
	    }
	    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);
	  }
	}

	/**
	 * @import {Effects, State, TokenType} from 'micromark-util-types'
	 */

	/**
	 * Parse destinations.
	 *
	 * ###### Examples
	 *
	 * ```markdown
	 * <a>
	 * <a\>b>
	 * <a b>
	 * <a)>
	 * a
	 * a\)b
	 * a(b)c
	 * a(b)
	 * ```
	 *
	 * @param {Effects} effects
	 *   Context.
	 * @param {State} ok
	 *   State switched to when successful.
	 * @param {State} nok
	 *   State switched to when unsuccessful.
	 * @param {TokenType} type
	 *   Type for whole (`<a>` or `b`).
	 * @param {TokenType} literalType
	 *   Type when enclosed (`<a>`).
	 * @param {TokenType} literalMarkerType
	 *   Type for enclosing (`<` and `>`).
	 * @param {TokenType} rawType
	 *   Type when not enclosed (`b`).
	 * @param {TokenType} stringType
	 *   Type for the value (`a` or `b`).
	 * @param {number | undefined} [max=Infinity]
	 *   Depth of nested parens (inclusive).
	 * @returns {State}
	 *   Start state.
	 */
	function factoryDestination(effects, ok, nok, type, literalType, literalMarkerType, rawType, stringType, max) {
	  const limit = max || Number.POSITIVE_INFINITY;
	  let balance = 0;
	  return start;

	  /**
	   * Start of destination.
	   *
	   * ```markdown
	   * > | <aa>
	   *     ^
	   * > | aa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    if (code === 60) {
	      effects.enter(type);
	      effects.enter(literalType);
	      effects.enter(literalMarkerType);
	      effects.consume(code);
	      effects.exit(literalMarkerType);
	      return enclosedBefore;
	    }

	    // ASCII control, space, closing paren.
	    if (code === null || code === 32 || code === 41 || asciiControl(code)) {
	      return nok(code);
	    }
	    effects.enter(type);
	    effects.enter(rawType);
	    effects.enter(stringType);
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return raw(code);
	  }

	  /**
	   * After `<`, at an enclosed destination.
	   *
	   * ```markdown
	   * > | <aa>
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function enclosedBefore(code) {
	    if (code === 62) {
	      effects.enter(literalMarkerType);
	      effects.consume(code);
	      effects.exit(literalMarkerType);
	      effects.exit(literalType);
	      effects.exit(type);
	      return ok;
	    }
	    effects.enter(stringType);
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return enclosed(code);
	  }

	  /**
	   * In enclosed destination.
	   *
	   * ```markdown
	   * > | <aa>
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function enclosed(code) {
	    if (code === 62) {
	      effects.exit("chunkString");
	      effects.exit(stringType);
	      return enclosedBefore(code);
	    }
	    if (code === null || code === 60 || markdownLineEnding(code)) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return code === 92 ? enclosedEscape : enclosed;
	  }

	  /**
	   * After `\`, at a special character.
	   *
	   * ```markdown
	   * > | <a\*a>
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function enclosedEscape(code) {
	    if (code === 60 || code === 62 || code === 92) {
	      effects.consume(code);
	      return enclosed;
	    }
	    return enclosed(code);
	  }

	  /**
	   * In raw destination.
	   *
	   * ```markdown
	   * > | aa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function raw(code) {
	    if (!balance && (code === null || code === 41 || markdownLineEndingOrSpace(code))) {
	      effects.exit("chunkString");
	      effects.exit(stringType);
	      effects.exit(rawType);
	      effects.exit(type);
	      return ok(code);
	    }
	    if (balance < limit && code === 40) {
	      effects.consume(code);
	      balance++;
	      return raw;
	    }
	    if (code === 41) {
	      effects.consume(code);
	      balance--;
	      return raw;
	    }

	    // ASCII control (but *not* `\0`) and space and `(`.
	    // Note: in `markdown-rs`, `\0` exists in codes, in `micromark-js` it
	    // doesnt.
	    if (code === null || code === 32 || code === 40 || asciiControl(code)) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return code === 92 ? rawEscape : raw;
	  }

	  /**
	   * After `\`, at special character.
	   *
	   * ```markdown
	   * > | a\*a
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function rawEscape(code) {
	    if (code === 40 || code === 41 || code === 92) {
	      effects.consume(code);
	      return raw;
	    }
	    return raw(code);
	  }
	}

	/**
	 * @import {
	 *   Effects,
	 *   State,
	 *   TokenizeContext,
	 *   TokenType
	 * } from 'micromark-util-types'
	 */

	/**
	 * Parse labels.
	 *
	 * >  **Note**: labels in markdown are capped at 999 characters in the string.
	 *
	 * ###### Examples
	 *
	 * ```markdown
	 * [a]
	 * [a
	 * b]
	 * [a\]b]
	 * ```
	 *
	 * @this {TokenizeContext}
	 *   Tokenize context.
	 * @param {Effects} effects
	 *   Context.
	 * @param {State} ok
	 *   State switched to when successful.
	 * @param {State} nok
	 *   State switched to when unsuccessful.
	 * @param {TokenType} type
	 *   Type of the whole label (`[a]`).
	 * @param {TokenType} markerType
	 *   Type for the markers (`[` and `]`).
	 * @param {TokenType} stringType
	 *   Type for the identifier (`a`).
	 * @returns {State}
	 *   Start state.
	 */
	function factoryLabel(effects, ok, nok, type, markerType, stringType) {
	  const self = this;
	  let size = 0;
	  /** @type {boolean} */
	  let seen;
	  return start;

	  /**
	   * Start of label.
	   *
	   * ```markdown
	   * > | [a]
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter(type);
	    effects.enter(markerType);
	    effects.consume(code);
	    effects.exit(markerType);
	    effects.enter(stringType);
	    return atBreak;
	  }

	  /**
	   * In label, at something, before something else.
	   *
	   * ```markdown
	   * > | [a]
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function atBreak(code) {
	    if (size > 999 || code === null || code === 91 || code === 93 && !seen ||
	    // To do: remove in the future once weve switched from
	    // `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
	    // which doesnt need this.
	    // Hidden footnotes hook.
	    /* c8 ignore next 3 */
	    code === 94 && !size && '_hiddenFootnoteSupport' in self.parser.constructs) {
	      return nok(code);
	    }
	    if (code === 93) {
	      effects.exit(stringType);
	      effects.enter(markerType);
	      effects.consume(code);
	      effects.exit(markerType);
	      effects.exit(type);
	      return ok;
	    }

	    // To do: indent? Link chunks and EOLs together?
	    if (markdownLineEnding(code)) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return atBreak;
	    }
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return labelInside(code);
	  }

	  /**
	   * In label, in text.
	   *
	   * ```markdown
	   * > | [a]
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function labelInside(code) {
	    if (code === null || code === 91 || code === 93 || markdownLineEnding(code) || size++ > 999) {
	      effects.exit("chunkString");
	      return atBreak(code);
	    }
	    effects.consume(code);
	    if (!seen) seen = !markdownSpace(code);
	    return code === 92 ? labelEscape : labelInside;
	  }

	  /**
	   * After `\`, at a special character.
	   *
	   * ```markdown
	   * > | [a\*a]
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function labelEscape(code) {
	    if (code === 91 || code === 92 || code === 93) {
	      effects.consume(code);
	      size++;
	      return labelInside;
	    }
	    return labelInside(code);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Effects,
	 *   State,
	 *   TokenType
	 * } from 'micromark-util-types'
	 */

	/**
	 * Parse titles.
	 *
	 * ###### Examples
	 *
	 * ```markdown
	 * "a"
	 * 'b'
	 * (c)
	 * "a
	 * b"
	 * 'a
	 *     b'
	 * (a\)b)
	 * ```
	 *
	 * @param {Effects} effects
	 *   Context.
	 * @param {State} ok
	 *   State switched to when successful.
	 * @param {State} nok
	 *   State switched to when unsuccessful.
	 * @param {TokenType} type
	 *   Type of the whole title (`"a"`, `'b'`, `(c)`).
	 * @param {TokenType} markerType
	 *   Type for the markers (`"`, `'`, `(`, and `)`).
	 * @param {TokenType} stringType
	 *   Type for the value (`a`).
	 * @returns {State}
	 *   Start state.
	 */
	function factoryTitle(effects, ok, nok, type, markerType, stringType) {
	  /** @type {NonNullable<Code>} */
	  let marker;
	  return start;

	  /**
	   * Start of title.
	   *
	   * ```markdown
	   * > | "a"
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    if (code === 34 || code === 39 || code === 40) {
	      effects.enter(type);
	      effects.enter(markerType);
	      effects.consume(code);
	      effects.exit(markerType);
	      marker = code === 40 ? 41 : code;
	      return begin;
	    }
	    return nok(code);
	  }

	  /**
	   * After opening marker.
	   *
	   * This is also used at the closing marker.
	   *
	   * ```markdown
	   * > | "a"
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function begin(code) {
	    if (code === marker) {
	      effects.enter(markerType);
	      effects.consume(code);
	      effects.exit(markerType);
	      effects.exit(type);
	      return ok;
	    }
	    effects.enter(stringType);
	    return atBreak(code);
	  }

	  /**
	   * At something, before something else.
	   *
	   * ```markdown
	   * > | "a"
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function atBreak(code) {
	    if (code === marker) {
	      effects.exit(stringType);
	      return begin(marker);
	    }
	    if (code === null) {
	      return nok(code);
	    }

	    // Note: blank lines cant exist in content.
	    if (markdownLineEnding(code)) {
	      // To do: use `space_or_tab_eol_with_options`, connect.
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return factorySpace(effects, atBreak, "linePrefix");
	    }
	    effects.enter("chunkString", {
	      contentType: "string"
	    });
	    return inside(code);
	  }

	  /**
	   *
	   *
	   * @type {State}
	   */
	  function inside(code) {
	    if (code === marker || code === null || markdownLineEnding(code)) {
	      effects.exit("chunkString");
	      return atBreak(code);
	    }
	    effects.consume(code);
	    return code === 92 ? escape : inside;
	  }

	  /**
	   * After `\`, at a special character.
	   *
	   * ```markdown
	   * > | "a\*b"
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function escape(code) {
	    if (code === marker || code === 92) {
	      effects.consume(code);
	      return inside;
	    }
	    return inside(code);
	  }
	}

	/**
	 * @import {Effects, State} from 'micromark-util-types'
	 */

	/**
	 * Parse spaces and tabs.
	 *
	 * There is no `nok` parameter:
	 *
	 * *   line endings or spaces in markdown are often optional, in which case this
	 *     factory can be used and `ok` will be switched to whether spaces were found
	 *     or not
	 * *   one line ending or space can be detected with
	 *     `markdownLineEndingOrSpace(code)` right before using `factoryWhitespace`
	 *
	 * @param {Effects} effects
	 *   Context.
	 * @param {State} ok
	 *   State switched to when successful.
	 * @returns {State}
	 *   Start state.
	 */
	function factoryWhitespace(effects, ok) {
	  /** @type {boolean} */
	  let seen;
	  return start;

	  /** @type {State} */
	  function start(code) {
	    if (markdownLineEnding(code)) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      seen = true;
	      return start;
	    }
	    if (markdownSpace(code)) {
	      return factorySpace(effects, start, seen ? "linePrefix" : "lineSuffix")(code);
	    }
	    return ok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const definition$1 = {
	  name: 'definition',
	  tokenize: tokenizeDefinition
	};

	/** @type {Construct} */
	const titleBefore = {
	  partial: true,
	  tokenize: tokenizeTitleBefore
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeDefinition(effects, ok, nok) {
	  const self = this;
	  /** @type {string} */
	  let identifier;
	  return start;

	  /**
	   * At start of a definition.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // Do not interrupt paragraphs (but do follow definitions).
	    // To do: do `interrupt` the way `markdown-rs` does.
	    // To do: parse whitespace the way `markdown-rs` does.
	    effects.enter("definition");
	    return before(code);
	  }

	  /**
	   * After optional whitespace, at `[`.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function before(code) {
	    // To do: parse whitespace the way `markdown-rs` does.

	    return factoryLabel.call(self, effects, labelAfter,
	    // Note: we dont need to reset the way `markdown-rs` does.
	    nok, "definitionLabel", "definitionLabelMarker", "definitionLabelString")(code);
	  }

	  /**
	   * After label.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function labelAfter(code) {
	    identifier = normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1));
	    if (code === 58) {
	      effects.enter("definitionMarker");
	      effects.consume(code);
	      effects.exit("definitionMarker");
	      return markerAfter;
	    }
	    return nok(code);
	  }

	  /**
	   * After marker.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function markerAfter(code) {
	    // Note: whitespace is optional.
	    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, destinationBefore)(code) : destinationBefore(code);
	  }

	  /**
	   * Before destination.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function destinationBefore(code) {
	    return factoryDestination(effects, destinationAfter,
	    // Note: we dont need to reset the way `markdown-rs` does.
	    nok, "definitionDestination", "definitionDestinationLiteral", "definitionDestinationLiteralMarker", "definitionDestinationRaw", "definitionDestinationString")(code);
	  }

	  /**
	   * After destination.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function destinationAfter(code) {
	    return effects.attempt(titleBefore, after, after)(code);
	  }

	  /**
	   * After definition.
	   *
	   * ```markdown
	   * > | [a]: b
	   *           ^
	   * > | [a]: b "c"
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    return markdownSpace(code) ? factorySpace(effects, afterWhitespace, "whitespace")(code) : afterWhitespace(code);
	  }

	  /**
	   * After definition, after optional whitespace.
	   *
	   * ```markdown
	   * > | [a]: b
	   *           ^
	   * > | [a]: b "c"
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function afterWhitespace(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("definition");

	      // Note: we dont care about uniqueness.
	      // Its likely that that doesnt happen very frequently.
	      // It is more likely that it wastes precious time.
	      self.parser.defined.push(identifier);

	      // To do: `markdown-rs` interrupt.
	      // // Youd be interrupting.
	      // tokenizer.interrupt = true
	      return ok(code);
	    }
	    return nok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeTitleBefore(effects, ok, nok) {
	  return titleBefore;

	  /**
	   * After destination, at whitespace.
	   *
	   * ```markdown
	   * > | [a]: b
	   *           ^
	   * > | [a]: b "c"
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function titleBefore(code) {
	    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, beforeMarker)(code) : nok(code);
	  }

	  /**
	   * At title.
	   *
	   * ```markdown
	   *   | [a]: b
	   * > | "c"
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function beforeMarker(code) {
	    return factoryTitle(effects, titleAfter, nok, "definitionTitle", "definitionTitleMarker", "definitionTitleString")(code);
	  }

	  /**
	   * After title.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function titleAfter(code) {
	    return markdownSpace(code) ? factorySpace(effects, titleAfterOptionalWhitespace, "whitespace")(code) : titleAfterOptionalWhitespace(code);
	  }

	  /**
	   * After title, after optional whitespace.
	   *
	   * ```markdown
	   * > | [a]: b "c"
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function titleAfterOptionalWhitespace(code) {
	    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const hardBreakEscape = {
	  name: 'hardBreakEscape',
	  tokenize: tokenizeHardBreakEscape
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeHardBreakEscape(effects, ok, nok) {
	  return start;

	  /**
	   * Start of a hard break (escape).
	   *
	   * ```markdown
	   * > | a\
	   *      ^
	   *   | b
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("hardBreakEscape");
	    effects.consume(code);
	    return after;
	  }

	  /**
	   * After `\`, at eol.
	   *
	   * ```markdown
	   * > | a\
	   *       ^
	   *   | b
	   * ```
	   *
	   *  @type {State}
	   */
	  function after(code) {
	    if (markdownLineEnding(code)) {
	      effects.exit("hardBreakEscape");
	      return ok(code);
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const headingAtx = {
	  name: 'headingAtx',
	  resolve: resolveHeadingAtx,
	  tokenize: tokenizeHeadingAtx
	};

	/** @type {Resolver} */
	function resolveHeadingAtx(events, context) {
	  let contentEnd = events.length - 2;
	  let contentStart = 3;
	  /** @type {Token} */
	  let content;
	  /** @type {Token} */
	  let text;

	  // Prefix whitespace, part of the opening.
	  if (events[contentStart][1].type === "whitespace") {
	    contentStart += 2;
	  }

	  // Suffix whitespace, part of the closing.
	  if (contentEnd - 2 > contentStart && events[contentEnd][1].type === "whitespace") {
	    contentEnd -= 2;
	  }
	  if (events[contentEnd][1].type === "atxHeadingSequence" && (contentStart === contentEnd - 1 || contentEnd - 4 > contentStart && events[contentEnd - 2][1].type === "whitespace")) {
	    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;
	  }
	  if (contentEnd > contentStart) {
	    content = {
	      type: "atxHeadingText",
	      start: events[contentStart][1].start,
	      end: events[contentEnd][1].end
	    };
	    text = {
	      type: "chunkText",
	      start: events[contentStart][1].start,
	      end: events[contentEnd][1].end,
	      contentType: "text"
	    };
	    splice(events, contentStart, contentEnd - contentStart + 1, [['enter', content, context], ['enter', text, context], ['exit', text, context], ['exit', content, context]]);
	  }
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeHeadingAtx(effects, ok, nok) {
	  let size = 0;
	  return start;

	  /**
	   * Start of a heading (atx).
	   *
	   * ```markdown
	   * > | ## aa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // To do: parse indent like `markdown-rs`.
	    effects.enter("atxHeading");
	    return before(code);
	  }

	  /**
	   * After optional whitespace, at `#`.
	   *
	   * ```markdown
	   * > | ## aa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function before(code) {
	    effects.enter("atxHeadingSequence");
	    return sequenceOpen(code);
	  }

	  /**
	   * In opening sequence.
	   *
	   * ```markdown
	   * > | ## aa
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function sequenceOpen(code) {
	    if (code === 35 && size++ < 6) {
	      effects.consume(code);
	      return sequenceOpen;
	    }

	    // Always at least one `#`.
	    if (code === null || markdownLineEndingOrSpace(code)) {
	      effects.exit("atxHeadingSequence");
	      return atBreak(code);
	    }
	    return nok(code);
	  }

	  /**
	   * After something, before something else.
	   *
	   * ```markdown
	   * > | ## aa
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function atBreak(code) {
	    if (code === 35) {
	      effects.enter("atxHeadingSequence");
	      return sequenceFurther(code);
	    }
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("atxHeading");
	      // To do: interrupt like `markdown-rs`.
	      // // Feel free to interrupt.
	      // tokenizer.interrupt = false
	      return ok(code);
	    }
	    if (markdownSpace(code)) {
	      return factorySpace(effects, atBreak, "whitespace")(code);
	    }

	    // To do: generate `data` tokens, add the `text` token later.
	    // Needs edit map, see: `markdown.rs`.
	    effects.enter("atxHeadingText");
	    return data(code);
	  }

	  /**
	   * In further sequence (after whitespace).
	   *
	   * Could be normal visible hashes in the heading or a final sequence.
	   *
	   * ```markdown
	   * > | ## aa ##
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function sequenceFurther(code) {
	    if (code === 35) {
	      effects.consume(code);
	      return sequenceFurther;
	    }
	    effects.exit("atxHeadingSequence");
	    return atBreak(code);
	  }

	  /**
	   * In text.
	   *
	   * ```markdown
	   * > | ## aa
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function data(code) {
	    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {
	      effects.exit("atxHeadingText");
	      return atBreak(code);
	    }
	    effects.consume(code);
	    return data;
	  }
	}

	/**
	 * List of lowercase HTML block tag names.
	 *
	 * The list, when parsing HTML (flow), results in more relaxed rules (condition
	 * 6).
	 * Because they are known blocks, the HTML-like syntax doesnt have to be
	 * strictly parsed.
	 * For tag names not in this list, a more strict algorithm (condition 7) is used
	 * to detect whether the HTML-like syntax is seen as HTML (flow) or not.
	 *
	 * This is copied from:
	 * <https://spec.commonmark.org/0.30/#html-blocks>.
	 *
	 * >  **Note**: `search` was added in `CommonMark@0.31`.
	 */
	const htmlBlockNames = [
	  'address',
	  'article',
	  'aside',
	  'base',
	  'basefont',
	  'blockquote',
	  'body',
	  'caption',
	  'center',
	  'col',
	  'colgroup',
	  'dd',
	  'details',
	  'dialog',
	  'dir',
	  'div',
	  'dl',
	  'dt',
	  'fieldset',
	  'figcaption',
	  'figure',
	  'footer',
	  'form',
	  'frame',
	  'frameset',
	  'h1',
	  'h2',
	  'h3',
	  'h4',
	  'h5',
	  'h6',
	  'head',
	  'header',
	  'hr',
	  'html',
	  'iframe',
	  'legend',
	  'li',
	  'link',
	  'main',
	  'menu',
	  'menuitem',
	  'nav',
	  'noframes',
	  'ol',
	  'optgroup',
	  'option',
	  'p',
	  'param',
	  'search',
	  'section',
	  'summary',
	  'table',
	  'tbody',
	  'td',
	  'tfoot',
	  'th',
	  'thead',
	  'title',
	  'tr',
	  'track',
	  'ul'
	];

	/**
	 * List of lowercase HTML raw tag names.
	 *
	 * The list, when parsing HTML (flow), results in HTML that can include lines
	 * without exiting, until a closing tag also in this list is found (condition
	 * 1).
	 *
	 * This module is copied from:
	 * <https://spec.commonmark.org/0.30/#html-blocks>.
	 *
	 * >  **Note**: `textarea` was added in `CommonMark@0.30`.
	 */
	const htmlRawNames = ['pre', 'script', 'style', 'textarea'];

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */


	/** @type {Construct} */
	const htmlFlow = {
	  concrete: true,
	  name: 'htmlFlow',
	  resolveTo: resolveToHtmlFlow,
	  tokenize: tokenizeHtmlFlow
	};

	/** @type {Construct} */
	const blankLineBefore = {
	  partial: true,
	  tokenize: tokenizeBlankLineBefore
	};
	const nonLazyContinuationStart = {
	  partial: true,
	  tokenize: tokenizeNonLazyContinuationStart
	};

	/** @type {Resolver} */
	function resolveToHtmlFlow(events) {
	  let index = events.length;
	  while (index--) {
	    if (events[index][0] === 'enter' && events[index][1].type === "htmlFlow") {
	      break;
	    }
	  }
	  if (index > 1 && events[index - 2][1].type === "linePrefix") {
	    // Add the prefix start to the HTML token.
	    events[index][1].start = events[index - 2][1].start;
	    // Add the prefix start to the HTML line token.
	    events[index + 1][1].start = events[index - 2][1].start;
	    // Remove the line prefix.
	    events.splice(index - 2, 2);
	  }
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeHtmlFlow(effects, ok, nok) {
	  const self = this;
	  /** @type {number} */
	  let marker;
	  /** @type {boolean} */
	  let closingTag;
	  /** @type {string} */
	  let buffer;
	  /** @type {number} */
	  let index;
	  /** @type {Code} */
	  let markerB;
	  return start;

	  /**
	   * Start of HTML (flow).
	   *
	   * ```markdown
	   * > | <x />
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // To do: parse indent like `markdown-rs`.
	    return before(code);
	  }

	  /**
	   * At `<`, after optional whitespace.
	   *
	   * ```markdown
	   * > | <x />
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function before(code) {
	    effects.enter("htmlFlow");
	    effects.enter("htmlFlowData");
	    effects.consume(code);
	    return open;
	  }

	  /**
	   * After `<`, at tag name or other stuff.
	   *
	   * ```markdown
	   * > | <x />
	   *      ^
	   * > | <!doctype>
	   *      ^
	   * > | <!--xxx-->
	   *      ^
	   * ```
	   *
	   * @type {State}
	   */
	  function open(code) {
	    if (code === 33) {
	      effects.consume(code);
	      return declarationOpen;
	    }
	    if (code === 47) {
	      effects.consume(code);
	      closingTag = true;
	      return tagCloseStart;
	    }
	    if (code === 63) {
	      effects.consume(code);
	      marker = 3;
	      // To do:
	      // tokenizer.concrete = true
	      // To do: use `markdown-rs` style interrupt.
	      // While were in an instruction instead of a declaration, were on a `?`
	      // right now, so we do need to search for `>`, similar to declarations.
	      return self.interrupt ? ok : continuationDeclarationInside;
	    }

	    // ASCII alphabetical.
	    if (asciiAlpha(code)) {
	      // Always the case.
	      effects.consume(code);
	      buffer = String.fromCharCode(code);
	      return tagName;
	    }
	    return nok(code);
	  }

	  /**
	   * After `<!`, at declaration, comment, or CDATA.
	   *
	   * ```markdown
	   * > | <!doctype>
	   *       ^
	   * > | <!--xxx-->
	   *       ^
	   * > | <![CDATA[>&<]]>
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function declarationOpen(code) {
	    if (code === 45) {
	      effects.consume(code);
	      marker = 2;
	      return commentOpenInside;
	    }
	    if (code === 91) {
	      effects.consume(code);
	      marker = 5;
	      index = 0;
	      return cdataOpenInside;
	    }

	    // ASCII alphabetical.
	    if (asciiAlpha(code)) {
	      effects.consume(code);
	      marker = 4;
	      // // Do not form containers.
	      // tokenizer.concrete = true
	      return self.interrupt ? ok : continuationDeclarationInside;
	    }
	    return nok(code);
	  }

	  /**
	   * After `<!-`, inside a comment, at another `-`.
	   *
	   * ```markdown
	   * > | <!--xxx-->
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function commentOpenInside(code) {
	    if (code === 45) {
	      effects.consume(code);
	      // // Do not form containers.
	      // tokenizer.concrete = true
	      return self.interrupt ? ok : continuationDeclarationInside;
	    }
	    return nok(code);
	  }

	  /**
	   * After `<![`, inside CDATA, expecting `CDATA[`.
	   *
	   * ```markdown
	   * > | <![CDATA[>&<]]>
	   *        ^^^^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function cdataOpenInside(code) {
	    const value = "CDATA[";
	    if (code === value.charCodeAt(index++)) {
	      effects.consume(code);
	      if (index === value.length) {
	        // // Do not form containers.
	        // tokenizer.concrete = true
	        return self.interrupt ? ok : continuation;
	      }
	      return cdataOpenInside;
	    }
	    return nok(code);
	  }

	  /**
	   * After `</`, in closing tag, at tag name.
	   *
	   * ```markdown
	   * > | </x>
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagCloseStart(code) {
	    if (asciiAlpha(code)) {
	      // Always the case.
	      effects.consume(code);
	      buffer = String.fromCharCode(code);
	      return tagName;
	    }
	    return nok(code);
	  }

	  /**
	   * In tag name.
	   *
	   * ```markdown
	   * > | <ab>
	   *      ^^
	   * > | </ab>
	   *       ^^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagName(code) {
	    if (code === null || code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
	      const slash = code === 47;
	      const name = buffer.toLowerCase();
	      if (!slash && !closingTag && htmlRawNames.includes(name)) {
	        marker = 1;
	        // // Do not form containers.
	        // tokenizer.concrete = true
	        return self.interrupt ? ok(code) : continuation(code);
	      }
	      if (htmlBlockNames.includes(buffer.toLowerCase())) {
	        marker = 6;
	        if (slash) {
	          effects.consume(code);
	          return basicSelfClosing;
	        }

	        // // Do not form containers.
	        // tokenizer.concrete = true
	        return self.interrupt ? ok(code) : continuation(code);
	      }
	      marker = 7;
	      // Do not support complete HTML when interrupting.
	      return self.interrupt && !self.parser.lazy[self.now().line] ? nok(code) : closingTag ? completeClosingTagAfter(code) : completeAttributeNameBefore(code);
	    }

	    // ASCII alphanumerical and `-`.
	    if (code === 45 || asciiAlphanumeric(code)) {
	      effects.consume(code);
	      buffer += String.fromCharCode(code);
	      return tagName;
	    }
	    return nok(code);
	  }

	  /**
	   * After closing slash of a basic tag name.
	   *
	   * ```markdown
	   * > | <div/>
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function basicSelfClosing(code) {
	    if (code === 62) {
	      effects.consume(code);
	      // // Do not form containers.
	      // tokenizer.concrete = true
	      return self.interrupt ? ok : continuation;
	    }
	    return nok(code);
	  }

	  /**
	   * After closing slash of a complete tag name.
	   *
	   * ```markdown
	   * > | <x/>
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeClosingTagAfter(code) {
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return completeClosingTagAfter;
	    }
	    return completeEnd(code);
	  }

	  /**
	   * At an attribute name.
	   *
	   * At first, this state is used after a complete tag name, after whitespace,
	   * where it expects optional attributes or the end of the tag.
	   * It is also reused after attributes, when expecting more optional
	   * attributes.
	   *
	   * ```markdown
	   * > | <a />
	   *        ^
	   * > | <a :b>
	   *        ^
	   * > | <a _b>
	   *        ^
	   * > | <a b>
	   *        ^
	   * > | <a >
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeNameBefore(code) {
	    if (code === 47) {
	      effects.consume(code);
	      return completeEnd;
	    }

	    // ASCII alphanumerical and `:` and `_`.
	    if (code === 58 || code === 95 || asciiAlpha(code)) {
	      effects.consume(code);
	      return completeAttributeName;
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return completeAttributeNameBefore;
	    }
	    return completeEnd(code);
	  }

	  /**
	   * In attribute name.
	   *
	   * ```markdown
	   * > | <a :b>
	   *         ^
	   * > | <a _b>
	   *         ^
	   * > | <a b>
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeName(code) {
	    // ASCII alphanumerical and `-`, `.`, `:`, and `_`.
	    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {
	      effects.consume(code);
	      return completeAttributeName;
	    }
	    return completeAttributeNameAfter(code);
	  }

	  /**
	   * After attribute name, at an optional initializer, the end of the tag, or
	   * whitespace.
	   *
	   * ```markdown
	   * > | <a b>
	   *         ^
	   * > | <a b=c>
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeNameAfter(code) {
	    if (code === 61) {
	      effects.consume(code);
	      return completeAttributeValueBefore;
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return completeAttributeNameAfter;
	    }
	    return completeAttributeNameBefore(code);
	  }

	  /**
	   * Before unquoted, double quoted, or single quoted attribute value, allowing
	   * whitespace.
	   *
	   * ```markdown
	   * > | <a b=c>
	   *          ^
	   * > | <a b="c">
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeValueBefore(code) {
	    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {
	      return nok(code);
	    }
	    if (code === 34 || code === 39) {
	      effects.consume(code);
	      markerB = code;
	      return completeAttributeValueQuoted;
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return completeAttributeValueBefore;
	    }
	    return completeAttributeValueUnquoted(code);
	  }

	  /**
	   * In double or single quoted attribute value.
	   *
	   * ```markdown
	   * > | <a b="c">
	   *           ^
	   * > | <a b='c'>
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeValueQuoted(code) {
	    if (code === markerB) {
	      effects.consume(code);
	      markerB = null;
	      return completeAttributeValueQuotedAfter;
	    }
	    if (code === null || markdownLineEnding(code)) {
	      return nok(code);
	    }
	    effects.consume(code);
	    return completeAttributeValueQuoted;
	  }

	  /**
	   * In unquoted attribute value.
	   *
	   * ```markdown
	   * > | <a b=c>
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeValueUnquoted(code) {
	    if (code === null || code === 34 || code === 39 || code === 47 || code === 60 || code === 61 || code === 62 || code === 96 || markdownLineEndingOrSpace(code)) {
	      return completeAttributeNameAfter(code);
	    }
	    effects.consume(code);
	    return completeAttributeValueUnquoted;
	  }

	  /**
	   * After double or single quoted attribute value, before whitespace or the
	   * end of the tag.
	   *
	   * ```markdown
	   * > | <a b="c">
	   *            ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAttributeValueQuotedAfter(code) {
	    if (code === 47 || code === 62 || markdownSpace(code)) {
	      return completeAttributeNameBefore(code);
	    }
	    return nok(code);
	  }

	  /**
	   * In certain circumstances of a complete tag where only an `>` is allowed.
	   *
	   * ```markdown
	   * > | <a b="c">
	   *             ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeEnd(code) {
	    if (code === 62) {
	      effects.consume(code);
	      return completeAfter;
	    }
	    return nok(code);
	  }

	  /**
	   * After `>` in a complete tag.
	   *
	   * ```markdown
	   * > | <x>
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function completeAfter(code) {
	    if (code === null || markdownLineEnding(code)) {
	      // // Do not form containers.
	      // tokenizer.concrete = true
	      return continuation(code);
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return completeAfter;
	    }
	    return nok(code);
	  }

	  /**
	   * In continuation of any HTML kind.
	   *
	   * ```markdown
	   * > | <!--xxx-->
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuation(code) {
	    if (code === 45 && marker === 2) {
	      effects.consume(code);
	      return continuationCommentInside;
	    }
	    if (code === 60 && marker === 1) {
	      effects.consume(code);
	      return continuationRawTagOpen;
	    }
	    if (code === 62 && marker === 4) {
	      effects.consume(code);
	      return continuationClose;
	    }
	    if (code === 63 && marker === 3) {
	      effects.consume(code);
	      return continuationDeclarationInside;
	    }
	    if (code === 93 && marker === 5) {
	      effects.consume(code);
	      return continuationCdataInside;
	    }
	    if (markdownLineEnding(code) && (marker === 6 || marker === 7)) {
	      effects.exit("htmlFlowData");
	      return effects.check(blankLineBefore, continuationAfter, continuationStart)(code);
	    }
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("htmlFlowData");
	      return continuationStart(code);
	    }
	    effects.consume(code);
	    return continuation;
	  }

	  /**
	   * In continuation, at eol.
	   *
	   * ```markdown
	   * > | <x>
	   *        ^
	   *   | asd
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationStart(code) {
	    return effects.check(nonLazyContinuationStart, continuationStartNonLazy, continuationAfter)(code);
	  }

	  /**
	   * In continuation, at eol, before non-lazy content.
	   *
	   * ```markdown
	   * > | <x>
	   *        ^
	   *   | asd
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationStartNonLazy(code) {
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return continuationBefore;
	  }

	  /**
	   * In continuation, before non-lazy content.
	   *
	   * ```markdown
	   *   | <x>
	   * > | asd
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationBefore(code) {
	    if (code === null || markdownLineEnding(code)) {
	      return continuationStart(code);
	    }
	    effects.enter("htmlFlowData");
	    return continuation(code);
	  }

	  /**
	   * In comment continuation, after one `-`, expecting another.
	   *
	   * ```markdown
	   * > | <!--xxx-->
	   *             ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationCommentInside(code) {
	    if (code === 45) {
	      effects.consume(code);
	      return continuationDeclarationInside;
	    }
	    return continuation(code);
	  }

	  /**
	   * In raw continuation, after `<`, at `/`.
	   *
	   * ```markdown
	   * > | <script>console.log(1)</script>
	   *                            ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationRawTagOpen(code) {
	    if (code === 47) {
	      effects.consume(code);
	      buffer = '';
	      return continuationRawEndTag;
	    }
	    return continuation(code);
	  }

	  /**
	   * In raw continuation, after `</`, in a raw tag name.
	   *
	   * ```markdown
	   * > | <script>console.log(1)</script>
	   *                             ^^^^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationRawEndTag(code) {
	    if (code === 62) {
	      const name = buffer.toLowerCase();
	      if (htmlRawNames.includes(name)) {
	        effects.consume(code);
	        return continuationClose;
	      }
	      return continuation(code);
	    }
	    if (asciiAlpha(code) && buffer.length < 8) {
	      // Always the case.
	      effects.consume(code);
	      buffer += String.fromCharCode(code);
	      return continuationRawEndTag;
	    }
	    return continuation(code);
	  }

	  /**
	   * In cdata continuation, after `]`, expecting `]>`.
	   *
	   * ```markdown
	   * > | <![CDATA[>&<]]>
	   *                  ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationCdataInside(code) {
	    if (code === 93) {
	      effects.consume(code);
	      return continuationDeclarationInside;
	    }
	    return continuation(code);
	  }

	  /**
	   * In declaration or instruction continuation, at `>`.
	   *
	   * ```markdown
	   * > | <!-->
	   *         ^
	   * > | <?>
	   *       ^
	   * > | <!q>
	   *        ^
	   * > | <!--ab-->
	   *             ^
	   * > | <![CDATA[>&<]]>
	   *                   ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationDeclarationInside(code) {
	    if (code === 62) {
	      effects.consume(code);
	      return continuationClose;
	    }

	    // More dashes.
	    if (code === 45 && marker === 2) {
	      effects.consume(code);
	      return continuationDeclarationInside;
	    }
	    return continuation(code);
	  }

	  /**
	   * In closed continuation: everything we get until the eol/eof is part of it.
	   *
	   * ```markdown
	   * > | <!doctype>
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationClose(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("htmlFlowData");
	      return continuationAfter(code);
	    }
	    effects.consume(code);
	    return continuationClose;
	  }

	  /**
	   * Done.
	   *
	   * ```markdown
	   * > | <!doctype>
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function continuationAfter(code) {
	    effects.exit("htmlFlow");
	    // // Feel free to interrupt.
	    // tokenizer.interrupt = false
	    // // No longer concrete.
	    // tokenizer.concrete = false
	    return ok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeNonLazyContinuationStart(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   * At eol, before continuation.
	   *
	   * ```markdown
	   * > | * ```js
	   *            ^
	   *   | b
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    if (markdownLineEnding(code)) {
	      effects.enter("lineEnding");
	      effects.consume(code);
	      effects.exit("lineEnding");
	      return after;
	    }
	    return nok(code);
	  }

	  /**
	   * A continuation.
	   *
	   * ```markdown
	   *   | * ```js
	   * > | b
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeBlankLineBefore(effects, ok, nok) {
	  return start;

	  /**
	   * Before eol, expecting blank line.
	   *
	   * ```markdown
	   * > | <div>
	   *          ^
	   *   |
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return effects.attempt(blankLine, ok, nok);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const htmlText = {
	  name: 'htmlText',
	  tokenize: tokenizeHtmlText
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeHtmlText(effects, ok, nok) {
	  const self = this;
	  /** @type {NonNullable<Code> | undefined} */
	  let marker;
	  /** @type {number} */
	  let index;
	  /** @type {State} */
	  let returnState;
	  return start;

	  /**
	   * Start of HTML (text).
	   *
	   * ```markdown
	   * > | a <b> c
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("htmlText");
	    effects.enter("htmlTextData");
	    effects.consume(code);
	    return open;
	  }

	  /**
	   * After `<`, at tag name or other stuff.
	   *
	   * ```markdown
	   * > | a <b> c
	   *        ^
	   * > | a <!doctype> c
	   *        ^
	   * > | a <!--b--> c
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function open(code) {
	    if (code === 33) {
	      effects.consume(code);
	      return declarationOpen;
	    }
	    if (code === 47) {
	      effects.consume(code);
	      return tagCloseStart;
	    }
	    if (code === 63) {
	      effects.consume(code);
	      return instruction;
	    }

	    // ASCII alphabetical.
	    if (asciiAlpha(code)) {
	      effects.consume(code);
	      return tagOpen;
	    }
	    return nok(code);
	  }

	  /**
	   * After `<!`, at declaration, comment, or CDATA.
	   *
	   * ```markdown
	   * > | a <!doctype> c
	   *         ^
	   * > | a <!--b--> c
	   *         ^
	   * > | a <![CDATA[>&<]]> c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function declarationOpen(code) {
	    if (code === 45) {
	      effects.consume(code);
	      return commentOpenInside;
	    }
	    if (code === 91) {
	      effects.consume(code);
	      index = 0;
	      return cdataOpenInside;
	    }
	    if (asciiAlpha(code)) {
	      effects.consume(code);
	      return declaration;
	    }
	    return nok(code);
	  }

	  /**
	   * In a comment, after `<!-`, at another `-`.
	   *
	   * ```markdown
	   * > | a <!--b--> c
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function commentOpenInside(code) {
	    if (code === 45) {
	      effects.consume(code);
	      return commentEnd;
	    }
	    return nok(code);
	  }

	  /**
	   * In comment.
	   *
	   * ```markdown
	   * > | a <!--b--> c
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function comment(code) {
	    if (code === null) {
	      return nok(code);
	    }
	    if (code === 45) {
	      effects.consume(code);
	      return commentClose;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = comment;
	      return lineEndingBefore(code);
	    }
	    effects.consume(code);
	    return comment;
	  }

	  /**
	   * In comment, after `-`.
	   *
	   * ```markdown
	   * > | a <!--b--> c
	   *             ^
	   * ```
	   *
	   * @type {State}
	   */
	  function commentClose(code) {
	    if (code === 45) {
	      effects.consume(code);
	      return commentEnd;
	    }
	    return comment(code);
	  }

	  /**
	   * In comment, after `--`.
	   *
	   * ```markdown
	   * > | a <!--b--> c
	   *              ^
	   * ```
	   *
	   * @type {State}
	   */
	  function commentEnd(code) {
	    return code === 62 ? end(code) : code === 45 ? commentClose(code) : comment(code);
	  }

	  /**
	   * After `<![`, in CDATA, expecting `CDATA[`.
	   *
	   * ```markdown
	   * > | a <![CDATA[>&<]]> b
	   *          ^^^^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function cdataOpenInside(code) {
	    const value = "CDATA[";
	    if (code === value.charCodeAt(index++)) {
	      effects.consume(code);
	      return index === value.length ? cdata : cdataOpenInside;
	    }
	    return nok(code);
	  }

	  /**
	   * In CDATA.
	   *
	   * ```markdown
	   * > | a <![CDATA[>&<]]> b
	   *                ^^^
	   * ```
	   *
	   * @type {State}
	   */
	  function cdata(code) {
	    if (code === null) {
	      return nok(code);
	    }
	    if (code === 93) {
	      effects.consume(code);
	      return cdataClose;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = cdata;
	      return lineEndingBefore(code);
	    }
	    effects.consume(code);
	    return cdata;
	  }

	  /**
	   * In CDATA, after `]`, at another `]`.
	   *
	   * ```markdown
	   * > | a <![CDATA[>&<]]> b
	   *                    ^
	   * ```
	   *
	   * @type {State}
	   */
	  function cdataClose(code) {
	    if (code === 93) {
	      effects.consume(code);
	      return cdataEnd;
	    }
	    return cdata(code);
	  }

	  /**
	   * In CDATA, after `]]`, at `>`.
	   *
	   * ```markdown
	   * > | a <![CDATA[>&<]]> b
	   *                     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function cdataEnd(code) {
	    if (code === 62) {
	      return end(code);
	    }
	    if (code === 93) {
	      effects.consume(code);
	      return cdataEnd;
	    }
	    return cdata(code);
	  }

	  /**
	   * In declaration.
	   *
	   * ```markdown
	   * > | a <!b> c
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function declaration(code) {
	    if (code === null || code === 62) {
	      return end(code);
	    }
	    if (markdownLineEnding(code)) {
	      returnState = declaration;
	      return lineEndingBefore(code);
	    }
	    effects.consume(code);
	    return declaration;
	  }

	  /**
	   * In instruction.
	   *
	   * ```markdown
	   * > | a <?b?> c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function instruction(code) {
	    if (code === null) {
	      return nok(code);
	    }
	    if (code === 63) {
	      effects.consume(code);
	      return instructionClose;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = instruction;
	      return lineEndingBefore(code);
	    }
	    effects.consume(code);
	    return instruction;
	  }

	  /**
	   * In instruction, after `?`, at `>`.
	   *
	   * ```markdown
	   * > | a <?b?> c
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function instructionClose(code) {
	    return code === 62 ? end(code) : instruction(code);
	  }

	  /**
	   * After `</`, in closing tag, at tag name.
	   *
	   * ```markdown
	   * > | a </b> c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagCloseStart(code) {
	    // ASCII alphabetical.
	    if (asciiAlpha(code)) {
	      effects.consume(code);
	      return tagClose;
	    }
	    return nok(code);
	  }

	  /**
	   * After `</x`, in a tag name.
	   *
	   * ```markdown
	   * > | a </b> c
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagClose(code) {
	    // ASCII alphanumerical and `-`.
	    if (code === 45 || asciiAlphanumeric(code)) {
	      effects.consume(code);
	      return tagClose;
	    }
	    return tagCloseBetween(code);
	  }

	  /**
	   * In closing tag, after tag name.
	   *
	   * ```markdown
	   * > | a </b> c
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagCloseBetween(code) {
	    if (markdownLineEnding(code)) {
	      returnState = tagCloseBetween;
	      return lineEndingBefore(code);
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return tagCloseBetween;
	    }
	    return end(code);
	  }

	  /**
	   * After `<x`, in opening tag name.
	   *
	   * ```markdown
	   * > | a <b> c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpen(code) {
	    // ASCII alphanumerical and `-`.
	    if (code === 45 || asciiAlphanumeric(code)) {
	      effects.consume(code);
	      return tagOpen;
	    }
	    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
	      return tagOpenBetween(code);
	    }
	    return nok(code);
	  }

	  /**
	   * In opening tag, after tag name.
	   *
	   * ```markdown
	   * > | a <b> c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenBetween(code) {
	    if (code === 47) {
	      effects.consume(code);
	      return end;
	    }

	    // ASCII alphabetical and `:` and `_`.
	    if (code === 58 || code === 95 || asciiAlpha(code)) {
	      effects.consume(code);
	      return tagOpenAttributeName;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = tagOpenBetween;
	      return lineEndingBefore(code);
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return tagOpenBetween;
	    }
	    return end(code);
	  }

	  /**
	   * In attribute name.
	   *
	   * ```markdown
	   * > | a <b c> d
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeName(code) {
	    // ASCII alphabetical and `-`, `.`, `:`, and `_`.
	    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {
	      effects.consume(code);
	      return tagOpenAttributeName;
	    }
	    return tagOpenAttributeNameAfter(code);
	  }

	  /**
	   * After attribute name, before initializer, the end of the tag, or
	   * whitespace.
	   *
	   * ```markdown
	   * > | a <b c> d
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeNameAfter(code) {
	    if (code === 61) {
	      effects.consume(code);
	      return tagOpenAttributeValueBefore;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = tagOpenAttributeNameAfter;
	      return lineEndingBefore(code);
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return tagOpenAttributeNameAfter;
	    }
	    return tagOpenBetween(code);
	  }

	  /**
	   * Before unquoted, double quoted, or single quoted attribute value, allowing
	   * whitespace.
	   *
	   * ```markdown
	   * > | a <b c=d> e
	   *            ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeValueBefore(code) {
	    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {
	      return nok(code);
	    }
	    if (code === 34 || code === 39) {
	      effects.consume(code);
	      marker = code;
	      return tagOpenAttributeValueQuoted;
	    }
	    if (markdownLineEnding(code)) {
	      returnState = tagOpenAttributeValueBefore;
	      return lineEndingBefore(code);
	    }
	    if (markdownSpace(code)) {
	      effects.consume(code);
	      return tagOpenAttributeValueBefore;
	    }
	    effects.consume(code);
	    return tagOpenAttributeValueUnquoted;
	  }

	  /**
	   * In double or single quoted attribute value.
	   *
	   * ```markdown
	   * > | a <b c="d"> e
	   *             ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeValueQuoted(code) {
	    if (code === marker) {
	      effects.consume(code);
	      marker = undefined;
	      return tagOpenAttributeValueQuotedAfter;
	    }
	    if (code === null) {
	      return nok(code);
	    }
	    if (markdownLineEnding(code)) {
	      returnState = tagOpenAttributeValueQuoted;
	      return lineEndingBefore(code);
	    }
	    effects.consume(code);
	    return tagOpenAttributeValueQuoted;
	  }

	  /**
	   * In unquoted attribute value.
	   *
	   * ```markdown
	   * > | a <b c=d> e
	   *            ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeValueUnquoted(code) {
	    if (code === null || code === 34 || code === 39 || code === 60 || code === 61 || code === 96) {
	      return nok(code);
	    }
	    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
	      return tagOpenBetween(code);
	    }
	    effects.consume(code);
	    return tagOpenAttributeValueUnquoted;
	  }

	  /**
	   * After double or single quoted attribute value, before whitespace or the end
	   * of the tag.
	   *
	   * ```markdown
	   * > | a <b c="d"> e
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function tagOpenAttributeValueQuotedAfter(code) {
	    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
	      return tagOpenBetween(code);
	    }
	    return nok(code);
	  }

	  /**
	   * In certain circumstances of a tag where only an `>` is allowed.
	   *
	   * ```markdown
	   * > | a <b c="d"> e
	   *               ^
	   * ```
	   *
	   * @type {State}
	   */
	  function end(code) {
	    if (code === 62) {
	      effects.consume(code);
	      effects.exit("htmlTextData");
	      effects.exit("htmlText");
	      return ok;
	    }
	    return nok(code);
	  }

	  /**
	   * At eol.
	   *
	   * >  **Note**: we cant have blank lines in text, so no need to worry about
	   * > empty tokens.
	   *
	   * ```markdown
	   * > | a <!--a
	   *            ^
	   *   | b-->
	   * ```
	   *
	   * @type {State}
	   */
	  function lineEndingBefore(code) {
	    effects.exit("htmlTextData");
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return lineEndingAfter;
	  }

	  /**
	   * After eol, at optional whitespace.
	   *
	   * >  **Note**: we cant have blank lines in text, so no need to worry about
	   * > empty tokens.
	   *
	   * ```markdown
	   *   | a <!--a
	   * > | b-->
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function lineEndingAfter(code) {
	    // Always populated by defaults.

	    return markdownSpace(code) ? factorySpace(effects, lineEndingAfterPrefix, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : lineEndingAfterPrefix(code);
	  }

	  /**
	   * After eol, after optional whitespace.
	   *
	   * >  **Note**: we cant have blank lines in text, so no need to worry about
	   * > empty tokens.
	   *
	   * ```markdown
	   *   | a <!--a
	   * > | b-->
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function lineEndingAfterPrefix(code) {
	    effects.enter("htmlTextData");
	    return returnState(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   Event,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const labelEnd = {
	  name: 'labelEnd',
	  resolveAll: resolveAllLabelEnd,
	  resolveTo: resolveToLabelEnd,
	  tokenize: tokenizeLabelEnd
	};

	/** @type {Construct} */
	const resourceConstruct = {
	  tokenize: tokenizeResource
	};
	/** @type {Construct} */
	const referenceFullConstruct = {
	  tokenize: tokenizeReferenceFull
	};
	/** @type {Construct} */
	const referenceCollapsedConstruct = {
	  tokenize: tokenizeReferenceCollapsed
	};

	/** @type {Resolver} */
	function resolveAllLabelEnd(events) {
	  let index = -1;
	  /** @type {Array<Event>} */
	  const newEvents = [];
	  while (++index < events.length) {
	    const token = events[index][1];
	    newEvents.push(events[index]);
	    if (token.type === "labelImage" || token.type === "labelLink" || token.type === "labelEnd") {
	      // Remove the marker.
	      const offset = token.type === "labelImage" ? 4 : 2;
	      token.type = "data";
	      index += offset;
	    }
	  }

	  // If the events are equal, we don't have to copy newEvents to events
	  if (events.length !== newEvents.length) {
	    splice(events, 0, events.length, newEvents);
	  }
	  return events;
	}

	/** @type {Resolver} */
	function resolveToLabelEnd(events, context) {
	  let index = events.length;
	  let offset = 0;
	  /** @type {Token} */
	  let token;
	  /** @type {number | undefined} */
	  let open;
	  /** @type {number | undefined} */
	  let close;
	  /** @type {Array<Event>} */
	  let media;

	  // Find an opening.
	  while (index--) {
	    token = events[index][1];
	    if (open) {
	      // If we see another link, or inactive link label, weve been here before.
	      if (token.type === "link" || token.type === "labelLink" && token._inactive) {
	        break;
	      }

	      // Mark other link openings as inactive, as we cant have links in
	      // links.
	      if (events[index][0] === 'enter' && token.type === "labelLink") {
	        token._inactive = true;
	      }
	    } else if (close) {
	      if (events[index][0] === 'enter' && (token.type === "labelImage" || token.type === "labelLink") && !token._balanced) {
	        open = index;
	        if (token.type !== "labelLink") {
	          offset = 2;
	          break;
	        }
	      }
	    } else if (token.type === "labelEnd") {
	      close = index;
	    }
	  }
	  const group = {
	    type: events[open][1].type === "labelLink" ? "link" : "image",
	    start: {
	      ...events[open][1].start
	    },
	    end: {
	      ...events[events.length - 1][1].end
	    }
	  };
	  const label = {
	    type: "label",
	    start: {
	      ...events[open][1].start
	    },
	    end: {
	      ...events[close][1].end
	    }
	  };
	  const text = {
	    type: "labelText",
	    start: {
	      ...events[open + offset + 2][1].end
	    },
	    end: {
	      ...events[close - 2][1].start
	    }
	  };
	  media = [['enter', group, context], ['enter', label, context]];

	  // Opening marker.
	  media = push(media, events.slice(open + 1, open + offset + 3));

	  // Text open.
	  media = push(media, [['enter', text, context]]);

	  // Always populated by defaults.

	  // Between.
	  media = push(media, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + offset + 4, close - 3), context));

	  // Text close, marker close, label close.
	  media = push(media, [['exit', text, context], events[close - 2], events[close - 1], ['exit', label, context]]);

	  // Reference, resource, or so.
	  media = push(media, events.slice(close + 1));

	  // Media close.
	  media = push(media, [['exit', group, context]]);
	  splice(events, open, events.length, media);
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeLabelEnd(effects, ok, nok) {
	  const self = this;
	  let index = self.events.length;
	  /** @type {Token} */
	  let labelStart;
	  /** @type {boolean} */
	  let defined;

	  // Find an opening.
	  while (index--) {
	    if ((self.events[index][1].type === "labelImage" || self.events[index][1].type === "labelLink") && !self.events[index][1]._balanced) {
	      labelStart = self.events[index][1];
	      break;
	    }
	  }
	  return start;

	  /**
	   * Start of label end.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *       ^
	   * > | [a][b] c
	   *       ^
	   * > | [a][] b
	   *       ^
	   * > | [a] b
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    // If there is not an okay opening.
	    if (!labelStart) {
	      return nok(code);
	    }

	    // If the corresponding label (link) start is marked as inactive,
	    // it means wed be wrapping a link, like this:
	    //
	    // ```markdown
	    // > | a [b [c](d) e](f) g.
	    //                  ^
	    // ```
	    //
	    // We cant have that, so its just balanced brackets.
	    if (labelStart._inactive) {
	      return labelEndNok(code);
	    }
	    defined = self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize({
	      start: labelStart.end,
	      end: self.now()
	    })));
	    effects.enter("labelEnd");
	    effects.enter("labelMarker");
	    effects.consume(code);
	    effects.exit("labelMarker");
	    effects.exit("labelEnd");
	    return after;
	  }

	  /**
	   * After `]`.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *       ^
	   * > | [a][b] c
	   *       ^
	   * > | [a][] b
	   *       ^
	   * > | [a] b
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    // Note: `markdown-rs` also parses GFM footnotes here, which for us is in
	    // an extension.

	    // Resource (`[asd](fgh)`)?
	    if (code === 40) {
	      return effects.attempt(resourceConstruct, labelEndOk, defined ? labelEndOk : labelEndNok)(code);
	    }

	    // Full (`[asd][fgh]`) or collapsed (`[asd][]`) reference?
	    if (code === 91) {
	      return effects.attempt(referenceFullConstruct, labelEndOk, defined ? referenceNotFull : labelEndNok)(code);
	    }

	    // Shortcut (`[asd]`) reference?
	    return defined ? labelEndOk(code) : labelEndNok(code);
	  }

	  /**
	   * After `]`, at `[`, but not at a full reference.
	   *
	   * >  **Note**: we only get here if the label is defined.
	   *
	   * ```markdown
	   * > | [a][] b
	   *        ^
	   * > | [a] b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function referenceNotFull(code) {
	    return effects.attempt(referenceCollapsedConstruct, labelEndOk, labelEndNok)(code);
	  }

	  /**
	   * Done, we found something.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *           ^
	   * > | [a][b] c
	   *           ^
	   * > | [a][] b
	   *          ^
	   * > | [a] b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function labelEndOk(code) {
	    // Note: `markdown-rs` does a bunch of stuff here.
	    return ok(code);
	  }

	  /**
	   * Done, its nothing.
	   *
	   * There was an okay opening, but we didnt match anything.
	   *
	   * ```markdown
	   * > | [a](b c
	   *        ^
	   * > | [a][b c
	   *        ^
	   * > | [a] b
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function labelEndNok(code) {
	    labelStart._balanced = true;
	    return nok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeResource(effects, ok, nok) {
	  return resourceStart;

	  /**
	   * At a resource.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceStart(code) {
	    effects.enter("resource");
	    effects.enter("resourceMarker");
	    effects.consume(code);
	    effects.exit("resourceMarker");
	    return resourceBefore;
	  }

	  /**
	   * In resource, after `(`, at optional whitespace.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceBefore(code) {
	    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceOpen)(code) : resourceOpen(code);
	  }

	  /**
	   * In resource, after optional whitespace, at `)` or a destination.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceOpen(code) {
	    if (code === 41) {
	      return resourceEnd(code);
	    }
	    return factoryDestination(effects, resourceDestinationAfter, resourceDestinationMissing, "resourceDestination", "resourceDestinationLiteral", "resourceDestinationLiteralMarker", "resourceDestinationRaw", "resourceDestinationString", 32)(code);
	  }

	  /**
	   * In resource, after destination, at optional whitespace.
	   *
	   * ```markdown
	   * > | [a](b) c
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceDestinationAfter(code) {
	    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceBetween)(code) : resourceEnd(code);
	  }

	  /**
	   * At invalid destination.
	   *
	   * ```markdown
	   * > | [a](<<) b
	   *         ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceDestinationMissing(code) {
	    return nok(code);
	  }

	  /**
	   * In resource, after destination and whitespace, at `(` or title.
	   *
	   * ```markdown
	   * > | [a](b ) c
	   *           ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceBetween(code) {
	    if (code === 34 || code === 39 || code === 40) {
	      return factoryTitle(effects, resourceTitleAfter, nok, "resourceTitle", "resourceTitleMarker", "resourceTitleString")(code);
	    }
	    return resourceEnd(code);
	  }

	  /**
	   * In resource, after title, at optional whitespace.
	   *
	   * ```markdown
	   * > | [a](b "c") d
	   *              ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceTitleAfter(code) {
	    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceEnd)(code) : resourceEnd(code);
	  }

	  /**
	   * In resource, at `)`.
	   *
	   * ```markdown
	   * > | [a](b) d
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function resourceEnd(code) {
	    if (code === 41) {
	      effects.enter("resourceMarker");
	      effects.consume(code);
	      effects.exit("resourceMarker");
	      effects.exit("resource");
	      return ok;
	    }
	    return nok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeReferenceFull(effects, ok, nok) {
	  const self = this;
	  return referenceFull;

	  /**
	   * In a reference (full), at the `[`.
	   *
	   * ```markdown
	   * > | [a][b] d
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function referenceFull(code) {
	    return factoryLabel.call(self, effects, referenceFullAfter, referenceFullMissing, "reference", "referenceMarker", "referenceString")(code);
	  }

	  /**
	   * In a reference (full), after `]`.
	   *
	   * ```markdown
	   * > | [a][b] d
	   *          ^
	   * ```
	   *
	   * @type {State}
	   */
	  function referenceFullAfter(code) {
	    return self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1))) ? ok(code) : nok(code);
	  }

	  /**
	   * In reference (full) that was missing.
	   *
	   * ```markdown
	   * > | [a][b d
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function referenceFullMissing(code) {
	    return nok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeReferenceCollapsed(effects, ok, nok) {
	  return referenceCollapsedStart;

	  /**
	   * In reference (collapsed), at `[`.
	   *
	   * >  **Note**: we only get here if the label is defined.
	   *
	   * ```markdown
	   * > | [a][] d
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function referenceCollapsedStart(code) {
	    // We only attempt a collapsed label if theres a `[`.

	    effects.enter("reference");
	    effects.enter("referenceMarker");
	    effects.consume(code);
	    effects.exit("referenceMarker");
	    return referenceCollapsedOpen;
	  }

	  /**
	   * In reference (collapsed), at `]`.
	   *
	   * >  **Note**: we only get here if the label is defined.
	   *
	   * ```markdown
	   * > | [a][] d
	   *         ^
	   * ```
	   *
	   *  @type {State}
	   */
	  function referenceCollapsedOpen(code) {
	    if (code === 93) {
	      effects.enter("referenceMarker");
	      effects.consume(code);
	      effects.exit("referenceMarker");
	      effects.exit("reference");
	      return ok;
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */


	/** @type {Construct} */
	const labelStartImage = {
	  name: 'labelStartImage',
	  resolveAll: labelEnd.resolveAll,
	  tokenize: tokenizeLabelStartImage
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeLabelStartImage(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   * Start of label (image) start.
	   *
	   * ```markdown
	   * > | a ![b] c
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("labelImage");
	    effects.enter("labelImageMarker");
	    effects.consume(code);
	    effects.exit("labelImageMarker");
	    return open;
	  }

	  /**
	   * After `!`, at `[`.
	   *
	   * ```markdown
	   * > | a ![b] c
	   *        ^
	   * ```
	   *
	   * @type {State}
	   */
	  function open(code) {
	    if (code === 91) {
	      effects.enter("labelMarker");
	      effects.consume(code);
	      effects.exit("labelMarker");
	      effects.exit("labelImage");
	      return after;
	    }
	    return nok(code);
	  }

	  /**
	   * After `![`.
	   *
	   * ```markdown
	   * > | a ![b] c
	   *         ^
	   * ```
	   *
	   * This is needed in because, when GFM footnotes are enabled, images never
	   * form when started with a `^`.
	   * Instead, links form:
	   *
	   * ```markdown
	   * ![^a](b)
	   *
	   * ![^a][b]
	   *
	   * [b]: c
	   * ```
	   *
	   * ```html
	   * <p>!<a href=\"b\">^a</a></p>
	   * <p>!<a href=\"c\">^a</a></p>
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    // To do: use a new field to do this, this is still needed for
	    // `micromark-extension-gfm-footnote`, but the `label-start-link`
	    // behavior isnt.
	    // Hidden footnotes hook.
	    /* c8 ignore next 3 */
	    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */


	/** @type {Construct} */
	const labelStartLink = {
	  name: 'labelStartLink',
	  resolveAll: labelEnd.resolveAll,
	  tokenize: tokenizeLabelStartLink
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeLabelStartLink(effects, ok, nok) {
	  const self = this;
	  return start;

	  /**
	   * Start of label (link) start.
	   *
	   * ```markdown
	   * > | a [b] c
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("labelLink");
	    effects.enter("labelMarker");
	    effects.consume(code);
	    effects.exit("labelMarker");
	    effects.exit("labelLink");
	    return after;
	  }

	  /** @type {State} */
	  function after(code) {
	    // To do: this isnt needed in `micromark-extension-gfm-footnote`,
	    // remove.
	    // Hidden footnotes hook.
	    /* c8 ignore next 3 */
	    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);
	  }
	}

	/**
	 * @import {
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const lineEnding = {
	  name: 'lineEnding',
	  tokenize: tokenizeLineEnding
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeLineEnding(effects, ok) {
	  return start;

	  /** @type {State} */
	  function start(code) {
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    return factorySpace(effects, ok, "linePrefix");
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const thematicBreak$1 = {
	  name: 'thematicBreak',
	  tokenize: tokenizeThematicBreak
	};

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeThematicBreak(effects, ok, nok) {
	  let size = 0;
	  /** @type {NonNullable<Code>} */
	  let marker;
	  return start;

	  /**
	   * Start of thematic break.
	   *
	   * ```markdown
	   * > | ***
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    effects.enter("thematicBreak");
	    // To do: parse indent like `markdown-rs`.
	    return before(code);
	  }

	  /**
	   * After optional whitespace, at marker.
	   *
	   * ```markdown
	   * > | ***
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function before(code) {
	    marker = code;
	    return atBreak(code);
	  }

	  /**
	   * After something, before something else.
	   *
	   * ```markdown
	   * > | ***
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function atBreak(code) {
	    if (code === marker) {
	      effects.enter("thematicBreakSequence");
	      return sequence(code);
	    }
	    if (size >= 3 && (code === null || markdownLineEnding(code))) {
	      effects.exit("thematicBreak");
	      return ok(code);
	    }
	    return nok(code);
	  }

	  /**
	   * In sequence.
	   *
	   * ```markdown
	   * > | ***
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function sequence(code) {
	    if (code === marker) {
	      effects.consume(code);
	      size++;
	      return sequence;
	    }
	    effects.exit("thematicBreakSequence");
	    return markdownSpace(code) ? factorySpace(effects, atBreak, "whitespace")(code) : atBreak(code);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   Exiter,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */


	/** @type {Construct} */
	const list$2 = {
	  continuation: {
	    tokenize: tokenizeListContinuation
	  },
	  exit: tokenizeListEnd,
	  name: 'list',
	  tokenize: tokenizeListStart
	};

	/** @type {Construct} */
	const listItemPrefixWhitespaceConstruct = {
	  partial: true,
	  tokenize: tokenizeListItemPrefixWhitespace
	};

	/** @type {Construct} */
	const indentConstruct = {
	  partial: true,
	  tokenize: tokenizeIndent
	};

	// To do: `markdown-rs` parses list items on their own and later stitches them
	// together.

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeListStart(effects, ok, nok) {
	  const self = this;
	  const tail = self.events[self.events.length - 1];
	  let initialSize = tail && tail[1].type === "linePrefix" ? tail[2].sliceSerialize(tail[1], true).length : 0;
	  let size = 0;
	  return start;

	  /** @type {State} */
	  function start(code) {
	    const kind = self.containerState.type || (code === 42 || code === 43 || code === 45 ? "listUnordered" : "listOrdered");
	    if (kind === "listUnordered" ? !self.containerState.marker || code === self.containerState.marker : asciiDigit(code)) {
	      if (!self.containerState.type) {
	        self.containerState.type = kind;
	        effects.enter(kind, {
	          _container: true
	        });
	      }
	      if (kind === "listUnordered") {
	        effects.enter("listItemPrefix");
	        return code === 42 || code === 45 ? effects.check(thematicBreak$1, nok, atMarker)(code) : atMarker(code);
	      }
	      if (!self.interrupt || code === 49) {
	        effects.enter("listItemPrefix");
	        effects.enter("listItemValue");
	        return inside(code);
	      }
	    }
	    return nok(code);
	  }

	  /** @type {State} */
	  function inside(code) {
	    if (asciiDigit(code) && ++size < 10) {
	      effects.consume(code);
	      return inside;
	    }
	    if ((!self.interrupt || size < 2) && (self.containerState.marker ? code === self.containerState.marker : code === 41 || code === 46)) {
	      effects.exit("listItemValue");
	      return atMarker(code);
	    }
	    return nok(code);
	  }

	  /**
	   * @type {State}
	   **/
	  function atMarker(code) {
	    effects.enter("listItemMarker");
	    effects.consume(code);
	    effects.exit("listItemMarker");
	    self.containerState.marker = self.containerState.marker || code;
	    return effects.check(blankLine,
	    // Cant be empty when interrupting.
	    self.interrupt ? nok : onBlank, effects.attempt(listItemPrefixWhitespaceConstruct, endOfPrefix, otherPrefix));
	  }

	  /** @type {State} */
	  function onBlank(code) {
	    self.containerState.initialBlankLine = true;
	    initialSize++;
	    return endOfPrefix(code);
	  }

	  /** @type {State} */
	  function otherPrefix(code) {
	    if (markdownSpace(code)) {
	      effects.enter("listItemPrefixWhitespace");
	      effects.consume(code);
	      effects.exit("listItemPrefixWhitespace");
	      return endOfPrefix;
	    }
	    return nok(code);
	  }

	  /** @type {State} */
	  function endOfPrefix(code) {
	    self.containerState.size = initialSize + self.sliceSerialize(effects.exit("listItemPrefix"), true).length;
	    return ok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeListContinuation(effects, ok, nok) {
	  const self = this;
	  self.containerState._closeFlow = undefined;
	  return effects.check(blankLine, onBlank, notBlank);

	  /** @type {State} */
	  function onBlank(code) {
	    self.containerState.furtherBlankLines = self.containerState.furtherBlankLines || self.containerState.initialBlankLine;

	    // We have a blank line.
	    // Still, try to consume at most the items size.
	    return factorySpace(effects, ok, "listItemIndent", self.containerState.size + 1)(code);
	  }

	  /** @type {State} */
	  function notBlank(code) {
	    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {
	      self.containerState.furtherBlankLines = undefined;
	      self.containerState.initialBlankLine = undefined;
	      return notInCurrentItem(code);
	    }
	    self.containerState.furtherBlankLines = undefined;
	    self.containerState.initialBlankLine = undefined;
	    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code);
	  }

	  /** @type {State} */
	  function notInCurrentItem(code) {
	    // While we do continue, we signal that the flow should be closed.
	    self.containerState._closeFlow = true;
	    // As were closing flow, were no longer interrupting.
	    self.interrupt = undefined;
	    // Always populated by defaults.

	    return factorySpace(effects, effects.attempt(list$2, ok, nok), "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeIndent(effects, ok, nok) {
	  const self = this;
	  return factorySpace(effects, afterPrefix, "listItemIndent", self.containerState.size + 1);

	  /** @type {State} */
	  function afterPrefix(code) {
	    const tail = self.events[self.events.length - 1];
	    return tail && tail[1].type === "listItemIndent" && tail[2].sliceSerialize(tail[1], true).length === self.containerState.size ? ok(code) : nok(code);
	  }
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Exiter}
	 */
	function tokenizeListEnd(effects) {
	  effects.exit(this.containerState.type);
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeListItemPrefixWhitespace(effects, ok, nok) {
	  const self = this;

	  // Always populated by defaults.

	  return factorySpace(effects, afterPrefix, "listItemPrefixWhitespace", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4 + 1);

	  /** @type {State} */
	  function afterPrefix(code) {
	    const tail = self.events[self.events.length - 1];
	    return !markdownSpace(code) && tail && tail[1].type === "listItemPrefixWhitespace" ? ok(code) : nok(code);
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   Construct,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext,
	 *   Tokenizer
	 * } from 'micromark-util-types'
	 */

	/** @type {Construct} */
	const setextUnderline = {
	  name: 'setextUnderline',
	  resolveTo: resolveToSetextUnderline,
	  tokenize: tokenizeSetextUnderline
	};

	/** @type {Resolver} */
	function resolveToSetextUnderline(events, context) {
	  // To do: resolve like `markdown-rs`.
	  let index = events.length;
	  /** @type {number | undefined} */
	  let content;
	  /** @type {number | undefined} */
	  let text;
	  /** @type {number | undefined} */
	  let definition;

	  // Find the opening of the content.
	  // Itll always exist: we dont tokenize if it isnt there.
	  while (index--) {
	    if (events[index][0] === 'enter') {
	      if (events[index][1].type === "content") {
	        content = index;
	        break;
	      }
	      if (events[index][1].type === "paragraph") {
	        text = index;
	      }
	    }
	    // Exit
	    else {
	      if (events[index][1].type === "content") {
	        // Remove the content end (if needed well add it later)
	        events.splice(index, 1);
	      }
	      if (!definition && events[index][1].type === "definition") {
	        definition = index;
	      }
	    }
	  }
	  const heading = {
	    type: "setextHeading",
	    start: {
	      ...events[content][1].start
	    },
	    end: {
	      ...events[events.length - 1][1].end
	    }
	  };

	  // Change the paragraph to setext heading text.
	  events[text][1].type = "setextHeadingText";

	  // If we have definitions in the content, well keep on having content,
	  // but we need move it.
	  if (definition) {
	    events.splice(text, 0, ['enter', heading, context]);
	    events.splice(definition + 1, 0, ['exit', events[content][1], context]);
	    events[content][1].end = {
	      ...events[definition][1].end
	    };
	  } else {
	    events[content][1] = heading;
	  }

	  // Add the heading exit at the end.
	  events.push(['exit', heading, context]);
	  return events;
	}

	/**
	 * @this {TokenizeContext}
	 *   Context.
	 * @type {Tokenizer}
	 */
	function tokenizeSetextUnderline(effects, ok, nok) {
	  const self = this;
	  /** @type {NonNullable<Code>} */
	  let marker;
	  return start;

	  /**
	   * At start of heading (setext) underline.
	   *
	   * ```markdown
	   *   | aa
	   * > | ==
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function start(code) {
	    let index = self.events.length;
	    /** @type {boolean | undefined} */
	    let paragraph;
	    // Find an opening.
	    while (index--) {
	      // Skip enter/exit of line ending, line prefix, and content.
	      // We can now either have a definition or a paragraph.
	      if (self.events[index][1].type !== "lineEnding" && self.events[index][1].type !== "linePrefix" && self.events[index][1].type !== "content") {
	        paragraph = self.events[index][1].type === "paragraph";
	        break;
	      }
	    }

	    // To do: handle lazy/pierce like `markdown-rs`.
	    // To do: parse indent like `markdown-rs`.
	    if (!self.parser.lazy[self.now().line] && (self.interrupt || paragraph)) {
	      effects.enter("setextHeadingLine");
	      marker = code;
	      return before(code);
	    }
	    return nok(code);
	  }

	  /**
	   * After optional whitespace, at `-` or `=`.
	   *
	   * ```markdown
	   *   | aa
	   * > | ==
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function before(code) {
	    effects.enter("setextHeadingLineSequence");
	    return inside(code);
	  }

	  /**
	   * In sequence.
	   *
	   * ```markdown
	   *   | aa
	   * > | ==
	   *     ^
	   * ```
	   *
	   * @type {State}
	   */
	  function inside(code) {
	    if (code === marker) {
	      effects.consume(code);
	      return inside;
	    }
	    effects.exit("setextHeadingLineSequence");
	    return markdownSpace(code) ? factorySpace(effects, after, "lineSuffix")(code) : after(code);
	  }

	  /**
	   * After sequence, after optional whitespace.
	   *
	   * ```markdown
	   *   | aa
	   * > | ==
	   *       ^
	   * ```
	   *
	   * @type {State}
	   */
	  function after(code) {
	    if (code === null || markdownLineEnding(code)) {
	      effects.exit("setextHeadingLine");
	      return ok(code);
	    }
	    return nok(code);
	  }
	}

	/**
	 * @import {
	 *   InitialConstruct,
	 *   Initializer,
	 *   State,
	 *   TokenizeContext
	 * } from 'micromark-util-types'
	 */

	/** @type {InitialConstruct} */
	const flow$1 = {
	  tokenize: initializeFlow
	};

	/**
	 * @this {TokenizeContext}
	 *   Self.
	 * @type {Initializer}
	 *   Initializer.
	 */
	function initializeFlow(effects) {
	  const self = this;
	  const initial = effects.attempt(
	  // Try to parse a blank line.
	  blankLine, atBlankEnding,
	  // Try to parse initial flow (essentially, only code).
	  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), "linePrefix")));
	  return initial;

	  /** @type {State} */
	  function atBlankEnding(code) {
	    if (code === null) {
	      effects.consume(code);
	      return;
	    }
	    effects.enter("lineEndingBlank");
	    effects.consume(code);
	    effects.exit("lineEndingBlank");
	    self.currentConstruct = undefined;
	    return initial;
	  }

	  /** @type {State} */
	  function afterConstruct(code) {
	    if (code === null) {
	      effects.consume(code);
	      return;
	    }
	    effects.enter("lineEnding");
	    effects.consume(code);
	    effects.exit("lineEnding");
	    self.currentConstruct = undefined;
	    return initial;
	  }
	}

	/**
	 * @import {
	 *   Code,
	 *   InitialConstruct,
	 *   Initializer,
	 *   Resolver,
	 *   State,
	 *   TokenizeContext
	 * } from 'micromark-util-types'
	 */

	const resolver = {
	  resolveAll: createResolver()
	};
	const string$1 = initializeFactory('string');
	const text$2 = initializeFactory('text');

	/**
	 * @param {'string' | 'text'} field
	 *   Field.
	 * @returns {InitialConstruct}
	 *   Construct.
	 */
	function initializeFactory(field) {
	  return {
	    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),
	    tokenize: initializeText
	  };

	  /**
	   * @this {TokenizeContext}
	   *   Context.
	   * @type {Initializer}
	   */
	  function initializeText(effects) {
	    const self = this;
	    const constructs = this.parser.constructs[field];
	    const text = effects.attempt(constructs, start, notText);
	    return start;

	    /** @type {State} */
	    function start(code) {
	      return atBreak(code) ? text(code) : notText(code);
	    }

	    /** @type {State} */
	    function notText(code) {
	      if (code === null) {
	        effects.consume(code);
	        return;
	      }
	      effects.enter("data");
	      effects.consume(code);
	      return data;
	    }

	    /** @type {State} */
	    function data(code) {
	      if (atBreak(code)) {
	        effects.exit("data");
	        return text(code);
	      }

	      // Data.
	      effects.consume(code);
	      return data;
	    }

	    /**
	     * @param {Code} code
	     *   Code.
	     * @returns {boolean}
	     *   Whether the code is a break.
	     */
	    function atBreak(code) {
	      if (code === null) {
	        return true;
	      }
	      const list = constructs[code];
	      let index = -1;
	      if (list) {
	        // Always populated by defaults.

	        while (++index < list.length) {
	          const item = list[index];
	          if (!item.previous || item.previous.call(self, self.previous)) {
	            return true;
	          }
	        }
	      }
	      return false;
	    }
	  }
	}

	/**
	 * @param {Resolver | undefined} [extraResolver]
	 *   Resolver.
	 * @returns {Resolver}
	 *   Resolver.
	 */
	function createResolver(extraResolver) {
	  return resolveAllText;

	  /** @type {Resolver} */
	  function resolveAllText(events, context) {
	    let index = -1;
	    /** @type {number | undefined} */
	    let enter;

	    // A rather boring computation (to merge adjacent `data` events) which
	    // improves mm performance by 29%.
	    while (++index <= events.length) {
	      if (enter === undefined) {
	        if (events[index] && events[index][1].type === "data") {
	          enter = index;
	          index++;
	        }
	      } else if (!events[index] || events[index][1].type !== "data") {
	        // Dont do anything if there is one data token.
	        if (index !== enter + 2) {
	          events[enter][1].end = events[index - 1][1].end;
	          events.splice(enter + 2, index - enter - 2);
	          index = enter + 2;
	        }
	        enter = undefined;
	      }
	    }
	    return extraResolver ? extraResolver(events, context) : events;
	  }
	}

	/**
	 * A rather ugly set of instructions which again looks at chunks in the input
	 * stream.
	 * The reason to do this here is that it is *much* faster to parse in reverse.
	 * And that we cant hook into `null` to split the line suffix before an EOF.
	 * To do: figure out if we can make this into a clean utility, or even in core.
	 * As it will be useful for GFMs literal autolink extension (and maybe even
	 * tables?)
	 *
	 * @type {Resolver}
	 */
	function resolveAllLineSuffixes(events, context) {
	  let eventIndex = 0; // Skip first.

	  while (++eventIndex <= events.length) {
	    if ((eventIndex === events.length || events[eventIndex][1].type === "lineEnding") && events[eventIndex - 1][1].type === "data") {
	      const data = events[eventIndex - 1][1];
	      const chunks = context.sliceStream(data);
	      let index = chunks.length;
	      let bufferIndex = -1;
	      let size = 0;
	      /** @type {boolean | undefined} */
	      let tabs;
	      while (index--) {
	        const chunk = chunks[index];
	        if (typeof chunk === 'string') {
	          bufferIndex = chunk.length;
	          while (chunk.charCodeAt(bufferIndex - 1) === 32) {
	            size++;
	            bufferIndex--;
	          }
	          if (bufferIndex) break;
	          bufferIndex = -1;
	        }
	        // Number
	        else if (chunk === -2) {
	          tabs = true;
	          size++;
	        } else if (chunk === -1) ; else {
	          // Replacement character, exit.
	          index++;
	          break;
	        }
	      }

	      // Allow final trailing whitespace.
	      if (context._contentTypeTextTrailing && eventIndex === events.length) {
	        size = 0;
	      }
	      if (size) {
	        const token = {
	          type: eventIndex === events.length || tabs || size < 2 ? "lineSuffix" : "hardBreakTrailing",
	          start: {
	            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,
	            _index: data.start._index + index,
	            line: data.end.line,
	            column: data.end.column - size,
	            offset: data.end.offset - size
	          },
	          end: {
	            ...data.end
	          }
	        };
	        data.end = {
	          ...token.start
	        };
	        if (data.start.offset === data.end.offset) {
	          Object.assign(data, token);
	        } else {
	          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);
	          eventIndex += 2;
	        }
	      }
	      eventIndex++;
	    }
	  }
	  return events;
	}

	/**
	 * @import {Extension} from 'micromark-util-types'
	 */


	/** @satisfies {Extension['document']} */
	const document$1 = {
	  [42]: list$2,
	  [43]: list$2,
	  [45]: list$2,
	  [48]: list$2,
	  [49]: list$2,
	  [50]: list$2,
	  [51]: list$2,
	  [52]: list$2,
	  [53]: list$2,
	  [54]: list$2,
	  [55]: list$2,
	  [56]: list$2,
	  [57]: list$2,
	  [62]: blockQuote
	};

	/** @satisfies {Extension['contentInitial']} */
	const contentInitial = {
	  [91]: definition$1
	};

	/** @satisfies {Extension['flowInitial']} */
	const flowInitial = {
	  [-2]: codeIndented,
	  [-1]: codeIndented,
	  [32]: codeIndented
	};

	/** @satisfies {Extension['flow']} */
	const flow = {
	  [35]: headingAtx,
	  [42]: thematicBreak$1,
	  [45]: [setextUnderline, thematicBreak$1],
	  [60]: htmlFlow,
	  [61]: setextUnderline,
	  [95]: thematicBreak$1,
	  [96]: codeFenced,
	  [126]: codeFenced
	};

	/** @satisfies {Extension['string']} */
	const string = {
	  [38]: characterReference,
	  [92]: characterEscape
	};

	/** @satisfies {Extension['text']} */
	const text$1 = {
	  [-5]: lineEnding,
	  [-4]: lineEnding,
	  [-3]: lineEnding,
	  [33]: labelStartImage,
	  [38]: characterReference,
	  [42]: attention,
	  [60]: [autolink, htmlText],
	  [91]: labelStartLink,
	  [92]: [hardBreakEscape, characterEscape],
	  [93]: labelEnd,
	  [95]: attention,
	  [96]: codeText
	};

	/** @satisfies {Extension['insideSpan']} */
	const insideSpan = {
	  null: [attention, resolver]
	};

	/** @satisfies {Extension['attentionMarkers']} */
	const attentionMarkers = {
	  null: [42, 95]
	};

	/** @satisfies {Extension['disable']} */
	const disable = {
	  null: []
	};

	var defaultConstructs = /*#__PURE__*/Object.freeze({
		__proto__: null,
		attentionMarkers: attentionMarkers,
		contentInitial: contentInitial,
		disable: disable,
		document: document$1,
		flow: flow,
		flowInitial: flowInitial,
		insideSpan: insideSpan,
		string: string,
		text: text$1
	});

	/**
	 * @import {
	 *   Chunk,
	 *   Code,
	 *   ConstructRecord,
	 *   Construct,
	 *   Effects,
	 *   InitialConstruct,
	 *   ParseContext,
	 *   Point,
	 *   State,
	 *   TokenizeContext,
	 *   Token
	 * } from 'micromark-util-types'
	 */

	/**
	 * Create a tokenizer.
	 * Tokenizers deal with one type of data (e.g., containers, flow, text).
	 * The parser is the object dealing with it all.
	 * `initialize` works like other constructs, except that only its `tokenize`
	 * function is used, in which case it doesnt receive an `ok` or `nok`.
	 * `from` can be given to set the point before the first character, although
	 * when further lines are indented, they must be set with `defineSkip`.
	 *
	 * @param {ParseContext} parser
	 *   Parser.
	 * @param {InitialConstruct} initialize
	 *   Construct.
	 * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]
	 *   Point (optional).
	 * @returns {TokenizeContext}
	 *   Context.
	 */
	function createTokenizer(parser, initialize, from) {
	  /** @type {Point} */
	  let point = {
	    _bufferIndex: -1,
	    _index: 0,
	    line: from && from.line || 1,
	    column: from && from.column || 1,
	    offset: from && from.offset || 0
	  };
	  /** @type {Record<string, number>} */
	  const columnStart = {};
	  /** @type {Array<Construct>} */
	  const resolveAllConstructs = [];
	  /** @type {Array<Chunk>} */
	  let chunks = [];
	  /** @type {Array<Token>} */
	  let stack = [];

	  /**
	   * Tools used for tokenizing.
	   *
	   * @type {Effects}
	   */
	  const effects = {
	    attempt: constructFactory(onsuccessfulconstruct),
	    check: constructFactory(onsuccessfulcheck),
	    consume,
	    enter,
	    exit,
	    interrupt: constructFactory(onsuccessfulcheck, {
	      interrupt: true
	    })
	  };

	  /**
	   * State and tools for resolving and serializing.
	   *
	   * @type {TokenizeContext}
	   */
	  const context = {
	    code: null,
	    containerState: {},
	    defineSkip,
	    events: [],
	    now,
	    parser,
	    previous: null,
	    sliceSerialize,
	    sliceStream,
	    write
	  };

	  /**
	   * The state function.
	   *
	   * @type {State | undefined}
	   */
	  let state = initialize.tokenize.call(context, effects);
	  if (initialize.resolveAll) {
	    resolveAllConstructs.push(initialize);
	  }
	  return context;

	  /** @type {TokenizeContext['write']} */
	  function write(slice) {
	    chunks = push(chunks, slice);
	    main();

	    // Exit if were not done, resolve might change stuff.
	    if (chunks[chunks.length - 1] !== null) {
	      return [];
	    }
	    addResult(initialize, 0);

	    // Otherwise, resolve, and exit.
	    context.events = resolveAll(resolveAllConstructs, context.events, context);
	    return context.events;
	  }

	  //
	  // Tools.
	  //

	  /** @type {TokenizeContext['sliceSerialize']} */
	  function sliceSerialize(token, expandTabs) {
	    return serializeChunks(sliceStream(token), expandTabs);
	  }

	  /** @type {TokenizeContext['sliceStream']} */
	  function sliceStream(token) {
	    return sliceChunks(chunks, token);
	  }

	  /** @type {TokenizeContext['now']} */
	  function now() {
	    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`
	    const {
	      _bufferIndex,
	      _index,
	      line,
	      column,
	      offset
	    } = point;
	    return {
	      _bufferIndex,
	      _index,
	      line,
	      column,
	      offset
	    };
	  }

	  /** @type {TokenizeContext['defineSkip']} */
	  function defineSkip(value) {
	    columnStart[value.line] = value.column;
	    accountForPotentialSkip();
	  }

	  //
	  // State management.
	  //

	  /**
	   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by
	   * `consume`).
	   * Here is where we walk through the chunks, which either include strings of
	   * several characters, or numerical character codes.
	   * The reason to do this in a loop instead of a call is so the stack can
	   * drain.
	   *
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function main() {
	    /** @type {number} */
	    let chunkIndex;
	    while (point._index < chunks.length) {
	      const chunk = chunks[point._index];

	      // If were in a buffer chunk, loop through it.
	      if (typeof chunk === 'string') {
	        chunkIndex = point._index;
	        if (point._bufferIndex < 0) {
	          point._bufferIndex = 0;
	        }
	        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {
	          go(chunk.charCodeAt(point._bufferIndex));
	        }
	      } else {
	        go(chunk);
	      }
	    }
	  }

	  /**
	   * Deal with one code.
	   *
	   * @param {Code} code
	   *   Code.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function go(code) {
	    state = state(code);
	  }

	  /** @type {Effects['consume']} */
	  function consume(code) {
	    if (markdownLineEnding(code)) {
	      point.line++;
	      point.column = 1;
	      point.offset += code === -3 ? 2 : 1;
	      accountForPotentialSkip();
	    } else if (code !== -1) {
	      point.column++;
	      point.offset++;
	    }

	    // Not in a string chunk.
	    if (point._bufferIndex < 0) {
	      point._index++;
	    } else {
	      point._bufferIndex++;

	      // At end of string chunk.
	      if (point._bufferIndex ===
	      // Points w/ non-negative `_bufferIndex` reference
	      // strings.
	      /** @type {string} */
	      chunks[point._index].length) {
	        point._bufferIndex = -1;
	        point._index++;
	      }
	    }

	    // Expose the previous character.
	    context.previous = code;
	  }

	  /** @type {Effects['enter']} */
	  function enter(type, fields) {
	    /** @type {Token} */
	    // @ts-expect-error Patch instead of assign required fields to help GC.
	    const token = fields || {};
	    token.type = type;
	    token.start = now();
	    context.events.push(['enter', token, context]);
	    stack.push(token);
	    return token;
	  }

	  /** @type {Effects['exit']} */
	  function exit(type) {
	    const token = stack.pop();
	    token.end = now();
	    context.events.push(['exit', token, context]);
	    return token;
	  }

	  /**
	   * Use results.
	   *
	   * @type {ReturnHandle}
	   */
	  function onsuccessfulconstruct(construct, info) {
	    addResult(construct, info.from);
	  }

	  /**
	   * Discard results.
	   *
	   * @type {ReturnHandle}
	   */
	  function onsuccessfulcheck(_, info) {
	    info.restore();
	  }

	  /**
	   * Factory to attempt/check/interrupt.
	   *
	   * @param {ReturnHandle} onreturn
	   *   Callback.
	   * @param {{interrupt?: boolean | undefined} | undefined} [fields]
	   *   Fields.
	   */
	  function constructFactory(onreturn, fields) {
	    return hook;

	    /**
	     * Handle either an object mapping codes to constructs, a list of
	     * constructs, or a single construct.
	     *
	     * @param {Array<Construct> | ConstructRecord | Construct} constructs
	     *   Constructs.
	     * @param {State} returnState
	     *   State.
	     * @param {State | undefined} [bogusState]
	     *   State.
	     * @returns {State}
	     *   State.
	     */
	    function hook(constructs, returnState, bogusState) {
	      /** @type {ReadonlyArray<Construct>} */
	      let listOfConstructs;
	      /** @type {number} */
	      let constructIndex;
	      /** @type {Construct} */
	      let currentConstruct;
	      /** @type {Info} */
	      let info;
	      return Array.isArray(constructs) ? /* c8 ignore next 1 */
	      handleListOfConstructs(constructs) : 'tokenize' in constructs ?
	      // Looks like a construct.
	      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);

	      /**
	       * Handle a list of construct.
	       *
	       * @param {ConstructRecord} map
	       *   Constructs.
	       * @returns {State}
	       *   State.
	       */
	      function handleMapOfConstructs(map) {
	        return start;

	        /** @type {State} */
	        function start(code) {
	          const left = code !== null && map[code];
	          const all = code !== null && map.null;
	          const list = [
	          // To do: add more extension tests.
	          /* c8 ignore next 2 */
	          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];
	          return handleListOfConstructs(list)(code);
	        }
	      }

	      /**
	       * Handle a list of construct.
	       *
	       * @param {ReadonlyArray<Construct>} list
	       *   Constructs.
	       * @returns {State}
	       *   State.
	       */
	      function handleListOfConstructs(list) {
	        listOfConstructs = list;
	        constructIndex = 0;
	        if (list.length === 0) {
	          return bogusState;
	        }
	        return handleConstruct(list[constructIndex]);
	      }

	      /**
	       * Handle a single construct.
	       *
	       * @param {Construct} construct
	       *   Construct.
	       * @returns {State}
	       *   State.
	       */
	      function handleConstruct(construct) {
	        return start;

	        /** @type {State} */
	        function start(code) {
	          // To do: not needed to store if there is no bogus state, probably?
	          // Currently doesnt work because `inspect` in document does a check
	          // w/o a bogus, which doesnt make sense. But it does seem to help perf
	          // by not storing.
	          info = store();
	          currentConstruct = construct;
	          if (!construct.partial) {
	            context.currentConstruct = construct;
	          }

	          // Always populated by defaults.

	          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {
	            return nok();
	          }
	          return construct.tokenize.call(
	          // If we do have fields, create an object w/ `context` as its
	          // prototype.
	          // This allows a live binding, which is needed for `interrupt`.
	          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);
	        }
	      }

	      /** @type {State} */
	      function ok(code) {
	        onreturn(currentConstruct, info);
	        return returnState;
	      }

	      /** @type {State} */
	      function nok(code) {
	        info.restore();
	        if (++constructIndex < listOfConstructs.length) {
	          return handleConstruct(listOfConstructs[constructIndex]);
	        }
	        return bogusState;
	      }
	    }
	  }

	  /**
	   * @param {Construct} construct
	   *   Construct.
	   * @param {number} from
	   *   From.
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function addResult(construct, from) {
	    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {
	      resolveAllConstructs.push(construct);
	    }
	    if (construct.resolve) {
	      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));
	    }
	    if (construct.resolveTo) {
	      context.events = construct.resolveTo(context.events, context);
	    }
	  }

	  /**
	   * Store state.
	   *
	   * @returns {Info}
	   *   Info.
	   */
	  function store() {
	    const startPoint = now();
	    const startPrevious = context.previous;
	    const startCurrentConstruct = context.currentConstruct;
	    const startEventsIndex = context.events.length;
	    const startStack = Array.from(stack);
	    return {
	      from: startEventsIndex,
	      restore
	    };

	    /**
	     * Restore state.
	     *
	     * @returns {undefined}
	     *   Nothing.
	     */
	    function restore() {
	      point = startPoint;
	      context.previous = startPrevious;
	      context.currentConstruct = startCurrentConstruct;
	      context.events.length = startEventsIndex;
	      stack = startStack;
	      accountForPotentialSkip();
	    }
	  }

	  /**
	   * Move the current point a bit forward in the line when its on a column
	   * skip.
	   *
	   * @returns {undefined}
	   *   Nothing.
	   */
	  function accountForPotentialSkip() {
	    if (point.line in columnStart && point.column < 2) {
	      point.column = columnStart[point.line];
	      point.offset += columnStart[point.line] - 1;
	    }
	  }
	}

	/**
	 * Get the chunks from a slice of chunks in the range of a token.
	 *
	 * @param {ReadonlyArray<Chunk>} chunks
	 *   Chunks.
	 * @param {Pick<Token, 'end' | 'start'>} token
	 *   Token.
	 * @returns {Array<Chunk>}
	 *   Chunks.
	 */
	function sliceChunks(chunks, token) {
	  const startIndex = token.start._index;
	  const startBufferIndex = token.start._bufferIndex;
	  const endIndex = token.end._index;
	  const endBufferIndex = token.end._bufferIndex;
	  /** @type {Array<Chunk>} */
	  let view;
	  if (startIndex === endIndex) {
	    // @ts-expect-error `_bufferIndex` is used on string chunks.
	    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];
	  } else {
	    view = chunks.slice(startIndex, endIndex);
	    if (startBufferIndex > -1) {
	      const head = view[0];
	      if (typeof head === 'string') {
	        view[0] = head.slice(startBufferIndex);
	        /* c8 ignore next 4 -- used to be used, no longer */
	      } else {
	        view.shift();
	      }
	    }
	    if (endBufferIndex > 0) {
	      // @ts-expect-error `_bufferIndex` is used on string chunks.
	      view.push(chunks[endIndex].slice(0, endBufferIndex));
	    }
	  }
	  return view;
	}

	/**
	 * Get the string value of a slice of chunks.
	 *
	 * @param {ReadonlyArray<Chunk>} chunks
	 *   Chunks.
	 * @param {boolean | undefined} [expandTabs=false]
	 *   Whether to expand tabs (default: `false`).
	 * @returns {string}
	 *   Result.
	 */
	function serializeChunks(chunks, expandTabs) {
	  let index = -1;
	  /** @type {Array<string>} */
	  const result = [];
	  /** @type {boolean | undefined} */
	  let atTab;
	  while (++index < chunks.length) {
	    const chunk = chunks[index];
	    /** @type {string} */
	    let value;
	    if (typeof chunk === 'string') {
	      value = chunk;
	    } else switch (chunk) {
	      case -5:
	        {
	          value = "\r";
	          break;
	        }
	      case -4:
	        {
	          value = "\n";
	          break;
	        }
	      case -3:
	        {
	          value = "\r" + "\n";
	          break;
	        }
	      case -2:
	        {
	          value = expandTabs ? " " : "\t";
	          break;
	        }
	      case -1:
	        {
	          if (!expandTabs && atTab) continue;
	          value = " ";
	          break;
	        }
	      default:
	        {
	          // Currently only replacement character.
	          value = String.fromCharCode(chunk);
	        }
	    }
	    atTab = chunk === -2;
	    result.push(value);
	  }
	  return result.join('');
	}

	/**
	 * @import {
	 *   Create,
	 *   FullNormalizedExtension,
	 *   InitialConstruct,
	 *   ParseContext,
	 *   ParseOptions
	 * } from 'micromark-util-types'
	 */


	/**
	 * @param {ParseOptions | null | undefined} [options]
	 *   Configuration (optional).
	 * @returns {ParseContext}
	 *   Parser.
	 */
	function parse(options) {
	  const settings = options || {};
	  const constructs = /** @type {FullNormalizedExtension} */
	  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);

	  /** @type {ParseContext} */
	  const parser = {
	    constructs,
	    content: create(content$1),
	    defined: [],
	    document: create(document$2),
	    flow: create(flow$1),
	    lazy: {},
	    string: create(string$1),
	    text: create(text$2)
	  };
	  return parser;

	  /**
	   * @param {InitialConstruct} initial
	   *   Construct to start with.
	   * @returns {Create}
	   *   Create a tokenizer.
	   */
	  function create(initial) {
	    return creator;
	    /** @type {Create} */
	    function creator(from) {
	      return createTokenizer(parser, initial, from);
	    }
	  }
	}

	/**
	 * @import {Event} from 'micromark-util-types'
	 */


	/**
	 * @param {Array<Event>} events
	 *   Events.
	 * @returns {Array<Event>}
	 *   Events.
	 */
	function postprocess(events) {
	  while (!subtokenize(events)) {
	    // Empty
	  }
	  return events;
	}

	/**
	 * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'
	 */

	/**
	 * @callback Preprocessor
	 *   Preprocess a value.
	 * @param {Value} value
	 *   Value.
	 * @param {Encoding | null | undefined} [encoding]
	 *   Encoding when `value` is a typed array (optional).
	 * @param {boolean | null | undefined} [end=false]
	 *   Whether this is the last chunk (default: `false`).
	 * @returns {Array<Chunk>}
	 *   Chunks.
	 */

	const search = /[\0\t\n\r]/g;

	/**
	 * @returns {Preprocessor}
	 *   Preprocess a value.
	 */
	function preprocess() {
	  let column = 1;
	  let buffer = '';
	  /** @type {boolean | undefined} */
	  let start = true;
	  /** @type {boolean | undefined} */
	  let atCarriageReturn;
	  return preprocessor;

	  /** @type {Preprocessor} */
	  // eslint-disable-next-line complexity
	  function preprocessor(value, encoding, end) {
	    /** @type {Array<Chunk>} */
	    const chunks = [];
	    /** @type {RegExpMatchArray | null} */
	    let match;
	    /** @type {number} */
	    let next;
	    /** @type {number} */
	    let startPosition;
	    /** @type {number} */
	    let endPosition;
	    /** @type {Code} */
	    let code;
	    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));
	    startPosition = 0;
	    buffer = '';
	    if (start) {
	      // To do: `markdown-rs` actually parses BOMs (byte order mark).
	      if (value.charCodeAt(0) === 65279) {
	        startPosition++;
	      }
	      start = undefined;
	    }
	    while (startPosition < value.length) {
	      search.lastIndex = startPosition;
	      match = search.exec(value);
	      endPosition = match && match.index !== undefined ? match.index : value.length;
	      code = value.charCodeAt(endPosition);
	      if (!match) {
	        buffer = value.slice(startPosition);
	        break;
	      }
	      if (code === 10 && startPosition === endPosition && atCarriageReturn) {
	        chunks.push(-3);
	        atCarriageReturn = undefined;
	      } else {
	        if (atCarriageReturn) {
	          chunks.push(-5);
	          atCarriageReturn = undefined;
	        }
	        if (startPosition < endPosition) {
	          chunks.push(value.slice(startPosition, endPosition));
	          column += endPosition - startPosition;
	        }
	        switch (code) {
	          case 0:
	            {
	              chunks.push(65533);
	              column++;
	              break;
	            }
	          case 9:
	            {
	              next = Math.ceil(column / 4) * 4;
	              chunks.push(-2);
	              while (column++ < next) chunks.push(-1);
	              break;
	            }
	          case 10:
	            {
	              chunks.push(-4);
	              column = 1;
	              break;
	            }
	          default:
	            {
	              atCarriageReturn = true;
	              column = 1;
	            }
	        }
	      }
	      startPosition = endPosition + 1;
	    }
	    if (end) {
	      if (atCarriageReturn) chunks.push(-5);
	      if (buffer) chunks.push(buffer);
	      chunks.push(null);
	    }
	    return chunks;
	  }
	}

	const characterEscapeOrReference = /\\([!-/:-@[-`{-~])|&(#(?:\d{1,7}|x[\da-f]{1,6})|[\da-z]{1,31});/gi;

	/**
	 * Decode markdown strings (which occur in places such as fenced code info
	 * strings, destinations, labels, and titles).
	 *
	 * The string content type allows character escapes and -references.
	 * This decodes those.
	 *
	 * @param {string} value
	 *   Value to decode.
	 * @returns {string}
	 *   Decoded value.
	 */
	function decodeString(value) {
	  return value.replace(characterEscapeOrReference, decode);
	}

	/**
	 * @param {string} $0
	 *   Match.
	 * @param {string} $1
	 *   Character escape.
	 * @param {string} $2
	 *   Character reference.
	 * @returns {string}
	 *   Decoded value
	 */
	function decode($0, $1, $2) {
	  if ($1) {
	    // Escape.
	    return $1;
	  }

	  // Reference.
	  const head = $2.charCodeAt(0);
	  if (head === 35) {
	    const head = $2.charCodeAt(1);
	    const hex = head === 120 || head === 88;
	    return decodeNumericCharacterReference($2.slice(hex ? 2 : 1), hex ? 16 : 10);
	  }
	  return decodeNamedCharacterReference($2) || $0;
	}

	/**
	 * @import {
	 *   Break,
	 *   Blockquote,
	 *   Code,
	 *   Definition,
	 *   Emphasis,
	 *   Heading,
	 *   Html,
	 *   Image,
	 *   InlineCode,
	 *   Link,
	 *   ListItem,
	 *   List,
	 *   Nodes,
	 *   Paragraph,
	 *   PhrasingContent,
	 *   ReferenceType,
	 *   Root,
	 *   Strong,
	 *   Text,
	 *   ThematicBreak
	 * } from 'mdast'
	 * @import {
	 *   Encoding,
	 *   Event,
	 *   Token,
	 *   Value
	 * } from 'micromark-util-types'
	 * @import {Point} from 'unist'
	 * @import {
	 *   CompileContext,
	 *   CompileData,
	 *   Config,
	 *   Extension,
	 *   Handle,
	 *   OnEnterError,
	 *   Options
	 * } from './types.js'
	 */

	const own$2 = {}.hasOwnProperty;

	/**
	 * Turn markdown into a syntax tree.
	 *
	 * @overload
	 * @param {Value} value
	 * @param {Encoding | null | undefined} [encoding]
	 * @param {Options | null | undefined} [options]
	 * @returns {Root}
	 *
	 * @overload
	 * @param {Value} value
	 * @param {Options | null | undefined} [options]
	 * @returns {Root}
	 *
	 * @param {Value} value
	 *   Markdown to parse.
	 * @param {Encoding | Options | null | undefined} [encoding]
	 *   Character encoding for when `value` is `Buffer`.
	 * @param {Options | null | undefined} [options]
	 *   Configuration.
	 * @returns {Root}
	 *   mdast tree.
	 */
	function fromMarkdown(value, encoding, options) {
	  if (typeof encoding !== 'string') {
	    options = encoding;
	    encoding = undefined;
	  }
	  return compiler(options)(postprocess(parse(options).document().write(preprocess()(value, encoding, true))));
	}

	/**
	 * Note this compiler only understand complete buffering, not streaming.
	 *
	 * @param {Options | null | undefined} [options]
	 */
	function compiler(options) {
	  /** @type {Config} */
	  const config = {
	    transforms: [],
	    canContainEols: ['emphasis', 'fragment', 'heading', 'paragraph', 'strong'],
	    enter: {
	      autolink: opener(link),
	      autolinkProtocol: onenterdata,
	      autolinkEmail: onenterdata,
	      atxHeading: opener(heading),
	      blockQuote: opener(blockQuote),
	      characterEscape: onenterdata,
	      characterReference: onenterdata,
	      codeFenced: opener(codeFlow),
	      codeFencedFenceInfo: buffer,
	      codeFencedFenceMeta: buffer,
	      codeIndented: opener(codeFlow, buffer),
	      codeText: opener(codeText, buffer),
	      codeTextData: onenterdata,
	      data: onenterdata,
	      codeFlowValue: onenterdata,
	      definition: opener(definition),
	      definitionDestinationString: buffer,
	      definitionLabelString: buffer,
	      definitionTitleString: buffer,
	      emphasis: opener(emphasis),
	      hardBreakEscape: opener(hardBreak),
	      hardBreakTrailing: opener(hardBreak),
	      htmlFlow: opener(html, buffer),
	      htmlFlowData: onenterdata,
	      htmlText: opener(html, buffer),
	      htmlTextData: onenterdata,
	      image: opener(image),
	      label: buffer,
	      link: opener(link),
	      listItem: opener(listItem),
	      listItemValue: onenterlistitemvalue,
	      listOrdered: opener(list, onenterlistordered),
	      listUnordered: opener(list),
	      paragraph: opener(paragraph),
	      reference: onenterreference,
	      referenceString: buffer,
	      resourceDestinationString: buffer,
	      resourceTitleString: buffer,
	      setextHeading: opener(heading),
	      strong: opener(strong),
	      thematicBreak: opener(thematicBreak)
	    },
	    exit: {
	      atxHeading: closer(),
	      atxHeadingSequence: onexitatxheadingsequence,
	      autolink: closer(),
	      autolinkEmail: onexitautolinkemail,
	      autolinkProtocol: onexitautolinkprotocol,
	      blockQuote: closer(),
	      characterEscapeValue: onexitdata,
	      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,
	      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,
	      characterReferenceValue: onexitcharacterreferencevalue,
	      characterReference: onexitcharacterreference,
	      codeFenced: closer(onexitcodefenced),
	      codeFencedFence: onexitcodefencedfence,
	      codeFencedFenceInfo: onexitcodefencedfenceinfo,
	      codeFencedFenceMeta: onexitcodefencedfencemeta,
	      codeFlowValue: onexitdata,
	      codeIndented: closer(onexitcodeindented),
	      codeText: closer(onexitcodetext),
	      codeTextData: onexitdata,
	      data: onexitdata,
	      definition: closer(),
	      definitionDestinationString: onexitdefinitiondestinationstring,
	      definitionLabelString: onexitdefinitionlabelstring,
	      definitionTitleString: onexitdefinitiontitlestring,
	      emphasis: closer(),
	      hardBreakEscape: closer(onexithardbreak),
	      hardBreakTrailing: closer(onexithardbreak),
	      htmlFlow: closer(onexithtmlflow),
	      htmlFlowData: onexitdata,
	      htmlText: closer(onexithtmltext),
	      htmlTextData: onexitdata,
	      image: closer(onexitimage),
	      label: onexitlabel,
	      labelText: onexitlabeltext,
	      lineEnding: onexitlineending,
	      link: closer(onexitlink),
	      listItem: closer(),
	      listOrdered: closer(),
	      listUnordered: closer(),
	      paragraph: closer(),
	      referenceString: onexitreferencestring,
	      resourceDestinationString: onexitresourcedestinationstring,
	      resourceTitleString: onexitresourcetitlestring,
	      resource: onexitresource,
	      setextHeading: closer(onexitsetextheading),
	      setextHeadingLineSequence: onexitsetextheadinglinesequence,
	      setextHeadingText: onexitsetextheadingtext,
	      strong: closer(),
	      thematicBreak: closer()
	    }
	  };
	  configure$1(config, (options || {}).mdastExtensions || []);

	  /** @type {CompileData} */
	  const data = {};
	  return compile;

	  /**
	   * Turn micromark events into an mdast tree.
	   *
	   * @param {Array<Event>} events
	   *   Events.
	   * @returns {Root}
	   *   mdast tree.
	   */
	  function compile(events) {
	    /** @type {Root} */
	    let tree = {
	      type: 'root',
	      children: []
	    };
	    /** @type {Omit<CompileContext, 'sliceSerialize'>} */
	    const context = {
	      stack: [tree],
	      tokenStack: [],
	      config,
	      enter,
	      exit,
	      buffer,
	      resume,
	      data
	    };
	    /** @type {Array<number>} */
	    const listStack = [];
	    let index = -1;
	    while (++index < events.length) {
	      // We preprocess lists to add `listItem` tokens, and to infer whether
	      // items the list itself are spread out.
	      if (events[index][1].type === "listOrdered" || events[index][1].type === "listUnordered") {
	        if (events[index][0] === 'enter') {
	          listStack.push(index);
	        } else {
	          const tail = listStack.pop();
	          index = prepareList(events, tail, index);
	        }
	      }
	    }
	    index = -1;
	    while (++index < events.length) {
	      const handler = config[events[index][0]];
	      if (own$2.call(handler, events[index][1].type)) {
	        handler[events[index][1].type].call(Object.assign({
	          sliceSerialize: events[index][2].sliceSerialize
	        }, context), events[index][1]);
	      }
	    }

	    // Handle tokens still being open.
	    if (context.tokenStack.length > 0) {
	      const tail = context.tokenStack[context.tokenStack.length - 1];
	      const handler = tail[1] || defaultOnError;
	      handler.call(context, undefined, tail[0]);
	    }

	    // Figure out `root` position.
	    tree.position = {
	      start: point(events.length > 0 ? events[0][1].start : {
	        line: 1,
	        column: 1,
	        offset: 0
	      }),
	      end: point(events.length > 0 ? events[events.length - 2][1].end : {
	        line: 1,
	        column: 1,
	        offset: 0
	      })
	    };

	    // Call transforms.
	    index = -1;
	    while (++index < config.transforms.length) {
	      tree = config.transforms[index](tree) || tree;
	    }
	    return tree;
	  }

	  /**
	   * @param {Array<Event>} events
	   * @param {number} start
	   * @param {number} length
	   * @returns {number}
	   */
	  function prepareList(events, start, length) {
	    let index = start - 1;
	    let containerBalance = -1;
	    let listSpread = false;
	    /** @type {Token | undefined} */
	    let listItem;
	    /** @type {number | undefined} */
	    let lineIndex;
	    /** @type {number | undefined} */
	    let firstBlankLineIndex;
	    /** @type {boolean | undefined} */
	    let atMarker;
	    while (++index <= length) {
	      const event = events[index];
	      switch (event[1].type) {
	        case "listUnordered":
	        case "listOrdered":
	        case "blockQuote":
	          {
	            if (event[0] === 'enter') {
	              containerBalance++;
	            } else {
	              containerBalance--;
	            }
	            atMarker = undefined;
	            break;
	          }
	        case "lineEndingBlank":
	          {
	            if (event[0] === 'enter') {
	              if (listItem && !atMarker && !containerBalance && !firstBlankLineIndex) {
	                firstBlankLineIndex = index;
	              }
	              atMarker = undefined;
	            }
	            break;
	          }
	        case "linePrefix":
	        case "listItemValue":
	        case "listItemMarker":
	        case "listItemPrefix":
	        case "listItemPrefixWhitespace":
	          {
	            // Empty.

	            break;
	          }
	        default:
	          {
	            atMarker = undefined;
	          }
	      }
	      if (!containerBalance && event[0] === 'enter' && event[1].type === "listItemPrefix" || containerBalance === -1 && event[0] === 'exit' && (event[1].type === "listUnordered" || event[1].type === "listOrdered")) {
	        if (listItem) {
	          let tailIndex = index;
	          lineIndex = undefined;
	          while (tailIndex--) {
	            const tailEvent = events[tailIndex];
	            if (tailEvent[1].type === "lineEnding" || tailEvent[1].type === "lineEndingBlank") {
	              if (tailEvent[0] === 'exit') continue;
	              if (lineIndex) {
	                events[lineIndex][1].type = "lineEndingBlank";
	                listSpread = true;
	              }
	              tailEvent[1].type = "lineEnding";
	              lineIndex = tailIndex;
	            } else if (tailEvent[1].type === "linePrefix" || tailEvent[1].type === "blockQuotePrefix" || tailEvent[1].type === "blockQuotePrefixWhitespace" || tailEvent[1].type === "blockQuoteMarker" || tailEvent[1].type === "listItemIndent") ; else {
	              break;
	            }
	          }
	          if (firstBlankLineIndex && (!lineIndex || firstBlankLineIndex < lineIndex)) {
	            listItem._spread = true;
	          }

	          // Fix position.
	          listItem.end = Object.assign({}, lineIndex ? events[lineIndex][1].start : event[1].end);
	          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]]);
	          index++;
	          length++;
	        }

	        // Create a new list item.
	        if (event[1].type === "listItemPrefix") {
	          /** @type {Token} */
	          const item = {
	            type: 'listItem',
	            _spread: false,
	            start: Object.assign({}, event[1].start),
	            // @ts-expect-error: well add `end` in a second.
	            end: undefined
	          };
	          listItem = item;
	          events.splice(index, 0, ['enter', item, event[2]]);
	          index++;
	          length++;
	          firstBlankLineIndex = undefined;
	          atMarker = true;
	        }
	      }
	    }
	    events[start][1]._spread = listSpread;
	    return length;
	  }

	  /**
	   * Create an opener handle.
	   *
	   * @param {(token: Token) => Nodes} create
	   *   Create a node.
	   * @param {Handle | undefined} [and]
	   *   Optional function to also run.
	   * @returns {Handle}
	   *   Handle.
	   */
	  function opener(create, and) {
	    return open;

	    /**
	     * @this {CompileContext}
	     * @param {Token} token
	     * @returns {undefined}
	     */
	    function open(token) {
	      enter.call(this, create(token), token);
	      if (and) and.call(this, token);
	    }
	  }

	  /**
	   * @type {CompileContext['buffer']}
	   */
	  function buffer() {
	    this.stack.push({
	      type: 'fragment',
	      children: []
	    });
	  }

	  /**
	   * @type {CompileContext['enter']}
	   */
	  function enter(node, token, errorHandler) {
	    const parent = this.stack[this.stack.length - 1];
	    /** @type {Array<Nodes>} */
	    const siblings = parent.children;
	    siblings.push(node);
	    this.stack.push(node);
	    this.tokenStack.push([token, errorHandler || undefined]);
	    node.position = {
	      start: point(token.start),
	      // @ts-expect-error: `end` will be patched later.
	      end: undefined
	    };
	  }

	  /**
	   * Create a closer handle.
	   *
	   * @param {Handle | undefined} [and]
	   *   Optional function to also run.
	   * @returns {Handle}
	   *   Handle.
	   */
	  function closer(and) {
	    return close;

	    /**
	     * @this {CompileContext}
	     * @param {Token} token
	     * @returns {undefined}
	     */
	    function close(token) {
	      if (and) and.call(this, token);
	      exit.call(this, token);
	    }
	  }

	  /**
	   * @type {CompileContext['exit']}
	   */
	  function exit(token, onExitError) {
	    const node = this.stack.pop();
	    const open = this.tokenStack.pop();
	    if (!open) {
	      throw new Error('Cannot close `' + token.type + '` (' + stringifyPosition({
	        start: token.start,
	        end: token.end
	      }) + '): its not open');
	    } else if (open[0].type !== token.type) {
	      if (onExitError) {
	        onExitError.call(this, token, open[0]);
	      } else {
	        const handler = open[1] || defaultOnError;
	        handler.call(this, token, open[0]);
	      }
	    }
	    node.position.end = point(token.end);
	  }

	  /**
	   * @type {CompileContext['resume']}
	   */
	  function resume() {
	    return toString(this.stack.pop());
	  }

	  //
	  // Handlers.
	  //

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onenterlistordered() {
	    this.data.expectingFirstListItemValue = true;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onenterlistitemvalue(token) {
	    if (this.data.expectingFirstListItemValue) {
	      const ancestor = this.stack[this.stack.length - 2];
	      ancestor.start = Number.parseInt(this.sliceSerialize(token), 10);
	      this.data.expectingFirstListItemValue = undefined;
	    }
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcodefencedfenceinfo() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.lang = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcodefencedfencemeta() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.meta = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcodefencedfence() {
	    // Exit if this is the closing fence.
	    if (this.data.flowCodeInside) return;
	    this.buffer();
	    this.data.flowCodeInside = true;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcodefenced() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.value = data.replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
	    this.data.flowCodeInside = undefined;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcodeindented() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.value = data.replace(/(\r?\n|\r)$/g, '');
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitdefinitionlabelstring(token) {
	    const label = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.label = label;
	    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitdefinitiontitlestring() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.title = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitdefinitiondestinationstring() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.url = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitatxheadingsequence(token) {
	    const node = this.stack[this.stack.length - 1];
	    if (!node.depth) {
	      const depth = this.sliceSerialize(token).length;
	      node.depth = depth;
	    }
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitsetextheadingtext() {
	    this.data.setextHeadingSlurpLineEnding = true;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitsetextheadinglinesequence(token) {
	    const node = this.stack[this.stack.length - 1];
	    node.depth = this.sliceSerialize(token).codePointAt(0) === 61 ? 1 : 2;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitsetextheading() {
	    this.data.setextHeadingSlurpLineEnding = undefined;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onenterdata(token) {
	    const node = this.stack[this.stack.length - 1];
	    /** @type {Array<Nodes>} */
	    const siblings = node.children;
	    let tail = siblings[siblings.length - 1];
	    if (!tail || tail.type !== 'text') {
	      // Add a new text node.
	      tail = text();
	      tail.position = {
	        start: point(token.start),
	        // @ts-expect-error: well add `end` later.
	        end: undefined
	      };
	      siblings.push(tail);
	    }
	    this.stack.push(tail);
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitdata(token) {
	    const tail = this.stack.pop();
	    tail.value += this.sliceSerialize(token);
	    tail.position.end = point(token.end);
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitlineending(token) {
	    const context = this.stack[this.stack.length - 1];
	    // If were at a hard break, include the line ending in there.
	    if (this.data.atHardBreak) {
	      const tail = context.children[context.children.length - 1];
	      tail.position.end = point(token.end);
	      this.data.atHardBreak = undefined;
	      return;
	    }
	    if (!this.data.setextHeadingSlurpLineEnding && config.canContainEols.includes(context.type)) {
	      onenterdata.call(this, token);
	      onexitdata.call(this, token);
	    }
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexithardbreak() {
	    this.data.atHardBreak = true;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexithtmlflow() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.value = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexithtmltext() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.value = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitcodetext() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.value = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitlink() {
	    const node = this.stack[this.stack.length - 1];
	    // Note: there are also `identifier` and `label` fields on this link node!
	    // These are used / cleaned here.

	    // To do: clean.
	    if (this.data.inReference) {
	      /** @type {ReferenceType} */
	      const referenceType = this.data.referenceType || 'shortcut';
	      node.type += 'Reference';
	      // @ts-expect-error: mutate.
	      node.referenceType = referenceType;
	      // @ts-expect-error: mutate.
	      delete node.url;
	      delete node.title;
	    } else {
	      // @ts-expect-error: mutate.
	      delete node.identifier;
	      // @ts-expect-error: mutate.
	      delete node.label;
	    }
	    this.data.referenceType = undefined;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitimage() {
	    const node = this.stack[this.stack.length - 1];
	    // Note: there are also `identifier` and `label` fields on this link node!
	    // These are used / cleaned here.

	    // To do: clean.
	    if (this.data.inReference) {
	      /** @type {ReferenceType} */
	      const referenceType = this.data.referenceType || 'shortcut';
	      node.type += 'Reference';
	      // @ts-expect-error: mutate.
	      node.referenceType = referenceType;
	      // @ts-expect-error: mutate.
	      delete node.url;
	      delete node.title;
	    } else {
	      // @ts-expect-error: mutate.
	      delete node.identifier;
	      // @ts-expect-error: mutate.
	      delete node.label;
	    }
	    this.data.referenceType = undefined;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitlabeltext(token) {
	    const string = this.sliceSerialize(token);
	    const ancestor = this.stack[this.stack.length - 2];
	    // @ts-expect-error: stash this on the node, as it might become a reference
	    // later.
	    ancestor.label = decodeString(string);
	    // @ts-expect-error: same as above.
	    ancestor.identifier = normalizeIdentifier(string).toLowerCase();
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitlabel() {
	    const fragment = this.stack[this.stack.length - 1];
	    const value = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    // Assume a reference.
	    this.data.inReference = true;
	    if (node.type === 'link') {
	      /** @type {Array<PhrasingContent>} */
	      const children = fragment.children;
	      node.children = children;
	    } else {
	      node.alt = value;
	    }
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitresourcedestinationstring() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.url = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitresourcetitlestring() {
	    const data = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    node.title = data;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitresource() {
	    this.data.inReference = undefined;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onenterreference() {
	    this.data.referenceType = 'collapsed';
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitreferencestring(token) {
	    const label = this.resume();
	    const node = this.stack[this.stack.length - 1];
	    // @ts-expect-error: stash this on the node, as it might become a reference
	    // later.
	    node.label = label;
	    // @ts-expect-error: same as above.
	    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();
	    this.data.referenceType = 'full';
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */

	  function onexitcharacterreferencemarker(token) {
	    this.data.characterReferenceType = token.type;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcharacterreferencevalue(token) {
	    const data = this.sliceSerialize(token);
	    const type = this.data.characterReferenceType;
	    /** @type {string} */
	    let value;
	    if (type) {
	      value = decodeNumericCharacterReference(data, type === "characterReferenceMarkerNumeric" ? 10 : 16);
	      this.data.characterReferenceType = undefined;
	    } else {
	      const result = decodeNamedCharacterReference(data);
	      value = result;
	    }
	    const tail = this.stack[this.stack.length - 1];
	    tail.value += value;
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitcharacterreference(token) {
	    const tail = this.stack.pop();
	    tail.position.end = point(token.end);
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitautolinkprotocol(token) {
	    onexitdata.call(this, token);
	    const node = this.stack[this.stack.length - 1];
	    node.url = this.sliceSerialize(token);
	  }

	  /**
	   * @this {CompileContext}
	   * @type {Handle}
	   */
	  function onexitautolinkemail(token) {
	    onexitdata.call(this, token);
	    const node = this.stack[this.stack.length - 1];
	    node.url = 'mailto:' + this.sliceSerialize(token);
	  }

	  //
	  // Creaters.
	  //

	  /** @returns {Blockquote} */
	  function blockQuote() {
	    return {
	      type: 'blockquote',
	      children: []
	    };
	  }

	  /** @returns {Code} */
	  function codeFlow() {
	    return {
	      type: 'code',
	      lang: null,
	      meta: null,
	      value: ''
	    };
	  }

	  /** @returns {InlineCode} */
	  function codeText() {
	    return {
	      type: 'inlineCode',
	      value: ''
	    };
	  }

	  /** @returns {Definition} */
	  function definition() {
	    return {
	      type: 'definition',
	      identifier: '',
	      label: null,
	      title: null,
	      url: ''
	    };
	  }

	  /** @returns {Emphasis} */
	  function emphasis() {
	    return {
	      type: 'emphasis',
	      children: []
	    };
	  }

	  /** @returns {Heading} */
	  function heading() {
	    return {
	      type: 'heading',
	      // @ts-expect-error `depth` will be set later.
	      depth: 0,
	      children: []
	    };
	  }

	  /** @returns {Break} */
	  function hardBreak() {
	    return {
	      type: 'break'
	    };
	  }

	  /** @returns {Html} */
	  function html() {
	    return {
	      type: 'html',
	      value: ''
	    };
	  }

	  /** @returns {Image} */
	  function image() {
	    return {
	      type: 'image',
	      title: null,
	      url: '',
	      alt: null
	    };
	  }

	  /** @returns {Link} */
	  function link() {
	    return {
	      type: 'link',
	      title: null,
	      url: '',
	      children: []
	    };
	  }

	  /**
	   * @param {Token} token
	   * @returns {List}
	   */
	  function list(token) {
	    return {
	      type: 'list',
	      ordered: token.type === 'listOrdered',
	      start: null,
	      spread: token._spread,
	      children: []
	    };
	  }

	  /**
	   * @param {Token} token
	   * @returns {ListItem}
	   */
	  function listItem(token) {
	    return {
	      type: 'listItem',
	      spread: token._spread,
	      checked: null,
	      children: []
	    };
	  }

	  /** @returns {Paragraph} */
	  function paragraph() {
	    return {
	      type: 'paragraph',
	      children: []
	    };
	  }

	  /** @returns {Strong} */
	  function strong() {
	    return {
	      type: 'strong',
	      children: []
	    };
	  }

	  /** @returns {Text} */
	  function text() {
	    return {
	      type: 'text',
	      value: ''
	    };
	  }

	  /** @returns {ThematicBreak} */
	  function thematicBreak() {
	    return {
	      type: 'thematicBreak'
	    };
	  }
	}

	/**
	 * Copy a point-like value.
	 *
	 * @param {Point} d
	 *   Point-like value.
	 * @returns {Point}
	 *   unist point.
	 */
	function point(d) {
	  return {
	    line: d.line,
	    column: d.column,
	    offset: d.offset
	  };
	}

	/**
	 * @param {Config} combined
	 * @param {Array<Array<Extension> | Extension>} extensions
	 * @returns {undefined}
	 */
	function configure$1(combined, extensions) {
	  let index = -1;
	  while (++index < extensions.length) {
	    const value = extensions[index];
	    if (Array.isArray(value)) {
	      configure$1(combined, value);
	    } else {
	      extension(combined, value);
	    }
	  }
	}

	/**
	 * @param {Config} combined
	 * @param {Extension} extension
	 * @returns {undefined}
	 */
	function extension(combined, extension) {
	  /** @type {keyof Extension} */
	  let key;
	  for (key in extension) {
	    if (own$2.call(extension, key)) {
	      switch (key) {
	        case 'canContainEols':
	          {
	            const right = extension[key];
	            if (right) {
	              combined[key].push(...right);
	            }
	            break;
	          }
	        case 'transforms':
	          {
	            const right = extension[key];
	            if (right) {
	              combined[key].push(...right);
	            }
	            break;
	          }
	        case 'enter':
	        case 'exit':
	          {
	            const right = extension[key];
	            if (right) {
	              Object.assign(combined[key], right);
	            }
	            break;
	          }
	        // No default
	      }
	    }
	  }
	}

	/** @type {OnEnterError} */
	function defaultOnError(left, right) {
	  if (left) {
	    throw new Error('Cannot close `' + left.type + '` (' + stringifyPosition({
	      start: left.start,
	      end: left.end
	    }) + '): a different token (`' + right.type + '`, ' + stringifyPosition({
	      start: right.start,
	      end: right.end
	    }) + ') is open');
	  } else {
	    throw new Error('Cannot close document, a token (`' + right.type + '`, ' + stringifyPosition({
	      start: right.start,
	      end: right.end
	    }) + ') is still open');
	  }
	}

	/**
	 * @typedef {import('mdast').Root} Root
	 * @typedef {import('mdast-util-from-markdown').Options} FromMarkdownOptions
	 * @typedef {import('unified').Parser<Root>} Parser
	 * @typedef {import('unified').Processor<Root>} Processor
	 */


	/**
	 * Aadd support for parsing from markdown.
	 *
	 * @param {Readonly<Options> | null | undefined} [options]
	 *   Configuration (optional).
	 * @returns {undefined}
	 *   Nothing.
	 */
	function remarkParse(options) {
	  /** @type {Processor} */
	  // @ts-expect-error: TS in JSDoc generates wrong types if `this` is typed regularly.
	  const self = this;

	  self.parser = parser;

	  /**
	   * @type {Parser}
	   */
	  function parser(doc) {
	    return fromMarkdown(doc, {
	      ...self.data('settings'),
	      ...options,
	      // Note: these options are not in the readme.
	      // The goal is for them to be set by plugins on `data` instead of being
	      // passed by users.
	      extensions: self.data('micromarkExtensions') || [],
	      mdastExtensions: self.data('fromMarkdownExtensions') || []
	    })
	  }
	}

	/**
	 * @callback Handler
	 *   Handle a value, with a certain ID field set to a certain value.
	 *   The ID field is passed to `zwitch`, and its value is this functions
	 *   place on the `handlers` record.
	 * @param {...any} parameters
	 *   Arbitrary parameters passed to the zwitch.
	 *   The first will be an object with a certain ID field set to a certain value.
	 * @returns {any}
	 *   Anything!
	 */

	/**
	 * @callback UnknownHandler
	 *   Handle values that do have a certain ID field, but its set to a value
	 *   that is not listed in the `handlers` record.
	 * @param {unknown} value
	 *   An object with a certain ID field set to an unknown value.
	 * @param {...any} rest
	 *   Arbitrary parameters passed to the zwitch.
	 * @returns {any}
	 *   Anything!
	 */

	/**
	 * @callback InvalidHandler
	 *   Handle values that do not have a certain ID field.
	 * @param {unknown} value
	 *   Any unknown value.
	 * @param {...any} rest
	 *   Arbitrary parameters passed to the zwitch.
	 * @returns {void|null|undefined|never}
	 *   This should crash or return nothing.
	 */

	/**
	 * @template {InvalidHandler} [Invalid=InvalidHandler]
	 * @template {UnknownHandler} [Unknown=UnknownHandler]
	 * @template {Record<string, Handler>} [Handlers=Record<string, Handler>]
	 * @typedef Options
	 *   Configuration (required).
	 * @property {Invalid} [invalid]
	 *   Handler to use for invalid values.
	 * @property {Unknown} [unknown]
	 *   Handler to use for unknown values.
	 * @property {Handlers} [handlers]
	 *   Handlers to use.
	 */

	const own$1 = {}.hasOwnProperty;

	/**
	 * Handle values based on a field.
	 *
	 * @template {InvalidHandler} [Invalid=InvalidHandler]
	 * @template {UnknownHandler} [Unknown=UnknownHandler]
	 * @template {Record<string, Handler>} [Handlers=Record<string, Handler>]
	 * @param {string} key
	 *   Field to switch on.
	 * @param {Options<Invalid, Unknown, Handlers>} [options]
	 *   Configuration (required).
	 * @returns {{unknown: Unknown, invalid: Invalid, handlers: Handlers, (...parameters: Parameters<Handlers[keyof Handlers]>): ReturnType<Handlers[keyof Handlers]>, (...parameters: Parameters<Unknown>): ReturnType<Unknown>}}
	 */
	function zwitch(key, options) {
	  const settings = options || {};

	  /**
	   * Handle one value.
	   *
	   * Based on the bound `key`, a respective handler will be called.
	   * If `value` is not an object, or doesnt have a `key` property, the special
	   * invalid handler will be called.
	   * If `value` has an unknown `key`, the special unknown handler will be
	   * called.
	   *
	   * All arguments, and the context object, are passed through to the handler,
	   * and its result is returned.
	   *
	   * @this {unknown}
	   *   Any context object.
	   * @param {unknown} [value]
	   *   Any value.
	   * @param {...unknown} parameters
	   *   Arbitrary parameters passed to the zwitch.
	   * @property {Handler} invalid
	   *   Handle for values that do not have a certain ID field.
	   * @property {Handler} unknown
	   *   Handle values that do have a certain ID field, but its set to a value
	   *   that is not listed in the `handlers` record.
	   * @property {Handlers} handlers
	   *   Record of handlers.
	   * @returns {unknown}
	   *   Anything.
	   */
	  function one(value, ...parameters) {
	    /** @type {Handler|undefined} */
	    let fn = one.invalid;
	    const handlers = one.handlers;

	    if (value && own$1.call(value, key)) {
	      // @ts-expect-error Indexable.
	      const id = String(value[key]);
	      // @ts-expect-error Indexable.
	      fn = own$1.call(handlers, id) ? handlers[id] : one.unknown;
	    }

	    if (fn) {
	      return fn.call(this, value, ...parameters)
	    }
	  }

	  one.handlers = settings.handlers || {};
	  one.invalid = settings.invalid;
	  one.unknown = settings.unknown;

	  // @ts-expect-error: matches!
	  return one
	}

	/**
	 * @import {Options, State} from './types.js'
	 */

	const own = {}.hasOwnProperty;

	/**
	 * @param {State} base
	 * @param {Options} extension
	 * @returns {State}
	 */
	function configure(base, extension) {
	  let index = -1;
	  /** @type {keyof Options} */
	  let key;

	  // First do subextensions.
	  if (extension.extensions) {
	    while (++index < extension.extensions.length) {
	      configure(base, extension.extensions[index]);
	    }
	  }

	  for (key in extension) {
	    if (own.call(extension, key)) {
	      switch (key) {
	        case 'extensions': {
	          // Empty.
	          break
	        }

	        /* c8 ignore next 4 */
	        case 'unsafe': {
	          list$1(base[key], extension[key]);
	          break
	        }

	        case 'join': {
	          list$1(base[key], extension[key]);
	          break
	        }

	        case 'handlers': {
	          map$2(base[key], extension[key]);
	          break
	        }

	        default: {
	          // @ts-expect-error: matches.
	          base.options[key] = extension[key];
	        }
	      }
	    }
	  }

	  return base
	}

	/**
	 * @template T
	 * @param {Array<T>} left
	 * @param {Array<T> | null | undefined} right
	 */
	function list$1(left, right) {
	  if (right) {
	    left.push(...right);
	  }
	}

	/**
	 * @template T
	 * @param {Record<string, T>} left
	 * @param {Record<string, T> | null | undefined} right
	 */
	function map$2(left, right) {
	  if (right) {
	    Object.assign(left, right);
	  }
	}

	/**
	 * @import {Blockquote, Parents} from 'mdast'
	 * @import {Info, Map, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {Blockquote} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function blockquote(node, _, state, info) {
	  const exit = state.enter('blockquote');
	  const tracker = state.createTracker(info);
	  tracker.move('> ');
	  tracker.shift(2);
	  const value = state.indentLines(
	    state.containerFlow(node, tracker.current()),
	    map$1
	  );
	  exit();
	  return value
	}

	/** @type {Map} */
	function map$1(line, _, blank) {
	  return '>' + (blank ? '' : ' ') + line
	}

	/**
	 * @import {ConstructName, Unsafe} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {Array<ConstructName>} stack
	 * @param {Unsafe} pattern
	 * @returns {boolean}
	 */
	function patternInScope(stack, pattern) {
	  return (
	    listInScope(stack, pattern.inConstruct, true) &&
	    !listInScope(stack, pattern.notInConstruct, false)
	  )
	}

	/**
	 * @param {Array<ConstructName>} stack
	 * @param {Unsafe['inConstruct']} list
	 * @param {boolean} none
	 * @returns {boolean}
	 */
	function listInScope(stack, list, none) {
	  if (typeof list === 'string') {
	    list = [list];
	  }

	  if (!list || list.length === 0) {
	    return none
	  }

	  let index = -1;

	  while (++index < list.length) {
	    if (stack.includes(list[index])) {
	      return true
	    }
	  }

	  return false
	}

	/**
	 * @import {Break, Parents} from 'mdast'
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 */


	/**
	 * @param {Break} _
	 * @param {Parents | undefined} _1
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function hardBreak(_, _1, state, info) {
	  let index = -1;

	  while (++index < state.unsafe.length) {
	    // If we cant put eols in this construct (setext headings, tables), use a
	    // space instead.
	    if (
	      state.unsafe[index].character === '\n' &&
	      patternInScope(state.stack, state.unsafe[index])
	    ) {
	      return /[ \t]/.test(info.before) ? '' : ' '
	    }
	  }

	  return '\\\n'
	}

	/**
	 * Get the count of the longest repeating streak of `substring` in `value`.
	 *
	 * @param {string} value
	 *   Content to search in.
	 * @param {string} substring
	 *   Substring to look for, typically one character.
	 * @returns {number}
	 *   Count of most frequent adjacent `substring`s in `value`.
	 */
	function longestStreak(value, substring) {
	  const source = String(value);
	  let index = source.indexOf(substring);
	  let expected = index;
	  let count = 0;
	  let max = 0;

	  if (typeof substring !== 'string') {
	    throw new TypeError('Expected substring')
	  }

	  while (index !== -1) {
	    if (index === expected) {
	      if (++count > max) {
	        max = count;
	      }
	    } else {
	      count = 1;
	    }

	    expected = index + substring.length;
	    index = source.indexOf(substring, expected);
	  }

	  return max
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {Code} from 'mdast'
	 */

	/**
	 * @param {Code} node
	 * @param {State} state
	 * @returns {boolean}
	 */
	function formatCodeAsIndented(node, state) {
	  return Boolean(
	    state.options.fences === false &&
	      node.value &&
	      // If theres no info
	      !node.lang &&
	      // And theres a non-whitespace character
	      /[^ \r\n]/.test(node.value) &&
	      // And the value doesnt start or end in a blank
	      !/^[\t ]*(?:[\r\n]|$)|(?:^|[\r\n])[\t ]*$/.test(node.value)
	  )
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['fence'], null | undefined>}
	 */
	function checkFence(state) {
	  const marker = state.options.fence || '`';

	  if (marker !== '`' && marker !== '~') {
	    throw new Error(
	      'Cannot serialize code with `' +
	        marker +
	        '` for `options.fence`, expected `` ` `` or `~`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Info, Map, State} from 'mdast-util-to-markdown'
	 * @import {Code, Parents} from 'mdast'
	 */


	/**
	 * @param {Code} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function code(node, _, state, info) {
	  const marker = checkFence(state);
	  const raw = node.value || '';
	  const suffix = marker === '`' ? 'GraveAccent' : 'Tilde';

	  if (formatCodeAsIndented(node, state)) {
	    const exit = state.enter('codeIndented');
	    const value = state.indentLines(raw, map);
	    exit();
	    return value
	  }

	  const tracker = state.createTracker(info);
	  const sequence = marker.repeat(Math.max(longestStreak(raw, marker) + 1, 3));
	  const exit = state.enter('codeFenced');
	  let value = tracker.move(sequence);

	  if (node.lang) {
	    const subexit = state.enter(`codeFencedLang${suffix}`);
	    value += tracker.move(
	      state.safe(node.lang, {
	        before: value,
	        after: ' ',
	        encode: ['`'],
	        ...tracker.current()
	      })
	    );
	    subexit();
	  }

	  if (node.lang && node.meta) {
	    const subexit = state.enter(`codeFencedMeta${suffix}`);
	    value += tracker.move(' ');
	    value += tracker.move(
	      state.safe(node.meta, {
	        before: value,
	        after: '\n',
	        encode: ['`'],
	        ...tracker.current()
	      })
	    );
	    subexit();
	  }

	  value += tracker.move('\n');

	  if (raw) {
	    value += tracker.move(raw + '\n');
	  }

	  value += tracker.move(sequence);
	  exit();
	  return value
	}

	/** @type {Map} */
	function map(line, _, blank) {
	  return (blank ? '' : '    ') + line
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['quote'], null | undefined>}
	 */
	function checkQuote(state) {
	  const marker = state.options.quote || '"';

	  if (marker !== '"' && marker !== "'") {
	    throw new Error(
	      'Cannot serialize title with `' +
	        marker +
	        '` for `options.quote`, expected `"`, or `\'`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Definition, Parents} from 'mdast'
	 */


	/**
	 * @param {Definition} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function definition(node, _, state, info) {
	  const quote = checkQuote(state);
	  const suffix = quote === '"' ? 'Quote' : 'Apostrophe';
	  const exit = state.enter('definition');
	  let subexit = state.enter('label');
	  const tracker = state.createTracker(info);
	  let value = tracker.move('[');
	  value += tracker.move(
	    state.safe(state.associationId(node), {
	      before: value,
	      after: ']',
	      ...tracker.current()
	    })
	  );
	  value += tracker.move(']: ');

	  subexit();

	  if (
	    // If theres no url, or
	    !node.url ||
	    // If there are control characters or whitespace.
	    /[\0- \u007F]/.test(node.url)
	  ) {
	    subexit = state.enter('destinationLiteral');
	    value += tracker.move('<');
	    value += tracker.move(
	      state.safe(node.url, {before: value, after: '>', ...tracker.current()})
	    );
	    value += tracker.move('>');
	  } else {
	    // No whitespace, raw is prettier.
	    subexit = state.enter('destinationRaw');
	    value += tracker.move(
	      state.safe(node.url, {
	        before: value,
	        after: node.title ? ' ' : '\n',
	        ...tracker.current()
	      })
	    );
	  }

	  subexit();

	  if (node.title) {
	    subexit = state.enter(`title${suffix}`);
	    value += tracker.move(' ' + quote);
	    value += tracker.move(
	      state.safe(node.title, {
	        before: value,
	        after: quote,
	        ...tracker.current()
	      })
	    );
	    value += tracker.move(quote);
	    subexit();
	  }

	  exit();

	  return value
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['emphasis'], null | undefined>}
	 */
	function checkEmphasis(state) {
	  const marker = state.options.emphasis || '*';

	  if (marker !== '*' && marker !== '_') {
	    throw new Error(
	      'Cannot serialize emphasis with `' +
	        marker +
	        '` for `options.emphasis`, expected `*`, or `_`'
	    )
	  }

	  return marker
	}

	/**
	 * Encode a code point as a character reference.
	 *
	 * @param {number} code
	 *   Code point to encode.
	 * @returns {string}
	 *   Encoded character reference.
	 */
	function encodeCharacterReference(code) {
	  return '&#x' + code.toString(16).toUpperCase() + ';'
	}

	/**
	 * @import {EncodeSides} from '../types.js'
	 */


	/**
	 * Check whether to encode (as a character reference) the characters
	 * surrounding an attention run.
	 *
	 * Which characters are around an attention run influence whether it works or
	 * not.
	 *
	 * See <https://github.com/orgs/syntax-tree/discussions/60> for more info.
	 * See this markdown in a particular renderer to see what works:
	 *
	 * ```markdown
	 * |                         | A (letter inside) | B (punctuation inside) | C (whitespace inside) | D (nothing inside) |
	 * | ----------------------- | ----------------- | ---------------------- | --------------------- | ------------------ |
	 * | 1 (letter outside)      | x*y*z             | x*.*z                  | x* *z                 | x**z               |
	 * | 2 (punctuation outside) | .*y*.             | .*.*.                  | .* *.                 | .**.               |
	 * | 3 (whitespace outside)  | x *y* z           | x *.* z                | x * * z               | x ** z             |
	 * | 4 (nothing outside)     | *x*               | *.*                    | * *                   | **                 |
	 * ```
	 *
	 * @param {number} outside
	 *   Code point on the outer side of the run.
	 * @param {number} inside
	 *   Code point on the inner side of the run.
	 * @param {'*' | '_'} marker
	 *   Marker of the run.
	 *   Underscores are handled more strictly (they form less often) than
	 *   asterisks.
	 * @returns {EncodeSides}
	 *   Whether to encode characters.
	 */
	// Important: punctuation must never be encoded.
	// Punctuation is solely used by markdown constructs.
	// And by encoding itself.
	// Encoding them will break constructs or double encode things.
	function encodeInfo(outside, inside, marker) {
	  const outsideKind = classifyCharacter(outside);
	  const insideKind = classifyCharacter(inside);

	  // Letter outside:
	  if (outsideKind === undefined) {
	    return insideKind === undefined
	      ? // Letter inside:
	        // we have to encode *both* letters for `_` as it is looser.
	        // it already forms for `*` (and GFMs `~`).
	        marker === '_'
	        ? {inside: true, outside: true}
	        : {inside: false, outside: false}
	      : insideKind === 1
	        ? // Whitespace inside: encode both (letter, whitespace).
	          {inside: true, outside: true}
	        : // Punctuation inside: encode outer (letter)
	          {inside: false, outside: true}
	  }

	  // Whitespace outside:
	  if (outsideKind === 1) {
	    return insideKind === undefined
	      ? // Letter inside: already forms.
	        {inside: false, outside: false}
	      : insideKind === 1
	        ? // Whitespace inside: encode both (whitespace).
	          {inside: true, outside: true}
	        : // Punctuation inside: already forms.
	          {inside: false, outside: false}
	  }

	  // Punctuation outside:
	  return insideKind === undefined
	    ? // Letter inside: already forms.
	      {inside: false, outside: false}
	    : insideKind === 1
	      ? // Whitespace inside: encode inner (whitespace).
	        {inside: true, outside: false}
	      : // Punctuation inside: already forms.
	        {inside: false, outside: false}
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Emphasis, Parents} from 'mdast'
	 */


	emphasis.peek = emphasisPeek;

	/**
	 * @param {Emphasis} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function emphasis(node, _, state, info) {
	  const marker = checkEmphasis(state);
	  const exit = state.enter('emphasis');
	  const tracker = state.createTracker(info);
	  const before = tracker.move(marker);

	  let between = tracker.move(
	    state.containerPhrasing(node, {
	      after: marker,
	      before,
	      ...tracker.current()
	    })
	  );
	  const betweenHead = between.charCodeAt(0);
	  const open = encodeInfo(
	    info.before.charCodeAt(info.before.length - 1),
	    betweenHead,
	    marker
	  );

	  if (open.inside) {
	    between = encodeCharacterReference(betweenHead) + between.slice(1);
	  }

	  const betweenTail = between.charCodeAt(between.length - 1);
	  const close = encodeInfo(info.after.charCodeAt(0), betweenTail, marker);

	  if (close.inside) {
	    between = between.slice(0, -1) + encodeCharacterReference(betweenTail);
	  }

	  const after = tracker.move(marker);

	  exit();

	  state.attentionEncodeSurroundingInfo = {
	    after: close.outside,
	    before: open.outside
	  };
	  return before + between + after
	}

	/**
	 * @param {Emphasis} _
	 * @param {Parents | undefined} _1
	 * @param {State} state
	 * @returns {string}
	 */
	function emphasisPeek(_, _1, state) {
	  return state.options.emphasis || '*'
	}

	/**
	 * @typedef {import('unist').Node} Node
	 * @typedef {import('unist').Parent} Parent
	 */


	/**
	 * Generate an assertion from a test.
	 *
	 * Useful if youre going to test many nodes, for example when creating a
	 * utility where something else passes a compatible test.
	 *
	 * The created function is a bit faster because it expects valid input only:
	 * a `node`, `index`, and `parent`.
	 *
	 * @param {Test} test
	 *   *   when nullish, checks if `node` is a `Node`.
	 *   *   when `string`, works like passing `(node) => node.type === test`.
	 *   *   when `function` checks if function passed the node is true.
	 *   *   when `object`, checks that all keys in test are in node, and that they have (strictly) equal values.
	 *   *   when `array`, checks if any one of the subtests pass.
	 * @returns {Check}
	 *   An assertion.
	 */
	const convert =
	  // Note: overloads in JSDoc cant yet use different `@template`s.
	  /**
	   * @type {(
	   *   (<Condition extends string>(test: Condition) => (node: unknown, index?: number | null | undefined, parent?: Parent | null | undefined, context?: unknown) => node is Node & {type: Condition}) &
	   *   (<Condition extends Props>(test: Condition) => (node: unknown, index?: number | null | undefined, parent?: Parent | null | undefined, context?: unknown) => node is Node & Condition) &
	   *   (<Condition extends TestFunction>(test: Condition) => (node: unknown, index?: number | null | undefined, parent?: Parent | null | undefined, context?: unknown) => node is Node & Predicate<Condition, Node>) &
	   *   ((test?: null | undefined) => (node?: unknown, index?: number | null | undefined, parent?: Parent | null | undefined, context?: unknown) => node is Node) &
	   *   ((test?: Test) => Check)
	   * )}
	   */
	  (
	    /**
	     * @param {Test} [test]
	     * @returns {Check}
	     */
	    function (test) {
	      if (test === null || test === undefined) {
	        return ok
	      }

	      if (typeof test === 'function') {
	        return castFactory(test)
	      }

	      if (typeof test === 'object') {
	        return Array.isArray(test) ? anyFactory(test) : propsFactory(test)
	      }

	      if (typeof test === 'string') {
	        return typeFactory(test)
	      }

	      throw new Error('Expected function, string, or object as test')
	    }
	  );

	/**
	 * @param {Array<Props | TestFunction | string>} tests
	 * @returns {Check}
	 */
	function anyFactory(tests) {
	  /** @type {Array<Check>} */
	  const checks = [];
	  let index = -1;

	  while (++index < tests.length) {
	    checks[index] = convert(tests[index]);
	  }

	  return castFactory(any)

	  /**
	   * @this {unknown}
	   * @type {TestFunction}
	   */
	  function any(...parameters) {
	    let index = -1;

	    while (++index < checks.length) {
	      if (checks[index].apply(this, parameters)) return true
	    }

	    return false
	  }
	}

	/**
	 * Turn an object into a test for a node with a certain fields.
	 *
	 * @param {Props} check
	 * @returns {Check}
	 */
	function propsFactory(check) {
	  const checkAsRecord = /** @type {Record<string, unknown>} */ (check);

	  return castFactory(all)

	  /**
	   * @param {Node} node
	   * @returns {boolean}
	   */
	  function all(node) {
	    const nodeAsRecord = /** @type {Record<string, unknown>} */ (
	      /** @type {unknown} */ (node)
	    );

	    /** @type {string} */
	    let key;

	    for (key in check) {
	      if (nodeAsRecord[key] !== checkAsRecord[key]) return false
	    }

	    return true
	  }
	}

	/**
	 * Turn a string into a test for a node with a certain type.
	 *
	 * @param {string} check
	 * @returns {Check}
	 */
	function typeFactory(check) {
	  return castFactory(type)

	  /**
	   * @param {Node} node
	   */
	  function type(node) {
	    return node && node.type === check
	  }
	}

	/**
	 * Turn a custom test into a test for a node that passes that test.
	 *
	 * @param {TestFunction} testFunction
	 * @returns {Check}
	 */
	function castFactory(testFunction) {
	  return check

	  /**
	   * @this {unknown}
	   * @type {Check}
	   */
	  function check(value, index, parent) {
	    return Boolean(
	      looksLikeANode(value) &&
	        testFunction.call(
	          this,
	          value,
	          typeof index === 'number' ? index : undefined,
	          parent || undefined
	        )
	    )
	  }
	}

	function ok() {
	  return true
	}

	/**
	 * @param {unknown} value
	 * @returns {value is Node}
	 */
	function looksLikeANode(value) {
	  return value !== null && typeof value === 'object' && 'type' in value
	}

	/**
	 * @param {string} d
	 * @returns {string}
	 */
	function color(d) {
	  return d
	}

	/**
	 * @typedef {import('unist').Node} UnistNode
	 * @typedef {import('unist').Parent} UnistParent
	 */


	/** @type {Readonly<ActionTuple>} */
	const empty = [];

	/**
	 * Continue traversing as normal.
	 */
	const CONTINUE = true;

	/**
	 * Stop traversing immediately.
	 */
	const EXIT = false;

	/**
	 * Do not traverse this nodes children.
	 */
	const SKIP = 'skip';

	/**
	 * Visit nodes, with ancestral information.
	 *
	 * This algorithm performs *depth-first* *tree traversal* in *preorder*
	 * (**NLR**) or if `reverse` is given, in *reverse preorder* (**NRL**).
	 *
	 * You can choose for which nodes `visitor` is called by passing a `test`.
	 * For complex tests, you should test yourself in `visitor`, as it will be
	 * faster and will have improved type information.
	 *
	 * Walking the tree is an intensive task.
	 * Make use of the return values of the visitor when possible.
	 * Instead of walking a tree multiple times, walk it once, use `unist-util-is`
	 * to check if a node matches, and then perform different operations.
	 *
	 * You can change the tree.
	 * See `Visitor` for more info.
	 *
	 * @overload
	 * @param {Tree} tree
	 * @param {Check} check
	 * @param {BuildVisitor<Tree, Check>} visitor
	 * @param {boolean | null | undefined} [reverse]
	 * @returns {undefined}
	 *
	 * @overload
	 * @param {Tree} tree
	 * @param {BuildVisitor<Tree>} visitor
	 * @param {boolean | null | undefined} [reverse]
	 * @returns {undefined}
	 *
	 * @param {UnistNode} tree
	 *   Tree to traverse.
	 * @param {Visitor | Test} test
	 *   `unist-util-is`-compatible test
	 * @param {Visitor | boolean | null | undefined} [visitor]
	 *   Handle each node.
	 * @param {boolean | null | undefined} [reverse]
	 *   Traverse in reverse preorder (NRL) instead of the default preorder (NLR).
	 * @returns {undefined}
	 *   Nothing.
	 *
	 * @template {UnistNode} Tree
	 *   Node type.
	 * @template {Test} Check
	 *   `unist-util-is`-compatible test.
	 */
	function visitParents(tree, test, visitor, reverse) {
	  /** @type {Test} */
	  let check;

	  if (typeof test === 'function' && typeof visitor !== 'function') {
	    reverse = visitor;
	    // @ts-expect-error no visitor given, so `visitor` is test.
	    visitor = test;
	  } else {
	    // @ts-expect-error visitor given, so `test` isnt a visitor.
	    check = test;
	  }

	  const is = convert(check);
	  const step = reverse ? -1 : 1;

	  factory(tree, undefined, [])();

	  /**
	   * @param {UnistNode} node
	   * @param {number | undefined} index
	   * @param {Array<UnistParent>} parents
	   */
	  function factory(node, index, parents) {
	    const value = /** @type {Record<string, unknown>} */ (
	      node && typeof node === 'object' ? node : {}
	    );

	    if (typeof value.type === 'string') {
	      const name =
	        // `hast`
	        typeof value.tagName === 'string'
	          ? value.tagName
	          : // `xast`
	          typeof value.name === 'string'
	          ? value.name
	          : undefined;

	      Object.defineProperty(visit, 'name', {
	        value:
	          'node (' + color(node.type + (name ? '<' + name + '>' : '')) + ')'
	      });
	    }

	    return visit

	    function visit() {
	      /** @type {Readonly<ActionTuple>} */
	      let result = empty;
	      /** @type {Readonly<ActionTuple>} */
	      let subresult;
	      /** @type {number} */
	      let offset;
	      /** @type {Array<UnistParent>} */
	      let grandparents;

	      if (!test || is(node, index, parents[parents.length - 1] || undefined)) {
	        // @ts-expect-error: `visitor` is now a visitor.
	        result = toResult(visitor(node, parents));

	        if (result[0] === EXIT) {
	          return result
	        }
	      }

	      if ('children' in node && node.children) {
	        const nodeAsParent = /** @type {UnistParent} */ (node);

	        if (nodeAsParent.children && result[0] !== SKIP) {
	          offset = (reverse ? nodeAsParent.children.length : -1) + step;
	          grandparents = parents.concat(nodeAsParent);

	          while (offset > -1 && offset < nodeAsParent.children.length) {
	            const child = nodeAsParent.children[offset];

	            subresult = factory(child, offset, grandparents)();

	            if (subresult[0] === EXIT) {
	              return subresult
	            }

	            offset =
	              typeof subresult[1] === 'number' ? subresult[1] : offset + step;
	          }
	        }
	      }

	      return result
	    }
	  }
	}

	/**
	 * Turn a return value into a clean result.
	 *
	 * @param {VisitorResult} value
	 *   Valid return values from visitors.
	 * @returns {Readonly<ActionTuple>}
	 *   Clean result.
	 */
	function toResult(value) {
	  if (Array.isArray(value)) {
	    return value
	  }

	  if (typeof value === 'number') {
	    return [CONTINUE, value]
	  }

	  return value === null || value === undefined ? empty : [value]
	}

	/**
	 * @typedef {import('unist').Node} UnistNode
	 * @typedef {import('unist').Parent} UnistParent
	 * @typedef {import('unist-util-visit-parents').VisitorResult} VisitorResult
	 */


	/**
	 * Visit nodes.
	 *
	 * This algorithm performs *depth-first* *tree traversal* in *preorder*
	 * (**NLR**) or if `reverse` is given, in *reverse preorder* (**NRL**).
	 *
	 * You can choose for which nodes `visitor` is called by passing a `test`.
	 * For complex tests, you should test yourself in `visitor`, as it will be
	 * faster and will have improved type information.
	 *
	 * Walking the tree is an intensive task.
	 * Make use of the return values of the visitor when possible.
	 * Instead of walking a tree multiple times, walk it once, use `unist-util-is`
	 * to check if a node matches, and then perform different operations.
	 *
	 * You can change the tree.
	 * See `Visitor` for more info.
	 *
	 * @overload
	 * @param {Tree} tree
	 * @param {Check} check
	 * @param {BuildVisitor<Tree, Check>} visitor
	 * @param {boolean | null | undefined} [reverse]
	 * @returns {undefined}
	 *
	 * @overload
	 * @param {Tree} tree
	 * @param {BuildVisitor<Tree>} visitor
	 * @param {boolean | null | undefined} [reverse]
	 * @returns {undefined}
	 *
	 * @param {UnistNode} tree
	 *   Tree to traverse.
	 * @param {Visitor | Test} testOrVisitor
	 *   `unist-util-is`-compatible test (optional, omit to pass a visitor).
	 * @param {Visitor | boolean | null | undefined} [visitorOrReverse]
	 *   Handle each node (when test is omitted, pass `reverse`).
	 * @param {boolean | null | undefined} [maybeReverse=false]
	 *   Traverse in reverse preorder (NRL) instead of the default preorder (NLR).
	 * @returns {undefined}
	 *   Nothing.
	 *
	 * @template {UnistNode} Tree
	 *   Node type.
	 * @template {Test} Check
	 *   `unist-util-is`-compatible test.
	 */
	function visit(tree, testOrVisitor, visitorOrReverse, maybeReverse) {
	  /** @type {boolean | null | undefined} */
	  let reverse;
	  /** @type {Test} */
	  let test;
	  /** @type {Visitor} */
	  let visitor;

	  if (
	    typeof testOrVisitor === 'function' &&
	    typeof visitorOrReverse !== 'function'
	  ) {
	    test = undefined;
	    visitor = testOrVisitor;
	    reverse = visitorOrReverse;
	  } else {
	    // @ts-expect-error: assume the overload with test was given.
	    test = testOrVisitor;
	    // @ts-expect-error: assume the overload with test was given.
	    visitor = visitorOrReverse;
	    reverse = maybeReverse;
	  }

	  visitParents(tree, test, overload, reverse);

	  /**
	   * @param {UnistNode} node
	   * @param {Array<UnistParent>} parents
	   */
	  function overload(node, parents) {
	    const parent = parents[parents.length - 1];
	    const index = parent ? parent.children.indexOf(node) : undefined;
	    return visitor(node, index, parent)
	  }
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {Heading} from 'mdast'
	 */


	/**
	 * @param {Heading} node
	 * @param {State} state
	 * @returns {boolean}
	 */
	function formatHeadingAsSetext(node, state) {
	  let literalWithBreak = false;

	  // Look for literals with a line break.
	  // Note that this also
	  visit(node, function (node) {
	    if (
	      ('value' in node && /\r?\n|\r/.test(node.value)) ||
	      node.type === 'break'
	    ) {
	      literalWithBreak = true;
	      return EXIT
	    }
	  });

	  return Boolean(
	    (!node.depth || node.depth < 3) &&
	      toString(node) &&
	      (state.options.setext || literalWithBreak)
	  )
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Heading, Parents} from 'mdast'
	 */


	/**
	 * @param {Heading} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function heading(node, _, state, info) {
	  const rank = Math.max(Math.min(6, node.depth || 1), 1);
	  const tracker = state.createTracker(info);

	  if (formatHeadingAsSetext(node, state)) {
	    const exit = state.enter('headingSetext');
	    const subexit = state.enter('phrasing');
	    const value = state.containerPhrasing(node, {
	      ...tracker.current(),
	      before: '\n',
	      after: '\n'
	    });
	    subexit();
	    exit();

	    return (
	      value +
	      '\n' +
	      (rank === 1 ? '=' : '-').repeat(
	        // The whole size
	        value.length -
	          // Minus the position of the character after the last EOL (or
	          // 0 if there is none)
	          (Math.max(value.lastIndexOf('\r'), value.lastIndexOf('\n')) + 1)
	      )
	    )
	  }

	  const sequence = '#'.repeat(rank);
	  const exit = state.enter('headingAtx');
	  const subexit = state.enter('phrasing');

	  // Note: for proper tracking, we should reset the output positions when there
	  // is no content returned, because then the space is not output.
	  // Practically, in that case, there is no content, so it doesnt matter that
	  // weve tracked one too many characters.
	  tracker.move(sequence + ' ');

	  let value = state.containerPhrasing(node, {
	    before: '# ',
	    after: '\n',
	    ...tracker.current()
	  });

	  if (/^[\t ]/.test(value)) {
	    // To do: what effect has the character reference on tracking?
	    value = encodeCharacterReference(value.charCodeAt(0)) + value.slice(1);
	  }

	  value = value ? sequence + ' ' + value : sequence;

	  if (state.options.closeAtx) {
	    value += ' ' + sequence;
	  }

	  subexit();
	  exit();

	  return value
	}

	/**
	 * @import {Html} from 'mdast'
	 */

	html.peek = htmlPeek;

	/**
	 * @param {Html} node
	 * @returns {string}
	 */
	function html(node) {
	  return node.value || ''
	}

	/**
	 * @returns {string}
	 */
	function htmlPeek() {
	  return '<'
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Image, Parents} from 'mdast'
	 */


	image.peek = imagePeek;

	/**
	 * @param {Image} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function image(node, _, state, info) {
	  const quote = checkQuote(state);
	  const suffix = quote === '"' ? 'Quote' : 'Apostrophe';
	  const exit = state.enter('image');
	  let subexit = state.enter('label');
	  const tracker = state.createTracker(info);
	  let value = tracker.move('![');
	  value += tracker.move(
	    state.safe(node.alt, {before: value, after: ']', ...tracker.current()})
	  );
	  value += tracker.move('](');

	  subexit();

	  if (
	    // If theres no url but there is a title
	    (!node.url && node.title) ||
	    // If there are control characters or whitespace.
	    /[\0- \u007F]/.test(node.url)
	  ) {
	    subexit = state.enter('destinationLiteral');
	    value += tracker.move('<');
	    value += tracker.move(
	      state.safe(node.url, {before: value, after: '>', ...tracker.current()})
	    );
	    value += tracker.move('>');
	  } else {
	    // No whitespace, raw is prettier.
	    subexit = state.enter('destinationRaw');
	    value += tracker.move(
	      state.safe(node.url, {
	        before: value,
	        after: node.title ? ' ' : ')',
	        ...tracker.current()
	      })
	    );
	  }

	  subexit();

	  if (node.title) {
	    subexit = state.enter(`title${suffix}`);
	    value += tracker.move(' ' + quote);
	    value += tracker.move(
	      state.safe(node.title, {
	        before: value,
	        after: quote,
	        ...tracker.current()
	      })
	    );
	    value += tracker.move(quote);
	    subexit();
	  }

	  value += tracker.move(')');
	  exit();

	  return value
	}

	/**
	 * @returns {string}
	 */
	function imagePeek() {
	  return '!'
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {ImageReference, Parents} from 'mdast'
	 */

	imageReference.peek = imageReferencePeek;

	/**
	 * @param {ImageReference} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function imageReference(node, _, state, info) {
	  const type = node.referenceType;
	  const exit = state.enter('imageReference');
	  let subexit = state.enter('label');
	  const tracker = state.createTracker(info);
	  let value = tracker.move('![');
	  const alt = state.safe(node.alt, {
	    before: value,
	    after: ']',
	    ...tracker.current()
	  });
	  value += tracker.move(alt + '][');

	  subexit();
	  // Hide the fact that were in phrasing, because escapes dont work.
	  const stack = state.stack;
	  state.stack = [];
	  subexit = state.enter('reference');
	  // Note: for proper tracking, we should reset the output positions when we end
	  // up making a `shortcut` reference, because then there is no brace output.
	  // Practically, in that case, there is no content, so it doesnt matter that
	  // weve tracked one too many characters.
	  const reference = state.safe(state.associationId(node), {
	    before: value,
	    after: ']',
	    ...tracker.current()
	  });
	  subexit();
	  state.stack = stack;
	  exit();

	  if (type === 'full' || !alt || alt !== reference) {
	    value += tracker.move(reference + ']');
	  } else if (type === 'shortcut') {
	    // Remove the unwanted `[`.
	    value = value.slice(0, -1);
	  } else {
	    value += tracker.move(']');
	  }

	  return value
	}

	/**
	 * @returns {string}
	 */
	function imageReferencePeek() {
	  return '!'
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {InlineCode, Parents} from 'mdast'
	 */

	inlineCode.peek = inlineCodePeek;

	/**
	 * @param {InlineCode} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @returns {string}
	 */
	function inlineCode(node, _, state) {
	  let value = node.value || '';
	  let sequence = '`';
	  let index = -1;

	  // If there is a single grave accent on its own in the code, use a fence of
	  // two.
	  // If there are two in a row, use one.
	  while (new RegExp('(^|[^`])' + sequence + '([^`]|$)').test(value)) {
	    sequence += '`';
	  }

	  // If this is not just spaces or eols (tabs dont count), and either the
	  // first or last character are a space, eol, or tick, then pad with spaces.
	  if (
	    /[^ \r\n]/.test(value) &&
	    ((/^[ \r\n]/.test(value) && /[ \r\n]$/.test(value)) || /^`|`$/.test(value))
	  ) {
	    value = ' ' + value + ' ';
	  }

	  // We have a potential problem: certain characters after eols could result in
	  // blocks being seen.
	  // For example, if someone injected the string `'\n# b'`, then that would
	  // result in an ATX heading.
	  // We cant escape characters in `inlineCode`, but because eols are
	  // transformed to spaces when going from markdown to HTML anyway, we can swap
	  // them out.
	  while (++index < state.unsafe.length) {
	    const pattern = state.unsafe[index];
	    const expression = state.compilePattern(pattern);
	    /** @type {RegExpExecArray | null} */
	    let match;

	    // Only look for `atBreak`s.
	    // Btw: note that `atBreak` patterns will always start the regex at LF or
	    // CR.
	    if (!pattern.atBreak) continue

	    while ((match = expression.exec(value))) {
	      let position = match.index;

	      // Support CRLF (patterns only look for one of the characters).
	      if (
	        value.charCodeAt(position) === 10 /* `\n` */ &&
	        value.charCodeAt(position - 1) === 13 /* `\r` */
	      ) {
	        position--;
	      }

	      value = value.slice(0, position) + ' ' + value.slice(match.index + 1);
	    }
	  }

	  return sequence + value + sequence
	}

	/**
	 * @returns {string}
	 */
	function inlineCodePeek() {
	  return '`'
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {Link} from 'mdast'
	 */


	/**
	 * @param {Link} node
	 * @param {State} state
	 * @returns {boolean}
	 */
	function formatLinkAsAutolink(node, state) {
	  const raw = toString(node);

	  return Boolean(
	    !state.options.resourceLink &&
	      // If theres a url
	      node.url &&
	      // And theres a no title
	      !node.title &&
	      // And the content of `node` is a single text node
	      node.children &&
	      node.children.length === 1 &&
	      node.children[0].type === 'text' &&
	      // And if the url is the same as the content
	      (raw === node.url || 'mailto:' + raw === node.url) &&
	      // And that starts w/ a protocol
	      /^[a-z][a-z+.-]+:/i.test(node.url) &&
	      // And that doesnt contain ASCII control codes (character escapes and
	      // references dont work), space, or angle brackets
	      !/[\0- <>\u007F]/.test(node.url)
	  )
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Link, Parents} from 'mdast'
	 * @import {Exit} from '../types.js'
	 */


	link.peek = linkPeek;

	/**
	 * @param {Link} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function link(node, _, state, info) {
	  const quote = checkQuote(state);
	  const suffix = quote === '"' ? 'Quote' : 'Apostrophe';
	  const tracker = state.createTracker(info);
	  /** @type {Exit} */
	  let exit;
	  /** @type {Exit} */
	  let subexit;

	  if (formatLinkAsAutolink(node, state)) {
	    // Hide the fact that were in phrasing, because escapes dont work.
	    const stack = state.stack;
	    state.stack = [];
	    exit = state.enter('autolink');
	    let value = tracker.move('<');
	    value += tracker.move(
	      state.containerPhrasing(node, {
	        before: value,
	        after: '>',
	        ...tracker.current()
	      })
	    );
	    value += tracker.move('>');
	    exit();
	    state.stack = stack;
	    return value
	  }

	  exit = state.enter('link');
	  subexit = state.enter('label');
	  let value = tracker.move('[');
	  value += tracker.move(
	    state.containerPhrasing(node, {
	      before: value,
	      after: '](',
	      ...tracker.current()
	    })
	  );
	  value += tracker.move('](');
	  subexit();

	  if (
	    // If theres no url but there is a title
	    (!node.url && node.title) ||
	    // If there are control characters or whitespace.
	    /[\0- \u007F]/.test(node.url)
	  ) {
	    subexit = state.enter('destinationLiteral');
	    value += tracker.move('<');
	    value += tracker.move(
	      state.safe(node.url, {before: value, after: '>', ...tracker.current()})
	    );
	    value += tracker.move('>');
	  } else {
	    // No whitespace, raw is prettier.
	    subexit = state.enter('destinationRaw');
	    value += tracker.move(
	      state.safe(node.url, {
	        before: value,
	        after: node.title ? ' ' : ')',
	        ...tracker.current()
	      })
	    );
	  }

	  subexit();

	  if (node.title) {
	    subexit = state.enter(`title${suffix}`);
	    value += tracker.move(' ' + quote);
	    value += tracker.move(
	      state.safe(node.title, {
	        before: value,
	        after: quote,
	        ...tracker.current()
	      })
	    );
	    value += tracker.move(quote);
	    subexit();
	  }

	  value += tracker.move(')');

	  exit();
	  return value
	}

	/**
	 * @param {Link} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @returns {string}
	 */
	function linkPeek(node, _, state) {
	  return formatLinkAsAutolink(node, state) ? '<' : '['
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {LinkReference, Parents} from 'mdast'
	 */

	linkReference.peek = linkReferencePeek;

	/**
	 * @param {LinkReference} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function linkReference(node, _, state, info) {
	  const type = node.referenceType;
	  const exit = state.enter('linkReference');
	  let subexit = state.enter('label');
	  const tracker = state.createTracker(info);
	  let value = tracker.move('[');
	  const text = state.containerPhrasing(node, {
	    before: value,
	    after: ']',
	    ...tracker.current()
	  });
	  value += tracker.move(text + '][');

	  subexit();
	  // Hide the fact that were in phrasing, because escapes dont work.
	  const stack = state.stack;
	  state.stack = [];
	  subexit = state.enter('reference');
	  // Note: for proper tracking, we should reset the output positions when we end
	  // up making a `shortcut` reference, because then there is no brace output.
	  // Practically, in that case, there is no content, so it doesnt matter that
	  // weve tracked one too many characters.
	  const reference = state.safe(state.associationId(node), {
	    before: value,
	    after: ']',
	    ...tracker.current()
	  });
	  subexit();
	  state.stack = stack;
	  exit();

	  if (type === 'full' || !text || text !== reference) {
	    value += tracker.move(reference + ']');
	  } else if (type === 'shortcut') {
	    // Remove the unwanted `[`.
	    value = value.slice(0, -1);
	  } else {
	    value += tracker.move(']');
	  }

	  return value
	}

	/**
	 * @returns {string}
	 */
	function linkReferencePeek() {
	  return '['
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['bullet'], null | undefined>}
	 */
	function checkBullet(state) {
	  const marker = state.options.bullet || '*';

	  if (marker !== '*' && marker !== '+' && marker !== '-') {
	    throw new Error(
	      'Cannot serialize items with `' +
	        marker +
	        '` for `options.bullet`, expected `*`, `+`, or `-`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */


	/**
	 * @param {State} state
	 * @returns {Exclude<Options['bullet'], null | undefined>}
	 */
	function checkBulletOther(state) {
	  const bullet = checkBullet(state);
	  const bulletOther = state.options.bulletOther;

	  if (!bulletOther) {
	    return bullet === '*' ? '-' : '*'
	  }

	  if (bulletOther !== '*' && bulletOther !== '+' && bulletOther !== '-') {
	    throw new Error(
	      'Cannot serialize items with `' +
	        bulletOther +
	        '` for `options.bulletOther`, expected `*`, `+`, or `-`'
	    )
	  }

	  if (bulletOther === bullet) {
	    throw new Error(
	      'Expected `bullet` (`' +
	        bullet +
	        '`) and `bulletOther` (`' +
	        bulletOther +
	        '`) to be different'
	    )
	  }

	  return bulletOther
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['bulletOrdered'], null | undefined>}
	 */
	function checkBulletOrdered(state) {
	  const marker = state.options.bulletOrdered || '.';

	  if (marker !== '.' && marker !== ')') {
	    throw new Error(
	      'Cannot serialize items with `' +
	        marker +
	        '` for `options.bulletOrdered`, expected `.` or `)`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['rule'], null | undefined>}
	 */
	function checkRule(state) {
	  const marker = state.options.rule || '*';

	  if (marker !== '*' && marker !== '-' && marker !== '_') {
	    throw new Error(
	      'Cannot serialize rules with `' +
	        marker +
	        '` for `options.rule`, expected `*`, `-`, or `_`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {List, Parents} from 'mdast'
	 */


	/**
	 * @param {List} node
	 * @param {Parents | undefined} parent
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function list(node, parent, state, info) {
	  const exit = state.enter('list');
	  const bulletCurrent = state.bulletCurrent;
	  /** @type {string} */
	  let bullet = node.ordered ? checkBulletOrdered(state) : checkBullet(state);
	  /** @type {string} */
	  const bulletOther = node.ordered
	    ? bullet === '.'
	      ? ')'
	      : '.'
	    : checkBulletOther(state);
	  let useDifferentMarker =
	    parent && state.bulletLastUsed ? bullet === state.bulletLastUsed : false;

	  if (!node.ordered) {
	    const firstListItem = node.children ? node.children[0] : undefined;

	    // If theres an empty first list item directly in two list items,
	    // we have to use a different bullet:
	    //
	    // ```markdown
	    // * - *
	    // ```
	    //
	    // because otherwise it would become one big thematic break.
	    if (
	      // Bullet could be used as a thematic break marker:
	      (bullet === '*' || bullet === '-') &&
	      // Empty first list item:
	      firstListItem &&
	      (!firstListItem.children || !firstListItem.children[0]) &&
	      // Directly in two other list items:
	      state.stack[state.stack.length - 1] === 'list' &&
	      state.stack[state.stack.length - 2] === 'listItem' &&
	      state.stack[state.stack.length - 3] === 'list' &&
	      state.stack[state.stack.length - 4] === 'listItem' &&
	      // That are each the first child.
	      state.indexStack[state.indexStack.length - 1] === 0 &&
	      state.indexStack[state.indexStack.length - 2] === 0 &&
	      state.indexStack[state.indexStack.length - 3] === 0
	    ) {
	      useDifferentMarker = true;
	    }

	    // If theres a thematic break at the start of the first list item,
	    // we have to use a different bullet:
	    //
	    // ```markdown
	    // * ---
	    // ```
	    //
	    // because otherwise it would become one big thematic break.
	    if (checkRule(state) === bullet && firstListItem) {
	      let index = -1;

	      while (++index < node.children.length) {
	        const item = node.children[index];

	        if (
	          item &&
	          item.type === 'listItem' &&
	          item.children &&
	          item.children[0] &&
	          item.children[0].type === 'thematicBreak'
	        ) {
	          useDifferentMarker = true;
	          break
	        }
	      }
	    }
	  }

	  if (useDifferentMarker) {
	    bullet = bulletOther;
	  }

	  state.bulletCurrent = bullet;
	  const value = state.containerFlow(node, info);
	  state.bulletLastUsed = bullet;
	  state.bulletCurrent = bulletCurrent;
	  exit();
	  return value
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['listItemIndent'], null | undefined>}
	 */
	function checkListItemIndent(state) {
	  const style = state.options.listItemIndent || 'one';

	  if (style !== 'tab' && style !== 'one' && style !== 'mixed') {
	    throw new Error(
	      'Cannot serialize items with `' +
	        style +
	        '` for `options.listItemIndent`, expected `tab`, `one`, or `mixed`'
	    )
	  }

	  return style
	}

	/**
	 * @import {Info, Map, State} from 'mdast-util-to-markdown'
	 * @import {ListItem, Parents} from 'mdast'
	 */


	/**
	 * @param {ListItem} node
	 * @param {Parents | undefined} parent
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function listItem(node, parent, state, info) {
	  const listItemIndent = checkListItemIndent(state);
	  let bullet = state.bulletCurrent || checkBullet(state);

	  // Add the marker value for ordered lists.
	  if (parent && parent.type === 'list' && parent.ordered) {
	    bullet =
	      (typeof parent.start === 'number' && parent.start > -1
	        ? parent.start
	        : 1) +
	      (state.options.incrementListMarker === false
	        ? 0
	        : parent.children.indexOf(node)) +
	      bullet;
	  }

	  let size = bullet.length + 1;

	  if (
	    listItemIndent === 'tab' ||
	    (listItemIndent === 'mixed' &&
	      ((parent && parent.type === 'list' && parent.spread) || node.spread))
	  ) {
	    size = Math.ceil(size / 4) * 4;
	  }

	  const tracker = state.createTracker(info);
	  tracker.move(bullet + ' '.repeat(size - bullet.length));
	  tracker.shift(size);
	  const exit = state.enter('listItem');
	  const value = state.indentLines(
	    state.containerFlow(node, tracker.current()),
	    map
	  );
	  exit();

	  return value

	  /** @type {Map} */
	  function map(line, index, blank) {
	    if (index) {
	      return (blank ? '' : ' '.repeat(size)) + line
	    }

	    return (blank ? bullet : bullet + ' '.repeat(size - bullet.length)) + line
	  }
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Paragraph, Parents} from 'mdast'
	 */

	/**
	 * @param {Paragraph} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function paragraph(node, _, state, info) {
	  const exit = state.enter('paragraph');
	  const subexit = state.enter('phrasing');
	  const value = state.containerPhrasing(node, info);
	  subexit();
	  exit();
	  return value
	}

	/**
	 * @typedef {import('mdast').Html} Html
	 * @typedef {import('mdast').PhrasingContent} PhrasingContent
	 */


	/**
	 * Check if the given value is *phrasing content*.
	 *
	 * >  **Note**: Excludes `html`, which can be both phrasing or flow.
	 *
	 * @param node
	 *   Thing to check, typically `Node`.
	 * @returns
	 *   Whether `value` is phrasing content.
	 */

	const phrasing =
	  /** @type {(node?: unknown) => node is Exclude<PhrasingContent, Html>} */
	  (
	    convert([
	      'break',
	      'delete',
	      'emphasis',
	      // To do: next major: removed since footnotes were added to GFM.
	      'footnote',
	      'footnoteReference',
	      'image',
	      'imageReference',
	      'inlineCode',
	      // Enabled by `mdast-util-math`:
	      'inlineMath',
	      'link',
	      'linkReference',
	      // Enabled by `mdast-util-mdx`:
	      'mdxJsxTextElement',
	      // Enabled by `mdast-util-mdx`:
	      'mdxTextExpression',
	      'strong',
	      'text',
	      // Enabled by `mdast-util-directive`:
	      'textDirective'
	    ])
	  );

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Parents, Root} from 'mdast'
	 */


	/**
	 * @param {Root} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function root(node, _, state, info) {
	  // Note: `html` nodes are ambiguous.
	  const hasPhrasing = node.children.some(function (d) {
	    return phrasing(d)
	  });

	  const container = hasPhrasing ? state.containerPhrasing : state.containerFlow;
	  return container.call(state, node, info)
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['strong'], null | undefined>}
	 */
	function checkStrong(state) {
	  const marker = state.options.strong || '*';

	  if (marker !== '*' && marker !== '_') {
	    throw new Error(
	      'Cannot serialize strong with `' +
	        marker +
	        '` for `options.strong`, expected `*`, or `_`'
	    )
	  }

	  return marker
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Parents, Strong} from 'mdast'
	 */


	strong.peek = strongPeek;

	/**
	 * @param {Strong} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function strong(node, _, state, info) {
	  const marker = checkStrong(state);
	  const exit = state.enter('strong');
	  const tracker = state.createTracker(info);
	  const before = tracker.move(marker + marker);

	  let between = tracker.move(
	    state.containerPhrasing(node, {
	      after: marker,
	      before,
	      ...tracker.current()
	    })
	  );
	  const betweenHead = between.charCodeAt(0);
	  const open = encodeInfo(
	    info.before.charCodeAt(info.before.length - 1),
	    betweenHead,
	    marker
	  );

	  if (open.inside) {
	    between = encodeCharacterReference(betweenHead) + between.slice(1);
	  }

	  const betweenTail = between.charCodeAt(between.length - 1);
	  const close = encodeInfo(info.after.charCodeAt(0), betweenTail, marker);

	  if (close.inside) {
	    between = between.slice(0, -1) + encodeCharacterReference(betweenTail);
	  }

	  const after = tracker.move(marker + marker);

	  exit();

	  state.attentionEncodeSurroundingInfo = {
	    after: close.outside,
	    before: open.outside
	  };
	  return before + between + after
	}

	/**
	 * @param {Strong} _
	 * @param {Parents | undefined} _1
	 * @param {State} state
	 * @returns {string}
	 */
	function strongPeek(_, _1, state) {
	  return state.options.strong || '*'
	}

	/**
	 * @import {Info, State} from 'mdast-util-to-markdown'
	 * @import {Parents, Text} from 'mdast'
	 */

	/**
	 * @param {Text} node
	 * @param {Parents | undefined} _
	 * @param {State} state
	 * @param {Info} info
	 * @returns {string}
	 */
	function text(node, _, state, info) {
	  return state.safe(node.value, info)
	}

	/**
	 * @import {Options, State} from 'mdast-util-to-markdown'
	 */

	/**
	 * @param {State} state
	 * @returns {Exclude<Options['ruleRepetition'], null | undefined>}
	 */
	function checkRuleRepetition(state) {
	  const repetition = state.options.ruleRepetition || 3;

	  if (repetition < 3) {
	    throw new Error(
	      'Cannot serialize rules with repetition `' +
	        repetition +
	        '` for `options.ruleRepetition`, expected `3` or more'
	    )
	  }

	  return repetition
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {Parents, ThematicBreak} from 'mdast'
	 */


	/**
	 * @param {ThematicBreak} _
	 * @param {Parents | undefined} _1
	 * @param {State} state
	 * @returns {string}
	 */
	function thematicBreak(_, _1, state) {
	  const value = (
	    checkRule(state) + (state.options.ruleSpaces ? ' ' : '')
	  ).repeat(checkRuleRepetition(state));

	  return state.options.ruleSpaces ? value.slice(0, -1) : value
	}

	/**
	 * Default (CommonMark) handlers.
	 */
	const handle = {
	  blockquote,
	  break: hardBreak,
	  code,
	  definition,
	  emphasis,
	  hardBreak,
	  heading,
	  html,
	  image,
	  imageReference,
	  inlineCode,
	  link,
	  linkReference,
	  list,
	  listItem,
	  paragraph,
	  root,
	  strong,
	  text,
	  thematicBreak
	};

	/**
	 * @import {Join} from 'mdast-util-to-markdown'
	 */


	/** @type {Array<Join>} */
	const join = [joinDefaults];

	/** @type {Join} */
	function joinDefaults(left, right, parent, state) {
	  // Indented code after list or another indented code.
	  if (
	    right.type === 'code' &&
	    formatCodeAsIndented(right, state) &&
	    (left.type === 'list' ||
	      (left.type === right.type && formatCodeAsIndented(left, state)))
	  ) {
	    return false
	  }

	  // Join children of a list or an item.
	  // In which case, `parent` has a `spread` field.
	  if ('spread' in parent && typeof parent.spread === 'boolean') {
	    if (
	      left.type === 'paragraph' &&
	      // Two paragraphs.
	      (left.type === right.type ||
	        right.type === 'definition' ||
	        // Paragraph followed by a setext heading.
	        (right.type === 'heading' && formatHeadingAsSetext(right, state)))
	    ) {
	      return
	    }

	    return parent.spread ? 1 : 0
	  }
	}

	/**
	 * @import {ConstructName, Unsafe} from 'mdast-util-to-markdown'
	 */

	/**
	 * List of constructs that occur in phrasing (paragraphs, headings), but cannot
	 * contain things like attention (emphasis, strong), images, or links.
	 * So they sort of cancel each other out.
	 * Note: could use a better name.
	 *
	 * @type {Array<ConstructName>}
	 */
	const fullPhrasingSpans = [
	  'autolink',
	  'destinationLiteral',
	  'destinationRaw',
	  'reference',
	  'titleQuote',
	  'titleApostrophe'
	];

	/** @type {Array<Unsafe>} */
	const unsafe = [
	  {character: '\t', after: '[\\r\\n]', inConstruct: 'phrasing'},
	  {character: '\t', before: '[\\r\\n]', inConstruct: 'phrasing'},
	  {
	    character: '\t',
	    inConstruct: ['codeFencedLangGraveAccent', 'codeFencedLangTilde']
	  },
	  {
	    character: '\r',
	    inConstruct: [
	      'codeFencedLangGraveAccent',
	      'codeFencedLangTilde',
	      'codeFencedMetaGraveAccent',
	      'codeFencedMetaTilde',
	      'destinationLiteral',
	      'headingAtx'
	    ]
	  },
	  {
	    character: '\n',
	    inConstruct: [
	      'codeFencedLangGraveAccent',
	      'codeFencedLangTilde',
	      'codeFencedMetaGraveAccent',
	      'codeFencedMetaTilde',
	      'destinationLiteral',
	      'headingAtx'
	    ]
	  },
	  {character: ' ', after: '[\\r\\n]', inConstruct: 'phrasing'},
	  {character: ' ', before: '[\\r\\n]', inConstruct: 'phrasing'},
	  {
	    character: ' ',
	    inConstruct: ['codeFencedLangGraveAccent', 'codeFencedLangTilde']
	  },
	  // An exclamation mark can start an image, if it is followed by a link or
	  // a link reference.
	  {
	    character: '!',
	    after: '\\[',
	    inConstruct: 'phrasing',
	    notInConstruct: fullPhrasingSpans
	  },
	  // A quote can break out of a title.
	  {character: '"', inConstruct: 'titleQuote'},
	  // A number sign could start an ATX heading if it starts a line.
	  {atBreak: true, character: '#'},
	  {character: '#', inConstruct: 'headingAtx', after: '(?:[\r\n]|$)'},
	  // Dollar sign and percentage are not used in markdown.
	  // An ampersand could start a character reference.
	  {character: '&', after: '[#A-Za-z]', inConstruct: 'phrasing'},
	  // An apostrophe can break out of a title.
	  {character: "'", inConstruct: 'titleApostrophe'},
	  // A left paren could break out of a destination raw.
	  {character: '(', inConstruct: 'destinationRaw'},
	  // A left paren followed by `]` could make something into a link or image.
	  {
	    before: '\\]',
	    character: '(',
	    inConstruct: 'phrasing',
	    notInConstruct: fullPhrasingSpans
	  },
	  // A right paren could start a list item or break out of a destination
	  // raw.
	  {atBreak: true, before: '\\d+', character: ')'},
	  {character: ')', inConstruct: 'destinationRaw'},
	  // An asterisk can start thematic breaks, list items, emphasis, strong.
	  {atBreak: true, character: '*', after: '(?:[ \t\r\n*])'},
	  {character: '*', inConstruct: 'phrasing', notInConstruct: fullPhrasingSpans},
	  // A plus sign could start a list item.
	  {atBreak: true, character: '+', after: '(?:[ \t\r\n])'},
	  // A dash can start thematic breaks, list items, and setext heading
	  // underlines.
	  {atBreak: true, character: '-', after: '(?:[ \t\r\n-])'},
	  // A dot could start a list item.
	  {atBreak: true, before: '\\d+', character: '.', after: '(?:[ \t\r\n]|$)'},
	  // Slash, colon, and semicolon are not used in markdown for constructs.
	  // A less than can start html (flow or text) or an autolink.
	  // HTML could start with an exclamation mark (declaration, cdata, comment),
	  // slash (closing tag), question mark (instruction), or a letter (tag).
	  // An autolink also starts with a letter.
	  // Finally, it could break out of a destination literal.
	  {atBreak: true, character: '<', after: '[!/?A-Za-z]'},
	  {
	    character: '<',
	    after: '[!/?A-Za-z]',
	    inConstruct: 'phrasing',
	    notInConstruct: fullPhrasingSpans
	  },
	  {character: '<', inConstruct: 'destinationLiteral'},
	  // An equals to can start setext heading underlines.
	  {atBreak: true, character: '='},
	  // A greater than can start block quotes and it can break out of a
	  // destination literal.
	  {atBreak: true, character: '>'},
	  {character: '>', inConstruct: 'destinationLiteral'},
	  // Question mark and at sign are not used in markdown for constructs.
	  // A left bracket can start definitions, references, labels,
	  {atBreak: true, character: '['},
	  {character: '[', inConstruct: 'phrasing', notInConstruct: fullPhrasingSpans},
	  {character: '[', inConstruct: ['label', 'reference']},
	  // A backslash can start an escape (when followed by punctuation) or a
	  // hard break (when followed by an eol).
	  // Note: typical escapes are handled in `safe`!
	  {character: '\\', after: '[\\r\\n]', inConstruct: 'phrasing'},
	  // A right bracket can exit labels.
	  {character: ']', inConstruct: ['label', 'reference']},
	  // Caret is not used in markdown for constructs.
	  // An underscore can start emphasis, strong, or a thematic break.
	  {atBreak: true, character: '_'},
	  {character: '_', inConstruct: 'phrasing', notInConstruct: fullPhrasingSpans},
	  // A grave accent can start code (fenced or text), or it can break out of
	  // a grave accent code fence.
	  {atBreak: true, character: '`'},
	  {
	    character: '`',
	    inConstruct: ['codeFencedLangGraveAccent', 'codeFencedMetaGraveAccent']
	  },
	  {character: '`', inConstruct: 'phrasing', notInConstruct: fullPhrasingSpans},
	  // Left brace, vertical bar, right brace are not used in markdown for
	  // constructs.
	  // A tilde can start code (fenced).
	  {atBreak: true, character: '~'}
	];

	/**
	 * @import {AssociationId} from '../types.js'
	 */


	/**
	 * Get an identifier from an association to match it to others.
	 *
	 * Associations are nodes that match to something else through an ID:
	 * <https://github.com/syntax-tree/mdast#association>.
	 *
	 * The `label` of an association is the string value: character escapes and
	 * references work, and casing is intact.
	 * The `identifier` is used to match one association to another:
	 * controversially, character escapes and references dont work in this
	 * matching: `&copy;` does not match ``, and `\+` does not match `+`.
	 *
	 * But casing is ignored (and whitespace) is trimmed and collapsed: ` A\nb`
	 * matches `a b`.
	 * So, we do prefer the label when figuring out how were going to serialize:
	 * it has whitespace, casing, and we can ignore most useless character
	 * escapes and all character references.
	 *
	 * @type {AssociationId}
	 */
	function association(node) {
	  if (node.label || !node.identifier) {
	    return node.label || ''
	  }

	  return decodeString(node.identifier)
	}

	/**
	 * @import {CompilePattern} from '../types.js'
	 */

	/**
	 * @type {CompilePattern}
	 */
	function compilePattern(pattern) {
	  if (!pattern._compiled) {
	    const before =
	      (pattern.atBreak ? '[\\r\\n][\\t ]*' : '') +
	      (pattern.before ? '(?:' + pattern.before + ')' : '');

	    pattern._compiled = new RegExp(
	      (before ? '(' + before + ')' : '') +
	        (/[|\\{}()[\]^$+*?.-]/.test(pattern.character) ? '\\' : '') +
	        pattern.character +
	        (pattern.after ? '(?:' + pattern.after + ')' : ''),
	      'g'
	    );
	  }

	  return pattern._compiled
	}

	/**
	 * @import {Handle, Info, State} from 'mdast-util-to-markdown'
	 * @import {PhrasingParents} from '../types.js'
	 */


	/**
	 * Serialize the children of a parent that contains phrasing children.
	 *
	 * These children will be joined flush together.
	 *
	 * @param {PhrasingParents} parent
	 *   Parent of flow nodes.
	 * @param {State} state
	 *   Info passed around about the current state.
	 * @param {Info} info
	 *   Info on where we are in the document we are generating.
	 * @returns {string}
	 *   Serialized children, joined together.
	 */
	function containerPhrasing(parent, state, info) {
	  const indexStack = state.indexStack;
	  const children = parent.children || [];
	  /** @type {Array<string>} */
	  const results = [];
	  let index = -1;
	  let before = info.before;
	  /** @type {string | undefined} */
	  let encodeAfter;

	  indexStack.push(-1);
	  let tracker = state.createTracker(info);

	  while (++index < children.length) {
	    const child = children[index];
	    /** @type {string} */
	    let after;

	    indexStack[indexStack.length - 1] = index;

	    if (index + 1 < children.length) {
	      /** @type {Handle} */
	      // @ts-expect-error: hush, its actually a `zwitch`.
	      let handle = state.handle.handlers[children[index + 1].type];
	      /** @type {Handle} */
	      // @ts-expect-error: hush, its actually a `zwitch`.
	      if (handle && handle.peek) handle = handle.peek;
	      after = handle
	        ? handle(children[index + 1], parent, state, {
	            before: '',
	            after: '',
	            ...tracker.current()
	          }).charAt(0)
	        : '';
	    } else {
	      after = info.after;
	    }

	    // In some cases, html (text) can be found in phrasing right after an eol.
	    // When wed serialize that, in most cases that would be seen as html
	    // (flow).
	    // As we cant escape or so to prevent it from happening, we take a somewhat
	    // reasonable approach: replace that eol with a space.
	    // See: <https://github.com/syntax-tree/mdast-util-to-markdown/issues/15>
	    if (
	      results.length > 0 &&
	      (before === '\r' || before === '\n') &&
	      child.type === 'html'
	    ) {
	      results[results.length - 1] = results[results.length - 1].replace(
	        /(\r?\n|\r)$/,
	        ' '
	      );
	      before = ' ';

	      // To do: does this work to reset tracker?
	      tracker = state.createTracker(info);
	      tracker.move(results.join(''));
	    }

	    let value = state.handle(child, parent, state, {
	      ...tracker.current(),
	      after,
	      before
	    });

	    // If we had to encode the first character after the previous node and its
	    // still the same character,
	    // encode it.
	    if (encodeAfter && encodeAfter === value.slice(0, 1)) {
	      value =
	        encodeCharacterReference(encodeAfter.charCodeAt(0)) + value.slice(1);
	    }

	    const encodingInfo = state.attentionEncodeSurroundingInfo;
	    state.attentionEncodeSurroundingInfo = undefined;
	    encodeAfter = undefined;

	    // If we have to encode the first character before the current node and
	    // its still the same character,
	    // encode it.
	    if (encodingInfo) {
	      if (
	        results.length > 0 &&
	        encodingInfo.before &&
	        before === results[results.length - 1].slice(-1)
	      ) {
	        results[results.length - 1] =
	          results[results.length - 1].slice(0, -1) +
	          encodeCharacterReference(before.charCodeAt(0));
	      }

	      if (encodingInfo.after) encodeAfter = after;
	    }

	    tracker.move(value);
	    results.push(value);
	    before = value.slice(-1);
	  }

	  indexStack.pop();

	  return results.join('')
	}

	/**
	 * @import {State} from 'mdast-util-to-markdown'
	 * @import {FlowChildren, FlowParents, TrackFields} from '../types.js'
	 */

	/**
	 * @param {FlowParents} parent
	 *   Parent of flow nodes.
	 * @param {State} state
	 *   Info passed around about the current state.
	 * @param {TrackFields} info
	 *   Info on where we are in the document we are generating.
	 * @returns {string}
	 *   Serialized children, joined by (blank) lines.
	 */
	function containerFlow(parent, state, info) {
	  const indexStack = state.indexStack;
	  const children = parent.children || [];
	  const tracker = state.createTracker(info);
	  /** @type {Array<string>} */
	  const results = [];
	  let index = -1;

	  indexStack.push(-1);

	  while (++index < children.length) {
	    const child = children[index];

	    indexStack[indexStack.length - 1] = index;

	    results.push(
	      tracker.move(
	        state.handle(child, parent, state, {
	          before: '\n',
	          after: '\n',
	          ...tracker.current()
	        })
	      )
	    );

	    if (child.type !== 'list') {
	      state.bulletLastUsed = undefined;
	    }

	    if (index < children.length - 1) {
	      results.push(
	        tracker.move(between(child, children[index + 1], parent, state))
	      );
	    }
	  }

	  indexStack.pop();

	  return results.join('')
	}

	/**
	 * @param {FlowChildren} left
	 * @param {FlowChildren} right
	 * @param {FlowParents} parent
	 * @param {State} state
	 * @returns {string}
	 */
	function between(left, right, parent, state) {
	  let index = state.join.length;

	  while (index--) {
	    const result = state.join[index](left, right, parent, state);

	    if (result === true || result === 1) {
	      break
	    }

	    if (typeof result === 'number') {
	      return '\n'.repeat(1 + result)
	    }

	    if (result === false) {
	      return '\n\n<!---->\n\n'
	    }
	  }

	  return '\n\n'
	}

	/**
	 * @import {IndentLines} from '../types.js'
	 */

	const eol = /\r?\n|\r/g;

	/**
	 * @type {IndentLines}
	 */
	function indentLines(value, map) {
	  /** @type {Array<string>} */
	  const result = [];
	  let start = 0;
	  let line = 0;
	  /** @type {RegExpExecArray | null} */
	  let match;

	  while ((match = eol.exec(value))) {
	    one(value.slice(start, match.index));
	    result.push(match[0]);
	    start = match.index + match[0].length;
	    line++;
	  }

	  one(value.slice(start));

	  return result.join('')

	  /**
	   * @param {string} value
	   */
	  function one(value) {
	    result.push(map(value, line, !value));
	  }
	}

	/**
	 * @import {SafeConfig, State} from 'mdast-util-to-markdown'
	 */


	/**
	 * Make a string safe for embedding in markdown constructs.
	 *
	 * In markdown, almost all punctuation characters can, in certain cases,
	 * result in something.
	 * Whether they do is highly subjective to where they happen and in what
	 * they happen.
	 *
	 * To solve this, `mdast-util-to-markdown` tracks:
	 *
	 * * Characters before and after something;
	 * * What constructs we are in.
	 *
	 * This information is then used by this function to escape or encode
	 * special characters.
	 *
	 * @param {State} state
	 *   Info passed around about the current state.
	 * @param {string | null | undefined} input
	 *   Raw value to make safe.
	 * @param {SafeConfig} config
	 *   Configuration.
	 * @returns {string}
	 *   Serialized markdown safe for embedding.
	 */
	function safe(state, input, config) {
	  const value = (config.before || '') + (input || '') + (config.after || '');
	  /** @type {Array<number>} */
	  const positions = [];
	  /** @type {Array<string>} */
	  const result = [];
	  /** @type {Record<number, {before: boolean, after: boolean}>} */
	  const infos = {};
	  let index = -1;

	  while (++index < state.unsafe.length) {
	    const pattern = state.unsafe[index];

	    if (!patternInScope(state.stack, pattern)) {
	      continue
	    }

	    const expression = state.compilePattern(pattern);
	    /** @type {RegExpExecArray | null} */
	    let match;

	    while ((match = expression.exec(value))) {
	      const before = 'before' in pattern || Boolean(pattern.atBreak);
	      const after = 'after' in pattern;
	      const position = match.index + (before ? match[1].length : 0);

	      if (positions.includes(position)) {
	        if (infos[position].before && !before) {
	          infos[position].before = false;
	        }

	        if (infos[position].after && !after) {
	          infos[position].after = false;
	        }
	      } else {
	        positions.push(position);
	        infos[position] = {before, after};
	      }
	    }
	  }

	  positions.sort(numerical);

	  let start = config.before ? config.before.length : 0;
	  const end = value.length - (config.after ? config.after.length : 0);
	  index = -1;

	  while (++index < positions.length) {
	    const position = positions[index];

	    // Character before or after matched:
	    if (position < start || position >= end) {
	      continue
	    }

	    // If this character is supposed to be escaped because it has a condition on
	    // the next character, and the next character is definitly being escaped,
	    // then skip this escape.
	    if (
	      (position + 1 < end &&
	        positions[index + 1] === position + 1 &&
	        infos[position].after &&
	        !infos[position + 1].before &&
	        !infos[position + 1].after) ||
	      (positions[index - 1] === position - 1 &&
	        infos[position].before &&
	        !infos[position - 1].before &&
	        !infos[position - 1].after)
	    ) {
	      continue
	    }

	    if (start !== position) {
	      // If we have to use a character reference, an ampersand would be more
	      // correct, but as backslashes only care about punctuation, either will
	      // do the trick
	      result.push(escapeBackslashes(value.slice(start, position), '\\'));
	    }

	    start = position;

	    if (
	      /[!-/:-@[-`{-~]/.test(value.charAt(position)) &&
	      (!config.encode || !config.encode.includes(value.charAt(position)))
	    ) {
	      // Character escape.
	      result.push('\\');
	    } else {
	      // Character reference.
	      result.push(encodeCharacterReference(value.charCodeAt(position)));
	      start++;
	    }
	  }

	  result.push(escapeBackslashes(value.slice(start, end), config.after));

	  return result.join('')
	}

	/**
	 * @param {number} a
	 * @param {number} b
	 * @returns {number}
	 */
	function numerical(a, b) {
	  return a - b
	}

	/**
	 * @param {string} value
	 * @param {string} after
	 * @returns {string}
	 */
	function escapeBackslashes(value, after) {
	  const expression = /\\(?=[!-/:-@[-`{-~])/g;
	  /** @type {Array<number>} */
	  const positions = [];
	  /** @type {Array<string>} */
	  const results = [];
	  const whole = value + after;
	  let index = -1;
	  let start = 0;
	  /** @type {RegExpExecArray | null} */
	  let match;

	  while ((match = expression.exec(whole))) {
	    positions.push(match.index);
	  }

	  while (++index < positions.length) {
	    if (start !== positions[index]) {
	      results.push(value.slice(start, positions[index]));
	    }

	    results.push('\\');
	    start = positions[index];
	  }

	  results.push(value.slice(start));

	  return results.join('')
	}

	/**
	 * @import {CreateTracker, TrackCurrent, TrackMove, TrackShift} from '../types.js'
	 */

	/**
	 * Track positional info in the output.
	 *
	 * @type {CreateTracker}
	 */
	function track(config) {
	  // Defaults are used to prevent crashes when older utilities somehow activate
	  // this code.
	  /* c8 ignore next 5 */
	  const options = config || {};
	  const now = options.now || {};
	  let lineShift = options.lineShift || 0;
	  let line = now.line || 1;
	  let column = now.column || 1;

	  return {move, current, shift}

	  /**
	   * Get the current tracked info.
	   *
	   * @type {TrackCurrent}
	   */
	  function current() {
	    return {now: {line, column}, lineShift}
	  }

	  /**
	   * Define an increased line shift (the typical indent for lines).
	   *
	   * @type {TrackShift}
	   */
	  function shift(value) {
	    lineShift += value;
	  }

	  /**
	   * Move past some generated markdown.
	   *
	   * @type {TrackMove}
	   */
	  function move(input) {
	    // eslint-disable-next-line unicorn/prefer-default-parameters
	    const value = input || '';
	    const chunks = value.split(/\r?\n|\r/g);
	    const tail = chunks[chunks.length - 1];
	    line += chunks.length - 1;
	    column =
	      chunks.length === 1 ? column + tail.length : 1 + tail.length + lineShift;
	    return value
	  }
	}

	/**
	 * @import {Info, Join, Options, SafeConfig, State} from 'mdast-util-to-markdown'
	 * @import {Nodes} from 'mdast'
	 * @import {Enter, FlowParents, PhrasingParents, TrackFields} from './types.js'
	 */


	/**
	 * Turn an mdast syntax tree into markdown.
	 *
	 * @param {Nodes} tree
	 *   Tree to serialize.
	 * @param {Options | null | undefined} [options]
	 *   Configuration (optional).
	 * @returns {string}
	 *   Serialized markdown representing `tree`.
	 */
	function toMarkdown(tree, options) {
	  const settings = options || {};
	  /** @type {State} */
	  const state = {
	    associationId: association,
	    containerPhrasing: containerPhrasingBound,
	    containerFlow: containerFlowBound,
	    createTracker: track,
	    compilePattern,
	    enter,
	    // @ts-expect-error: GFM / frontmatter are typed in `mdast` but not defined
	    // here.
	    handlers: {...handle},
	    // @ts-expect-error: add `handle` in a second.
	    handle: undefined,
	    indentLines,
	    indexStack: [],
	    join: [...join],
	    options: {},
	    safe: safeBound,
	    stack: [],
	    unsafe: [...unsafe]
	  };

	  configure(state, settings);

	  if (state.options.tightDefinitions) {
	    state.join.push(joinDefinition);
	  }

	  state.handle = zwitch('type', {
	    invalid,
	    unknown,
	    handlers: state.handlers
	  });

	  let result = state.handle(tree, undefined, state, {
	    before: '\n',
	    after: '\n',
	    now: {line: 1, column: 1},
	    lineShift: 0
	  });

	  if (
	    result &&
	    result.charCodeAt(result.length - 1) !== 10 &&
	    result.charCodeAt(result.length - 1) !== 13
	  ) {
	    result += '\n';
	  }

	  return result

	  /** @type {Enter} */
	  function enter(name) {
	    state.stack.push(name);
	    return exit

	    /**
	     * @returns {undefined}
	     */
	    function exit() {
	      state.stack.pop();
	    }
	  }
	}

	/**
	 * @param {unknown} value
	 * @returns {never}
	 */
	function invalid(value) {
	  throw new Error('Cannot handle value `' + value + '`, expected node')
	}

	/**
	 * @param {unknown} value
	 * @returns {never}
	 */
	function unknown(value) {
	  // Always a node.
	  const node = /** @type {Nodes} */ (value);
	  throw new Error('Cannot handle unknown node `' + node.type + '`')
	}

	/** @type {Join} */
	function joinDefinition(left, right) {
	  // No blank line between adjacent definitions.
	  if (left.type === 'definition' && left.type === right.type) {
	    return 0
	  }
	}

	/**
	 * Serialize the children of a parent that contains phrasing children.
	 *
	 * These children will be joined flush together.
	 *
	 * @this {State}
	 *   Info passed around about the current state.
	 * @param {PhrasingParents} parent
	 *   Parent of flow nodes.
	 * @param {Info} info
	 *   Info on where we are in the document we are generating.
	 * @returns {string}
	 *   Serialized children, joined together.
	 */
	function containerPhrasingBound(parent, info) {
	  return containerPhrasing(parent, this, info)
	}

	/**
	 * Serialize the children of a parent that contains flow children.
	 *
	 * These children will typically be joined by blank lines.
	 * What they are joined by exactly is defined by `Join` functions.
	 *
	 * @this {State}
	 *   Info passed around about the current state.
	 * @param {FlowParents} parent
	 *   Parent of flow nodes.
	 * @param {TrackFields} info
	 *   Info on where we are in the document we are generating.
	 * @returns {string}
	 *   Serialized children, joined by (blank) lines.
	 */
	function containerFlowBound(parent, info) {
	  return containerFlow(parent, this, info)
	}

	/**
	 * Make a string safe for embedding in markdown constructs.
	 *
	 * In markdown, almost all punctuation characters can, in certain cases,
	 * result in something.
	 * Whether they do is highly subjective to where they happen and in what
	 * they happen.
	 *
	 * To solve this, `mdast-util-to-markdown` tracks:
	 *
	 * * Characters before and after something;
	 * * What constructs we are in.
	 *
	 * This information is then used by this function to escape or encode
	 * special characters.
	 *
	 * @this {State}
	 *   Info passed around about the current state.
	 * @param {string | null | undefined} value
	 *   Raw value to make safe.
	 * @param {SafeConfig} config
	 *   Configuration.
	 * @returns {string}
	 *   Serialized markdown safe for embedding.
	 */
	function safeBound(value, config) {
	  return safe(this, value, config)
	}

	/**
	 * @typedef {import('mdast').Root} Root
	 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownOptions
	 * @typedef {import('unified').Compiler<Root, string>} Compiler
	 * @typedef {import('unified').Processor<undefined, undefined, undefined, Root, string>} Processor
	 */


	/**
	 * Add support for serializing to markdown.
	 *
	 * @param {Readonly<Options> | null | undefined} [options]
	 *   Configuration (optional).
	 * @returns {undefined}
	 *   Nothing.
	 */
	function remarkStringify(options) {
	  /** @type {Processor} */
	  // @ts-expect-error: TS in JSDoc generates wrong types if `this` is typed regularly.
	  const self = this;

	  self.compiler = compiler;

	  /**
	   * @type {Compiler}
	   */
	  function compiler(tree) {
	    return toMarkdown(tree, {
	      ...self.data('settings'),
	      ...options,
	      // Note: this option is not in the readme.
	      // The goal is for it to be set by plugins on `data` instead of being
	      // passed by users.
	      extensions: self.data('toMarkdownExtensions') || []
	    })
	  }
	}

	var lib = {};

	/*
	 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
	 */

	var IdentifierIssuer_1;
	var hasRequiredIdentifierIssuer;

	function requireIdentifierIssuer () {
		if (hasRequiredIdentifierIssuer) return IdentifierIssuer_1;
		hasRequiredIdentifierIssuer = 1;

		IdentifierIssuer_1 = class IdentifierIssuer {
		  /**
		   * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique
		   * identifiers, keeping track of any previously issued identifiers.
		   *
		   * @param prefix the prefix to use ('<prefix><counter>').
		   * @param existing an existing Map to use.
		   * @param counter the counter to use.
		   */
		  constructor(prefix, existing = new Map(), counter = 0) {
		    this.prefix = prefix;
		    this._existing = existing;
		    this.counter = counter;
		  }

		  /**
		   * Copies this IdentifierIssuer.
		   *
		   * @return a copy of this IdentifierIssuer.
		   */
		  clone() {
		    const {prefix, _existing, counter} = this;
		    return new IdentifierIssuer(prefix, new Map(_existing), counter);
		  }

		  /**
		   * Gets the new identifier for the given old identifier, where if no old
		   * identifier is given a new identifier will be generated.
		   *
		   * @param [old] the old identifier to get the new identifier for.
		   *
		   * @return the new identifier.
		   */
		  getId(old) {
		    // return existing old identifier
		    const existing = old && this._existing.get(old);
		    if(existing) {
		      return existing;
		    }

		    // get next identifier
		    const identifier = this.prefix + this.counter;
		    this.counter++;

		    // save mapping
		    if(old) {
		      this._existing.set(old, identifier);
		    }

		    return identifier;
		  }

		  /**
		   * Returns true if the given old identifer has already been assigned a new
		   * identifier.
		   *
		   * @param old the old identifier to check.
		   *
		   * @return true if the old identifier has been assigned a new identifier,
		   *   false if not.
		   */
		  hasId(old) {
		    return this._existing.has(old);
		  }

		  /**
		   * Returns all of the IDs that have been issued new IDs in the order in
		   * which they were issued new IDs.
		   *
		   * @return the list of old IDs that has been issued new IDs in order.
		   */
		  getOldIds() {
		    return [...this._existing.keys()];
		  }
		};
		return IdentifierIssuer_1;
	}

	var setImmediate$1 = {};

	var hasRequiredSetImmediate;

	function requireSetImmediate () {
		if (hasRequiredSetImmediate) return setImmediate$1;
		hasRequiredSetImmediate = 1;
		(function (global, undefined$1) {

		    if (global.setImmediate) {
		        return;
		    }

		    var nextHandle = 1; // Spec says greater than zero
		    var tasksByHandle = {};
		    var currentlyRunningATask = false;
		    var doc = global.document;
		    var registerImmediate;

		    function setImmediate(callback) {
		      // Callback can either be a function or a string
		      if (typeof callback !== "function") {
		        callback = new Function("" + callback);
		      }
		      // Copy function arguments
		      var args = new Array(arguments.length - 1);
		      for (var i = 0; i < args.length; i++) {
		          args[i] = arguments[i + 1];
		      }
		      // Store and register the task
		      var task = { callback: callback, args: args };
		      tasksByHandle[nextHandle] = task;
		      registerImmediate(nextHandle);
		      return nextHandle++;
		    }

		    function clearImmediate(handle) {
		        delete tasksByHandle[handle];
		    }

		    function run(task) {
		        var callback = task.callback;
		        var args = task.args;
		        switch (args.length) {
		        case 0:
		            callback();
		            break;
		        case 1:
		            callback(args[0]);
		            break;
		        case 2:
		            callback(args[0], args[1]);
		            break;
		        case 3:
		            callback(args[0], args[1], args[2]);
		            break;
		        default:
		            callback.apply(undefined$1, args);
		            break;
		        }
		    }

		    function runIfPresent(handle) {
		        // From the spec: "Wait until any invocations of this algorithm started before this one have completed."
		        // So if we're currently running a task, we'll need to delay this invocation.
		        if (currentlyRunningATask) {
		            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a
		            // "too much recursion" error.
		            setTimeout(runIfPresent, 0, handle);
		        } else {
		            var task = tasksByHandle[handle];
		            if (task) {
		                currentlyRunningATask = true;
		                try {
		                    run(task);
		                } finally {
		                    clearImmediate(handle);
		                    currentlyRunningATask = false;
		                }
		            }
		        }
		    }

		    function installNextTickImplementation() {
		        registerImmediate = function(handle) {
		            process.nextTick(function () { runIfPresent(handle); });
		        };
		    }

		    function canUsePostMessage() {
		        // The test against `importScripts` prevents this implementation from being installed inside a web worker,
		        // where `global.postMessage` means something completely different and can't be used for this purpose.
		        if (global.postMessage && !global.importScripts) {
		            var postMessageIsAsynchronous = true;
		            var oldOnMessage = global.onmessage;
		            global.onmessage = function() {
		                postMessageIsAsynchronous = false;
		            };
		            global.postMessage("", "*");
		            global.onmessage = oldOnMessage;
		            return postMessageIsAsynchronous;
		        }
		    }

		    function installPostMessageImplementation() {
		        // Installs an event handler on `global` for the `message` event: see
		        // * https://developer.mozilla.org/en/DOM/window.postMessage
		        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages

		        var messagePrefix = "setImmediate$" + Math.random() + "$";
		        var onGlobalMessage = function(event) {
		            if (event.source === global &&
		                typeof event.data === "string" &&
		                event.data.indexOf(messagePrefix) === 0) {
		                runIfPresent(+event.data.slice(messagePrefix.length));
		            }
		        };

		        if (global.addEventListener) {
		            global.addEventListener("message", onGlobalMessage, false);
		        } else {
		            global.attachEvent("onmessage", onGlobalMessage);
		        }

		        registerImmediate = function(handle) {
		            global.postMessage(messagePrefix + handle, "*");
		        };
		    }

		    function installMessageChannelImplementation() {
		        var channel = new MessageChannel();
		        channel.port1.onmessage = function(event) {
		            var handle = event.data;
		            runIfPresent(handle);
		        };

		        registerImmediate = function(handle) {
		            channel.port2.postMessage(handle);
		        };
		    }

		    function installReadyStateChangeImplementation() {
		        var html = doc.documentElement;
		        registerImmediate = function(handle) {
		            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted
		            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.
		            var script = doc.createElement("script");
		            script.onreadystatechange = function () {
		                runIfPresent(handle);
		                script.onreadystatechange = null;
		                html.removeChild(script);
		                script = null;
		            };
		            html.appendChild(script);
		        };
		    }

		    function installSetTimeoutImplementation() {
		        registerImmediate = function(handle) {
		            setTimeout(runIfPresent, 0, handle);
		        };
		    }

		    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.
		    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);
		    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;

		    // Don't get fooled by e.g. browserify environments.
		    if ({}.toString.call(global.process) === "[object process]") {
		        // For Node.js before 0.9
		        installNextTickImplementation();

		    } else if (canUsePostMessage()) {
		        // For non-IE10 modern browsers
		        installPostMessageImplementation();

		    } else if (global.MessageChannel) {
		        // For web workers, where supported
		        installMessageChannelImplementation();

		    } else if (doc && "onreadystatechange" in doc.createElement("script")) {
		        // For IE 68
		        installReadyStateChangeImplementation();

		    } else {
		        // For older browsers
		        installSetTimeoutImplementation();
		    }

		    attachTo.setImmediate = setImmediate;
		    attachTo.clearImmediate = clearImmediate;
		}(typeof self === "undefined" ? typeof commonjsGlobal === "undefined" ? setImmediate$1 : commonjsGlobal : self));
		return setImmediate$1;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var MessageDigestBrowser;
	var hasRequiredMessageDigestBrowser;

	function requireMessageDigestBrowser () {
		if (hasRequiredMessageDigestBrowser) return MessageDigestBrowser;
		hasRequiredMessageDigestBrowser = 1;

		requireSetImmediate();

		const crypto = self.crypto || self.msCrypto;

		MessageDigestBrowser = class MessageDigest {
		  /**
		   * Creates a new MessageDigest.
		   *
		   * @param algorithm the algorithm to use.
		   */
		  constructor(algorithm) {
		    // check if crypto.subtle is available
		    // check is here rather than top-level to only fail if class is used
		    if(!(crypto && crypto.subtle)) {
		      throw new Error('crypto.subtle not found.');
		    }
		    if(algorithm === 'sha256') {
		      this.algorithm = {name: 'SHA-256'};
		    } else if(algorithm === 'sha1') {
		      this.algorithm = {name: 'SHA-1'};
		    } else {
		      throw new Error(`Unsupported algorithm "${algorithm}".`);
		    }
		    this._content = '';
		  }

		  update(msg) {
		    this._content += msg;
		  }

		  async digest() {
		    const data = new TextEncoder().encode(this._content);
		    const buffer = new Uint8Array(
		      await crypto.subtle.digest(this.algorithm, data));
		    // return digest in hex
		    let hex = '';
		    for(let i = 0; i < buffer.length; ++i) {
		      hex += buffer[i].toString(16).padStart(2, '0');
		    }
		    return hex;
		  }
		};
		return MessageDigestBrowser;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var Permuter_1;
	var hasRequiredPermuter;

	function requirePermuter () {
		if (hasRequiredPermuter) return Permuter_1;
		hasRequiredPermuter = 1;

		Permuter_1 = class Permuter {
		  /**
		   * A Permuter iterates over all possible permutations of the given array
		   * of elements.
		   *
		   * @param list the array of elements to iterate over.
		   */
		  constructor(list) {
		    // original array
		    this.current = list.sort();
		    // indicates whether there are more permutations
		    this.done = false;
		    // directional info for permutation algorithm
		    this.dir = new Map();
		    for(let i = 0; i < list.length; ++i) {
		      this.dir.set(list[i], true);
		    }
		  }

		  /**
		   * Returns true if there is another permutation.
		   *
		   * @return true if there is another permutation, false if not.
		   */
		  hasNext() {
		    return !this.done;
		  }

		  /**
		   * Gets the next permutation. Call hasNext() to ensure there is another one
		   * first.
		   *
		   * @return the next permutation.
		   */
		  next() {
		    // copy current permutation to return it
		    const {current, dir} = this;
		    const rval = current.slice();

		    /* Calculate the next permutation using the Steinhaus-Johnson-Trotter
		     permutation algorithm. */

		    // get largest mobile element k
		    // (mobile: element is greater than the one it is looking at)
		    let k = null;
		    let pos = 0;
		    const length = current.length;
		    for(let i = 0; i < length; ++i) {
		      const element = current[i];
		      const left = dir.get(element);
		      if((k === null || element > k) &&
		        ((left && i > 0 && element > current[i - 1]) ||
		        (!left && i < (length - 1) && element > current[i + 1]))) {
		        k = element;
		        pos = i;
		      }
		    }

		    // no more permutations
		    if(k === null) {
		      this.done = true;
		    } else {
		      // swap k and the element it is looking at
		      const swap = dir.get(k) ? pos - 1 : pos + 1;
		      current[pos] = current[swap];
		      current[swap] = k;

		      // reverse the direction of all elements larger than k
		      for(const element of current) {
		        if(element > k) {
		          dir.set(element, !dir.get(element));
		        }
		      }
		    }

		    return rval;
		  }
		};
		return Permuter_1;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var NQuads_1;
	var hasRequiredNQuads$1;

	function requireNQuads$1 () {
		if (hasRequiredNQuads$1) return NQuads_1;
		hasRequiredNQuads$1 = 1;
		const RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';
		const RDF_LANGSTRING = RDF + 'langString';
		const XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';

		const TYPE_NAMED_NODE = 'NamedNode';
		const TYPE_BLANK_NODE = 'BlankNode';
		const TYPE_LITERAL = 'Literal';
		const TYPE_DEFAULT_GRAPH = 'DefaultGraph';

		// build regexes
		const REGEX = {};
		(() => {
		  const iri = '(?:<([^:]+:[^>]*)>)';
		  // https://www.w3.org/TR/turtle/#grammar-production-BLANK_NODE_LABEL
		  const PN_CHARS_BASE =
		    'A-Z' + 'a-z' +
		    '\u00C0-\u00D6' +
		    '\u00D8-\u00F6' +
		    '\u00F8-\u02FF' +
		    '\u0370-\u037D' +
		    '\u037F-\u1FFF' +
		    '\u200C-\u200D' +
		    '\u2070-\u218F' +
		    '\u2C00-\u2FEF' +
		    '\u3001-\uD7FF' +
		    '\uF900-\uFDCF' +
		    '\uFDF0-\uFFFD';
		    // TODO:
		    //'\u10000-\uEFFFF';
		  const PN_CHARS_U =
		    PN_CHARS_BASE +
		    '_';
		  const PN_CHARS =
		    PN_CHARS_U +
		    '0-9' +
		    '-' +
		    '\u00B7' +
		    '\u0300-\u036F' +
		    '\u203F-\u2040';
		  const BLANK_NODE_LABEL =
		    '(_:' +
		      '(?:[' + PN_CHARS_U + '0-9])' +
		      '(?:(?:[' + PN_CHARS + '.])*(?:[' + PN_CHARS + ']))?' +
		    ')';
		  const bnode = BLANK_NODE_LABEL;
		  const plain = '"([^"\\\\]*(?:\\\\.[^"\\\\]*)*)"';
		  const datatype = '(?:\\^\\^' + iri + ')';
		  const language = '(?:@([a-zA-Z]+(?:-[a-zA-Z0-9]+)*))';
		  const literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';
		  const ws = '[ \\t]+';
		  const wso = '[ \\t]*';

		  // define quad part regexes
		  const subject = '(?:' + iri + '|' + bnode + ')' + ws;
		  const property = iri + ws;
		  const object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;
		  const graphName = '(?:\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\.))';

		  // end of line and empty regexes
		  REGEX.eoln = /(?:\r\n)|(?:\n)|(?:\r)/g;
		  REGEX.empty = new RegExp('^' + wso + '$');

		  // full quad regex
		  REGEX.quad = new RegExp(
		    '^' + wso + subject + property + object + graphName + wso + '$');
		})();

		NQuads_1 = class NQuads {
		  /**
		   * Parses RDF in the form of N-Quads.
		   *
		   * @param input the N-Quads input to parse.
		   *
		   * @return an RDF dataset (an array of quads per http://rdf.js.org/).
		   */
		  static parse(input) {
		    // build RDF dataset
		    const dataset = [];

		    const graphs = {};

		    // split N-Quad input into lines
		    const lines = input.split(REGEX.eoln);
		    let lineNumber = 0;
		    for(const line of lines) {
		      lineNumber++;

		      // skip empty lines
		      if(REGEX.empty.test(line)) {
		        continue;
		      }

		      // parse quad
		      const match = line.match(REGEX.quad);
		      if(match === null) {
		        throw new Error('N-Quads parse error on line ' + lineNumber + '.');
		      }

		      // create RDF quad
		      const quad = {subject: null, predicate: null, object: null, graph: null};

		      // get subject
		      if(match[1] !== undefined) {
		        quad.subject = {termType: TYPE_NAMED_NODE, value: match[1]};
		      } else {
		        quad.subject = {termType: TYPE_BLANK_NODE, value: match[2]};
		      }

		      // get predicate
		      quad.predicate = {termType: TYPE_NAMED_NODE, value: match[3]};

		      // get object
		      if(match[4] !== undefined) {
		        quad.object = {termType: TYPE_NAMED_NODE, value: match[4]};
		      } else if(match[5] !== undefined) {
		        quad.object = {termType: TYPE_BLANK_NODE, value: match[5]};
		      } else {
		        quad.object = {
		          termType: TYPE_LITERAL,
		          value: undefined,
		          datatype: {
		            termType: TYPE_NAMED_NODE
		          }
		        };
		        if(match[7] !== undefined) {
		          quad.object.datatype.value = match[7];
		        } else if(match[8] !== undefined) {
		          quad.object.datatype.value = RDF_LANGSTRING;
		          quad.object.language = match[8];
		        } else {
		          quad.object.datatype.value = XSD_STRING;
		        }
		        quad.object.value = _unescape(match[6]);
		      }

		      // get graph
		      if(match[9] !== undefined) {
		        quad.graph = {
		          termType: TYPE_NAMED_NODE,
		          value: match[9]
		        };
		      } else if(match[10] !== undefined) {
		        quad.graph = {
		          termType: TYPE_BLANK_NODE,
		          value: match[10]
		        };
		      } else {
		        quad.graph = {
		          termType: TYPE_DEFAULT_GRAPH,
		          value: ''
		        };
		      }

		      // only add quad if it is unique in its graph
		      if(!(quad.graph.value in graphs)) {
		        graphs[quad.graph.value] = [quad];
		        dataset.push(quad);
		      } else {
		        let unique = true;
		        const quads = graphs[quad.graph.value];
		        for(const q of quads) {
		          if(_compareTriples(q, quad)) {
		            unique = false;
		            break;
		          }
		        }
		        if(unique) {
		          quads.push(quad);
		          dataset.push(quad);
		        }
		      }
		    }

		    return dataset;
		  }

		  /**
		   * Converts an RDF dataset to N-Quads.
		   *
		   * @param dataset (array of quads) the RDF dataset to convert.
		   *
		   * @return the N-Quads string.
		   */
		  static serialize(dataset) {
		    if(!Array.isArray(dataset)) {
		      dataset = NQuads.legacyDatasetToQuads(dataset);
		    }
		    const quads = [];
		    for(const quad of dataset) {
		      quads.push(NQuads.serializeQuad(quad));
		    }
		    return quads.sort().join('');
		  }

		  /**
		   * Converts RDF quad components to an N-Quad string (a single quad).
		   *
		   * @param {Object} s - N-Quad subject component.
		   * @param {Object} p - N-Quad predicate component.
		   * @param {Object} o - N-Quad object component.
		   * @param {Object} g - N-Quad graph component.
		   *
		   * @return {string} the N-Quad.
		   */
		  static serializeQuadComponents(s, p, o, g) {
		    let nquad = '';

		    // subject can only be NamedNode or BlankNode
		    if(s.termType === TYPE_NAMED_NODE) {
		      nquad += `<${s.value}>`;
		    } else {
		      nquad += `${s.value}`;
		    }

		    // predicate can only be NamedNode
		    nquad += ` <${p.value}> `;

		    // object is NamedNode, BlankNode, or Literal
		    if(o.termType === TYPE_NAMED_NODE) {
		      nquad += `<${o.value}>`;
		    } else if(o.termType === TYPE_BLANK_NODE) {
		      nquad += o.value;
		    } else {
		      nquad += `"${_escape(o.value)}"`;
		      if(o.datatype.value === RDF_LANGSTRING) {
		        if(o.language) {
		          nquad += `@${o.language}`;
		        }
		      } else if(o.datatype.value !== XSD_STRING) {
		        nquad += `^^<${o.datatype.value}>`;
		      }
		    }

		    // graph can only be NamedNode or BlankNode (or DefaultGraph, but that
		    // does not add to `nquad`)
		    if(g.termType === TYPE_NAMED_NODE) {
		      nquad += ` <${g.value}>`;
		    } else if(g.termType === TYPE_BLANK_NODE) {
		      nquad += ` ${g.value}`;
		    }

		    nquad += ' .\n';
		    return nquad;
		  }

		  /**
		   * Converts an RDF quad to an N-Quad string (a single quad).
		   *
		   * @param quad the RDF quad convert.
		   *
		   * @return the N-Quad string.
		   */
		  static serializeQuad(quad) {
		    return NQuads.serializeQuadComponents(
		      quad.subject, quad.predicate, quad.object, quad.graph);
		  }

		  /**
		   * Converts a legacy-formatted dataset to an array of quads dataset per
		   * http://rdf.js.org/.
		   *
		   * @param dataset the legacy dataset to convert.
		   *
		   * @return the array of quads dataset.
		   */
		  static legacyDatasetToQuads(dataset) {
		    const quads = [];

		    const termTypeMap = {
		      'blank node': TYPE_BLANK_NODE,
		      IRI: TYPE_NAMED_NODE,
		      literal: TYPE_LITERAL
		    };

		    for(const graphName in dataset) {
		      const triples = dataset[graphName];
		      triples.forEach(triple => {
		        const quad = {};
		        for(const componentName in triple) {
		          const oldComponent = triple[componentName];
		          const newComponent = {
		            termType: termTypeMap[oldComponent.type],
		            value: oldComponent.value
		          };
		          if(newComponent.termType === TYPE_LITERAL) {
		            newComponent.datatype = {
		              termType: TYPE_NAMED_NODE
		            };
		            if('datatype' in oldComponent) {
		              newComponent.datatype.value = oldComponent.datatype;
		            }
		            if('language' in oldComponent) {
		              if(!('datatype' in oldComponent)) {
		                newComponent.datatype.value = RDF_LANGSTRING;
		              }
		              newComponent.language = oldComponent.language;
		            } else if(!('datatype' in oldComponent)) {
		              newComponent.datatype.value = XSD_STRING;
		            }
		          }
		          quad[componentName] = newComponent;
		        }
		        if(graphName === '@default') {
		          quad.graph = {
		            termType: TYPE_DEFAULT_GRAPH,
		            value: ''
		          };
		        } else {
		          quad.graph = {
		            termType: graphName.startsWith('_:') ?
		              TYPE_BLANK_NODE : TYPE_NAMED_NODE,
		            value: graphName
		          };
		        }
		        quads.push(quad);
		      });
		    }

		    return quads;
		  }
		};

		/**
		 * Compares two RDF triples for equality.
		 *
		 * @param t1 the first triple.
		 * @param t2 the second triple.
		 *
		 * @return true if the triples are the same, false if not.
		 */
		function _compareTriples(t1, t2) {
		  // compare subject and object types first as it is the quickest check
		  if(!(t1.subject.termType === t2.subject.termType &&
		    t1.object.termType === t2.object.termType)) {
		    return false;
		  }
		  // compare values
		  if(!(t1.subject.value === t2.subject.value &&
		    t1.predicate.value === t2.predicate.value &&
		    t1.object.value === t2.object.value)) {
		    return false;
		  }
		  if(t1.object.termType !== TYPE_LITERAL) {
		    // no `datatype` or `language` to check
		    return true;
		  }
		  return (
		    (t1.object.datatype.termType === t2.object.datatype.termType) &&
		    (t1.object.language === t2.object.language) &&
		    (t1.object.datatype.value === t2.object.datatype.value)
		  );
		}

		const _escapeRegex = /["\\\n\r]/g;
		/**
		 * Escape string to N-Quads literal
		 */
		function _escape(s) {
		  return s.replace(_escapeRegex, function(match) {
		    switch(match) {
		      case '"': return '\\"';
		      case '\\': return '\\\\';
		      case '\n': return '\\n';
		      case '\r': return '\\r';
		    }
		  });
		}

		const _unescapeRegex =
		  /(?:\\([tbnrf"'\\]))|(?:\\u([0-9A-Fa-f]{4}))|(?:\\U([0-9A-Fa-f]{8}))/g;
		/**
		 * Unescape N-Quads literal to string
		 */
		function _unescape(s) {
		  return s.replace(_unescapeRegex, function(match, code, u, U) {
		    if(code) {
		      switch(code) {
		        case 't': return '\t';
		        case 'b': return '\b';
		        case 'n': return '\n';
		        case 'r': return '\r';
		        case 'f': return '\f';
		        case '"': return '"';
		        case '\'': return '\'';
		        case '\\': return '\\';
		      }
		    }
		    if(u) {
		      return String.fromCharCode(parseInt(u, 16));
		    }
		    if(U) {
		      // FIXME: support larger values
		      throw new Error('Unsupported U escape');
		    }
		  });
		}
		return NQuads_1;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var URDNA2015_1;
	var hasRequiredURDNA2015;

	function requireURDNA2015 () {
		if (hasRequiredURDNA2015) return URDNA2015_1;
		hasRequiredURDNA2015 = 1;

		const IdentifierIssuer = requireIdentifierIssuer();
		const MessageDigest = requireMessageDigestBrowser();
		const Permuter = requirePermuter();
		const NQuads = requireNQuads$1();

		URDNA2015_1 = class URDNA2015 {
		  constructor({
		    createMessageDigest = () => new MessageDigest('sha256'),
		    canonicalIdMap = new Map(),
		    maxDeepIterations = Infinity
		  } = {}) {
		    this.name = 'URDNA2015';
		    this.blankNodeInfo = new Map();
		    this.canonicalIssuer = new IdentifierIssuer('_:c14n', canonicalIdMap);
		    this.createMessageDigest = createMessageDigest;
		    this.maxDeepIterations = maxDeepIterations;
		    this.quads = null;
		    this.deepIterations = null;
		  }

		  // 4.4) Normalization Algorithm
		  async main(dataset) {
		    this.deepIterations = new Map();
		    this.quads = dataset;

		    // 1) Create the normalization state.
		    // 2) For every quad in input dataset:
		    for(const quad of dataset) {
		      // 2.1) For each blank node that occurs in the quad, add a reference
		      // to the quad using the blank node identifier in the blank node to
		      // quads map, creating a new entry if necessary.
		      this._addBlankNodeQuadInfo({quad, component: quad.subject});
		      this._addBlankNodeQuadInfo({quad, component: quad.object});
		      this._addBlankNodeQuadInfo({quad, component: quad.graph});
		    }

		    // 3) Create a list of non-normalized blank node identifiers
		    // non-normalized identifiers and populate it using the keys from the
		    // blank node to quads map.
		    // Note: We use a map here and it was generated during step 2.

		    // 4) `simple` flag is skipped -- loop is optimized away. This optimization
		    // is permitted because there was a typo in the hash first degree quads
		    // algorithm in the URDNA2015 spec that was implemented widely making it
		    // such that it could not be fixed; the result was that the loop only
		    // needs to be run once and the first degree quad hashes will never change.
		    // 5.1-5.2 are skipped; first degree quad hashes are generated just once
		    // for all non-normalized blank nodes.

		    // 5.3) For each blank node identifier identifier in non-normalized
		    // identifiers:
		    const hashToBlankNodes = new Map();
		    const nonNormalized = [...this.blankNodeInfo.keys()];
		    let i = 0;
		    for(const id of nonNormalized) {
		      // Note: batch hashing first degree quads 100 at a time
		      if(++i % 100 === 0) {
		        await this._yield();
		      }
		      // steps 5.3.1 and 5.3.2:
		      await this._hashAndTrackBlankNode({id, hashToBlankNodes});
		    }

		    // 5.4) For each hash to identifier list mapping in hash to blank
		    // nodes map, lexicographically-sorted by hash:
		    const hashes = [...hashToBlankNodes.keys()].sort();
		    // optimize away second sort, gather non-unique hashes in order as we go
		    const nonUnique = [];
		    for(const hash of hashes) {
		      // 5.4.1) If the length of identifier list is greater than 1,
		      // continue to the next mapping.
		      const idList = hashToBlankNodes.get(hash);
		      if(idList.length > 1) {
		        nonUnique.push(idList);
		        continue;
		      }

		      // 5.4.2) Use the Issue Identifier algorithm, passing canonical
		      // issuer and the single blank node identifier in identifier
		      // list, identifier, to issue a canonical replacement identifier
		      // for identifier.
		      const id = idList[0];
		      this.canonicalIssuer.getId(id);

		      // Note: These steps are skipped, optimized away since the loop
		      // only needs to be run once.
		      // 5.4.3) Remove identifier from non-normalized identifiers.
		      // 5.4.4) Remove hash from the hash to blank nodes map.
		      // 5.4.5) Set simple to true.
		    }

		    // 6) For each hash to identifier list mapping in hash to blank nodes map,
		    // lexicographically-sorted by hash:
		    // Note: sort optimized away, use `nonUnique`.
		    for(const idList of nonUnique) {
		      // 6.1) Create hash path list where each item will be a result of
		      // running the Hash N-Degree Quads algorithm.
		      const hashPathList = [];

		      // 6.2) For each blank node identifier identifier in identifier list:
		      for(const id of idList) {
		        // 6.2.1) If a canonical identifier has already been issued for
		        // identifier, continue to the next identifier.
		        if(this.canonicalIssuer.hasId(id)) {
		          continue;
		        }

		        // 6.2.2) Create temporary issuer, an identifier issuer
		        // initialized with the prefix _:b.
		        const issuer = new IdentifierIssuer('_:b');

		        // 6.2.3) Use the Issue Identifier algorithm, passing temporary
		        // issuer and identifier, to issue a new temporary blank node
		        // identifier for identifier.
		        issuer.getId(id);

		        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing
		        // temporary issuer, and append the result to the hash path list.
		        const result = await this.hashNDegreeQuads(id, issuer);
		        hashPathList.push(result);
		      }

		      // 6.3) For each result in the hash path list,
		      // lexicographically-sorted by the hash in result:
		      hashPathList.sort(_stringHashCompare);
		      for(const result of hashPathList) {
		        // 6.3.1) For each blank node identifier, existing identifier,
		        // that was issued a temporary identifier by identifier issuer
		        // in result, issue a canonical identifier, in the same order,
		        // using the Issue Identifier algorithm, passing canonical
		        // issuer and existing identifier.
		        const oldIds = result.issuer.getOldIds();
		        for(const id of oldIds) {
		          this.canonicalIssuer.getId(id);
		        }
		      }
		    }

		    /* Note: At this point all blank nodes in the set of RDF quads have been
		    assigned canonical identifiers, which have been stored in the canonical
		    issuer. Here each quad is updated by assigning each of its blank nodes
		    its new identifier. */

		    // 7) For each quad, quad, in input dataset:
		    const normalized = [];
		    for(const quad of this.quads) {
		      // 7.1) Create a copy, quad copy, of quad and replace any existing
		      // blank node identifiers using the canonical identifiers
		      // previously issued by canonical issuer.
		      // Note: We optimize away the copy here.
		      const nQuad = NQuads.serializeQuadComponents(
		        this._componentWithCanonicalId(quad.subject),
		        quad.predicate,
		        this._componentWithCanonicalId(quad.object),
		        this._componentWithCanonicalId(quad.graph)
		      );
		      // 7.2) Add quad copy to the normalized dataset.
		      normalized.push(nQuad);
		    }

		    // sort normalized output
		    normalized.sort();

		    // 8) Return the normalized dataset.
		    return normalized.join('');
		  }

		  // 4.6) Hash First Degree Quads
		  async hashFirstDegreeQuads(id) {
		    // 1) Initialize nquads to an empty list. It will be used to store quads in
		    // N-Quads format.
		    const nquads = [];

		    // 2) Get the list of quads `quads` associated with the reference blank node
		    // identifier in the blank node to quads map.
		    const info = this.blankNodeInfo.get(id);
		    const quads = info.quads;

		    // 3) For each quad `quad` in `quads`:
		    for(const quad of quads) {
		      // 3.1) Serialize the quad in N-Quads format with the following special
		      // rule:

		      // 3.1.1) If any component in quad is an blank node, then serialize it
		      // using a special identifier as follows:
		      const copy = {
		        subject: null, predicate: quad.predicate, object: null, graph: null
		      };
		      // 3.1.2) If the blank node's existing blank node identifier matches
		      // the reference blank node identifier then use the blank node
		      // identifier _:a, otherwise, use the blank node identifier _:z.
		      copy.subject = this.modifyFirstDegreeComponent(
		        id, quad.subject, 'subject');
		      copy.object = this.modifyFirstDegreeComponent(
		        id, quad.object, 'object');
		      copy.graph = this.modifyFirstDegreeComponent(
		        id, quad.graph, 'graph');
		      nquads.push(NQuads.serializeQuad(copy));
		    }

		    // 4) Sort nquads in lexicographical order.
		    nquads.sort();

		    // 5) Return the hash that results from passing the sorted, joined nquads
		    // through the hash algorithm.
		    const md = this.createMessageDigest();
		    for(const nquad of nquads) {
		      md.update(nquad);
		    }
		    info.hash = await md.digest();
		    return info.hash;
		  }

		  // 4.7) Hash Related Blank Node
		  async hashRelatedBlankNode(related, quad, issuer, position) {
		    // 1) Set the identifier to use for related, preferring first the canonical
		    // identifier for related if issued, second the identifier issued by issuer
		    // if issued, and last, if necessary, the result of the Hash First Degree
		    // Quads algorithm, passing related.
		    let id;
		    if(this.canonicalIssuer.hasId(related)) {
		      id = this.canonicalIssuer.getId(related);
		    } else if(issuer.hasId(related)) {
		      id = issuer.getId(related);
		    } else {
		      id = this.blankNodeInfo.get(related).hash;
		    }

		    // 2) Initialize a string input to the value of position.
		    // Note: We use a hash object instead.
		    const md = this.createMessageDigest();
		    md.update(position);

		    // 3) If position is not g, append <, the value of the predicate in quad,
		    // and > to input.
		    if(position !== 'g') {
		      md.update(this.getRelatedPredicate(quad));
		    }

		    // 4) Append identifier to input.
		    md.update(id);

		    // 5) Return the hash that results from passing input through the hash
		    // algorithm.
		    return md.digest();
		  }

		  // 4.8) Hash N-Degree Quads
		  async hashNDegreeQuads(id, issuer) {
		    const deepIterations = this.deepIterations.get(id) || 0;
		    if(deepIterations > this.maxDeepIterations) {
		      throw new Error(
		        `Maximum deep iterations (${this.maxDeepIterations}) exceeded.`);
		    }
		    this.deepIterations.set(id, deepIterations + 1);

		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    // Note: 2) and 3) handled within `createHashToRelated`
		    const md = this.createMessageDigest();
		    const hashToRelated = await this.createHashToRelated(id, issuer);

		    // 4) Create an empty string, data to hash.
		    // Note: We created a hash object `md` above instead.

		    // 5) For each related hash to blank node list mapping in hash to related
		    // blank nodes map, sorted lexicographically by related hash:
		    const hashes = [...hashToRelated.keys()].sort();
		    for(const hash of hashes) {
		      // 5.1) Append the related hash to the data to hash.
		      md.update(hash);

		      // 5.2) Create a string chosen path.
		      let chosenPath = '';

		      // 5.3) Create an unset chosen issuer variable.
		      let chosenIssuer;

		      // 5.4) For each permutation of blank node list:
		      const permuter = new Permuter(hashToRelated.get(hash));
		      let i = 0;
		      while(permuter.hasNext()) {
		        const permutation = permuter.next();
		        // Note: batch permutations 3 at a time
		        if(++i % 3 === 0) {
		          await this._yield();
		        }

		        // 5.4.1) Create a copy of issuer, issuer copy.
		        let issuerCopy = issuer.clone();

		        // 5.4.2) Create a string path.
		        let path = '';

		        // 5.4.3) Create a recursion list, to store blank node identifiers
		        // that must be recursively processed by this algorithm.
		        const recursionList = [];

		        // 5.4.4) For each related in permutation:
		        let nextPermutation = false;
		        for(const related of permutation) {
		          // 5.4.4.1) If a canonical identifier has been issued for
		          // related, append it to path.
		          if(this.canonicalIssuer.hasId(related)) {
		            path += this.canonicalIssuer.getId(related);
		          } else {
		            // 5.4.4.2) Otherwise:
		            // 5.4.4.2.1) If issuer copy has not issued an identifier for
		            // related, append related to recursion list.
		            if(!issuerCopy.hasId(related)) {
		              recursionList.push(related);
		            }
		            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing
		            // issuer copy and related and append the result to path.
		            path += issuerCopy.getId(related);
		          }

		          // 5.4.4.3) If chosen path is not empty and the length of path
		          // is greater than or equal to the length of chosen path and
		          // path is lexicographically greater than chosen path, then
		          // skip to the next permutation.
		          // Note: Comparing path length to chosen path length can be optimized
		          // away; only compare lexicographically.
		          if(chosenPath.length !== 0 && path > chosenPath) {
		            nextPermutation = true;
		            break;
		          }
		        }

		        if(nextPermutation) {
		          continue;
		        }

		        // 5.4.5) For each related in recursion list:
		        for(const related of recursionList) {
		          // 5.4.5.1) Set result to the result of recursively executing
		          // the Hash N-Degree Quads algorithm, passing related for
		          // identifier and issuer copy for path identifier issuer.
		          const result = await this.hashNDegreeQuads(related, issuerCopy);

		          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer
		          // copy and related and append the result to path.
		          path += issuerCopy.getId(related);

		          // 5.4.5.3) Append <, the hash in result, and > to path.
		          path += `<${result.hash}>`;

		          // 5.4.5.4) Set issuer copy to the identifier issuer in
		          // result.
		          issuerCopy = result.issuer;

		          // 5.4.5.5) If chosen path is not empty and the length of path
		          // is greater than or equal to the length of chosen path and
		          // path is lexicographically greater than chosen path, then
		          // skip to the next permutation.
		          // Note: Comparing path length to chosen path length can be optimized
		          // away; only compare lexicographically.
		          if(chosenPath.length !== 0 && path > chosenPath) {
		            nextPermutation = true;
		            break;
		          }
		        }

		        if(nextPermutation) {
		          continue;
		        }

		        // 5.4.6) If chosen path is empty or path is lexicographically
		        // less than chosen path, set chosen path to path and chosen
		        // issuer to issuer copy.
		        if(chosenPath.length === 0 || path < chosenPath) {
		          chosenPath = path;
		          chosenIssuer = issuerCopy;
		        }
		      }

		      // 5.5) Append chosen path to data to hash.
		      md.update(chosenPath);

		      // 5.6) Replace issuer, by reference, with chosen issuer.
		      issuer = chosenIssuer;
		    }

		    // 6) Return issuer and the hash that results from passing data to hash
		    // through the hash algorithm.
		    return {hash: await md.digest(), issuer};
		  }

		  // helper for modifying component during Hash First Degree Quads
		  modifyFirstDegreeComponent(id, component) {
		    if(component.termType !== 'BlankNode') {
		      return component;
		    }
		    /* Note: A mistake in the URDNA2015 spec that made its way into
		    implementations (and therefore must stay to avoid interop breakage)
		    resulted in an assigned canonical ID, if available for
		    `component.value`, not being used in place of `_:a`/`_:z`, so
		    we don't use it here. */
		    return {
		      termType: 'BlankNode',
		      value: component.value === id ? '_:a' : '_:z'
		    };
		  }

		  // helper for getting a related predicate
		  getRelatedPredicate(quad) {
		    return `<${quad.predicate.value}>`;
		  }

		  // helper for creating hash to related blank nodes map
		  async createHashToRelated(id, issuer) {
		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    const hashToRelated = new Map();

		    // 2) Get a reference, quads, to the list of quads in the blank node to
		    // quads map for the key identifier.
		    const quads = this.blankNodeInfo.get(id).quads;

		    // 3) For each quad in quads:
		    let i = 0;
		    for(const quad of quads) {
		      // Note: batch hashing related blank node quads 100 at a time
		      if(++i % 100 === 0) {
		        await this._yield();
		      }
		      // 3.1) For each component in quad, if component is the subject, object,
		      // and graph name and it is a blank node that is not identified by
		      // identifier:
		      // steps 3.1.1 and 3.1.2 occur in helpers:
		      await Promise.all([
		        this._addRelatedBlankNodeHash({
		          quad, component: quad.subject, position: 's',
		          id, issuer, hashToRelated
		        }),
		        this._addRelatedBlankNodeHash({
		          quad, component: quad.object, position: 'o',
		          id, issuer, hashToRelated
		        }),
		        this._addRelatedBlankNodeHash({
		          quad, component: quad.graph, position: 'g',
		          id, issuer, hashToRelated
		        })
		      ]);
		    }

		    return hashToRelated;
		  }

		  async _hashAndTrackBlankNode({id, hashToBlankNodes}) {
		    // 5.3.1) Create a hash, hash, according to the Hash First Degree
		    // Quads algorithm.
		    const hash = await this.hashFirstDegreeQuads(id);

		    // 5.3.2) Add hash and identifier to hash to blank nodes map,
		    // creating a new entry if necessary.
		    const idList = hashToBlankNodes.get(hash);
		    if(!idList) {
		      hashToBlankNodes.set(hash, [id]);
		    } else {
		      idList.push(id);
		    }
		  }

		  _addBlankNodeQuadInfo({quad, component}) {
		    if(component.termType !== 'BlankNode') {
		      return;
		    }
		    const id = component.value;
		    const info = this.blankNodeInfo.get(id);
		    if(info) {
		      info.quads.add(quad);
		    } else {
		      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});
		    }
		  }

		  async _addRelatedBlankNodeHash(
		    {quad, component, position, id, issuer, hashToRelated}) {
		    if(!(component.termType === 'BlankNode' && component.value !== id)) {
		      return;
		    }
		    // 3.1.1) Set hash to the result of the Hash Related Blank Node
		    // algorithm, passing the blank node identifier for component as
		    // related, quad, path identifier issuer as issuer, and position as
		    // either s, o, or g based on whether component is a subject, object,
		    // graph name, respectively.
		    const related = component.value;
		    const hash = await this.hashRelatedBlankNode(
		      related, quad, issuer, position);

		    // 3.1.2) Add a mapping of hash to the blank node identifier for
		    // component to hash to related blank nodes map, adding an entry as
		    // necessary.
		    const entries = hashToRelated.get(hash);
		    if(entries) {
		      entries.push(related);
		    } else {
		      hashToRelated.set(hash, [related]);
		    }
		  }

		  // canonical ids for 7.1
		  _componentWithCanonicalId(component) {
		    if(component.termType === 'BlankNode' &&
		      !component.value.startsWith(this.canonicalIssuer.prefix)) {
		      // create new BlankNode
		      return {
		        termType: 'BlankNode',
		        value: this.canonicalIssuer.getId(component.value)
		      };
		    }
		    return component;
		  }

		  async _yield() {
		    return new Promise(resolve => setImmediate(resolve));
		  }
		};

		function _stringHashCompare(a, b) {
		  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
		}
		return URDNA2015_1;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var URGNA2012;
	var hasRequiredURGNA2012;

	function requireURGNA2012 () {
		if (hasRequiredURGNA2012) return URGNA2012;
		hasRequiredURGNA2012 = 1;

		const MessageDigest = requireMessageDigestBrowser();
		const URDNA2015 = requireURDNA2015();

		URGNA2012 = class URDNA2012 extends URDNA2015 {
		  constructor() {
		    super();
		    this.name = 'URGNA2012';
		    this.createMessageDigest = () => new MessageDigest('sha1');
		  }

		  // helper for modifying component during Hash First Degree Quads
		  modifyFirstDegreeComponent(id, component, key) {
		    if(component.termType !== 'BlankNode') {
		      return component;
		    }
		    if(key === 'graph') {
		      return {
		        termType: 'BlankNode',
		        value: '_:g'
		      };
		    }
		    return {
		      termType: 'BlankNode',
		      value: (component.value === id ? '_:a' : '_:z')
		    };
		  }

		  // helper for getting a related predicate
		  getRelatedPredicate(quad) {
		    return quad.predicate.value;
		  }

		  // helper for creating hash to related blank nodes map
		  async createHashToRelated(id, issuer) {
		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    const hashToRelated = new Map();

		    // 2) Get a reference, quads, to the list of quads in the blank node to
		    // quads map for the key identifier.
		    const quads = this.blankNodeInfo.get(id).quads;

		    // 3) For each quad in quads:
		    let i = 0;
		    for(const quad of quads) {
		      // 3.1) If the quad's subject is a blank node that does not match
		      // identifier, set hash to the result of the Hash Related Blank Node
		      // algorithm, passing the blank node identifier for subject as related,
		      // quad, path identifier issuer as issuer, and p as position.
		      let position;
		      let related;
		      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {
		        related = quad.subject.value;
		        position = 'p';
		      } else if(
		        quad.object.termType === 'BlankNode' && quad.object.value !== id) {
		        // 3.2) Otherwise, if quad's object is a blank node that does not match
		        // identifier, to the result of the Hash Related Blank Node algorithm,
		        // passing the blank node identifier for object as related, quad, path
		        // identifier issuer as issuer, and r as position.
		        related = quad.object.value;
		        position = 'r';
		      } else {
		        // 3.3) Otherwise, continue to the next quad.
		        continue;
		      }
		      // Note: batch hashing related blank nodes 100 at a time
		      if(++i % 100 === 0) {
		        await this._yield();
		      }
		      // 3.4) Add a mapping of hash to the blank node identifier for the
		      // component that matched (subject or object) to hash to related blank
		      // nodes map, adding an entry as necessary.
		      const hash = await this.hashRelatedBlankNode(
		        related, quad, issuer, position);
		      const entries = hashToRelated.get(hash);
		      if(entries) {
		        entries.push(related);
		      } else {
		        hashToRelated.set(hash, [related]);
		      }
		    }

		    return hashToRelated;
		  }
		};
		return URGNA2012;
	}

	/*!
	 * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.
	 */

	var URDNA2015Sync_1;
	var hasRequiredURDNA2015Sync;

	function requireURDNA2015Sync () {
		if (hasRequiredURDNA2015Sync) return URDNA2015Sync_1;
		hasRequiredURDNA2015Sync = 1;

		const IdentifierIssuer = requireIdentifierIssuer();
		// FIXME: do not import; convert to requiring a
		// hash factory
		const MessageDigest = requireMessageDigestBrowser();
		const Permuter = requirePermuter();
		const NQuads = requireNQuads$1();

		URDNA2015Sync_1 = class URDNA2015Sync {
		  constructor({
		    createMessageDigest = () => new MessageDigest('sha256'),
		    canonicalIdMap = new Map(),
		    maxDeepIterations = Infinity
		  } = {}) {
		    this.name = 'URDNA2015';
		    this.blankNodeInfo = new Map();
		    this.canonicalIssuer = new IdentifierIssuer('_:c14n', canonicalIdMap);
		    this.createMessageDigest = createMessageDigest;
		    this.maxDeepIterations = maxDeepIterations;
		    this.quads = null;
		    this.deepIterations = null;
		  }

		  // 4.4) Normalization Algorithm
		  main(dataset) {
		    this.deepIterations = new Map();
		    this.quads = dataset;

		    // 1) Create the normalization state.
		    // 2) For every quad in input dataset:
		    for(const quad of dataset) {
		      // 2.1) For each blank node that occurs in the quad, add a reference
		      // to the quad using the blank node identifier in the blank node to
		      // quads map, creating a new entry if necessary.
		      this._addBlankNodeQuadInfo({quad, component: quad.subject});
		      this._addBlankNodeQuadInfo({quad, component: quad.object});
		      this._addBlankNodeQuadInfo({quad, component: quad.graph});
		    }

		    // 3) Create a list of non-normalized blank node identifiers
		    // non-normalized identifiers and populate it using the keys from the
		    // blank node to quads map.
		    // Note: We use a map here and it was generated during step 2.

		    // 4) `simple` flag is skipped -- loop is optimized away. This optimization
		    // is permitted because there was a typo in the hash first degree quads
		    // algorithm in the URDNA2015 spec that was implemented widely making it
		    // such that it could not be fixed; the result was that the loop only
		    // needs to be run once and the first degree quad hashes will never change.
		    // 5.1-5.2 are skipped; first degree quad hashes are generated just once
		    // for all non-normalized blank nodes.

		    // 5.3) For each blank node identifier identifier in non-normalized
		    // identifiers:
		    const hashToBlankNodes = new Map();
		    const nonNormalized = [...this.blankNodeInfo.keys()];
		    for(const id of nonNormalized) {
		      // steps 5.3.1 and 5.3.2:
		      this._hashAndTrackBlankNode({id, hashToBlankNodes});
		    }

		    // 5.4) For each hash to identifier list mapping in hash to blank
		    // nodes map, lexicographically-sorted by hash:
		    const hashes = [...hashToBlankNodes.keys()].sort();
		    // optimize away second sort, gather non-unique hashes in order as we go
		    const nonUnique = [];
		    for(const hash of hashes) {
		      // 5.4.1) If the length of identifier list is greater than 1,
		      // continue to the next mapping.
		      const idList = hashToBlankNodes.get(hash);
		      if(idList.length > 1) {
		        nonUnique.push(idList);
		        continue;
		      }

		      // 5.4.2) Use the Issue Identifier algorithm, passing canonical
		      // issuer and the single blank node identifier in identifier
		      // list, identifier, to issue a canonical replacement identifier
		      // for identifier.
		      const id = idList[0];
		      this.canonicalIssuer.getId(id);

		      // Note: These steps are skipped, optimized away since the loop
		      // only needs to be run once.
		      // 5.4.3) Remove identifier from non-normalized identifiers.
		      // 5.4.4) Remove hash from the hash to blank nodes map.
		      // 5.4.5) Set simple to true.
		    }

		    // 6) For each hash to identifier list mapping in hash to blank nodes map,
		    // lexicographically-sorted by hash:
		    // Note: sort optimized away, use `nonUnique`.
		    for(const idList of nonUnique) {
		      // 6.1) Create hash path list where each item will be a result of
		      // running the Hash N-Degree Quads algorithm.
		      const hashPathList = [];

		      // 6.2) For each blank node identifier identifier in identifier list:
		      for(const id of idList) {
		        // 6.2.1) If a canonical identifier has already been issued for
		        // identifier, continue to the next identifier.
		        if(this.canonicalIssuer.hasId(id)) {
		          continue;
		        }

		        // 6.2.2) Create temporary issuer, an identifier issuer
		        // initialized with the prefix _:b.
		        const issuer = new IdentifierIssuer('_:b');

		        // 6.2.3) Use the Issue Identifier algorithm, passing temporary
		        // issuer and identifier, to issue a new temporary blank node
		        // identifier for identifier.
		        issuer.getId(id);

		        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing
		        // temporary issuer, and append the result to the hash path list.
		        const result = this.hashNDegreeQuads(id, issuer);
		        hashPathList.push(result);
		      }

		      // 6.3) For each result in the hash path list,
		      // lexicographically-sorted by the hash in result:
		      hashPathList.sort(_stringHashCompare);
		      for(const result of hashPathList) {
		        // 6.3.1) For each blank node identifier, existing identifier,
		        // that was issued a temporary identifier by identifier issuer
		        // in result, issue a canonical identifier, in the same order,
		        // using the Issue Identifier algorithm, passing canonical
		        // issuer and existing identifier.
		        const oldIds = result.issuer.getOldIds();
		        for(const id of oldIds) {
		          this.canonicalIssuer.getId(id);
		        }
		      }
		    }

		    /* Note: At this point all blank nodes in the set of RDF quads have been
		    assigned canonical identifiers, which have been stored in the canonical
		    issuer. Here each quad is updated by assigning each of its blank nodes
		    its new identifier. */

		    // 7) For each quad, quad, in input dataset:
		    const normalized = [];
		    for(const quad of this.quads) {
		      // 7.1) Create a copy, quad copy, of quad and replace any existing
		      // blank node identifiers using the canonical identifiers
		      // previously issued by canonical issuer.
		      // Note: We optimize away the copy here.
		      const nQuad = NQuads.serializeQuadComponents(
		        this._componentWithCanonicalId({component: quad.subject}),
		        quad.predicate,
		        this._componentWithCanonicalId({component: quad.object}),
		        this._componentWithCanonicalId({component: quad.graph})
		      );
		      // 7.2) Add quad copy to the normalized dataset.
		      normalized.push(nQuad);
		    }

		    // sort normalized output
		    normalized.sort();

		    // 8) Return the normalized dataset.
		    return normalized.join('');
		  }

		  // 4.6) Hash First Degree Quads
		  hashFirstDegreeQuads(id) {
		    // 1) Initialize nquads to an empty list. It will be used to store quads in
		    // N-Quads format.
		    const nquads = [];

		    // 2) Get the list of quads `quads` associated with the reference blank node
		    // identifier in the blank node to quads map.
		    const info = this.blankNodeInfo.get(id);
		    const quads = info.quads;

		    // 3) For each quad `quad` in `quads`:
		    for(const quad of quads) {
		      // 3.1) Serialize the quad in N-Quads format with the following special
		      // rule:

		      // 3.1.1) If any component in quad is an blank node, then serialize it
		      // using a special identifier as follows:
		      const copy = {
		        subject: null, predicate: quad.predicate, object: null, graph: null
		      };
		      // 3.1.2) If the blank node's existing blank node identifier matches
		      // the reference blank node identifier then use the blank node
		      // identifier _:a, otherwise, use the blank node identifier _:z.
		      copy.subject = this.modifyFirstDegreeComponent(
		        id, quad.subject, 'subject');
		      copy.object = this.modifyFirstDegreeComponent(
		        id, quad.object, 'object');
		      copy.graph = this.modifyFirstDegreeComponent(
		        id, quad.graph, 'graph');
		      nquads.push(NQuads.serializeQuad(copy));
		    }

		    // 4) Sort nquads in lexicographical order.
		    nquads.sort();

		    // 5) Return the hash that results from passing the sorted, joined nquads
		    // through the hash algorithm.
		    const md = this.createMessageDigest();
		    for(const nquad of nquads) {
		      md.update(nquad);
		    }
		    info.hash = md.digest();
		    return info.hash;
		  }

		  // 4.7) Hash Related Blank Node
		  hashRelatedBlankNode(related, quad, issuer, position) {
		    // 1) Set the identifier to use for related, preferring first the canonical
		    // identifier for related if issued, second the identifier issued by issuer
		    // if issued, and last, if necessary, the result of the Hash First Degree
		    // Quads algorithm, passing related.
		    let id;
		    if(this.canonicalIssuer.hasId(related)) {
		      id = this.canonicalIssuer.getId(related);
		    } else if(issuer.hasId(related)) {
		      id = issuer.getId(related);
		    } else {
		      id = this.blankNodeInfo.get(related).hash;
		    }

		    // 2) Initialize a string input to the value of position.
		    // Note: We use a hash object instead.
		    const md = this.createMessageDigest();
		    md.update(position);

		    // 3) If position is not g, append <, the value of the predicate in quad,
		    // and > to input.
		    if(position !== 'g') {
		      md.update(this.getRelatedPredicate(quad));
		    }

		    // 4) Append identifier to input.
		    md.update(id);

		    // 5) Return the hash that results from passing input through the hash
		    // algorithm.
		    return md.digest();
		  }

		  // 4.8) Hash N-Degree Quads
		  hashNDegreeQuads(id, issuer) {
		    const deepIterations = this.deepIterations.get(id) || 0;
		    if(deepIterations > this.maxDeepIterations) {
		      throw new Error(
		        `Maximum deep iterations (${this.maxDeepIterations}) exceeded.`);
		    }
		    this.deepIterations.set(id, deepIterations + 1);

		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    // Note: 2) and 3) handled within `createHashToRelated`
		    const md = this.createMessageDigest();
		    const hashToRelated = this.createHashToRelated(id, issuer);

		    // 4) Create an empty string, data to hash.
		    // Note: We created a hash object `md` above instead.

		    // 5) For each related hash to blank node list mapping in hash to related
		    // blank nodes map, sorted lexicographically by related hash:
		    const hashes = [...hashToRelated.keys()].sort();
		    for(const hash of hashes) {
		      // 5.1) Append the related hash to the data to hash.
		      md.update(hash);

		      // 5.2) Create a string chosen path.
		      let chosenPath = '';

		      // 5.3) Create an unset chosen issuer variable.
		      let chosenIssuer;

		      // 5.4) For each permutation of blank node list:
		      const permuter = new Permuter(hashToRelated.get(hash));
		      while(permuter.hasNext()) {
		        const permutation = permuter.next();

		        // 5.4.1) Create a copy of issuer, issuer copy.
		        let issuerCopy = issuer.clone();

		        // 5.4.2) Create a string path.
		        let path = '';

		        // 5.4.3) Create a recursion list, to store blank node identifiers
		        // that must be recursively processed by this algorithm.
		        const recursionList = [];

		        // 5.4.4) For each related in permutation:
		        let nextPermutation = false;
		        for(const related of permutation) {
		          // 5.4.4.1) If a canonical identifier has been issued for
		          // related, append it to path.
		          if(this.canonicalIssuer.hasId(related)) {
		            path += this.canonicalIssuer.getId(related);
		          } else {
		            // 5.4.4.2) Otherwise:
		            // 5.4.4.2.1) If issuer copy has not issued an identifier for
		            // related, append related to recursion list.
		            if(!issuerCopy.hasId(related)) {
		              recursionList.push(related);
		            }
		            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing
		            // issuer copy and related and append the result to path.
		            path += issuerCopy.getId(related);
		          }

		          // 5.4.4.3) If chosen path is not empty and the length of path
		          // is greater than or equal to the length of chosen path and
		          // path is lexicographically greater than chosen path, then
		          // skip to the next permutation.
		          // Note: Comparing path length to chosen path length can be optimized
		          // away; only compare lexicographically.
		          if(chosenPath.length !== 0 && path > chosenPath) {
		            nextPermutation = true;
		            break;
		          }
		        }

		        if(nextPermutation) {
		          continue;
		        }

		        // 5.4.5) For each related in recursion list:
		        for(const related of recursionList) {
		          // 5.4.5.1) Set result to the result of recursively executing
		          // the Hash N-Degree Quads algorithm, passing related for
		          // identifier and issuer copy for path identifier issuer.
		          const result = this.hashNDegreeQuads(related, issuerCopy);

		          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer
		          // copy and related and append the result to path.
		          path += issuerCopy.getId(related);

		          // 5.4.5.3) Append <, the hash in result, and > to path.
		          path += `<${result.hash}>`;

		          // 5.4.5.4) Set issuer copy to the identifier issuer in
		          // result.
		          issuerCopy = result.issuer;

		          // 5.4.5.5) If chosen path is not empty and the length of path
		          // is greater than or equal to the length of chosen path and
		          // path is lexicographically greater than chosen path, then
		          // skip to the next permutation.
		          // Note: Comparing path length to chosen path length can be optimized
		          // away; only compare lexicographically.
		          if(chosenPath.length !== 0 && path > chosenPath) {
		            nextPermutation = true;
		            break;
		          }
		        }

		        if(nextPermutation) {
		          continue;
		        }

		        // 5.4.6) If chosen path is empty or path is lexicographically
		        // less than chosen path, set chosen path to path and chosen
		        // issuer to issuer copy.
		        if(chosenPath.length === 0 || path < chosenPath) {
		          chosenPath = path;
		          chosenIssuer = issuerCopy;
		        }
		      }

		      // 5.5) Append chosen path to data to hash.
		      md.update(chosenPath);

		      // 5.6) Replace issuer, by reference, with chosen issuer.
		      issuer = chosenIssuer;
		    }

		    // 6) Return issuer and the hash that results from passing data to hash
		    // through the hash algorithm.
		    return {hash: md.digest(), issuer};
		  }

		  // helper for modifying component during Hash First Degree Quads
		  modifyFirstDegreeComponent(id, component) {
		    if(component.termType !== 'BlankNode') {
		      return component;
		    }
		    /* Note: A mistake in the URDNA2015 spec that made its way into
		    implementations (and therefore must stay to avoid interop breakage)
		    resulted in an assigned canonical ID, if available for
		    `component.value`, not being used in place of `_:a`/`_:z`, so
		    we don't use it here. */
		    return {
		      termType: 'BlankNode',
		      value: component.value === id ? '_:a' : '_:z'
		    };
		  }

		  // helper for getting a related predicate
		  getRelatedPredicate(quad) {
		    return `<${quad.predicate.value}>`;
		  }

		  // helper for creating hash to related blank nodes map
		  createHashToRelated(id, issuer) {
		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    const hashToRelated = new Map();

		    // 2) Get a reference, quads, to the list of quads in the blank node to
		    // quads map for the key identifier.
		    const quads = this.blankNodeInfo.get(id).quads;

		    // 3) For each quad in quads:
		    for(const quad of quads) {
		      // 3.1) For each component in quad, if component is the subject, object,
		      // or graph name and it is a blank node that is not identified by
		      // identifier:
		      // steps 3.1.1 and 3.1.2 occur in helpers:
		      this._addRelatedBlankNodeHash({
		        quad, component: quad.subject, position: 's',
		        id, issuer, hashToRelated
		      });
		      this._addRelatedBlankNodeHash({
		        quad, component: quad.object, position: 'o',
		        id, issuer, hashToRelated
		      });
		      this._addRelatedBlankNodeHash({
		        quad, component: quad.graph, position: 'g',
		        id, issuer, hashToRelated
		      });
		    }

		    return hashToRelated;
		  }

		  _hashAndTrackBlankNode({id, hashToBlankNodes}) {
		    // 5.3.1) Create a hash, hash, according to the Hash First Degree
		    // Quads algorithm.
		    const hash = this.hashFirstDegreeQuads(id);

		    // 5.3.2) Add hash and identifier to hash to blank nodes map,
		    // creating a new entry if necessary.
		    const idList = hashToBlankNodes.get(hash);
		    if(!idList) {
		      hashToBlankNodes.set(hash, [id]);
		    } else {
		      idList.push(id);
		    }
		  }

		  _addBlankNodeQuadInfo({quad, component}) {
		    if(component.termType !== 'BlankNode') {
		      return;
		    }
		    const id = component.value;
		    const info = this.blankNodeInfo.get(id);
		    if(info) {
		      info.quads.add(quad);
		    } else {
		      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});
		    }
		  }

		  _addRelatedBlankNodeHash(
		    {quad, component, position, id, issuer, hashToRelated}) {
		    if(!(component.termType === 'BlankNode' && component.value !== id)) {
		      return;
		    }
		    // 3.1.1) Set hash to the result of the Hash Related Blank Node
		    // algorithm, passing the blank node identifier for component as
		    // related, quad, path identifier issuer as issuer, and position as
		    // either s, o, or g based on whether component is a subject, object,
		    // graph name, respectively.
		    const related = component.value;
		    const hash = this.hashRelatedBlankNode(related, quad, issuer, position);

		    // 3.1.2) Add a mapping of hash to the blank node identifier for
		    // component to hash to related blank nodes map, adding an entry as
		    // necessary.
		    const entries = hashToRelated.get(hash);
		    if(entries) {
		      entries.push(related);
		    } else {
		      hashToRelated.set(hash, [related]);
		    }
		  }

		  // canonical ids for 7.1
		  _componentWithCanonicalId({component}) {
		    if(component.termType === 'BlankNode' &&
		      !component.value.startsWith(this.canonicalIssuer.prefix)) {
		      // create new BlankNode
		      return {
		        termType: 'BlankNode',
		        value: this.canonicalIssuer.getId(component.value)
		      };
		    }
		    return component;
		  }
		};

		function _stringHashCompare(a, b) {
		  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
		}
		return URDNA2015Sync_1;
	}

	/*!
	 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
	 */

	var URGNA2012Sync;
	var hasRequiredURGNA2012Sync;

	function requireURGNA2012Sync () {
		if (hasRequiredURGNA2012Sync) return URGNA2012Sync;
		hasRequiredURGNA2012Sync = 1;

		const MessageDigest = requireMessageDigestBrowser();
		const URDNA2015Sync = requireURDNA2015Sync();

		URGNA2012Sync = class URDNA2012Sync extends URDNA2015Sync {
		  constructor() {
		    super();
		    this.name = 'URGNA2012';
		    this.createMessageDigest = () => new MessageDigest('sha1');
		  }

		  // helper for modifying component during Hash First Degree Quads
		  modifyFirstDegreeComponent(id, component, key) {
		    if(component.termType !== 'BlankNode') {
		      return component;
		    }
		    if(key === 'graph') {
		      return {
		        termType: 'BlankNode',
		        value: '_:g'
		      };
		    }
		    return {
		      termType: 'BlankNode',
		      value: (component.value === id ? '_:a' : '_:z')
		    };
		  }

		  // helper for getting a related predicate
		  getRelatedPredicate(quad) {
		    return quad.predicate.value;
		  }

		  // helper for creating hash to related blank nodes map
		  createHashToRelated(id, issuer) {
		    // 1) Create a hash to related blank nodes map for storing hashes that
		    // identify related blank nodes.
		    const hashToRelated = new Map();

		    // 2) Get a reference, quads, to the list of quads in the blank node to
		    // quads map for the key identifier.
		    const quads = this.blankNodeInfo.get(id).quads;

		    // 3) For each quad in quads:
		    for(const quad of quads) {
		      // 3.1) If the quad's subject is a blank node that does not match
		      // identifier, set hash to the result of the Hash Related Blank Node
		      // algorithm, passing the blank node identifier for subject as related,
		      // quad, path identifier issuer as issuer, and p as position.
		      let position;
		      let related;
		      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {
		        related = quad.subject.value;
		        position = 'p';
		      } else if(
		        quad.object.termType === 'BlankNode' && quad.object.value !== id) {
		        // 3.2) Otherwise, if quad's object is a blank node that does not match
		        // identifier, to the result of the Hash Related Blank Node algorithm,
		        // passing the blank node identifier for object as related, quad, path
		        // identifier issuer as issuer, and r as position.
		        related = quad.object.value;
		        position = 'r';
		      } else {
		        // 3.3) Otherwise, continue to the next quad.
		        continue;
		      }
		      // 3.4) Add a mapping of hash to the blank node identifier for the
		      // component that matched (subject or object) to hash to related blank
		      // nodes map, adding an entry as necessary.
		      const hash = this.hashRelatedBlankNode(related, quad, issuer, position);
		      const entries = hashToRelated.get(hash);
		      if(entries) {
		        entries.push(related);
		      } else {
		        hashToRelated.set(hash, [related]);
		      }
		    }

		    return hashToRelated;
		  }
		};
		return URGNA2012Sync;
	}

	var _nodeResolve_empty = {};

	var _nodeResolve_empty$1 = /*#__PURE__*/Object.freeze({
		__proto__: null,
		default: _nodeResolve_empty
	});

	var require$$4 = /*@__PURE__*/getAugmentedNamespace(_nodeResolve_empty$1);

	/**
	 * An implementation of the RDF Dataset Normalization specification.
	 * This library works in the browser and node.js.
	 *
	 * BSD 3-Clause License
	 * Copyright (c) 2016-2023 Digital Bazaar, Inc.
	 * All rights reserved.
	 *
	 * Redistribution and use in source and binary forms, with or without
	 * modification, are permitted provided that the following conditions are met:
	 *
	 * Redistributions of source code must retain the above copyright notice,
	 * this list of conditions and the following disclaimer.
	 *
	 * Redistributions in binary form must reproduce the above copyright
	 * notice, this list of conditions and the following disclaimer in the
	 * documentation and/or other materials provided with the distribution.
	 *
	 * Neither the name of the Digital Bazaar, Inc. nor the names of its
	 * contributors may be used to endorse or promote products derived from
	 * this software without specific prior written permission.
	 *
	 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
	 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
	 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
	 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
	 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
	 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
	 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
	 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
	 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
	 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
	 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
	 */

	var hasRequiredLib;

	function requireLib () {
		if (hasRequiredLib) return lib;
		hasRequiredLib = 1;
		(function (exports) {

			const URDNA2015 = requireURDNA2015();
			const URGNA2012 = requireURGNA2012();
			const URDNA2015Sync = requireURDNA2015Sync();
			const URGNA2012Sync = requireURGNA2012Sync();

			// optional native support
			let rdfCanonizeNative;
			try {
			  rdfCanonizeNative = require$$4;
			} catch(e) {}

			// return a dataset from input dataset or legacy dataset
			function _inputToDataset(input/*, options*/) {
			  // back-compat with legacy dataset
			  if(!Array.isArray(input)) {
			    return exports.NQuads.legacyDatasetToQuads(input);
			  }
			  return input;
			}

			// expose helpers
			exports.NQuads = requireNQuads$1();
			exports.IdentifierIssuer = requireIdentifierIssuer();

			/**
			 * Get or set native API.
			 *
			 * @param api the native API.
			 *
			 * @return the currently set native API.
			 */
			exports._rdfCanonizeNative = function(api) {
			  if(api) {
			    rdfCanonizeNative = api;
			  }
			  return rdfCanonizeNative;
			};

			/**
			 * Asynchronously canonizes an RDF dataset.
			 *
			 * @param {Array|object|string} input - The input to canonize given as a
			 *   dataset or legacy dataset.
			 * @param {object} options - The options to use:
			 *   {string} algorithm - The canonicalization algorithm to use, `URDNA2015` or
			 *     `URGNA2012`.
			 *   {Function} [createMessageDigest] - A factory function for creating a
			 *     `MessageDigest` interface that overrides the built-in message digest
			 *     implementation used by the canonize algorithm; note that using a hash
			 *     algorithm (or HMAC algorithm) that differs from the one specified by
			 *     the canonize algorithm will result in different output.
			 *   {Map} [canonicalIdMap] - An optional Map to be populated by the canonical
			 *     identifier issuer with the bnode identifier mapping generated by the
			 *     canonicalization algorithm.
			 *   {boolean} [useNative=false] - Use native implementation.
			 *   {number} [maxDeepIterations=Infinity] - The maximum number of times to run
			 *     deep comparison algorithms (such as the N-Degree Hash Quads algorithm
			 *     used in URDNA2015) before bailing out and throwing an error; this is a
			 *     useful setting for preventing wasted CPU cycles or DoS when canonizing
			 *     meaningless or potentially malicious datasets, a recommended value is
			 *     `1`.
			 *
			 * @return a Promise that resolves to the canonicalized RDF Dataset.
			 */
			exports.canonize = async function(input, options) {
			  const dataset = _inputToDataset(input);

			  if(options.useNative) {
			    if(!rdfCanonizeNative) {
			      throw new Error('rdf-canonize-native not available');
			    }
			    if(options.createMessageDigest) {
			      throw new Error(
			        '"createMessageDigest" cannot be used with "useNative".');
			    }
			    return new Promise((resolve, reject) =>
			      rdfCanonizeNative.canonize(dataset, options, (err, canonical) =>
			        err ? reject(err) : resolve(canonical)));
			  }

			  if(options.algorithm === 'URDNA2015') {
			    return new URDNA2015(options).main(dataset);
			  }
			  if(options.algorithm === 'URGNA2012') {
			    if(options.createMessageDigest) {
			      throw new Error(
			        '"createMessageDigest" cannot be used with "URGNA2012".');
			    }
			    return new URGNA2012(options).main(dataset);
			  }
			  if(!('algorithm' in options)) {
			    throw new Error('No RDF Dataset Canonicalization algorithm specified.');
			  }
			  throw new Error(
			    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);
			};

			/**
			 * This method is no longer available in the public API, it is for testing
			 * only. It synchronously canonizes an RDF dataset and does not work in the
			 * browser.
			 *
			 * @param {Array|object|string} input - The input to canonize given as a
			 *   dataset or legacy dataset.
			 * @param {object} options - The options to use:
			 *   {string} algorithm - The canonicalization algorithm to use, `URDNA2015` or
			 *     `URGNA2012`.
			 *   {Function} [createMessageDigest] - A factory function for creating a
			 *     `MessageDigest` interface that overrides the built-in message digest
			 *     implementation used by the canonize algorithm; note that using a hash
			 *     algorithm (or HMAC algorithm) that differs from the one specified by
			 *     the canonize algorithm will result in different output.
			 *   {boolean} [useNative=false] - Use native implementation.
			 *   {number} [maxDeepIterations=Infinity] - The maximum number of times to run
			 *     deep comparison algorithms (such as the N-Degree Hash Quads algorithm
			 *     used in URDNA2015) before bailing out and throwing an error; this is a
			 *     useful setting for preventing wasted CPU cycles or DoS when canonizing
			 *     meaningless or potentially malicious datasets, a recommended value is
			 *     `1`.
			 *
			 * @return the RDF dataset in canonical form.
			 */
			exports._canonizeSync = function(input, options) {
			  const dataset = _inputToDataset(input);

			  if(options.useNative) {
			    if(!rdfCanonizeNative) {
			      throw new Error('rdf-canonize-native not available');
			    }
			    if(options.createMessageDigest) {
			      throw new Error(
			        '"createMessageDigest" cannot be used with "useNative".');
			    }
			    return rdfCanonizeNative.canonizeSync(dataset, options);
			  }
			  if(options.algorithm === 'URDNA2015') {
			    return new URDNA2015Sync(options).main(dataset);
			  }
			  if(options.algorithm === 'URGNA2012') {
			    if(options.createMessageDigest) {
			      throw new Error(
			        '"createMessageDigest" cannot be used with "URGNA2012".');
			    }
			    return new URGNA2012Sync(options).main(dataset);
			  }
			  if(!('algorithm' in options)) {
			    throw new Error('No RDF Dataset Canonicalization algorithm specified.');
			  }
			  throw new Error(
			    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);
			}; 
		} (lib));
		return lib;
	}

	/**
	 * An implementation of the RDF Dataset Normalization specification.
	 *
	 * @author Dave Longley
	 *
	 * Copyright 2010-2021 Digital Bazaar, Inc.
	 */

	var rdfCanonize;
	var hasRequiredRdfCanonize;

	function requireRdfCanonize () {
		if (hasRequiredRdfCanonize) return rdfCanonize;
		hasRequiredRdfCanonize = 1;
		rdfCanonize = requireLib();
		return rdfCanonize;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var types;
	var hasRequiredTypes;

	function requireTypes () {
		if (hasRequiredTypes) return types;
		hasRequiredTypes = 1;

		const api = {};
		types = api;

		/**
		 * Returns true if the given value is an Array.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is an Array, false if not.
		 */
		api.isArray = Array.isArray;

		/**
		 * Returns true if the given value is a Boolean.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a Boolean, false if not.
		 */
		api.isBoolean = v => (typeof v === 'boolean' ||
		  Object.prototype.toString.call(v) === '[object Boolean]');

		/**
		 * Returns true if the given value is a double.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a double, false if not.
		 */
		api.isDouble = v => api.isNumber(v) &&
		  (String(v).indexOf('.') !== -1 || Math.abs(v) >= 1e21);

		/**
		 * Returns true if the given value is an empty Object.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is an empty Object, false if not.
		 */
		api.isEmptyObject = v => api.isObject(v) && Object.keys(v).length === 0;

		/**
		 * Returns true if the given value is a Number.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a Number, false if not.
		 */
		api.isNumber = v => (typeof v === 'number' ||
		  Object.prototype.toString.call(v) === '[object Number]');

		/**
		 * Returns true if the given value is numeric.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is numeric, false if not.
		 */
		api.isNumeric = v => !isNaN(parseFloat(v)) && isFinite(v);

		/**
		 * Returns true if the given value is an Object.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is an Object, false if not.
		 */
		api.isObject = v => Object.prototype.toString.call(v) === '[object Object]';

		/**
		 * Returns true if the given value is a String.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a String, false if not.
		 */
		api.isString = v => (typeof v === 'string' ||
		  Object.prototype.toString.call(v) === '[object String]');

		/**
		 * Returns true if the given value is undefined.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is undefined, false if not.
		 */
		api.isUndefined = v => typeof v === 'undefined';
		return types;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var graphTypes;
	var hasRequiredGraphTypes;

	function requireGraphTypes () {
		if (hasRequiredGraphTypes) return graphTypes;
		hasRequiredGraphTypes = 1;

		const types = requireTypes();

		const api = {};
		graphTypes = api;

		/**
		 * Returns true if the given value is a subject with properties.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a subject with properties, false if not.
		 */
		api.isSubject = v => {
		  // Note: A value is a subject if all of these hold true:
		  // 1. It is an Object.
		  // 2. It is not a @value, @set, or @list.
		  // 3. It has more than 1 key OR any existing key is not @id.
		  if(types.isObject(v) &&
		    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {
		    const keyCount = Object.keys(v).length;
		    return (keyCount > 1 || !('@id' in v));
		  }
		  return false;
		};

		/**
		 * Returns true if the given value is a subject reference.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a subject reference, false if not.
		 */
		api.isSubjectReference = v =>
		  // Note: A value is a subject reference if all of these hold true:
		  // 1. It is an Object.
		  // 2. It has a single key: @id.
		  (types.isObject(v) && Object.keys(v).length === 1 && ('@id' in v));

		/**
		 * Returns true if the given value is a @value.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a @value, false if not.
		 */
		api.isValue = v =>
		  // Note: A value is a @value if all of these hold true:
		  // 1. It is an Object.
		  // 2. It has the @value property.
		  types.isObject(v) && ('@value' in v);

		/**
		 * Returns true if the given value is a @list.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a @list, false if not.
		 */
		api.isList = v =>
		  // Note: A value is a @list if all of these hold true:
		  // 1. It is an Object.
		  // 2. It has the @list property.
		  types.isObject(v) && ('@list' in v);

		/**
		 * Returns true if the given value is a @graph.
		 *
		 * @return true if the value is a @graph, false if not.
		 */
		api.isGraph = v => {
		  // Note: A value is a graph if all of these hold true:
		  // 1. It is an object.
		  // 2. It has an `@graph` key.
		  // 3. It may have '@id' or '@index'
		  return types.isObject(v) &&
		    '@graph' in v &&
		    Object.keys(v)
		      .filter(key => key !== '@id' && key !== '@index').length === 1;
		};

		/**
		 * Returns true if the given value is a simple @graph.
		 *
		 * @return true if the value is a simple @graph, false if not.
		 */
		api.isSimpleGraph = v => {
		  // Note: A value is a simple graph if all of these hold true:
		  // 1. It is an object.
		  // 2. It has an `@graph` key.
		  // 3. It has only 1 key or 2 keys where one of them is `@index`.
		  return api.isGraph(v) && !('@id' in v);
		};

		/**
		 * Returns true if the given value is a blank node.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a blank node, false if not.
		 */
		api.isBlankNode = v => {
		  // Note: A value is a blank node if all of these hold true:
		  // 1. It is an Object.
		  // 2. If it has an @id key that is not a string OR begins with '_:'.
		  // 3. It has no keys OR is not a @value, @set, or @list.
		  if(types.isObject(v)) {
		    if('@id' in v) {
		      const id = v['@id'];
		      return !types.isString(id) || id.indexOf('_:') === 0;
		    }
		    return (Object.keys(v).length === 0 ||
		      !(('@value' in v) || ('@set' in v) || ('@list' in v)));
		  }
		  return false;
		};
		return graphTypes;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var JsonLdError_1;
	var hasRequiredJsonLdError;

	function requireJsonLdError () {
		if (hasRequiredJsonLdError) return JsonLdError_1;
		hasRequiredJsonLdError = 1;

		JsonLdError_1 = class JsonLdError extends Error {
		  /**
		   * Creates a JSON-LD Error.
		   *
		   * @param msg the error message.
		   * @param type the error type.
		   * @param details the error details.
		   */
		  constructor(
		    message = 'An unspecified JSON-LD error occurred.',
		    name = 'jsonld.Error',
		    details = {}) {
		    super(message);
		    this.name = name;
		    this.message = message;
		    this.details = details;
		  }
		};
		return JsonLdError_1;
	}

	/*
	 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
	 */

	var util;
	var hasRequiredUtil;

	function requireUtil () {
		if (hasRequiredUtil) return util;
		hasRequiredUtil = 1;

		const graphTypes = requireGraphTypes();
		const types = requireTypes();
		// TODO: move `IdentifierIssuer` to its own package
		const IdentifierIssuer = requireRdfCanonize().IdentifierIssuer;
		const JsonLdError = requireJsonLdError();

		// constants
		const REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;
		const REGEX_LINK_HEADERS = /(?:<[^>]*?>|"[^"]*?"|[^,])+/g;
		const REGEX_LINK_HEADER = /\s*<([^>]*?)>\s*(?:;\s*(.*))?/;
		const REGEX_LINK_HEADER_PARAMS =
		  /(.*?)=(?:(?:"([^"]*?)")|([^"]*?))\s*(?:(?:;\s*)|$)/g;
		const REGEX_KEYWORD = /^@[a-zA-Z]+$/;

		const DEFAULTS = {
		  headers: {
		    accept: 'application/ld+json, application/json'
		  }
		};

		const api = {};
		util = api;
		api.IdentifierIssuer = IdentifierIssuer;
		api.REGEX_BCP47 = REGEX_BCP47;
		api.REGEX_KEYWORD = REGEX_KEYWORD;

		/**
		 * Clones an object, array, Map, Set, or string/number. If a typed JavaScript
		 * object is given, such as a Date, it will be converted to a string.
		 *
		 * @param value the value to clone.
		 *
		 * @return the cloned value.
		 */
		api.clone = function(value) {
		  if(value && typeof value === 'object') {
		    let rval;
		    if(types.isArray(value)) {
		      rval = [];
		      for(let i = 0; i < value.length; ++i) {
		        rval[i] = api.clone(value[i]);
		      }
		    } else if(value instanceof Map) {
		      rval = new Map();
		      for(const [k, v] of value) {
		        rval.set(k, api.clone(v));
		      }
		    } else if(value instanceof Set) {
		      rval = new Set();
		      for(const v of value) {
		        rval.add(api.clone(v));
		      }
		    } else if(types.isObject(value)) {
		      rval = {};
		      for(const key in value) {
		        rval[key] = api.clone(value[key]);
		      }
		    } else {
		      rval = value.toString();
		    }
		    return rval;
		  }
		  return value;
		};

		/**
		 * Ensure a value is an array. If the value is an array, it is returned.
		 * Otherwise, it is wrapped in an array.
		 *
		 * @param value the value to return as an array.
		 *
		 * @return the value as an array.
		 */
		api.asArray = function(value) {
		  return Array.isArray(value) ? value : [value];
		};

		/**
		 * Builds an HTTP headers object for making a JSON-LD request from custom
		 * headers and asserts the `accept` header isn't overridden.
		 *
		 * @param headers an object of headers with keys as header names and values
		 *          as header values.
		 *
		 * @return an object of headers with a valid `accept` header.
		 */
		api.buildHeaders = (headers = {}) => {
		  const hasAccept = Object.keys(headers).some(
		    h => h.toLowerCase() === 'accept');

		  if(hasAccept) {
		    throw new RangeError(
		      'Accept header may not be specified; only "' +
		      DEFAULTS.headers.accept + '" is supported.');
		  }

		  return Object.assign({Accept: DEFAULTS.headers.accept}, headers);
		};

		/**
		 * Parses a link header. The results will be key'd by the value of "rel".
		 *
		 * Link: <http://json-ld.org/contexts/person.jsonld>;
		 * rel="http://www.w3.org/ns/json-ld#context"; type="application/ld+json"
		 *
		 * Parses as: {
		 *   'http://www.w3.org/ns/json-ld#context': {
		 *     target: http://json-ld.org/contexts/person.jsonld,
		 *     type: 'application/ld+json'
		 *   }
		 * }
		 *
		 * If there is more than one "rel" with the same IRI, then entries in the
		 * resulting map for that "rel" will be arrays.
		 *
		 * @param header the link header to parse.
		 */
		api.parseLinkHeader = header => {
		  const rval = {};
		  // split on unbracketed/unquoted commas
		  const entries = header.match(REGEX_LINK_HEADERS);
		  for(let i = 0; i < entries.length; ++i) {
		    let match = entries[i].match(REGEX_LINK_HEADER);
		    if(!match) {
		      continue;
		    }
		    const result = {target: match[1]};
		    const params = match[2];
		    while((match = REGEX_LINK_HEADER_PARAMS.exec(params))) {
		      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];
		    }
		    const rel = result.rel || '';
		    if(Array.isArray(rval[rel])) {
		      rval[rel].push(result);
		    } else if(rval.hasOwnProperty(rel)) {
		      rval[rel] = [rval[rel], result];
		    } else {
		      rval[rel] = result;
		    }
		  }
		  return rval;
		};

		/**
		 * Throws an exception if the given value is not a valid @type value.
		 *
		 * @param v the value to check.
		 */
		api.validateTypeValue = (v, isFrame) => {
		  if(types.isString(v)) {
		    return;
		  }

		  if(types.isArray(v) && v.every(vv => types.isString(vv))) {
		    return;
		  }
		  if(isFrame && types.isObject(v)) {
		    switch(Object.keys(v).length) {
		      case 0:
		        // empty object is wildcard
		        return;
		      case 1:
		        // default entry is all strings
		        if('@default' in v &&
		          api.asArray(v['@default']).every(vv => types.isString(vv))) {
		          return;
		        }
		    }
		  }

		  throw new JsonLdError(
		    'Invalid JSON-LD syntax; "@type" value must a string, an array of ' +
		    'strings, an empty object, ' +
		    'or a default object.', 'jsonld.SyntaxError',
		    {code: 'invalid type value', value: v});
		};

		/**
		 * Returns true if the given subject has the given property.
		 *
		 * @param subject the subject to check.
		 * @param property the property to look for.
		 *
		 * @return true if the subject has the given property, false if not.
		 */
		api.hasProperty = (subject, property) => {
		  if(subject.hasOwnProperty(property)) {
		    const value = subject[property];
		    return (!types.isArray(value) || value.length > 0);
		  }
		  return false;
		};

		/**
		 * Determines if the given value is a property of the given subject.
		 *
		 * @param subject the subject to check.
		 * @param property the property to check.
		 * @param value the value to check.
		 *
		 * @return true if the value exists, false if not.
		 */
		api.hasValue = (subject, property, value) => {
		  if(api.hasProperty(subject, property)) {
		    let val = subject[property];
		    const isList = graphTypes.isList(val);
		    if(types.isArray(val) || isList) {
		      if(isList) {
		        val = val['@list'];
		      }
		      for(let i = 0; i < val.length; ++i) {
		        if(api.compareValues(value, val[i])) {
		          return true;
		        }
		      }
		    } else if(!types.isArray(value)) {
		      // avoid matching the set of values with an array value parameter
		      return api.compareValues(value, val);
		    }
		  }
		  return false;
		};

		/**
		 * Adds a value to a subject. If the value is an array, all values in the
		 * array will be added.
		 *
		 * @param subject the subject to add the value to.
		 * @param property the property that relates the value to the subject.
		 * @param value the value to add.
		 * @param [options] the options to use:
		 *        [propertyIsArray] true if the property is always an array, false
		 *          if not (default: false).
		 *        [valueIsArray] true if the value to be added should be preserved as
		 *          an array (lists) (default: false).
		 *        [allowDuplicate] true to allow duplicates, false not to (uses a
		 *          simple shallow comparison of subject ID or value) (default: true).
		 *        [prependValue] false to prepend value to any existing values.
		 *          (default: false)
		 */
		api.addValue = (subject, property, value, options) => {
		  options = options || {};
		  if(!('propertyIsArray' in options)) {
		    options.propertyIsArray = false;
		  }
		  if(!('valueIsArray' in options)) {
		    options.valueIsArray = false;
		  }
		  if(!('allowDuplicate' in options)) {
		    options.allowDuplicate = true;
		  }
		  if(!('prependValue' in options)) {
		    options.prependValue = false;
		  }

		  if(options.valueIsArray) {
		    subject[property] = value;
		  } else if(types.isArray(value)) {
		    if(value.length === 0 && options.propertyIsArray &&
		      !subject.hasOwnProperty(property)) {
		      subject[property] = [];
		    }
		    if(options.prependValue) {
		      value = value.concat(subject[property]);
		      subject[property] = [];
		    }
		    for(let i = 0; i < value.length; ++i) {
		      api.addValue(subject, property, value[i], options);
		    }
		  } else if(subject.hasOwnProperty(property)) {
		    // check if subject already has value if duplicates not allowed
		    const hasValue = (!options.allowDuplicate &&
		      api.hasValue(subject, property, value));

		    // make property an array if value not present or always an array
		    if(!types.isArray(subject[property]) &&
		      (!hasValue || options.propertyIsArray)) {
		      subject[property] = [subject[property]];
		    }

		    // add new value
		    if(!hasValue) {
		      if(options.prependValue) {
		        subject[property].unshift(value);
		      } else {
		        subject[property].push(value);
		      }
		    }
		  } else {
		    // add new value as set or single value
		    subject[property] = options.propertyIsArray ? [value] : value;
		  }
		};

		/**
		 * Gets all of the values for a subject's property as an array.
		 *
		 * @param subject the subject.
		 * @param property the property.
		 *
		 * @return all of the values for a subject's property as an array.
		 */
		api.getValues = (subject, property) => [].concat(subject[property] || []);

		/**
		 * Removes a property from a subject.
		 *
		 * @param subject the subject.
		 * @param property the property.
		 */
		api.removeProperty = (subject, property) => {
		  delete subject[property];
		};

		/**
		 * Removes a value from a subject.
		 *
		 * @param subject the subject.
		 * @param property the property that relates the value to the subject.
		 * @param value the value to remove.
		 * @param [options] the options to use:
		 *          [propertyIsArray] true if the property is always an array, false
		 *            if not (default: false).
		 */
		api.removeValue = (subject, property, value, options) => {
		  options = options || {};
		  if(!('propertyIsArray' in options)) {
		    options.propertyIsArray = false;
		  }

		  // filter out value
		  const values = api.getValues(subject, property).filter(
		    e => !api.compareValues(e, value));

		  if(values.length === 0) {
		    api.removeProperty(subject, property);
		  } else if(values.length === 1 && !options.propertyIsArray) {
		    subject[property] = values[0];
		  } else {
		    subject[property] = values;
		  }
		};

		/**
		 * Relabels all blank nodes in the given JSON-LD input.
		 *
		 * @param input the JSON-LD input.
		 * @param [options] the options to use:
		 *          [issuer] an IdentifierIssuer to use to label blank nodes.
		 */
		api.relabelBlankNodes = (input, options) => {
		  options = options || {};
		  const issuer = options.issuer || new IdentifierIssuer('_:b');
		  return _labelBlankNodes(issuer, input);
		};

		/**
		 * Compares two JSON-LD values for equality. Two JSON-LD values will be
		 * considered equal if:
		 *
		 * 1. They are both primitives of the same type and value.
		 * 2. They are both @values with the same @value, @type, @language,
		 *   and @index, OR
		 * 3. They both have @ids they are the same.
		 *
		 * @param v1 the first value.
		 * @param v2 the second value.
		 *
		 * @return true if v1 and v2 are considered equal, false if not.
		 */
		api.compareValues = (v1, v2) => {
		  // 1. equal primitives
		  if(v1 === v2) {
		    return true;
		  }

		  // 2. equal @values
		  if(graphTypes.isValue(v1) && graphTypes.isValue(v2) &&
		    v1['@value'] === v2['@value'] &&
		    v1['@type'] === v2['@type'] &&
		    v1['@language'] === v2['@language'] &&
		    v1['@index'] === v2['@index']) {
		    return true;
		  }

		  // 3. equal @ids
		  if(types.isObject(v1) &&
		    ('@id' in v1) &&
		    types.isObject(v2) &&
		    ('@id' in v2)) {
		    return v1['@id'] === v2['@id'];
		  }

		  return false;
		};

		/**
		 * Compares two strings first based on length and then lexicographically.
		 *
		 * @param a the first string.
		 * @param b the second string.
		 *
		 * @return -1 if a < b, 1 if a > b, 0 if a === b.
		 */
		api.compareShortestLeast = (a, b) => {
		  if(a.length < b.length) {
		    return -1;
		  }
		  if(b.length < a.length) {
		    return 1;
		  }
		  if(a === b) {
		    return 0;
		  }
		  return (a < b) ? -1 : 1;
		};

		/**
		 * Labels the blank nodes in the given value using the given IdentifierIssuer.
		 *
		 * @param issuer the IdentifierIssuer to use.
		 * @param element the element with blank nodes to rename.
		 *
		 * @return the element.
		 */
		function _labelBlankNodes(issuer, element) {
		  if(types.isArray(element)) {
		    for(let i = 0; i < element.length; ++i) {
		      element[i] = _labelBlankNodes(issuer, element[i]);
		    }
		  } else if(graphTypes.isList(element)) {
		    element['@list'] = _labelBlankNodes(issuer, element['@list']);
		  } else if(types.isObject(element)) {
		    // relabel blank node
		    if(graphTypes.isBlankNode(element)) {
		      element['@id'] = issuer.getId(element['@id']);
		    }

		    // recursively apply to all keys
		    const keys = Object.keys(element).sort();
		    for(let ki = 0; ki < keys.length; ++ki) {
		      const key = keys[ki];
		      if(key !== '@id') {
		        element[key] = _labelBlankNodes(issuer, element[key]);
		      }
		    }
		  }

		  return element;
		}
		return util;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var constants;
	var hasRequiredConstants;

	function requireConstants () {
		if (hasRequiredConstants) return constants;
		hasRequiredConstants = 1;

		const RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';
		const XSD = 'http://www.w3.org/2001/XMLSchema#';

		constants = {
		  // TODO: Deprecated and will be removed later. Use LINK_HEADER_CONTEXT.
		  LINK_HEADER_REL: 'http://www.w3.org/ns/json-ld#context',

		  LINK_HEADER_CONTEXT: 'http://www.w3.org/ns/json-ld#context',

		  RDF,
		  RDF_LIST: RDF + 'List',
		  RDF_FIRST: RDF + 'first',
		  RDF_REST: RDF + 'rest',
		  RDF_NIL: RDF + 'nil',
		  RDF_TYPE: RDF + 'type',
		  RDF_PLAIN_LITERAL: RDF + 'PlainLiteral',
		  RDF_XML_LITERAL: RDF + 'XMLLiteral',
		  RDF_JSON_LITERAL: RDF + 'JSON',
		  RDF_OBJECT: RDF + 'object',
		  RDF_LANGSTRING: RDF + 'langString',

		  XSD,
		  XSD_BOOLEAN: XSD + 'boolean',
		  XSD_DOUBLE: XSD + 'double',
		  XSD_INTEGER: XSD + 'integer',
		  XSD_STRING: XSD + 'string',
		};
		return constants;
	}

	/*
	 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
	 */

	var RequestQueue_1;
	var hasRequiredRequestQueue;

	function requireRequestQueue () {
		if (hasRequiredRequestQueue) return RequestQueue_1;
		hasRequiredRequestQueue = 1;

		RequestQueue_1 = class RequestQueue {
		  /**
		   * Creates a simple queue for requesting documents.
		   */
		  constructor() {
		    this._requests = {};
		  }

		  wrapLoader(loader) {
		    const self = this;
		    self._loader = loader;
		    return function(/* url */) {
		      return self.add.apply(self, arguments);
		    };
		  }

		  async add(url) {
		    let promise = this._requests[url];
		    if(promise) {
		      // URL already queued, wait for it to load
		      return Promise.resolve(promise);
		    }

		    // queue URL and load it
		    promise = this._requests[url] = this._loader(url);

		    try {
		      return await promise;
		    } finally {
		      delete this._requests[url];
		    }
		  }
		};
		return RequestQueue_1;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var url;
	var hasRequiredUrl;

	function requireUrl () {
		if (hasRequiredUrl) return url;
		hasRequiredUrl = 1;

		const types = requireTypes();

		const api = {};
		url = api;

		// define URL parser
		// parseUri 1.2.2
		// (c) Steven Levithan <stevenlevithan.com>
		// MIT License
		// with local jsonld.js modifications
		api.parsers = {
		  simple: {
		    // RFC 3986 basic parts
		    keys: [
		      'href', 'scheme', 'authority', 'path', 'query', 'fragment'
		    ],
		    /* eslint-disable-next-line max-len */
		    regex: /^(?:([^:\/?#]+):)?(?:\/\/([^\/?#]*))?([^?#]*)(?:\?([^#]*))?(?:#(.*))?/
		  },
		  full: {
		    keys: [
		      'href', 'protocol', 'scheme', 'authority', 'auth', 'user', 'password',
		      'hostname', 'port', 'path', 'directory', 'file', 'query', 'fragment'
		    ],
		    /* eslint-disable-next-line max-len */
		    regex: /^(([a-zA-Z][a-zA-Z0-9+-.]*):)?(?:\/\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?))?(?:(((?:[^?#\/]*\/)*)([^?#]*))(?:\?([^#]*))?(?:#(.*))?)/
		  }
		};
		api.parse = (str, parser) => {
		  const parsed = {};
		  const o = api.parsers[parser || 'full'];
		  const m = o.regex.exec(str);
		  let i = o.keys.length;
		  while(i--) {
		    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];
		  }

		  // remove default ports in found in URLs
		  if((parsed.scheme === 'https' && parsed.port === '443') ||
		    (parsed.scheme === 'http' && parsed.port === '80')) {
		    parsed.href = parsed.href.replace(':' + parsed.port, '');
		    parsed.authority = parsed.authority.replace(':' + parsed.port, '');
		    parsed.port = null;
		  }

		  parsed.normalizedPath = api.removeDotSegments(parsed.path);
		  return parsed;
		};

		/**
		 * Prepends a base IRI to the given relative IRI.
		 *
		 * @param base the base IRI.
		 * @param iri the relative IRI.
		 *
		 * @return the absolute IRI.
		 */
		api.prependBase = (base, iri) => {
		  // skip IRI processing
		  if(base === null) {
		    return iri;
		  }
		  // already an absolute IRI
		  if(api.isAbsolute(iri)) {
		    return iri;
		  }

		  // parse base if it is a string
		  if(!base || types.isString(base)) {
		    base = api.parse(base || '');
		  }

		  // parse given IRI
		  const rel = api.parse(iri);

		  // per RFC3986 5.2.2
		  const transform = {
		    protocol: base.protocol || ''
		  };

		  if(rel.authority !== null) {
		    transform.authority = rel.authority;
		    transform.path = rel.path;
		    transform.query = rel.query;
		  } else {
		    transform.authority = base.authority;

		    if(rel.path === '') {
		      transform.path = base.path;
		      if(rel.query !== null) {
		        transform.query = rel.query;
		      } else {
		        transform.query = base.query;
		      }
		    } else {
		      if(rel.path.indexOf('/') === 0) {
		        // IRI represents an absolute path
		        transform.path = rel.path;
		      } else {
		        // merge paths
		        let path = base.path;

		        // append relative path to the end of the last directory from base
		        path = path.substr(0, path.lastIndexOf('/') + 1);
		        if((path.length > 0 || base.authority) && path.substr(-1) !== '/') {
		          path += '/';
		        }
		        path += rel.path;

		        transform.path = path;
		      }
		      transform.query = rel.query;
		    }
		  }

		  if(rel.path !== '') {
		    // remove slashes and dots in path
		    transform.path = api.removeDotSegments(transform.path);
		  }

		  // construct URL
		  let rval = transform.protocol;
		  if(transform.authority !== null) {
		    rval += '//' + transform.authority;
		  }
		  rval += transform.path;
		  if(transform.query !== null) {
		    rval += '?' + transform.query;
		  }
		  if(rel.fragment !== null) {
		    rval += '#' + rel.fragment;
		  }

		  // handle empty base
		  if(rval === '') {
		    rval = './';
		  }

		  return rval;
		};

		/**
		 * Removes a base IRI from the given absolute IRI.
		 *
		 * @param base the base IRI.
		 * @param iri the absolute IRI.
		 *
		 * @return the relative IRI if relative to base, otherwise the absolute IRI.
		 */
		api.removeBase = (base, iri) => {
		  // skip IRI processing
		  if(base === null) {
		    return iri;
		  }

		  if(!base || types.isString(base)) {
		    base = api.parse(base || '');
		  }

		  // establish base root
		  let root = '';
		  if(base.href !== '') {
		    root += (base.protocol || '') + '//' + (base.authority || '');
		  } else if(iri.indexOf('//')) {
		    // support network-path reference with empty base
		    root += '//';
		  }

		  // IRI not relative to base
		  if(iri.indexOf(root) !== 0) {
		    return iri;
		  }

		  // remove root from IRI and parse remainder
		  const rel = api.parse(iri.substr(root.length));

		  // remove path segments that match (do not remove last segment unless there
		  // is a hash or query)
		  const baseSegments = base.normalizedPath.split('/');
		  const iriSegments = rel.normalizedPath.split('/');
		  const last = (rel.fragment || rel.query) ? 0 : 1;
		  while(baseSegments.length > 0 && iriSegments.length > last) {
		    if(baseSegments[0] !== iriSegments[0]) {
		      break;
		    }
		    baseSegments.shift();
		    iriSegments.shift();
		  }

		  // use '../' for each non-matching base segment
		  let rval = '';
		  if(baseSegments.length > 0) {
		    // don't count the last segment (if it ends with '/' last path doesn't
		    // count and if it doesn't end with '/' it isn't a path)
		    baseSegments.pop();
		    for(let i = 0; i < baseSegments.length; ++i) {
		      rval += '../';
		    }
		  }

		  // prepend remaining segments
		  rval += iriSegments.join('/');

		  // add query and hash
		  if(rel.query !== null) {
		    rval += '?' + rel.query;
		  }
		  if(rel.fragment !== null) {
		    rval += '#' + rel.fragment;
		  }

		  // handle empty base
		  if(rval === '') {
		    rval = './';
		  }

		  return rval;
		};

		/**
		 * Removes dot segments from a URL path.
		 *
		 * @param path the path to remove dot segments from.
		 */
		api.removeDotSegments = path => {
		  // RFC 3986 5.2.4 (reworked)

		  // empty path shortcut
		  if(path.length === 0) {
		    return '';
		  }

		  const input = path.split('/');
		  const output = [];

		  while(input.length > 0) {
		    const next = input.shift();
		    const done = input.length === 0;

		    if(next === '.') {
		      if(done) {
		        // ensure output has trailing /
		        output.push('');
		      }
		      continue;
		    }

		    if(next === '..') {
		      output.pop();
		      if(done) {
		        // ensure output has trailing /
		        output.push('');
		      }
		      continue;
		    }

		    output.push(next);
		  }

		  // if path was absolute, ensure output has leading /
		  if(path[0] === '/' && output.length > 0 && output[0] !== '') {
		    output.unshift('');
		  }
		  if(output.length === 1 && output[0] === '') {
		    return '/';
		  }

		  return output.join('/');
		};

		// TODO: time better isAbsolute/isRelative checks using full regexes:
		// http://jmrware.com/articles/2009/uri_regexp/URI_regex.html

		// regex to check for absolute IRI (starting scheme and ':') or blank node IRI
		const isAbsoluteRegex = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^\s]*$/;

		/**
		 * Returns true if the given value is an absolute IRI or blank node IRI, false
		 * if not.
		 * Note: This weak check only checks for a correct starting scheme.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is an absolute IRI, false if not.
		 */
		api.isAbsolute = v => types.isString(v) && isAbsoluteRegex.test(v);

		/**
		 * Returns true if the given value is a relative IRI, false if not.
		 * Note: this is a weak check.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a relative IRI, false if not.
		 */
		api.isRelative = v => types.isString(v);
		return url;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var xhr;
	var hasRequiredXhr;

	function requireXhr () {
		if (hasRequiredXhr) return xhr;
		hasRequiredXhr = 1;

		const {parseLinkHeader, buildHeaders} = requireUtil();
		const {LINK_HEADER_CONTEXT} = requireConstants();
		const JsonLdError = requireJsonLdError();
		const RequestQueue = requireRequestQueue();
		const {prependBase} = requireUrl();

		const REGEX_LINK_HEADER = /(^|(\r\n))link:/i;

		/**
		 * Creates a built-in XMLHttpRequest document loader.
		 *
		 * @param options the options to use:
		 *          secure: require all URLs to use HTTPS.
		 *          headers: an object (map) of headers which will be passed as request
		 *            headers for the requested document. Accept is not allowed.
		 *          [xhr]: the XMLHttpRequest API to use.
		 *
		 * @return the XMLHttpRequest document loader.
		 */
		xhr = ({
		  secure,
		  headers = {},
		  xhr
		} = {headers: {}}) => {
		  headers = buildHeaders(headers);
		  const queue = new RequestQueue();
		  return queue.wrapLoader(loader);

		  async function loader(url) {
		    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {
		      throw new JsonLdError(
		        'URL could not be dereferenced; only "http" and "https" URLs are ' +
		        'supported.',
		        'jsonld.InvalidUrl', {code: 'loading document failed', url});
		    }
		    if(secure && url.indexOf('https') !== 0) {
		      throw new JsonLdError(
		        'URL could not be dereferenced; secure mode is enabled and ' +
		        'the URL\'s scheme is not "https".',
		        'jsonld.InvalidUrl', {code: 'loading document failed', url});
		    }

		    let req;
		    try {
		      req = await _get(xhr, url, headers);
		    } catch(e) {
		      throw new JsonLdError(
		        'URL could not be dereferenced, an error occurred.',
		        'jsonld.LoadDocumentError',
		        {code: 'loading document failed', url, cause: e});
		    }

		    if(req.status >= 400) {
		      throw new JsonLdError(
		        'URL could not be dereferenced: ' + req.statusText,
		        'jsonld.LoadDocumentError', {
		          code: 'loading document failed',
		          url,
		          httpStatusCode: req.status
		        });
		    }

		    let doc = {contextUrl: null, documentUrl: url, document: req.response};
		    let alternate = null;

		    // handle Link Header (avoid unsafe header warning by existence testing)
		    const contentType = req.getResponseHeader('Content-Type');
		    let linkHeader;
		    if(REGEX_LINK_HEADER.test(req.getAllResponseHeaders())) {
		      linkHeader = req.getResponseHeader('Link');
		    }
		    if(linkHeader && contentType !== 'application/ld+json') {
		      // only 1 related link header permitted
		      const linkHeaders = parseLinkHeader(linkHeader);
		      const linkedContext = linkHeaders[LINK_HEADER_CONTEXT];
		      if(Array.isArray(linkedContext)) {
		        throw new JsonLdError(
		          'URL could not be dereferenced, it has more than one ' +
		          'associated HTTP Link Header.',
		          'jsonld.InvalidUrl',
		          {code: 'multiple context link headers', url});
		      }
		      if(linkedContext) {
		        doc.contextUrl = linkedContext.target;
		      }

		      // "alternate" link header is a redirect
		      alternate = linkHeaders.alternate;
		      if(alternate &&
		        alternate.type == 'application/ld+json' &&
		        !(contentType || '').match(/^application\/(\w*\+)?json$/)) {
		        doc = await loader(prependBase(url, alternate.target));
		      }
		    }

		    return doc;
		  }
		};

		function _get(xhr, url, headers) {
		  xhr = xhr || XMLHttpRequest;
		  const req = new xhr();
		  return new Promise((resolve, reject) => {
		    req.onload = () => resolve(req);
		    req.onerror = err => reject(err);
		    req.open('GET', url, true);
		    for(const k in headers) {
		      req.setRequestHeader(k, headers[k]);
		    }
		    req.send();
		  });
		}
		return xhr;
	}

	/*
	 * Copyright (c) 2021 Digital Bazaar, Inc. All rights reserved.
	 */

	var platformBrowser;
	var hasRequiredPlatformBrowser;

	function requirePlatformBrowser () {
		if (hasRequiredPlatformBrowser) return platformBrowser;
		hasRequiredPlatformBrowser = 1;

		const xhrLoader = requireXhr();

		const api = {};
		platformBrowser = api;

		/**
		 * Setup browser document loaders.
		 *
		 * @param jsonld the jsonld api.
		 */
		api.setupDocumentLoaders = function(jsonld) {
		  if(typeof XMLHttpRequest !== 'undefined') {
		    jsonld.documentLoaders.xhr = xhrLoader;
		    // use xhr document loader by default
		    jsonld.useDocumentLoader('xhr');
		  }
		};

		/**
		 * Setup browser globals.
		 *
		 * @param jsonld the jsonld api.
		 */
		api.setupGlobals = function(jsonld) {
		  // setup browser global JsonLdProcessor
		  if(typeof globalThis.JsonLdProcessor === 'undefined') {
		    Object.defineProperty(globalThis, 'JsonLdProcessor', {
		      writable: true,
		      enumerable: false,
		      configurable: true,
		      value: jsonld.JsonLdProcessor
		    });
		  }
		};
		return platformBrowser;
	}

	var iterator;
	var hasRequiredIterator;

	function requireIterator () {
		if (hasRequiredIterator) return iterator;
		hasRequiredIterator = 1;
		iterator = function (Yallist) {
		  Yallist.prototype[Symbol.iterator] = function* () {
		    for (let walker = this.head; walker; walker = walker.next) {
		      yield walker.value;
		    }
		  };
		};
		return iterator;
	}

	var yallist;
	var hasRequiredYallist;

	function requireYallist () {
		if (hasRequiredYallist) return yallist;
		hasRequiredYallist = 1;
		yallist = Yallist;

		Yallist.Node = Node;
		Yallist.create = Yallist;

		function Yallist (list) {
		  var self = this;
		  if (!(self instanceof Yallist)) {
		    self = new Yallist();
		  }

		  self.tail = null;
		  self.head = null;
		  self.length = 0;

		  if (list && typeof list.forEach === 'function') {
		    list.forEach(function (item) {
		      self.push(item);
		    });
		  } else if (arguments.length > 0) {
		    for (var i = 0, l = arguments.length; i < l; i++) {
		      self.push(arguments[i]);
		    }
		  }

		  return self
		}

		Yallist.prototype.removeNode = function (node) {
		  if (node.list !== this) {
		    throw new Error('removing node which does not belong to this list')
		  }

		  var next = node.next;
		  var prev = node.prev;

		  if (next) {
		    next.prev = prev;
		  }

		  if (prev) {
		    prev.next = next;
		  }

		  if (node === this.head) {
		    this.head = next;
		  }
		  if (node === this.tail) {
		    this.tail = prev;
		  }

		  node.list.length--;
		  node.next = null;
		  node.prev = null;
		  node.list = null;

		  return next
		};

		Yallist.prototype.unshiftNode = function (node) {
		  if (node === this.head) {
		    return
		  }

		  if (node.list) {
		    node.list.removeNode(node);
		  }

		  var head = this.head;
		  node.list = this;
		  node.next = head;
		  if (head) {
		    head.prev = node;
		  }

		  this.head = node;
		  if (!this.tail) {
		    this.tail = node;
		  }
		  this.length++;
		};

		Yallist.prototype.pushNode = function (node) {
		  if (node === this.tail) {
		    return
		  }

		  if (node.list) {
		    node.list.removeNode(node);
		  }

		  var tail = this.tail;
		  node.list = this;
		  node.prev = tail;
		  if (tail) {
		    tail.next = node;
		  }

		  this.tail = node;
		  if (!this.head) {
		    this.head = node;
		  }
		  this.length++;
		};

		Yallist.prototype.push = function () {
		  for (var i = 0, l = arguments.length; i < l; i++) {
		    push(this, arguments[i]);
		  }
		  return this.length
		};

		Yallist.prototype.unshift = function () {
		  for (var i = 0, l = arguments.length; i < l; i++) {
		    unshift(this, arguments[i]);
		  }
		  return this.length
		};

		Yallist.prototype.pop = function () {
		  if (!this.tail) {
		    return undefined
		  }

		  var res = this.tail.value;
		  this.tail = this.tail.prev;
		  if (this.tail) {
		    this.tail.next = null;
		  } else {
		    this.head = null;
		  }
		  this.length--;
		  return res
		};

		Yallist.prototype.shift = function () {
		  if (!this.head) {
		    return undefined
		  }

		  var res = this.head.value;
		  this.head = this.head.next;
		  if (this.head) {
		    this.head.prev = null;
		  } else {
		    this.tail = null;
		  }
		  this.length--;
		  return res
		};

		Yallist.prototype.forEach = function (fn, thisp) {
		  thisp = thisp || this;
		  for (var walker = this.head, i = 0; walker !== null; i++) {
		    fn.call(thisp, walker.value, i, this);
		    walker = walker.next;
		  }
		};

		Yallist.prototype.forEachReverse = function (fn, thisp) {
		  thisp = thisp || this;
		  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {
		    fn.call(thisp, walker.value, i, this);
		    walker = walker.prev;
		  }
		};

		Yallist.prototype.get = function (n) {
		  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {
		    // abort out of the list early if we hit a cycle
		    walker = walker.next;
		  }
		  if (i === n && walker !== null) {
		    return walker.value
		  }
		};

		Yallist.prototype.getReverse = function (n) {
		  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {
		    // abort out of the list early if we hit a cycle
		    walker = walker.prev;
		  }
		  if (i === n && walker !== null) {
		    return walker.value
		  }
		};

		Yallist.prototype.map = function (fn, thisp) {
		  thisp = thisp || this;
		  var res = new Yallist();
		  for (var walker = this.head; walker !== null;) {
		    res.push(fn.call(thisp, walker.value, this));
		    walker = walker.next;
		  }
		  return res
		};

		Yallist.prototype.mapReverse = function (fn, thisp) {
		  thisp = thisp || this;
		  var res = new Yallist();
		  for (var walker = this.tail; walker !== null;) {
		    res.push(fn.call(thisp, walker.value, this));
		    walker = walker.prev;
		  }
		  return res
		};

		Yallist.prototype.reduce = function (fn, initial) {
		  var acc;
		  var walker = this.head;
		  if (arguments.length > 1) {
		    acc = initial;
		  } else if (this.head) {
		    walker = this.head.next;
		    acc = this.head.value;
		  } else {
		    throw new TypeError('Reduce of empty list with no initial value')
		  }

		  for (var i = 0; walker !== null; i++) {
		    acc = fn(acc, walker.value, i);
		    walker = walker.next;
		  }

		  return acc
		};

		Yallist.prototype.reduceReverse = function (fn, initial) {
		  var acc;
		  var walker = this.tail;
		  if (arguments.length > 1) {
		    acc = initial;
		  } else if (this.tail) {
		    walker = this.tail.prev;
		    acc = this.tail.value;
		  } else {
		    throw new TypeError('Reduce of empty list with no initial value')
		  }

		  for (var i = this.length - 1; walker !== null; i--) {
		    acc = fn(acc, walker.value, i);
		    walker = walker.prev;
		  }

		  return acc
		};

		Yallist.prototype.toArray = function () {
		  var arr = new Array(this.length);
		  for (var i = 0, walker = this.head; walker !== null; i++) {
		    arr[i] = walker.value;
		    walker = walker.next;
		  }
		  return arr
		};

		Yallist.prototype.toArrayReverse = function () {
		  var arr = new Array(this.length);
		  for (var i = 0, walker = this.tail; walker !== null; i++) {
		    arr[i] = walker.value;
		    walker = walker.prev;
		  }
		  return arr
		};

		Yallist.prototype.slice = function (from, to) {
		  to = to || this.length;
		  if (to < 0) {
		    to += this.length;
		  }
		  from = from || 0;
		  if (from < 0) {
		    from += this.length;
		  }
		  var ret = new Yallist();
		  if (to < from || to < 0) {
		    return ret
		  }
		  if (from < 0) {
		    from = 0;
		  }
		  if (to > this.length) {
		    to = this.length;
		  }
		  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {
		    walker = walker.next;
		  }
		  for (; walker !== null && i < to; i++, walker = walker.next) {
		    ret.push(walker.value);
		  }
		  return ret
		};

		Yallist.prototype.sliceReverse = function (from, to) {
		  to = to || this.length;
		  if (to < 0) {
		    to += this.length;
		  }
		  from = from || 0;
		  if (from < 0) {
		    from += this.length;
		  }
		  var ret = new Yallist();
		  if (to < from || to < 0) {
		    return ret
		  }
		  if (from < 0) {
		    from = 0;
		  }
		  if (to > this.length) {
		    to = this.length;
		  }
		  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {
		    walker = walker.prev;
		  }
		  for (; walker !== null && i > from; i--, walker = walker.prev) {
		    ret.push(walker.value);
		  }
		  return ret
		};

		Yallist.prototype.splice = function (start, deleteCount, ...nodes) {
		  if (start > this.length) {
		    start = this.length - 1;
		  }
		  if (start < 0) {
		    start = this.length + start;
		  }

		  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {
		    walker = walker.next;
		  }

		  var ret = [];
		  for (var i = 0; walker && i < deleteCount; i++) {
		    ret.push(walker.value);
		    walker = this.removeNode(walker);
		  }
		  if (walker === null) {
		    walker = this.tail;
		  }

		  if (walker !== this.head && walker !== this.tail) {
		    walker = walker.prev;
		  }

		  for (var i = 0; i < nodes.length; i++) {
		    walker = insert(this, walker, nodes[i]);
		  }
		  return ret;
		};

		Yallist.prototype.reverse = function () {
		  var head = this.head;
		  var tail = this.tail;
		  for (var walker = head; walker !== null; walker = walker.prev) {
		    var p = walker.prev;
		    walker.prev = walker.next;
		    walker.next = p;
		  }
		  this.head = tail;
		  this.tail = head;
		  return this
		};

		function insert (self, node, value) {
		  var inserted = node === self.head ?
		    new Node(value, null, node, self) :
		    new Node(value, node, node.next, self);

		  if (inserted.next === null) {
		    self.tail = inserted;
		  }
		  if (inserted.prev === null) {
		    self.head = inserted;
		  }

		  self.length++;

		  return inserted
		}

		function push (self, item) {
		  self.tail = new Node(item, self.tail, null, self);
		  if (!self.head) {
		    self.head = self.tail;
		  }
		  self.length++;
		}

		function unshift (self, item) {
		  self.head = new Node(item, null, self.head, self);
		  if (!self.tail) {
		    self.tail = self.head;
		  }
		  self.length++;
		}

		function Node (value, prev, next, list) {
		  if (!(this instanceof Node)) {
		    return new Node(value, prev, next, list)
		  }

		  this.list = list;
		  this.value = value;

		  if (prev) {
		    prev.next = this;
		    this.prev = prev;
		  } else {
		    this.prev = null;
		  }

		  if (next) {
		    next.prev = this;
		    this.next = next;
		  } else {
		    this.next = null;
		  }
		}

		try {
		  // add if support for Symbol.iterator is present
		  requireIterator()(Yallist);
		} catch (er) {}
		return yallist;
	}

	var lruCache;
	var hasRequiredLruCache;

	function requireLruCache () {
		if (hasRequiredLruCache) return lruCache;
		hasRequiredLruCache = 1;

		// A linked list to keep track of recently-used-ness
		const Yallist = requireYallist();

		const MAX = Symbol('max');
		const LENGTH = Symbol('length');
		const LENGTH_CALCULATOR = Symbol('lengthCalculator');
		const ALLOW_STALE = Symbol('allowStale');
		const MAX_AGE = Symbol('maxAge');
		const DISPOSE = Symbol('dispose');
		const NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet');
		const LRU_LIST = Symbol('lruList');
		const CACHE = Symbol('cache');
		const UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet');

		const naiveLength = () => 1;

		// lruList is a yallist where the head is the youngest
		// item, and the tail is the oldest.  the list contains the Hit
		// objects as the entries.
		// Each Hit object has a reference to its Yallist.Node.  This
		// never changes.
		//
		// cache is a Map (or PseudoMap) that matches the keys to
		// the Yallist.Node object.
		class LRUCache {
		  constructor (options) {
		    if (typeof options === 'number')
		      options = { max: options };

		    if (!options)
		      options = {};

		    if (options.max && (typeof options.max !== 'number' || options.max < 0))
		      throw new TypeError('max must be a non-negative number')
		    // Kind of weird to have a default max of Infinity, but oh well.
		    this[MAX] = options.max || Infinity;

		    const lc = options.length || naiveLength;
		    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc;
		    this[ALLOW_STALE] = options.stale || false;
		    if (options.maxAge && typeof options.maxAge !== 'number')
		      throw new TypeError('maxAge must be a number')
		    this[MAX_AGE] = options.maxAge || 0;
		    this[DISPOSE] = options.dispose;
		    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false;
		    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false;
		    this.reset();
		  }

		  // resize the cache when the max changes.
		  set max (mL) {
		    if (typeof mL !== 'number' || mL < 0)
		      throw new TypeError('max must be a non-negative number')

		    this[MAX] = mL || Infinity;
		    trim(this);
		  }
		  get max () {
		    return this[MAX]
		  }

		  set allowStale (allowStale) {
		    this[ALLOW_STALE] = !!allowStale;
		  }
		  get allowStale () {
		    return this[ALLOW_STALE]
		  }

		  set maxAge (mA) {
		    if (typeof mA !== 'number')
		      throw new TypeError('maxAge must be a non-negative number')

		    this[MAX_AGE] = mA;
		    trim(this);
		  }
		  get maxAge () {
		    return this[MAX_AGE]
		  }

		  // resize the cache when the lengthCalculator changes.
		  set lengthCalculator (lC) {
		    if (typeof lC !== 'function')
		      lC = naiveLength;

		    if (lC !== this[LENGTH_CALCULATOR]) {
		      this[LENGTH_CALCULATOR] = lC;
		      this[LENGTH] = 0;
		      this[LRU_LIST].forEach(hit => {
		        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key);
		        this[LENGTH] += hit.length;
		      });
		    }
		    trim(this);
		  }
		  get lengthCalculator () { return this[LENGTH_CALCULATOR] }

		  get length () { return this[LENGTH] }
		  get itemCount () { return this[LRU_LIST].length }

		  rforEach (fn, thisp) {
		    thisp = thisp || this;
		    for (let walker = this[LRU_LIST].tail; walker !== null;) {
		      const prev = walker.prev;
		      forEachStep(this, fn, walker, thisp);
		      walker = prev;
		    }
		  }

		  forEach (fn, thisp) {
		    thisp = thisp || this;
		    for (let walker = this[LRU_LIST].head; walker !== null;) {
		      const next = walker.next;
		      forEachStep(this, fn, walker, thisp);
		      walker = next;
		    }
		  }

		  keys () {
		    return this[LRU_LIST].toArray().map(k => k.key)
		  }

		  values () {
		    return this[LRU_LIST].toArray().map(k => k.value)
		  }

		  reset () {
		    if (this[DISPOSE] &&
		        this[LRU_LIST] &&
		        this[LRU_LIST].length) {
		      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value));
		    }

		    this[CACHE] = new Map(); // hash of items by key
		    this[LRU_LIST] = new Yallist(); // list of items in order of use recency
		    this[LENGTH] = 0; // length of items in the list
		  }

		  dump () {
		    return this[LRU_LIST].map(hit =>
		      isStale(this, hit) ? false : {
		        k: hit.key,
		        v: hit.value,
		        e: hit.now + (hit.maxAge || 0)
		      }).toArray().filter(h => h)
		  }

		  dumpLru () {
		    return this[LRU_LIST]
		  }

		  set (key, value, maxAge) {
		    maxAge = maxAge || this[MAX_AGE];

		    if (maxAge && typeof maxAge !== 'number')
		      throw new TypeError('maxAge must be a number')

		    const now = maxAge ? Date.now() : 0;
		    const len = this[LENGTH_CALCULATOR](value, key);

		    if (this[CACHE].has(key)) {
		      if (len > this[MAX]) {
		        del(this, this[CACHE].get(key));
		        return false
		      }

		      const node = this[CACHE].get(key);
		      const item = node.value;

		      // dispose of the old one before overwriting
		      // split out into 2 ifs for better coverage tracking
		      if (this[DISPOSE]) {
		        if (!this[NO_DISPOSE_ON_SET])
		          this[DISPOSE](key, item.value);
		      }

		      item.now = now;
		      item.maxAge = maxAge;
		      item.value = value;
		      this[LENGTH] += len - item.length;
		      item.length = len;
		      this.get(key);
		      trim(this);
		      return true
		    }

		    const hit = new Entry(key, value, len, now, maxAge);

		    // oversized objects fall out of cache automatically.
		    if (hit.length > this[MAX]) {
		      if (this[DISPOSE])
		        this[DISPOSE](key, value);

		      return false
		    }

		    this[LENGTH] += hit.length;
		    this[LRU_LIST].unshift(hit);
		    this[CACHE].set(key, this[LRU_LIST].head);
		    trim(this);
		    return true
		  }

		  has (key) {
		    if (!this[CACHE].has(key)) return false
		    const hit = this[CACHE].get(key).value;
		    return !isStale(this, hit)
		  }

		  get (key) {
		    return get(this, key, true)
		  }

		  peek (key) {
		    return get(this, key, false)
		  }

		  pop () {
		    const node = this[LRU_LIST].tail;
		    if (!node)
		      return null

		    del(this, node);
		    return node.value
		  }

		  del (key) {
		    del(this, this[CACHE].get(key));
		  }

		  load (arr) {
		    // reset the cache
		    this.reset();

		    const now = Date.now();
		    // A previous serialized cache has the most recent items first
		    for (let l = arr.length - 1; l >= 0; l--) {
		      const hit = arr[l];
		      const expiresAt = hit.e || 0;
		      if (expiresAt === 0)
		        // the item was created without expiration in a non aged cache
		        this.set(hit.k, hit.v);
		      else {
		        const maxAge = expiresAt - now;
		        // dont add already expired items
		        if (maxAge > 0) {
		          this.set(hit.k, hit.v, maxAge);
		        }
		      }
		    }
		  }

		  prune () {
		    this[CACHE].forEach((value, key) => get(this, key, false));
		  }
		}

		const get = (self, key, doUse) => {
		  const node = self[CACHE].get(key);
		  if (node) {
		    const hit = node.value;
		    if (isStale(self, hit)) {
		      del(self, node);
		      if (!self[ALLOW_STALE])
		        return undefined
		    } else {
		      if (doUse) {
		        if (self[UPDATE_AGE_ON_GET])
		          node.value.now = Date.now();
		        self[LRU_LIST].unshiftNode(node);
		      }
		    }
		    return hit.value
		  }
		};

		const isStale = (self, hit) => {
		  if (!hit || (!hit.maxAge && !self[MAX_AGE]))
		    return false

		  const diff = Date.now() - hit.now;
		  return hit.maxAge ? diff > hit.maxAge
		    : self[MAX_AGE] && (diff > self[MAX_AGE])
		};

		const trim = self => {
		  if (self[LENGTH] > self[MAX]) {
		    for (let walker = self[LRU_LIST].tail;
		      self[LENGTH] > self[MAX] && walker !== null;) {
		      // We know that we're about to delete this one, and also
		      // what the next least recently used key will be, so just
		      // go ahead and set it now.
		      const prev = walker.prev;
		      del(self, walker);
		      walker = prev;
		    }
		  }
		};

		const del = (self, node) => {
		  if (node) {
		    const hit = node.value;
		    if (self[DISPOSE])
		      self[DISPOSE](hit.key, hit.value);

		    self[LENGTH] -= hit.length;
		    self[CACHE].delete(hit.key);
		    self[LRU_LIST].removeNode(node);
		  }
		};

		class Entry {
		  constructor (key, value, length, now, maxAge) {
		    this.key = key;
		    this.value = value;
		    this.length = length;
		    this.now = now;
		    this.maxAge = maxAge || 0;
		  }
		}

		const forEachStep = (self, fn, node, thisp) => {
		  let hit = node.value;
		  if (isStale(self, hit)) {
		    del(self, node);
		    if (!self[ALLOW_STALE])
		      hit = undefined;
		  }
		  if (hit)
		    fn.call(thisp, hit.value, hit.key, self);
		};

		lruCache = LRUCache;
		return lruCache;
	}

	/*
	 * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.
	 */

	var ResolvedContext_1;
	var hasRequiredResolvedContext;

	function requireResolvedContext () {
		if (hasRequiredResolvedContext) return ResolvedContext_1;
		hasRequiredResolvedContext = 1;

		const LRU = requireLruCache();

		const MAX_ACTIVE_CONTEXTS = 10;

		ResolvedContext_1 = class ResolvedContext {
		  /**
		   * Creates a ResolvedContext.
		   *
		   * @param document the context document.
		   */
		  constructor({document}) {
		    this.document = document;
		    // TODO: enable customization of processed context cache
		    // TODO: limit based on size of processed contexts vs. number of them
		    this.cache = new LRU({max: MAX_ACTIVE_CONTEXTS});
		  }

		  getProcessed(activeCtx) {
		    return this.cache.get(activeCtx);
		  }

		  setProcessed(activeCtx, processedCtx) {
		    this.cache.set(activeCtx, processedCtx);
		  }
		};
		return ResolvedContext_1;
	}

	/*
	 * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.
	 */

	var ContextResolver_1;
	var hasRequiredContextResolver;

	function requireContextResolver () {
		if (hasRequiredContextResolver) return ContextResolver_1;
		hasRequiredContextResolver = 1;

		const {
		  isArray: _isArray,
		  isObject: _isObject,
		  isString: _isString,
		} = requireTypes();
		const {
		  asArray: _asArray
		} = requireUtil();
		const {prependBase} = requireUrl();
		const JsonLdError = requireJsonLdError();
		const ResolvedContext = requireResolvedContext();

		const MAX_CONTEXT_URLS = 10;

		ContextResolver_1 = class ContextResolver {
		  /**
		   * Creates a ContextResolver.
		   *
		   * @param sharedCache a shared LRU cache with `get` and `set` APIs.
		   */
		  constructor({sharedCache}) {
		    this.perOpCache = new Map();
		    this.sharedCache = sharedCache;
		  }

		  async resolve({
		    activeCtx, context, documentLoader, base, cycles = new Set()
		  }) {
		    // process `@context`
		    if(context && _isObject(context) && context['@context']) {
		      context = context['@context'];
		    }

		    // context is one or more contexts
		    context = _asArray(context);

		    // resolve each context in the array
		    const allResolved = [];
		    for(const ctx of context) {
		      if(_isString(ctx)) {
		        // see if `ctx` has been resolved before...
		        let resolved = this._get(ctx);
		        if(!resolved) {
		          // not resolved yet, resolve
		          resolved = await this._resolveRemoteContext(
		            {activeCtx, url: ctx, documentLoader, base, cycles});
		        }

		        // add to output and continue
		        if(_isArray(resolved)) {
		          allResolved.push(...resolved);
		        } else {
		          allResolved.push(resolved);
		        }
		        continue;
		      }
		      if(ctx === null) {
		        // handle `null` context, nothing to cache
		        allResolved.push(new ResolvedContext({document: null}));
		        continue;
		      }
		      if(!_isObject(ctx)) {
		        _throwInvalidLocalContext(context);
		      }
		      // context is an object, get/create `ResolvedContext` for it
		      const key = JSON.stringify(ctx);
		      let resolved = this._get(key);
		      if(!resolved) {
		        // create a new static `ResolvedContext` and cache it
		        resolved = new ResolvedContext({document: ctx});
		        this._cacheResolvedContext({key, resolved, tag: 'static'});
		      }
		      allResolved.push(resolved);
		    }

		    return allResolved;
		  }

		  _get(key) {
		    // get key from per operation cache; no `tag` is used with this cache so
		    // any retrieved context will always be the same during a single operation
		    let resolved = this.perOpCache.get(key);
		    if(!resolved) {
		      // see if the shared cache has a `static` entry for this URL
		      const tagMap = this.sharedCache.get(key);
		      if(tagMap) {
		        resolved = tagMap.get('static');
		        if(resolved) {
		          this.perOpCache.set(key, resolved);
		        }
		      }
		    }
		    return resolved;
		  }

		  _cacheResolvedContext({key, resolved, tag}) {
		    this.perOpCache.set(key, resolved);
		    if(tag !== undefined) {
		      let tagMap = this.sharedCache.get(key);
		      if(!tagMap) {
		        tagMap = new Map();
		        this.sharedCache.set(key, tagMap);
		      }
		      tagMap.set(tag, resolved);
		    }
		    return resolved;
		  }

		  async _resolveRemoteContext({activeCtx, url, documentLoader, base, cycles}) {
		    // resolve relative URL and fetch context
		    url = prependBase(base, url);
		    const {context, remoteDoc} = await this._fetchContext(
		      {activeCtx, url, documentLoader, cycles});

		    // update base according to remote document and resolve any relative URLs
		    base = remoteDoc.documentUrl || url;
		    _resolveContextUrls({context, base});

		    // resolve, cache, and return context
		    const resolved = await this.resolve(
		      {activeCtx, context, documentLoader, base, cycles});
		    this._cacheResolvedContext({key: url, resolved, tag: remoteDoc.tag});
		    return resolved;
		  }

		  async _fetchContext({activeCtx, url, documentLoader, cycles}) {
		    // check for max context URLs fetched during a resolve operation
		    if(cycles.size > MAX_CONTEXT_URLS) {
		      throw new JsonLdError(
		        'Maximum number of @context URLs exceeded.',
		        'jsonld.ContextUrlError',
		        {
		          code: activeCtx.processingMode === 'json-ld-1.0' ?
		            'loading remote context failed' :
		            'context overflow',
		          max: MAX_CONTEXT_URLS
		        });
		    }

		    // check for context URL cycle
		    // shortcut to avoid extra work that would eventually hit the max above
		    if(cycles.has(url)) {
		      throw new JsonLdError(
		        'Cyclical @context URLs detected.',
		        'jsonld.ContextUrlError',
		        {
		          code: activeCtx.processingMode === 'json-ld-1.0' ?
		            'recursive context inclusion' :
		            'context overflow',
		          url
		        });
		    }

		    // track cycles
		    cycles.add(url);

		    let context;
		    let remoteDoc;

		    try {
		      remoteDoc = await documentLoader(url);
		      context = remoteDoc.document || null;
		      // parse string context as JSON
		      if(_isString(context)) {
		        context = JSON.parse(context);
		      }
		    } catch(e) {
		      throw new JsonLdError(
		        'Dereferencing a URL did not result in a valid JSON-LD object. ' +
		        'Possible causes are an inaccessible URL perhaps due to ' +
		        'a same-origin policy (ensure the server uses CORS if you are ' +
		        'using client-side JavaScript), too many redirects, a ' +
		        'non-JSON response, or more than one HTTP Link Header was ' +
		        'provided for a remote context. ' +
		        `URL: "${url}".`,
		        'jsonld.InvalidUrl',
		        {code: 'loading remote context failed', url, cause: e});
		    }

		    // ensure ctx is an object
		    if(!_isObject(context)) {
		      throw new JsonLdError(
		        'Dereferencing a URL did not result in a JSON object. The ' +
		        'response was valid JSON, but it was not a JSON object. ' +
		        `URL: "${url}".`,
		        'jsonld.InvalidUrl', {code: 'invalid remote context', url});
		    }

		    // use empty context if no @context key is present
		    if(!('@context' in context)) {
		      context = {'@context': {}};
		    } else {
		      context = {'@context': context['@context']};
		    }

		    // append @context URL to context if given
		    if(remoteDoc.contextUrl) {
		      if(!_isArray(context['@context'])) {
		        context['@context'] = [context['@context']];
		      }
		      context['@context'].push(remoteDoc.contextUrl);
		    }

		    return {context, remoteDoc};
		  }
		};

		function _throwInvalidLocalContext(ctx) {
		  throw new JsonLdError(
		    'Invalid JSON-LD syntax; @context must be an object.',
		    'jsonld.SyntaxError', {
		      code: 'invalid local context', context: ctx
		    });
		}

		/**
		 * Resolve all relative `@context` URLs in the given context by inline
		 * replacing them with absolute URLs.
		 *
		 * @param context the context.
		 * @param base the base IRI to use to resolve relative IRIs.
		 */
		function _resolveContextUrls({context, base}) {
		  if(!context) {
		    return;
		  }

		  const ctx = context['@context'];

		  if(_isString(ctx)) {
		    context['@context'] = prependBase(base, ctx);
		    return;
		  }

		  if(_isArray(ctx)) {
		    for(let i = 0; i < ctx.length; ++i) {
		      const element = ctx[i];
		      if(_isString(element)) {
		        ctx[i] = prependBase(base, element);
		        continue;
		      }
		      if(_isObject(element)) {
		        _resolveContextUrls({context: {'@context': element}, base});
		      }
		    }
		    return;
		  }

		  if(!_isObject(ctx)) {
		    // no @context URLs can be found in non-object
		    return;
		  }

		  // ctx is an object, resolve any context URLs in terms
		  for(const term in ctx) {
		    _resolveContextUrls({context: ctx[term], base});
		  }
		}
		return ContextResolver_1;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var NQuads;
	var hasRequiredNQuads;

	function requireNQuads () {
		if (hasRequiredNQuads) return NQuads;
		hasRequiredNQuads = 1;

		// TODO: move `NQuads` to its own package
		NQuads = requireRdfCanonize().NQuads;
		return NQuads;
	}

	/*
	 * Copyright (c) 2020 Digital Bazaar, Inc. All rights reserved.
	 */

	var events;
	var hasRequiredEvents;

	function requireEvents () {
		if (hasRequiredEvents) return events;
		hasRequiredEvents = 1;

		const JsonLdError = requireJsonLdError();

		const {
		  isArray: _isArray
		} = requireTypes();

		const {
		  asArray: _asArray
		} = requireUtil();

		const api = {};
		events = api;

		// default handler, store as null or an array
		// exposed to allow fast external pre-handleEvent() checks
		api.defaultEventHandler = null;

		/**
		 * Setup event handler.
		 *
		 * Return an array event handler constructed from an optional safe mode
		 * handler, an optional options event handler, and an optional default handler.
		 *
		 * @param {object} options - processing options
		 *   {function|object|array} [eventHandler] - an event handler.
		 *
		 * @return an array event handler.
		 */
		api.setupEventHandler = ({options = {}}) => {
		  // build in priority order
		  const eventHandler = [].concat(
		    options.safe ? api.safeEventHandler : [],
		    options.eventHandler ? _asArray(options.eventHandler) : [],
		    api.defaultEventHandler ? api.defaultEventHandler : []
		  );
		  // null if no handlers
		  return eventHandler.length === 0 ? null : eventHandler;
		};

		/**
		 * Handle an event.
		 *
		 * Top level APIs have a common 'eventHandler' option. This option can be a
		 * function, array of functions, object mapping event.code to functions (with a
		 * default to call next()), or any combination of such handlers. Handlers will
		 * be called with an object with an 'event' entry and a 'next' function. Custom
		 * handlers should process the event as appropriate. The 'next()' function
		 * should be called to let the next handler process the event.
		 *
		 * NOTE: Only call this function if options.eventHandler is set and is an
		 * array of hanlers. This is an optimization. Callers are expected to check
		 * for an event handler before constructing events and calling this function.
		 *
		 * @param {object} event - event structure:
		 *   {string} code - event code
		 *   {string} level - severity level, one of: ['warning']
		 *   {string} message - human readable message
		 *   {object} details - event specific details
		 * @param {object} options - processing options
		 *   {array} eventHandler - an event handler array.
		 */
		api.handleEvent = ({
		  event,
		  options
		}) => {
		  _handle({event, handlers: options.eventHandler});
		};

		function _handle({event, handlers}) {
		  let doNext = true;
		  for(let i = 0; doNext && i < handlers.length; ++i) {
		    doNext = false;
		    const handler = handlers[i];
		    if(_isArray(handler)) {
		      doNext = _handle({event, handlers: handler});
		    } else if(typeof handler === 'function') {
		      handler({event, next: () => {
		        doNext = true;
		      }});
		    } else if(typeof handler === 'object') {
		      if(event.code in handler) {
		        handler[event.code]({event, next: () => {
		          doNext = true;
		        }});
		      } else {
		        doNext = true;
		      }
		    } else {
		      throw new JsonLdError(
		        'Invalid event handler.',
		        'jsonld.InvalidEventHandler',
		        {event});
		    }
		  }
		  return doNext;
		}

		const _notSafeEventCodes = new Set([
		  'empty object',
		  'free-floating scalar',
		  'invalid @language value',
		  'invalid property',
		  // NOTE: spec edge case
		  'null @id value',
		  'null @value value',
		  'object with only @id',
		  'object with only @language',
		  'object with only @list',
		  'object with only @value',
		  'relative @id reference',
		  'relative @type reference',
		  'relative @vocab reference',
		  'reserved @id value',
		  'reserved @reverse value',
		  'reserved term',
		  // toRDF
		  'blank node predicate',
		  'relative graph reference',
		  'relative object reference',
		  'relative predicate reference',
		  'relative subject reference',
		  // toRDF / fromRDF
		  'rdfDirection not set'
		]);

		// safe handler that rejects unsafe warning conditions
		api.safeEventHandler = function safeEventHandler({event, next}) {
		  // fail on all unsafe warnings
		  if(event.level === 'warning' && _notSafeEventCodes.has(event.code)) {
		    throw new JsonLdError(
		      'Safe mode validation error.',
		      'jsonld.ValidationError',
		      {event}
		    );
		  }
		  next();
		};

		// logs all events and continues
		api.logEventHandler = function logEventHandler({event, next}) {
		  console.log(`EVENT: ${event.message}`, {event});
		  next();
		};

		// log 'warning' level events
		api.logWarningEventHandler = function logWarningEventHandler({event, next}) {
		  if(event.level === 'warning') {
		    console.warn(`WARNING: ${event.message}`, {event});
		  }
		  next();
		};

		// fallback to throw errors for any unhandled events
		api.unhandledEventHandler = function unhandledEventHandler({event}) {
		  throw new JsonLdError(
		    'No handler for event.',
		    'jsonld.UnhandledEvent',
		    {event}
		  );
		};

		/**
		 * Set default event handler.
		 *
		 * By default, all event are unhandled. It is recommended to pass in an
		 * eventHandler into each call. However, this call allows using a default
		 * eventHandler when one is not otherwise provided.
		 *
		 * @param {object} options - default handler options:
		 *   {function|object|array} eventHandler - a default event handler.
		 *     falsey to unset.
		 */
		api.setDefaultEventHandler = function({eventHandler} = {}) {
		  api.defaultEventHandler = eventHandler ? _asArray(eventHandler) : null;
		};
		return events;
	}

	/*
	 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
	 */

	var context;
	var hasRequiredContext;

	function requireContext () {
		if (hasRequiredContext) return context;
		hasRequiredContext = 1;

		const util = requireUtil();
		const JsonLdError = requireJsonLdError();

		const {
		  isArray: _isArray,
		  isObject: _isObject,
		  isString: _isString,
		  isUndefined: _isUndefined
		} = requireTypes();

		const {
		  isAbsolute: _isAbsoluteIri,
		  isRelative: _isRelativeIri,
		  prependBase
		} = requireUrl();

		const {
		  handleEvent: _handleEvent
		} = requireEvents();

		const {
		  REGEX_BCP47,
		  REGEX_KEYWORD,
		  asArray: _asArray,
		  compareShortestLeast: _compareShortestLeast
		} = requireUtil();

		const INITIAL_CONTEXT_CACHE = new Map();
		const INITIAL_CONTEXT_CACHE_MAX_SIZE = 10000;

		const api = {};
		context = api;

		/**
		 * Processes a local context and returns a new active context.
		 *
		 * @param activeCtx the current active context.
		 * @param localCtx the local context to process.
		 * @param options the context processing options.
		 * @param propagate `true` if `false`, retains any previously defined term,
		 *   which can be rolled back when the descending into a new node object.
		 * @param overrideProtected `false` allows protected terms to be modified.
		 *
		 * @return a Promise that resolves to the new active context.
		 */
		api.process = async ({
		  activeCtx, localCtx, options,
		  propagate = true,
		  overrideProtected = false,
		  cycles = new Set()
		}) => {
		  // normalize local context to an array of @context objects
		  if(_isObject(localCtx) && '@context' in localCtx &&
		    _isArray(localCtx['@context'])) {
		    localCtx = localCtx['@context'];
		  }
		  const ctxs = _asArray(localCtx);

		  // no contexts in array, return current active context w/o changes
		  if(ctxs.length === 0) {
		    return activeCtx;
		  }

		  // event handler for capturing events to replay when using a cached context
		  const events = [];
		  const eventCaptureHandler = [
		    ({event, next}) => {
		      events.push(event);
		      next();
		    }
		  ];
		  // chain to original handler
		  if(options.eventHandler) {
		    eventCaptureHandler.push(options.eventHandler);
		  }
		  // store original options to use when replaying events
		  const originalOptions = options;
		  // shallow clone options with event capture handler
		  options = {...options, eventHandler: eventCaptureHandler};

		  // resolve contexts
		  const resolved = await options.contextResolver.resolve({
		    activeCtx,
		    context: localCtx,
		    documentLoader: options.documentLoader,
		    base: options.base
		  });

		  // override propagate if first resolved context has `@propagate`
		  if(_isObject(resolved[0].document) &&
		    typeof resolved[0].document['@propagate'] === 'boolean') {
		    // retrieve early, error checking done later
		    propagate = resolved[0].document['@propagate'];
		  }

		  // process each context in order, update active context
		  // on each iteration to ensure proper caching
		  let rval = activeCtx;

		  // track the previous context
		  // if not propagating, make sure rval has a previous context
		  if(!propagate && !rval.previousContext) {
		    // clone `rval` context before updating
		    rval = rval.clone();
		    rval.previousContext = activeCtx;
		  }

		  for(const resolvedContext of resolved) {
		    let {document: ctx} = resolvedContext;

		    // update active context to one computed from last iteration
		    activeCtx = rval;

		    // reset to initial context
		    if(ctx === null) {
		      // We can't nullify if there are protected terms and we're
		      // not allowing overrides (e.g. processing a property term scoped context)
		      if(!overrideProtected && Object.keys(activeCtx.protected).length !== 0) {
		        throw new JsonLdError(
		          'Tried to nullify a context with protected terms outside of ' +
		          'a term definition.',
		          'jsonld.SyntaxError',
		          {code: 'invalid context nullification'});
		      }
		      rval = activeCtx = api.getInitialContext(options).clone();
		      continue;
		    }

		    // get processed context from cache if available
		    const processed = resolvedContext.getProcessed(activeCtx);
		    if(processed) {
		      if(originalOptions.eventHandler) {
		        // replay events with original non-capturing options
		        for(const event of processed.events) {
		          _handleEvent({event, options: originalOptions});
		        }
		      }

		      rval = activeCtx = processed.context;
		      continue;
		    }

		    // dereference @context key if present
		    if(_isObject(ctx) && '@context' in ctx) {
		      ctx = ctx['@context'];
		    }

		    // context must be an object by now, all URLs retrieved before this call
		    if(!_isObject(ctx)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context must be an object.',
		        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});
		    }

		    // TODO: there is likely a `previousContext` cloning optimization that
		    // could be applied here (no need to copy it under certain conditions)

		    // clone context before updating it
		    rval = rval.clone();

		    // define context mappings for keys in local context
		    const defined = new Map();

		    // handle @version
		    if('@version' in ctx) {
		      if(ctx['@version'] !== 1.1) {
		        throw new JsonLdError(
		          'Unsupported JSON-LD version: ' + ctx['@version'],
		          'jsonld.UnsupportedVersion',
		          {code: 'invalid @version value', context: ctx});
		      }
		      if(activeCtx.processingMode &&
		        activeCtx.processingMode === 'json-ld-1.0') {
		        throw new JsonLdError(
		          '@version: ' + ctx['@version'] + ' not compatible with ' +
		          activeCtx.processingMode,
		          'jsonld.ProcessingModeConflict',
		          {code: 'processing mode conflict', context: ctx});
		      }
		      rval.processingMode = 'json-ld-1.1';
		      rval['@version'] = ctx['@version'];
		      defined.set('@version', true);
		    }

		    // if not set explicitly, set processingMode to "json-ld-1.1"
		    rval.processingMode =
		      rval.processingMode || activeCtx.processingMode;

		    // handle @base
		    if('@base' in ctx) {
		      let base = ctx['@base'];

		      if(base === null || _isAbsoluteIri(base)) ; else if(_isRelativeIri(base)) {
		        base = prependBase(rval['@base'], base);
		      } else {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; the value of "@base" in a ' +
		          '@context must be an absolute IRI, a relative IRI, or null.',
		          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});
		      }

		      rval['@base'] = base;
		      defined.set('@base', true);
		    }

		    // handle @vocab
		    if('@vocab' in ctx) {
		      const value = ctx['@vocab'];
		      if(value === null) {
		        delete rval['@vocab'];
		      } else if(!_isString(value)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; the value of "@vocab" in a ' +
		          '@context must be a string or null.',
		          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});
		      } else if(!_isAbsoluteIri(value) && api.processingMode(rval, 1.0)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; the value of "@vocab" in a ' +
		          '@context must be an absolute IRI.',
		          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});
		      } else {
		        const vocab = _expandIri(rval, value, {vocab: true, base: true},
		          undefined, undefined, options);
		        if(!_isAbsoluteIri(vocab)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'relative @vocab reference',
		                level: 'warning',
		                message: 'Relative @vocab reference found.',
		                details: {
		                  vocab
		                }
		              },
		              options
		            });
		          }
		        }
		        rval['@vocab'] = vocab;
		      }
		      defined.set('@vocab', true);
		    }

		    // handle @language
		    if('@language' in ctx) {
		      const value = ctx['@language'];
		      if(value === null) {
		        delete rval['@language'];
		      } else if(!_isString(value)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; the value of "@language" in a ' +
		          '@context must be a string or null.',
		          'jsonld.SyntaxError',
		          {code: 'invalid default language', context: ctx});
		      } else {
		        if(!value.match(REGEX_BCP47)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'invalid @language value',
		                level: 'warning',
		                message: '@language value must be valid BCP47.',
		                details: {
		                  language: value
		                }
		              },
		              options
		            });
		          }
		        }
		        rval['@language'] = value.toLowerCase();
		      }
		      defined.set('@language', true);
		    }

		    // handle @direction
		    if('@direction' in ctx) {
		      const value = ctx['@direction'];
		      if(activeCtx.processingMode === 'json-ld-1.0') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @direction not compatible with ' +
		          activeCtx.processingMode,
		          'jsonld.SyntaxError',
		          {code: 'invalid context member', context: ctx});
		      }
		      if(value === null) {
		        delete rval['@direction'];
		      } else if(value !== 'ltr' && value !== 'rtl') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; the value of "@direction" in a ' +
		          '@context must be null, "ltr", or "rtl".',
		          'jsonld.SyntaxError',
		          {code: 'invalid base direction', context: ctx});
		      } else {
		        rval['@direction'] = value;
		      }
		      defined.set('@direction', true);
		    }

		    // handle @propagate
		    // note: we've already extracted it, here we just do error checking
		    if('@propagate' in ctx) {
		      const value = ctx['@propagate'];
		      if(activeCtx.processingMode === 'json-ld-1.0') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @propagate not compatible with ' +
		          activeCtx.processingMode,
		          'jsonld.SyntaxError',
		          {code: 'invalid context entry', context: ctx});
		      }
		      if(typeof value !== 'boolean') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @propagate value must be a boolean.',
		          'jsonld.SyntaxError',
		          {code: 'invalid @propagate value', context: localCtx});
		      }
		      defined.set('@propagate', true);
		    }

		    // handle @import
		    if('@import' in ctx) {
		      const value = ctx['@import'];
		      if(activeCtx.processingMode === 'json-ld-1.0') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @import not compatible with ' +
		          activeCtx.processingMode,
		          'jsonld.SyntaxError',
		          {code: 'invalid context entry', context: ctx});
		      }
		      if(!_isString(value)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @import must be a string.',
		          'jsonld.SyntaxError',
		          {code: 'invalid @import value', context: localCtx});
		      }

		      // resolve contexts
		      const resolvedImport = await options.contextResolver.resolve({
		        activeCtx,
		        context: value,
		        documentLoader: options.documentLoader,
		        base: options.base
		      });
		      if(resolvedImport.length !== 1) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @import must reference a single context.',
		          'jsonld.SyntaxError',
		          {code: 'invalid remote context', context: localCtx});
		      }
		      const processedImport = resolvedImport[0].getProcessed(activeCtx);
		      if(processedImport) {
		        // Note: if the same context were used in this active context
		        // as a reference context, then processed_input might not
		        // be a dict.
		        ctx = processedImport;
		      } else {
		        const importCtx = resolvedImport[0].document;
		        if('@import' in importCtx) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax: ' +
		            'imported context must not include @import.',
		            'jsonld.SyntaxError',
		            {code: 'invalid context entry', context: localCtx});
		        }

		        // merge ctx into importCtx and replace rval with the result
		        for(const key in importCtx) {
		          if(!ctx.hasOwnProperty(key)) {
		            ctx[key] = importCtx[key];
		          }
		        }

		        // Note: this could potenially conflict if the import
		        // were used in the same active context as a referenced
		        // context and an import. In this case, we
		        // could override the cached result, but seems unlikely.
		        resolvedImport[0].setProcessed(activeCtx, ctx);
		      }

		      defined.set('@import', true);
		    }

		    // handle @protected; determine whether this sub-context is declaring
		    // all its terms to be "protected" (exceptions can be made on a
		    // per-definition basis)
		    defined.set('@protected', ctx['@protected'] || false);

		    // process all other keys
		    for(const key in ctx) {
		      api.createTermDefinition({
		        activeCtx: rval,
		        localCtx: ctx,
		        term: key,
		        defined,
		        options,
		        overrideProtected
		      });

		      if(_isObject(ctx[key]) && '@context' in ctx[key]) {
		        const keyCtx = ctx[key]['@context'];
		        let process = true;
		        if(_isString(keyCtx)) {
		          const url = prependBase(options.base, keyCtx);
		          // track processed contexts to avoid scoped context recursion
		          if(cycles.has(url)) {
		            process = false;
		          } else {
		            cycles.add(url);
		          }
		        }
		        // parse context to validate
		        if(process) {
		          try {
		            await api.process({
		              activeCtx: rval.clone(),
		              localCtx: ctx[key]['@context'],
		              overrideProtected: true,
		              options,
		              cycles
		            });
		          } catch(e) {
		            throw new JsonLdError(
		              'Invalid JSON-LD syntax; invalid scoped context.',
		              'jsonld.SyntaxError',
		              {
		                code: 'invalid scoped context',
		                context: ctx[key]['@context'],
		                term: key
		              });
		          }
		        }
		      }
		    }

		    // cache processed result
		    resolvedContext.setProcessed(activeCtx, {
		      context: rval,
		      events
		    });
		  }

		  return rval;
		};

		/**
		 * Creates a term definition during context processing.
		 *
		 * @param activeCtx the current active context.
		 * @param localCtx the local context being processed.
		 * @param term the term in the local context to define the mapping for.
		 * @param defined a map of defining/defined keys to detect cycles and prevent
		 *          double definitions.
		 * @param {Object} [options] - creation options.
		 * @param overrideProtected `false` allows protected terms to be modified.
		 */
		api.createTermDefinition = ({
		  activeCtx,
		  localCtx,
		  term,
		  defined,
		  options,
		  overrideProtected = false,
		}) => {
		  if(defined.has(term)) {
		    // term already defined
		    if(defined.get(term)) {
		      return;
		    }
		    // cycle detected
		    throw new JsonLdError(
		      'Cyclical context definition detected.',
		      'jsonld.CyclicalContext',
		      {code: 'cyclic IRI mapping', context: localCtx, term});
		  }

		  // now defining term
		  defined.set(term, false);

		  // get context term value
		  let value;
		  if(localCtx.hasOwnProperty(term)) {
		    value = localCtx[term];
		  }

		  if(term === '@type' &&
		     _isObject(value) &&
		     (value['@container'] || '@set') === '@set' &&
		     api.processingMode(activeCtx, 1.1)) {

		    const validKeys = ['@container', '@id', '@protected'];
		    const keys = Object.keys(value);
		    if(keys.length === 0 || keys.some(k => !validKeys.includes(k))) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; keywords cannot be overridden.',
		        'jsonld.SyntaxError',
		        {code: 'keyword redefinition', context: localCtx, term});
		    }
		  } else if(api.isKeyword(term)) {
		    throw new JsonLdError(
		      'Invalid JSON-LD syntax; keywords cannot be overridden.',
		      'jsonld.SyntaxError',
		      {code: 'keyword redefinition', context: localCtx, term});
		  } else if(term.match(REGEX_KEYWORD)) {
		    if(options.eventHandler) {
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code: 'reserved term',
		          level: 'warning',
		          message:
		            'Terms beginning with "@" are ' +
		            'reserved for future use and dropped.',
		          details: {
		            term
		          }
		        },
		        options
		      });
		    }
		    return;
		  } else if(term === '') {
		    throw new JsonLdError(
		      'Invalid JSON-LD syntax; a term cannot be an empty string.',
		      'jsonld.SyntaxError',
		      {code: 'invalid term definition', context: localCtx});
		  }

		  // keep reference to previous mapping for potential `@protected` check
		  const previousMapping = activeCtx.mappings.get(term);

		  // remove old mapping
		  if(activeCtx.mappings.has(term)) {
		    activeCtx.mappings.delete(term);
		  }

		  // convert short-hand value to object w/@id
		  let simpleTerm = false;
		  if(_isString(value) || value === null) {
		    simpleTerm = true;
		    value = {'@id': value};
		  }

		  if(!_isObject(value)) {
		    throw new JsonLdError(
		      'Invalid JSON-LD syntax; @context term values must be ' +
		      'strings or objects.',
		      'jsonld.SyntaxError',
		      {code: 'invalid term definition', context: localCtx});
		  }

		  // create new mapping
		  const mapping = {};
		  activeCtx.mappings.set(term, mapping);
		  mapping.reverse = false;

		  // make sure term definition only has expected keywords
		  const validKeys = ['@container', '@id', '@language', '@reverse', '@type'];

		  // JSON-LD 1.1 support
		  if(api.processingMode(activeCtx, 1.1)) {
		    validKeys.push(
		      '@context', '@direction', '@index', '@nest', '@prefix', '@protected');
		  }

		  for(const kw in value) {
		    if(!validKeys.includes(kw)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a term definition must not contain ' + kw,
		        'jsonld.SyntaxError',
		        {code: 'invalid term definition', context: localCtx});
		    }
		  }

		  // always compute whether term has a colon as an optimization for
		  // _compactIri
		  const colon = term.indexOf(':');
		  mapping._termHasColon = (colon > 0);

		  if('@reverse' in value) {
		    if('@id' in value) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a @reverse term definition must not ' +
		        'contain @id.', 'jsonld.SyntaxError',
		        {code: 'invalid reverse property', context: localCtx});
		    }
		    if('@nest' in value) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a @reverse term definition must not ' +
		        'contain @nest.', 'jsonld.SyntaxError',
		        {code: 'invalid reverse property', context: localCtx});
		    }
		    const reverse = value['@reverse'];
		    if(!_isString(reverse)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',
		        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
		    }

		    if(reverse.match(REGEX_KEYWORD)) {
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'reserved @reverse value',
		            level: 'warning',
		            message:
		              '@reverse values beginning with "@" are ' +
		              'reserved for future use and dropped.',
		            details: {
		              reverse
		            }
		          },
		          options
		        });
		      }
		      if(previousMapping) {
		        activeCtx.mappings.set(term, previousMapping);
		      } else {
		        activeCtx.mappings.delete(term);
		      }
		      return;
		    }

		    // expand and add @id mapping
		    const id = _expandIri(
		      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined,
		      options);
		    if(!_isAbsoluteIri(id)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +
		        'absolute IRI or a blank node identifier.',
		        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
		    }

		    mapping['@id'] = id;
		    mapping.reverse = true;
		  } else if('@id' in value) {
		    let id = value['@id'];
		    if(id && !_isString(id)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; a @context @id value must be an array ' +
		        'of strings or a string.',
		        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
		    }
		    if(id === null) {
		      // reserve a null term, which may be protected
		      mapping['@id'] = null;
		    } else if(!api.isKeyword(id) && id.match(REGEX_KEYWORD)) {
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'reserved @id value',
		            level: 'warning',
		            message:
		              '@id values beginning with "@" are ' +
		              'reserved for future use and dropped.',
		            details: {
		              id
		            }
		          },
		          options
		        });
		      }
		      if(previousMapping) {
		        activeCtx.mappings.set(term, previousMapping);
		      } else {
		        activeCtx.mappings.delete(term);
		      }
		      return;
		    } else if(id !== term) {
		      // expand and add @id mapping
		      id = _expandIri(
		        activeCtx, id, {vocab: true, base: false}, localCtx, defined, options);
		      if(!_isAbsoluteIri(id) && !api.isKeyword(id)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; a @context @id value must be an ' +
		          'absolute IRI, a blank node identifier, or a keyword.',
		          'jsonld.SyntaxError',
		          {code: 'invalid IRI mapping', context: localCtx});
		      }

		      // if term has the form of an IRI it must map the same
		      if(term.match(/(?::[^:])|\//)) {
		        const termDefined = new Map(defined).set(term, true);
		        const termIri = _expandIri(
		          activeCtx, term, {vocab: true, base: false},
		          localCtx, termDefined, options);
		        if(termIri !== id) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; term in form of IRI must ' +
		            'expand to definition.',
		            'jsonld.SyntaxError',
		            {code: 'invalid IRI mapping', context: localCtx});
		        }
		      }

		      mapping['@id'] = id;
		      // indicate if this term may be used as a compact IRI prefix
		      mapping._prefix = (simpleTerm &&
		        !mapping._termHasColon &&
		        id.match(/[:\/\?#\[\]@]$/) !== null);
		    }
		  }

		  if(!('@id' in mapping)) {
		    // see if the term has a prefix
		    if(mapping._termHasColon) {
		      const prefix = term.substr(0, colon);
		      if(localCtx.hasOwnProperty(prefix)) {
		        // define parent prefix
		        api.createTermDefinition({
		          activeCtx, localCtx, term: prefix, defined, options
		        });
		      }

		      if(activeCtx.mappings.has(prefix)) {
		        // set @id based on prefix parent
		        const suffix = term.substr(colon + 1);
		        mapping['@id'] = activeCtx.mappings.get(prefix)['@id'] + suffix;
		      } else {
		        // term is an absolute IRI
		        mapping['@id'] = term;
		      }
		    } else if(term === '@type') {
		      // Special case, were we've previously determined that container is @set
		      mapping['@id'] = term;
		    } else {
		      // non-IRIs *must* define @ids if @vocab is not available
		      if(!('@vocab' in activeCtx)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; @context terms must define an @id.',
		          'jsonld.SyntaxError',
		          {code: 'invalid IRI mapping', context: localCtx, term});
		      }
		      // prepend vocab to term
		      mapping['@id'] = activeCtx['@vocab'] + term;
		    }
		  }

		  // Handle term protection
		  if(value['@protected'] === true ||
		    (defined.get('@protected') === true && value['@protected'] !== false)) {
		    activeCtx.protected[term] = true;
		    mapping.protected = true;
		  }

		  // IRI mapping now defined
		  defined.set(term, true);

		  if('@type' in value) {
		    let type = value['@type'];
		    if(!_isString(type)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; an @context @type value must be a string.',
		        'jsonld.SyntaxError',
		        {code: 'invalid type mapping', context: localCtx});
		    }

		    if((type === '@json' || type === '@none')) {
		      if(api.processingMode(activeCtx, 1.0)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; an @context @type value must not be ' +
		          `"${type}" in JSON-LD 1.0 mode.`,
		          'jsonld.SyntaxError',
		          {code: 'invalid type mapping', context: localCtx});
		      }
		    } else if(type !== '@id' && type !== '@vocab') {
		      // expand @type to full IRI
		      type = _expandIri(
		        activeCtx, type, {vocab: true, base: false}, localCtx, defined,
		        options);
		      if(!_isAbsoluteIri(type)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; an @context @type value must be an ' +
		          'absolute IRI.',
		          'jsonld.SyntaxError',
		          {code: 'invalid type mapping', context: localCtx});
		      }
		      if(type.indexOf('_:') === 0) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; an @context @type value must be an IRI, ' +
		          'not a blank node identifier.',
		          'jsonld.SyntaxError',
		          {code: 'invalid type mapping', context: localCtx});
		      }
		    }

		    // add @type to mapping
		    mapping['@type'] = type;
		  }

		  if('@container' in value) {
		    // normalize container to an array form
		    const container = _isString(value['@container']) ?
		      [value['@container']] : (value['@container'] || []);
		    const validContainers = ['@list', '@set', '@index', '@language'];
		    let isValid = true;
		    const hasSet = container.includes('@set');

		    // JSON-LD 1.1 support
		    if(api.processingMode(activeCtx, 1.1)) {
		      validContainers.push('@graph', '@id', '@type');

		      // check container length
		      if(container.includes('@list')) {
		        if(container.length !== 1) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; @context @container with @list must ' +
		            'have no other values',
		            'jsonld.SyntaxError',
		            {code: 'invalid container mapping', context: localCtx});
		        }
		      } else if(container.includes('@graph')) {
		        if(container.some(key =>
		          key !== '@graph' && key !== '@id' && key !== '@index' &&
		          key !== '@set')) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; @context @container with @graph must ' +
		            'have no other values other than @id, @index, and @set',
		            'jsonld.SyntaxError',
		            {code: 'invalid container mapping', context: localCtx});
		        }
		      } else {
		        // otherwise, container may also include @set
		        isValid &= container.length <= (hasSet ? 2 : 1);
		      }

		      if(container.includes('@type')) {
		        // If mapping does not have an @type,
		        // set it to @id
		        mapping['@type'] = mapping['@type'] || '@id';

		        // type mapping must be either @id or @vocab
		        if(!['@id', '@vocab'].includes(mapping['@type'])) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; container: @type requires @type to be ' +
		            '@id or @vocab.',
		            'jsonld.SyntaxError',
		            {code: 'invalid type mapping', context: localCtx});
		        }
		      }
		    } else {
		      // in JSON-LD 1.0, container must not be an array (it must be a string,
		      // which is one of the validContainers)
		      isValid &= !_isArray(value['@container']);

		      // check container length
		      isValid &= container.length <= 1;
		    }

		    // check against valid containers
		    isValid &= container.every(c => validContainers.includes(c));

		    // @set not allowed with @list
		    isValid &= !(hasSet && container.includes('@list'));

		    if(!isValid) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context @container value must be ' +
		        'one of the following: ' + validContainers.join(', '),
		        'jsonld.SyntaxError',
		        {code: 'invalid container mapping', context: localCtx});
		    }

		    if(mapping.reverse &&
		      !container.every(c => ['@index', '@set'].includes(c))) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +
		        'type definition must be @index or @set.', 'jsonld.SyntaxError',
		        {code: 'invalid reverse property', context: localCtx});
		    }

		    // add @container to mapping
		    mapping['@container'] = container;
		  }

		  // property indexing
		  if('@index' in value) {
		    if(!('@container' in value) || !mapping['@container'].includes('@index')) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @index without @index in @container: ' +
		        `"${value['@index']}" on term "${term}".`, 'jsonld.SyntaxError',
		        {code: 'invalid term definition', context: localCtx});
		    }
		    if(!_isString(value['@index']) || value['@index'].indexOf('@') === 0) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @index must expand to an IRI: ' +
		        `"${value['@index']}" on term "${term}".`, 'jsonld.SyntaxError',
		        {code: 'invalid term definition', context: localCtx});
		    }
		    mapping['@index'] = value['@index'];
		  }

		  // scoped contexts
		  if('@context' in value) {
		    mapping['@context'] = value['@context'];
		  }

		  if('@language' in value && !('@type' in value)) {
		    let language = value['@language'];
		    if(language !== null && !_isString(language)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context @language value must be ' +
		        'a string or null.', 'jsonld.SyntaxError',
		        {code: 'invalid language mapping', context: localCtx});
		    }

		    // add @language to mapping
		    if(language !== null) {
		      language = language.toLowerCase();
		    }
		    mapping['@language'] = language;
		  }

		  // term may be used as a prefix
		  if('@prefix' in value) {
		    if(term.match(/:|\//)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context @prefix used on a compact IRI term',
		        'jsonld.SyntaxError',
		        {code: 'invalid term definition', context: localCtx});
		    }
		    if(api.isKeyword(mapping['@id'])) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; keywords may not be used as prefixes',
		        'jsonld.SyntaxError',
		        {code: 'invalid term definition', context: localCtx});
		    }
		    if(typeof value['@prefix'] === 'boolean') {
		      mapping._prefix = value['@prefix'] === true;
		    } else {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context value for @prefix must be boolean',
		        'jsonld.SyntaxError',
		        {code: 'invalid @prefix value', context: localCtx});
		    }
		  }

		  if('@direction' in value) {
		    const direction = value['@direction'];
		    if(direction !== null && direction !== 'ltr' && direction !== 'rtl') {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @direction value must be ' +
		        'null, "ltr", or "rtl".',
		        'jsonld.SyntaxError',
		        {code: 'invalid base direction', context: localCtx});
		    }
		    mapping['@direction'] = direction;
		  }

		  if('@nest' in value) {
		    const nest = value['@nest'];
		    if(!_isString(nest) || (nest !== '@nest' && nest.indexOf('@') === 0)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; @context @nest value must be ' +
		        'a string which is not a keyword other than @nest.',
		        'jsonld.SyntaxError',
		        {code: 'invalid @nest value', context: localCtx});
		    }
		    mapping['@nest'] = nest;
		  }

		  // disallow aliasing @context and @preserve
		  const id = mapping['@id'];
		  if(id === '@context' || id === '@preserve') {
		    throw new JsonLdError(
		      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',
		      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});
		  }

		  // Check for overriding protected terms
		  if(previousMapping && previousMapping.protected && !overrideProtected) {
		    // force new term to continue to be protected and see if the mappings would
		    // be equal
		    activeCtx.protected[term] = true;
		    mapping.protected = true;
		    if(!_deepCompare(previousMapping, mapping)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; tried to redefine a protected term.',
		        'jsonld.SyntaxError',
		        {code: 'protected term redefinition', context: localCtx, term});
		    }
		  }
		};

		/**
		 * Expands a string to a full IRI. The string may be a term, a prefix, a
		 * relative IRI, or an absolute IRI. The associated absolute IRI will be
		 * returned.
		 *
		 * @param activeCtx the current active context.
		 * @param value the string to expand.
		 * @param relativeTo options for how to resolve relative IRIs:
		 *          base: true to resolve against the base IRI, false not to.
		 *          vocab: true to concatenate after @vocab, false not to.
		 * @param {Object} [options] - processing options.
		 *
		 * @return the expanded value.
		 */
		api.expandIri = (activeCtx, value, relativeTo, options) => {
		  return _expandIri(activeCtx, value, relativeTo, undefined, undefined,
		    options);
		};

		/**
		 * Expands a string to a full IRI. The string may be a term, a prefix, a
		 * relative IRI, or an absolute IRI. The associated absolute IRI will be
		 * returned.
		 *
		 * @param activeCtx the current active context.
		 * @param value the string to expand.
		 * @param relativeTo options for how to resolve relative IRIs:
		 *          base: true to resolve against the base IRI, false not to.
		 *          vocab: true to concatenate after @vocab, false not to.
		 * @param localCtx the local context being processed (only given if called
		 *          during context processing).
		 * @param defined a map for tracking cycles in context definitions (only given
		 *          if called during context processing).
		 * @param {Object} [options] - processing options.
		 *
		 * @return the expanded value.
		 */
		function _expandIri(activeCtx, value, relativeTo, localCtx, defined, options) {
		  // already expanded
		  if(value === null || !_isString(value) || api.isKeyword(value)) {
		    return value;
		  }

		  // ignore non-keyword things that look like a keyword
		  if(value.match(REGEX_KEYWORD)) {
		    return null;
		  }

		  // define term dependency if not defined
		  if(localCtx && localCtx.hasOwnProperty(value) &&
		    defined.get(value) !== true) {
		    api.createTermDefinition({
		      activeCtx, localCtx, term: value, defined, options
		    });
		  }

		  relativeTo = relativeTo || {};
		  if(relativeTo.vocab) {
		    const mapping = activeCtx.mappings.get(value);

		    // value is explicitly ignored with a null mapping
		    if(mapping === null) {
		      return null;
		    }

		    if(_isObject(mapping) && '@id' in mapping) {
		      // value is a term
		      return mapping['@id'];
		    }
		  }

		  // split value into prefix:suffix
		  const colon = value.indexOf(':');
		  if(colon > 0) {
		    const prefix = value.substr(0, colon);
		    const suffix = value.substr(colon + 1);

		    // do not expand blank nodes (prefix of '_') or already-absolute
		    // IRIs (suffix of '//')
		    if(prefix === '_' || suffix.indexOf('//') === 0) {
		      return value;
		    }

		    // prefix dependency not defined, define it
		    if(localCtx && localCtx.hasOwnProperty(prefix)) {
		      api.createTermDefinition({
		        activeCtx, localCtx, term: prefix, defined, options
		      });
		    }

		    // use mapping if prefix is defined
		    const mapping = activeCtx.mappings.get(prefix);
		    if(mapping && mapping._prefix) {
		      return mapping['@id'] + suffix;
		    }

		    // already absolute IRI
		    if(_isAbsoluteIri(value)) {
		      return value;
		    }
		  }

		  // A flag that captures whether the iri being expanded is
		  // the value for an @type
		  //let typeExpansion = false;

		  //if(options !== undefined && options.typeExpansion !== undefined) {
		  //  typeExpansion = options.typeExpansion;
		  //}

		  if(relativeTo.vocab && '@vocab' in activeCtx) {
		    // prepend vocab
		    const prependedResult = activeCtx['@vocab'] + value;
		    // FIXME: needed? may be better as debug event.
		    /*
		    if(options && options.eventHandler) {
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code: 'prepending @vocab during expansion',
		          level: 'info',
		          message: 'Prepending @vocab during expansion.',
		          details: {
		            type: '@vocab',
		            vocab: activeCtx['@vocab'],
		            value,
		            result: prependedResult,
		            typeExpansion
		          }
		        },
		        options
		      });
		    }
		    */
		    // the null case preserves value as potentially relative
		    value = prependedResult;
		  } else if(relativeTo.base) {
		    // prepend base
		    let prependedResult;
		    let base;
		    if('@base' in activeCtx) {
		      if(activeCtx['@base']) {
		        base = prependBase(options.base, activeCtx['@base']);
		        prependedResult = prependBase(base, value);
		      } else {
		        base = activeCtx['@base'];
		        prependedResult = value;
		      }
		    } else {
		      base = options.base;
		      prependedResult = prependBase(options.base, value);
		    }
		    // FIXME: needed? may be better as debug event.
		    /*
		    if(options && options.eventHandler) {
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code: 'prepending @base during expansion',
		          level: 'info',
		          message: 'Prepending @base during expansion.',
		          details: {
		            type: '@base',
		            base,
		            value,
		            result: prependedResult,
		            typeExpansion
		          }
		        },
		        options
		      });
		    }
		    */
		    // the null case preserves value as potentially relative
		    value = prependedResult;
		  }

		  // FIXME: duplicate? needed? maybe just enable in a verbose debug mode
		  /*
		  if(!_isAbsoluteIri(value) && options && options.eventHandler) {
		    // emit event indicating a relative IRI was found, which can result in it
		    // being dropped when converting to other RDF representations
		    _handleEvent({
		      event: {
		        type: ['JsonLdEvent'],
		        code: 'relative IRI after expansion',
		        // FIXME: what level?
		        level: 'warning',
		        message: 'Relative IRI after expansion.',
		        details: {
		          relativeIri: value,
		          typeExpansion
		        }
		      },
		      options
		    });
		    // NOTE: relative reference events emitted at calling sites as needed
		  }
		  */

		  return value;
		}

		/**
		 * Gets the initial context.
		 *
		 * @param options the options to use:
		 *          [base] the document base IRI.
		 *
		 * @return the initial context.
		 */
		api.getInitialContext = options => {
		  const key = JSON.stringify({processingMode: options.processingMode});
		  const cached = INITIAL_CONTEXT_CACHE.get(key);
		  if(cached) {
		    return cached;
		  }

		  const initialContext = {
		    processingMode: options.processingMode,
		    mappings: new Map(),
		    inverse: null,
		    getInverse: _createInverseContext,
		    clone: _cloneActiveContext,
		    revertToPreviousContext: _revertToPreviousContext,
		    protected: {}
		  };
		  // TODO: consider using LRU cache instead
		  if(INITIAL_CONTEXT_CACHE.size === INITIAL_CONTEXT_CACHE_MAX_SIZE) {
		    // clear whole cache -- assumes scenario where the cache fills means
		    // the cache isn't being used very efficiently anyway
		    INITIAL_CONTEXT_CACHE.clear();
		  }
		  INITIAL_CONTEXT_CACHE.set(key, initialContext);
		  return initialContext;

		  /**
		   * Generates an inverse context for use in the compaction algorithm, if
		   * not already generated for the given active context.
		   *
		   * @return the inverse context.
		   */
		  function _createInverseContext() {
		    const activeCtx = this;

		    // lazily create inverse
		    if(activeCtx.inverse) {
		      return activeCtx.inverse;
		    }
		    const inverse = activeCtx.inverse = {};

		    // variables for building fast CURIE map
		    const fastCurieMap = activeCtx.fastCurieMap = {};
		    const irisToTerms = {};

		    // handle default language
		    const defaultLanguage = (activeCtx['@language'] || '@none').toLowerCase();

		    // handle default direction
		    const defaultDirection = activeCtx['@direction'];

		    // create term selections for each mapping in the context, ordered by
		    // shortest and then lexicographically least
		    const mappings = activeCtx.mappings;
		    const terms = [...mappings.keys()].sort(_compareShortestLeast);
		    for(const term of terms) {
		      const mapping = mappings.get(term);
		      if(mapping === null) {
		        continue;
		      }

		      let container = mapping['@container'] || '@none';
		      container = [].concat(container).sort().join('');

		      if(mapping['@id'] === null) {
		        continue;
		      }
		      // iterate over every IRI in the mapping
		      const ids = _asArray(mapping['@id']);
		      for(const iri of ids) {
		        let entry = inverse[iri];
		        const isKeyword = api.isKeyword(iri);

		        if(!entry) {
		          // initialize entry
		          inverse[iri] = entry = {};

		          if(!isKeyword && !mapping._termHasColon) {
		            // init IRI to term map and fast CURIE prefixes
		            irisToTerms[iri] = [term];
		            const fastCurieEntry = {iri, terms: irisToTerms[iri]};
		            if(iri[0] in fastCurieMap) {
		              fastCurieMap[iri[0]].push(fastCurieEntry);
		            } else {
		              fastCurieMap[iri[0]] = [fastCurieEntry];
		            }
		          }
		        } else if(!isKeyword && !mapping._termHasColon) {
		          // add IRI to term match
		          irisToTerms[iri].push(term);
		        }

		        // add new entry
		        if(!entry[container]) {
		          entry[container] = {
		            '@language': {},
		            '@type': {},
		            '@any': {}
		          };
		        }
		        entry = entry[container];
		        _addPreferredTerm(term, entry['@any'], '@none');

		        if(mapping.reverse) {
		          // term is preferred for values using @reverse
		          _addPreferredTerm(term, entry['@type'], '@reverse');
		        } else if(mapping['@type'] === '@none') {
		          _addPreferredTerm(term, entry['@any'], '@none');
		          _addPreferredTerm(term, entry['@language'], '@none');
		          _addPreferredTerm(term, entry['@type'], '@none');
		        } else if('@type' in mapping) {
		          // term is preferred for values using specific type
		          _addPreferredTerm(term, entry['@type'], mapping['@type']);
		        } else if('@language' in mapping && '@direction' in mapping) {
		          // term is preferred for values using specific language and direction
		          const language = mapping['@language'];
		          const direction = mapping['@direction'];
		          if(language && direction) {
		            _addPreferredTerm(term, entry['@language'],
		              `${language}_${direction}`.toLowerCase());
		          } else if(language) {
		            _addPreferredTerm(term, entry['@language'], language.toLowerCase());
		          } else if(direction) {
		            _addPreferredTerm(term, entry['@language'], `_${direction}`);
		          } else {
		            _addPreferredTerm(term, entry['@language'], '@null');
		          }
		        } else if('@language' in mapping) {
		          _addPreferredTerm(term, entry['@language'],
		            (mapping['@language'] || '@null').toLowerCase());
		        } else if('@direction' in mapping) {
		          if(mapping['@direction']) {
		            _addPreferredTerm(term, entry['@language'],
		              `_${mapping['@direction']}`);
		          } else {
		            _addPreferredTerm(term, entry['@language'], '@none');
		          }
		        } else if(defaultDirection) {
		          _addPreferredTerm(term, entry['@language'], `_${defaultDirection}`);
		          _addPreferredTerm(term, entry['@language'], '@none');
		          _addPreferredTerm(term, entry['@type'], '@none');
		        } else {
		          // add entries for no type and no language
		          _addPreferredTerm(term, entry['@language'], defaultLanguage);
		          _addPreferredTerm(term, entry['@language'], '@none');
		          _addPreferredTerm(term, entry['@type'], '@none');
		        }
		      }
		    }

		    // build fast CURIE map
		    for(const key in fastCurieMap) {
		      _buildIriMap(fastCurieMap, key, 1);
		    }

		    return inverse;
		  }

		  /**
		   * Runs a recursive algorithm to build a lookup map for quickly finding
		   * potential CURIEs.
		   *
		   * @param iriMap the map to build.
		   * @param key the current key in the map to work on.
		   * @param idx the index into the IRI to compare.
		   */
		  function _buildIriMap(iriMap, key, idx) {
		    const entries = iriMap[key];
		    const next = iriMap[key] = {};

		    let iri;
		    let letter;
		    for(const entry of entries) {
		      iri = entry.iri;
		      if(idx >= iri.length) {
		        letter = '';
		      } else {
		        letter = iri[idx];
		      }
		      if(letter in next) {
		        next[letter].push(entry);
		      } else {
		        next[letter] = [entry];
		      }
		    }

		    for(const key in next) {
		      if(key === '') {
		        continue;
		      }
		      _buildIriMap(next, key, idx + 1);
		    }
		  }

		  /**
		   * Adds the term for the given entry if not already added.
		   *
		   * @param term the term to add.
		   * @param entry the inverse context typeOrLanguage entry to add to.
		   * @param typeOrLanguageValue the key in the entry to add to.
		   */
		  function _addPreferredTerm(term, entry, typeOrLanguageValue) {
		    if(!entry.hasOwnProperty(typeOrLanguageValue)) {
		      entry[typeOrLanguageValue] = term;
		    }
		  }

		  /**
		   * Clones an active context, creating a child active context.
		   *
		   * @return a clone (child) of the active context.
		   */
		  function _cloneActiveContext() {
		    const child = {};
		    child.mappings = util.clone(this.mappings);
		    child.clone = this.clone;
		    child.inverse = null;
		    child.getInverse = this.getInverse;
		    child.protected = util.clone(this.protected);
		    if(this.previousContext) {
		      child.previousContext = this.previousContext.clone();
		    }
		    child.revertToPreviousContext = this.revertToPreviousContext;
		    if('@base' in this) {
		      child['@base'] = this['@base'];
		    }
		    if('@language' in this) {
		      child['@language'] = this['@language'];
		    }
		    if('@vocab' in this) {
		      child['@vocab'] = this['@vocab'];
		    }
		    return child;
		  }

		  /**
		   * Reverts any type-scoped context in this active context to the previous
		   * context.
		   */
		  function _revertToPreviousContext() {
		    if(!this.previousContext) {
		      return this;
		    }
		    return this.previousContext.clone();
		  }
		};

		/**
		 * Gets the value for the given active context key and type, null if none is
		 * set or undefined if none is set and type is '@context'.
		 *
		 * @param ctx the active context.
		 * @param key the context key.
		 * @param [type] the type of value to get (eg: '@id', '@type'), if not
		 *          specified gets the entire entry for a key, null if not found.
		 *
		 * @return the value, null, or undefined.
		 */
		api.getContextValue = (ctx, key, type) => {
		  // invalid key
		  if(key === null) {
		    if(type === '@context') {
		      return undefined;
		    }
		    return null;
		  }

		  // get specific entry information
		  if(ctx.mappings.has(key)) {
		    const entry = ctx.mappings.get(key);

		    if(_isUndefined(type)) {
		      // return whole entry
		      return entry;
		    }
		    if(entry.hasOwnProperty(type)) {
		      // return entry value for type
		      return entry[type];
		    }
		  }

		  // get default language
		  if(type === '@language' && type in ctx) {
		    return ctx[type];
		  }

		  // get default direction
		  if(type === '@direction' && type in ctx) {
		    return ctx[type];
		  }

		  if(type === '@context') {
		    return undefined;
		  }
		  return null;
		};

		/**
		 * Processing Mode check.
		 *
		 * @param activeCtx the current active context.
		 * @param version the string or numeric version to check.
		 *
		 * @return boolean.
		 */
		api.processingMode = (activeCtx, version) => {
		  if(version.toString() >= '1.1') {
		    return !activeCtx.processingMode ||
		      activeCtx.processingMode >= 'json-ld-' + version.toString();
		  } else {
		    return activeCtx.processingMode === 'json-ld-1.0';
		  }
		};

		/**
		 * Returns whether or not the given value is a keyword.
		 *
		 * @param v the value to check.
		 *
		 * @return true if the value is a keyword, false if not.
		 */
		api.isKeyword = v => {
		  if(!_isString(v) || v[0] !== '@') {
		    return false;
		  }
		  switch(v) {
		    case '@base':
		    case '@container':
		    case '@context':
		    case '@default':
		    case '@direction':
		    case '@embed':
		    case '@explicit':
		    case '@graph':
		    case '@id':
		    case '@included':
		    case '@index':
		    case '@json':
		    case '@language':
		    case '@list':
		    case '@nest':
		    case '@none':
		    case '@omitDefault':
		    case '@prefix':
		    case '@preserve':
		    case '@protected':
		    case '@requireAll':
		    case '@reverse':
		    case '@set':
		    case '@type':
		    case '@value':
		    case '@version':
		    case '@vocab':
		      return true;
		  }
		  return false;
		};

		function _deepCompare(x1, x2) {
		  // compare `null` or primitive types directly
		  if((!(x1 && typeof x1 === 'object')) ||
		     (!(x2 && typeof x2 === 'object'))) {
		    return x1 === x2;
		  }
		  // x1 and x2 are objects (also potentially arrays)
		  const x1Array = Array.isArray(x1);
		  if(x1Array !== Array.isArray(x2)) {
		    return false;
		  }
		  if(x1Array) {
		    if(x1.length !== x2.length) {
		      return false;
		    }
		    for(let i = 0; i < x1.length; ++i) {
		      if(!_deepCompare(x1[i], x2[i])) {
		        return false;
		      }
		    }
		    return true;
		  }
		  // x1 and x2 are non-array objects
		  const k1s = Object.keys(x1);
		  const k2s = Object.keys(x2);
		  if(k1s.length !== k2s.length) {
		    return false;
		  }
		  for(const k1 in x1) {
		    let v1 = x1[k1];
		    let v2 = x2[k1];
		    // special case: `@container` can be in any order
		    if(k1 === '@container') {
		      if(Array.isArray(v1) && Array.isArray(v2)) {
		        v1 = v1.slice().sort();
		        v2 = v2.slice().sort();
		      }
		    }
		    if(!_deepCompare(v1, v2)) {
		      return false;
		    }
		  }
		  return true;
		}
		return context;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var expand;
	var hasRequiredExpand;

	function requireExpand () {
		if (hasRequiredExpand) return expand;
		hasRequiredExpand = 1;

		const JsonLdError = requireJsonLdError();

		const {
		  isArray: _isArray,
		  isObject: _isObject,
		  isEmptyObject: _isEmptyObject,
		  isString: _isString,
		  isUndefined: _isUndefined
		} = requireTypes();

		const {
		  isList: _isList,
		  isValue: _isValue,
		  isGraph: _isGraph,
		  isSubject: _isSubject
		} = requireGraphTypes();

		const {
		  expandIri: _expandIri,
		  getContextValue: _getContextValue,
		  isKeyword: _isKeyword,
		  process: _processContext,
		  processingMode: _processingMode
		} = requireContext();

		const {
		  isAbsolute: _isAbsoluteIri
		} = requireUrl();

		const {
		  REGEX_BCP47,
		  REGEX_KEYWORD,
		  addValue: _addValue,
		  asArray: _asArray,
		  getValues: _getValues,
		  validateTypeValue: _validateTypeValue
		} = requireUtil();

		const {
		  handleEvent: _handleEvent
		} = requireEvents();

		const api = {};
		expand = api;

		/**
		 * Recursively expands an element using the given context. Any context in
		 * the element will be removed. All context URLs must have been retrieved
		 * before calling this method.
		 *
		 * @param activeCtx the context to use.
		 * @param activeProperty the property for the element, null for none.
		 * @param element the element to expand.
		 * @param options the expansion options.
		 * @param insideList true if the element is a list, false if not.
		 * @param insideIndex true if the element is inside an index container,
		 *          false if not.
		 * @param typeScopedContext an optional type-scoped active context for
		 *          expanding values of nodes that were expressed according to
		 *          a type-scoped context.
		 *
		 * @return a Promise that resolves to the expanded value.
		 */
		api.expand = async ({
		  activeCtx,
		  activeProperty = null,
		  element,
		  options = {},
		  insideList = false,
		  insideIndex = false,
		  typeScopedContext = null
		}) => {
		  // nothing to expand
		  if(element === null || element === undefined) {
		    return null;
		  }

		  // disable framing if activeProperty is @default
		  if(activeProperty === '@default') {
		    options = Object.assign({}, options, {isFrame: false});
		  }

		  if(!_isArray(element) && !_isObject(element)) {
		    // drop free-floating scalars that are not in lists
		    if(!insideList && (activeProperty === null ||
		      _expandIri(activeCtx, activeProperty, {vocab: true},
		        options) === '@graph')) {
		      // FIXME
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'free-floating scalar',
		            level: 'warning',
		            message: 'Dropping free-floating scalar not in a list.',
		            details: {
		              value: element
		              //activeProperty
		              //insideList
		            }
		          },
		          options
		        });
		      }
		      return null;
		    }

		    // expand element according to value expansion rules
		    return _expandValue({activeCtx, activeProperty, value: element, options});
		  }

		  // recursively expand array
		  if(_isArray(element)) {
		    let rval = [];
		    const container = _getContextValue(
		      activeCtx, activeProperty, '@container') || [];
		    insideList = insideList || container.includes('@list');
		    for(let i = 0; i < element.length; ++i) {
		      // expand element
		      let e = await api.expand({
		        activeCtx,
		        activeProperty,
		        element: element[i],
		        options,
		        insideIndex,
		        typeScopedContext
		      });
		      if(insideList && _isArray(e)) {
		        e = {'@list': e};
		      }

		      if(e === null) {
		        // FIXME: add debug event?
		        //unmappedValue: element[i],
		        //activeProperty,
		        //parent: element,
		        //index: i,
		        //expandedParent: rval,
		        //insideList

		        // NOTE: no-value events emitted at calling sites as needed
		        continue;
		      }

		      if(_isArray(e)) {
		        rval = rval.concat(e);
		      } else {
		        rval.push(e);
		      }
		    }
		    return rval;
		  }

		  // recursively expand object:

		  // first, expand the active property
		  const expandedActiveProperty = _expandIri(
		    activeCtx, activeProperty, {vocab: true}, options);

		  // Get any property-scoped context for activeProperty
		  const propertyScopedCtx =
		    _getContextValue(activeCtx, activeProperty, '@context');

		  // second, determine if any type-scoped context should be reverted; it
		  // should only be reverted when the following are all true:
		  // 1. `element` is not a value or subject reference
		  // 2. `insideIndex` is false
		  typeScopedContext = typeScopedContext ||
		    (activeCtx.previousContext ? activeCtx : null);
		  let keys = Object.keys(element).sort();
		  let mustRevert = !insideIndex;
		  if(mustRevert && typeScopedContext && keys.length <= 2 &&
		    !keys.includes('@context')) {
		    for(const key of keys) {
		      const expandedProperty = _expandIri(
		        typeScopedContext, key, {vocab: true}, options);
		      if(expandedProperty === '@value') {
		        // value found, ensure type-scoped context is used to expand it
		        mustRevert = false;
		        activeCtx = typeScopedContext;
		        break;
		      }
		      if(expandedProperty === '@id' && keys.length === 1) {
		        // subject reference found, do not revert
		        mustRevert = false;
		        break;
		      }
		    }
		  }

		  if(mustRevert) {
		    // revert type scoped context
		    activeCtx = activeCtx.revertToPreviousContext();
		  }

		  // apply property-scoped context after reverting term-scoped context
		  if(!_isUndefined(propertyScopedCtx)) {
		    activeCtx = await _processContext({
		      activeCtx,
		      localCtx: propertyScopedCtx,
		      propagate: true,
		      overrideProtected: true,
		      options
		    });
		  }

		  // if element has a context, process it
		  if('@context' in element) {
		    activeCtx = await _processContext(
		      {activeCtx, localCtx: element['@context'], options});
		  }

		  // set the type-scoped context to the context on input, for use later
		  typeScopedContext = activeCtx;

		  // Remember the first key found expanding to @type
		  let typeKey = null;

		  // look for scoped contexts on `@type`
		  for(const key of keys) {
		    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);
		    if(expandedProperty === '@type') {
		      // set scoped contexts from @type
		      // avoid sorting if possible
		      typeKey = typeKey || key;
		      const value = element[key];
		      const types =
		        Array.isArray(value) ?
		          (value.length > 1 ? value.slice().sort() : value) : [value];
		      for(const type of types) {
		        const ctx = _getContextValue(typeScopedContext, type, '@context');
		        if(!_isUndefined(ctx)) {
		          activeCtx = await _processContext({
		            activeCtx,
		            localCtx: ctx,
		            options,
		            propagate: false
		          });
		        }
		      }
		    }
		  }

		  // process each key and value in element, ignoring @nest content
		  let rval = {};
		  await _expandObject({
		    activeCtx,
		    activeProperty,
		    expandedActiveProperty,
		    element,
		    expandedParent: rval,
		    options,
		    insideList,
		    typeKey,
		    typeScopedContext
		  });

		  // get property count on expanded output
		  keys = Object.keys(rval);
		  let count = keys.length;

		  if('@value' in rval) {
		    // @value must only have @language or @type
		    if('@type' in rval && ('@language' in rval || '@direction' in rval)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; an element containing "@value" may not ' +
		        'contain both "@type" and either "@language" or "@direction".',
		        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});
		    }
		    let validCount = count - 1;
		    if('@type' in rval) {
		      validCount -= 1;
		    }
		    if('@index' in rval) {
		      validCount -= 1;
		    }
		    if('@language' in rval) {
		      validCount -= 1;
		    }
		    if('@direction' in rval) {
		      validCount -= 1;
		    }
		    if(validCount !== 0) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; an element containing "@value" may only ' +
		        'have an "@index" property and either "@type" ' +
		        'or either or both "@language" or "@direction".',
		        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});
		    }
		    const values = rval['@value'] === null ? [] : _asArray(rval['@value']);
		    const types = _getValues(rval, '@type');

		    // drop null @values
		    if(_processingMode(activeCtx, 1.1) && types.includes('@json') &&
		      types.length === 1) ; else if(values.length === 0) {
		      // FIXME
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'null @value value',
		            level: 'warning',
		            message: 'Dropping null @value value.',
		            details: {
		              value: rval
		            }
		          },
		          options
		        });
		      }
		      rval = null;
		    } else if(!values.every(v => (_isString(v) || _isEmptyObject(v))) &&
		      '@language' in rval) {
		      // if @language is present, @value must be a string
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; only strings may be language-tagged.',
		        'jsonld.SyntaxError',
		        {code: 'invalid language-tagged value', element: rval});
		    } else if(!types.every(t =>
		      (_isAbsoluteIri(t) && !(_isString(t) && t.indexOf('_:') === 0) ||
		      _isEmptyObject(t)))) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; an element containing "@value" and "@type" ' +
		        'must have an absolute IRI for the value of "@type".',
		        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});
		    }
		  } else if('@type' in rval && !_isArray(rval['@type'])) {
		    // convert @type to an array
		    rval['@type'] = [rval['@type']];
		  } else if('@set' in rval || '@list' in rval) {
		    // handle @set and @list
		    if(count > 1 && !(count === 2 && '@index' in rval)) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; if an element has the property "@set" ' +
		        'or "@list", then it can have at most one other property that is ' +
		        '"@index".', 'jsonld.SyntaxError',
		        {code: 'invalid set or list object', element: rval});
		    }
		    // optimize away @set
		    if('@set' in rval) {
		      rval = rval['@set'];
		      keys = Object.keys(rval);
		      count = keys.length;
		    }
		  } else if(count === 1 && '@language' in rval) {
		    // drop objects with only @language
		    // FIXME
		    if(options.eventHandler) {
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code: 'object with only @language',
		          level: 'warning',
		          message: 'Dropping object with only @language.',
		          details: {
		            value: rval
		          }
		        },
		        options
		      });
		    }
		    rval = null;
		  }

		  // drop certain top-level objects that do not occur in lists
		  if(_isObject(rval) &&
		    !options.keepFreeFloatingNodes && !insideList &&
		    (activeProperty === null ||
		      expandedActiveProperty === '@graph' ||
		      (_getContextValue(activeCtx, activeProperty, '@container') || [])
		        .includes('@graph')
		    )) {
		    // drop empty object, top-level @value/@list, or object with only @id
		    rval = _dropUnsafeObject({value: rval, count, options});
		  }

		  return rval;
		};

		/**
		 * Drop empty object, top-level @value/@list, or object with only @id
		 *
		 * @param value Value to check.
		 * @param count Number of properties in object.
		 * @param options The expansion options.
		 *
		 * @return null if dropped, value otherwise.
		 */
		function _dropUnsafeObject({
		  value,
		  count,
		  options
		}) {
		  if(count === 0 || '@value' in value || '@list' in value ||
		    (count === 1 && '@id' in value)) {
		    // FIXME
		    if(options.eventHandler) {
		      // FIXME: one event or diff event for empty, @v/@l, {@id}?
		      let code;
		      let message;
		      if(count === 0) {
		        code = 'empty object';
		        message = 'Dropping empty object.';
		      } else if('@value' in value) {
		        code = 'object with only @value';
		        message = 'Dropping object with only @value.';
		      } else if('@list' in value) {
		        code = 'object with only @list';
		        message = 'Dropping object with only @list.';
		      } else if(count === 1 && '@id' in value) {
		        code = 'object with only @id';
		        message = 'Dropping object with only @id.';
		      }
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code,
		          level: 'warning',
		          message,
		          details: {
		            value
		          }
		        },
		        options
		      });
		    }
		    return null;
		  }
		  return value;
		}

		/**
		 * Expand each key and value of element adding to result
		 *
		 * @param activeCtx the context to use.
		 * @param activeProperty the property for the element.
		 * @param expandedActiveProperty the expansion of activeProperty
		 * @param element the element to expand.
		 * @param expandedParent the expanded result into which to add values.
		 * @param options the expansion options.
		 * @param insideList true if the element is a list, false if not.
		 * @param typeKey first key found expanding to @type.
		 * @param typeScopedContext the context before reverting.
		 */
		async function _expandObject({
		  activeCtx,
		  activeProperty,
		  expandedActiveProperty,
		  element,
		  expandedParent,
		  options = {},
		  insideList,
		  typeKey,
		  typeScopedContext
		}) {
		  const keys = Object.keys(element).sort();
		  const nests = [];
		  let unexpandedValue;

		  // Figure out if this is the type for a JSON literal
		  const isJsonType = element[typeKey] &&
		    _expandIri(activeCtx,
		      (_isArray(element[typeKey]) ? element[typeKey][0] : element[typeKey]),
		      {vocab: true}, {
		        ...options,
		        typeExpansion: true
		      }) === '@json';

		  for(const key of keys) {
		    let value = element[key];
		    let expandedValue;

		    // skip @context
		    if(key === '@context') {
		      continue;
		    }

		    // expand property
		    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);

		    // drop non-absolute IRI keys that aren't keywords
		    if(expandedProperty === null ||
		      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'invalid property',
		            level: 'warning',
		            message: 'Dropping property that did not expand into an ' +
		              'absolute IRI or keyword.',
		            details: {
		              property: key,
		              expandedProperty
		            }
		          },
		          options
		        });
		      }
		      continue;
		    }

		    if(_isKeyword(expandedProperty)) {
		      if(expandedActiveProperty === '@reverse') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +
		          'property.', 'jsonld.SyntaxError',
		          {code: 'invalid reverse property map', value});
		      }
		      if(expandedProperty in expandedParent &&
		         expandedProperty !== '@included' &&
		         expandedProperty !== '@type') {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; colliding keywords detected.',
		          'jsonld.SyntaxError',
		          {code: 'colliding keywords', keyword: expandedProperty});
		      }
		    }

		    // syntax error if @id is not a string
		    if(expandedProperty === '@id') {
		      if(!_isString(value)) {
		        if(!options.isFrame) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; "@id" value must a string.',
		            'jsonld.SyntaxError', {code: 'invalid @id value', value});
		        }
		        if(_isObject(value)) {
		          // empty object is a wildcard
		          if(!_isEmptyObject(value)) {
		            throw new JsonLdError(
		              'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
		              'of strings, if framing',
		              'jsonld.SyntaxError', {code: 'invalid @id value', value});
		          }
		        } else if(_isArray(value)) {
		          if(!value.every(v => _isString(v))) {
		            throw new JsonLdError(
		              'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
		              'of strings, if framing',
		              'jsonld.SyntaxError', {code: 'invalid @id value', value});
		          }
		        } else {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
		            'of strings, if framing',
		            'jsonld.SyntaxError', {code: 'invalid @id value', value});
		        }
		      }

		      _addValue(
		        expandedParent, '@id',
		        _asArray(value).map(v => {
		          if(_isString(v)) {
		            const ve = _expandIri(activeCtx, v, {base: true}, options);
		            if(options.eventHandler) {
		              if(ve === null) {
		                // NOTE: spec edge case
		                // See https://github.com/w3c/json-ld-api/issues/480
		                if(v === null) {
		                  _handleEvent({
		                    event: {
		                      type: ['JsonLdEvent'],
		                      code: 'null @id value',
		                      level: 'warning',
		                      message: 'Null @id found.',
		                      details: {
		                        id: v
		                      }
		                    },
		                    options
		                  });
		                } else {
		                  // matched KEYWORD regex
		                  _handleEvent({
		                    event: {
		                      type: ['JsonLdEvent'],
		                      code: 'reserved @id value',
		                      level: 'warning',
		                      message: 'Reserved @id found.',
		                      details: {
		                        id: v
		                      }
		                    },
		                    options
		                  });
		                }
		              } else if(!_isAbsoluteIri(ve)) {
		                _handleEvent({
		                  event: {
		                    type: ['JsonLdEvent'],
		                    code: 'relative @id reference',
		                    level: 'warning',
		                    message: 'Relative @id reference found.',
		                    details: {
		                      id: v,
		                      expandedId: ve
		                    }
		                  },
		                  options
		                });
		              }
		            }
		            return ve;
		          }
		          return v;
		        }),
		        {propertyIsArray: options.isFrame});
		      continue;
		    }

		    if(expandedProperty === '@type') {
		      // if framing, can be a default object, but need to expand
		      // key to determine that
		      if(_isObject(value)) {
		        value = Object.fromEntries(Object.entries(value).map(([k, v]) => [
		          _expandIri(typeScopedContext, k, {vocab: true}),
		          _asArray(v).map(vv =>
		            _expandIri(typeScopedContext, vv, {base: true, vocab: true},
		              {...options, typeExpansion: true})
		          )
		        ]));
		      }
		      _validateTypeValue(value, options.isFrame);
		      _addValue(
		        expandedParent, '@type',
		        _asArray(value).map(v => {
		          if(_isString(v)) {
		            const ve = _expandIri(typeScopedContext, v,
		              {base: true, vocab: true},
		              {...options, typeExpansion: true});
		            if(ve !== '@json' && !_isAbsoluteIri(ve)) {
		              if(options.eventHandler) {
		                _handleEvent({
		                  event: {
		                    type: ['JsonLdEvent'],
		                    code: 'relative @type reference',
		                    level: 'warning',
		                    message: 'Relative @type reference found.',
		                    details: {
		                      type: v
		                    }
		                  },
		                  options
		                });
		              }
		            }
		            return ve;
		          }
		          return v;
		        }),
		        {propertyIsArray: !!options.isFrame});
		      continue;
		    }

		    // Included blocks are treated as an array of separate object nodes sharing
		    // the same referencing active_property.
		    // For 1.0, it is skipped as are other unknown keywords
		    if(expandedProperty === '@included' && _processingMode(activeCtx, 1.1)) {
		      const includedResult = _asArray(await api.expand({
		        activeCtx,
		        activeProperty,
		        element: value,
		        options
		      }));

		      // Expanded values must be node objects
		      if(!includedResult.every(v => _isSubject(v))) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; ' +
		          'values of @included must expand to node objects.',
		          'jsonld.SyntaxError', {code: 'invalid @included value', value});
		      }

		      _addValue(
		        expandedParent, '@included', includedResult, {propertyIsArray: true});
		      continue;
		    }

		    // @graph must be an array or an object
		    if(expandedProperty === '@graph' &&
		      !(_isObject(value) || _isArray(value))) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; "@graph" value must not be an ' +
		        'object or an array.',
		        'jsonld.SyntaxError', {code: 'invalid @graph value', value});
		    }

		    if(expandedProperty === '@value') {
		      // capture value for later
		      // "colliding keywords" check prevents this from being set twice
		      unexpandedValue = value;
		      if(isJsonType && _processingMode(activeCtx, 1.1)) {
		        // no coercion to array, and retain all values
		        expandedParent['@value'] = value;
		      } else {
		        _addValue(
		          expandedParent, '@value', value, {propertyIsArray: options.isFrame});
		      }
		      continue;
		    }

		    // @language must be a string
		    // it should match BCP47
		    if(expandedProperty === '@language') {
		      if(value === null) {
		        // drop null @language values, they expand as if they didn't exist
		        continue;
		      }
		      if(!_isString(value) && !options.isFrame) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; "@language" value must be a string.',
		          'jsonld.SyntaxError',
		          {code: 'invalid language-tagged string', value});
		      }
		      // ensure language value is lowercase
		      value = _asArray(value).map(v => _isString(v) ? v.toLowerCase() : v);

		      // ensure language tag matches BCP47
		      for(const language of value) {
		        if(_isString(language) && !language.match(REGEX_BCP47)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'invalid @language value',
		                level: 'warning',
		                message: '@language value must be valid BCP47.',
		                details: {
		                  language
		                }
		              },
		              options
		            });
		          }
		        }
		      }

		      _addValue(
		        expandedParent, '@language', value, {propertyIsArray: options.isFrame});
		      continue;
		    }

		    // @direction must be "ltr" or "rtl"
		    if(expandedProperty === '@direction') {
		      if(!_isString(value) && !options.isFrame) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; "@direction" value must be a string.',
		          'jsonld.SyntaxError',
		          {code: 'invalid base direction', value});
		      }

		      value = _asArray(value);

		      // ensure direction is "ltr" or "rtl"
		      for(const dir of value) {
		        if(_isString(dir) && dir !== 'ltr' && dir !== 'rtl') {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; "@direction" must be "ltr" or "rtl".',
		            'jsonld.SyntaxError',
		            {code: 'invalid base direction', value});
		        }
		      }

		      _addValue(
		        expandedParent, '@direction', value,
		        {propertyIsArray: options.isFrame});
		      continue;
		    }

		    // @index must be a string
		    if(expandedProperty === '@index') {
		      if(!_isString(value)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; "@index" value must be a string.',
		          'jsonld.SyntaxError',
		          {code: 'invalid @index value', value});
		      }
		      _addValue(expandedParent, '@index', value);
		      continue;
		    }

		    // @reverse must be an object
		    if(expandedProperty === '@reverse') {
		      if(!_isObject(value)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; "@reverse" value must be an object.',
		          'jsonld.SyntaxError', {code: 'invalid @reverse value', value});
		      }

		      expandedValue = await api.expand({
		        activeCtx,
		        activeProperty: '@reverse',
		        element: value,
		        options
		      });
		      // properties double-reversed
		      if('@reverse' in expandedValue) {
		        for(const property in expandedValue['@reverse']) {
		          _addValue(
		            expandedParent, property, expandedValue['@reverse'][property],
		            {propertyIsArray: true});
		        }
		      }

		      // FIXME: can this be merged with code below to simplify?
		      // merge in all reversed properties
		      let reverseMap = expandedParent['@reverse'] || null;
		      for(const property in expandedValue) {
		        if(property === '@reverse') {
		          continue;
		        }
		        if(reverseMap === null) {
		          reverseMap = expandedParent['@reverse'] = {};
		        }
		        _addValue(reverseMap, property, [], {propertyIsArray: true});
		        const items = expandedValue[property];
		        for(let ii = 0; ii < items.length; ++ii) {
		          const item = items[ii];
		          if(_isValue(item) || _isList(item)) {
		            throw new JsonLdError(
		              'Invalid JSON-LD syntax; "@reverse" value must not be a ' +
		              '@value or an @list.', 'jsonld.SyntaxError',
		              {code: 'invalid reverse property value', value: expandedValue});
		          }
		          _addValue(reverseMap, property, item, {propertyIsArray: true});
		        }
		      }

		      continue;
		    }

		    // nested keys
		    if(expandedProperty === '@nest') {
		      nests.push(key);
		      continue;
		    }

		    // use potential scoped context for key
		    let termCtx = activeCtx;
		    const ctx = _getContextValue(activeCtx, key, '@context');
		    if(!_isUndefined(ctx)) {
		      termCtx = await _processContext({
		        activeCtx,
		        localCtx: ctx,
		        propagate: true,
		        overrideProtected: true,
		        options
		      });
		    }

		    const container = _getContextValue(activeCtx, key, '@container') || [];

		    if(container.includes('@language') && _isObject(value)) {
		      const direction = _getContextValue(termCtx, key, '@direction');
		      // handle language map container (skip if value is not an object)
		      expandedValue = _expandLanguageMap(termCtx, value, direction, options);
		    } else if(container.includes('@index') && _isObject(value)) {
		      // handle index container (skip if value is not an object)
		      const asGraph = container.includes('@graph');
		      const indexKey = _getContextValue(termCtx, key, '@index') || '@index';
		      const propertyIndex = indexKey !== '@index' &&
		        _expandIri(activeCtx, indexKey, {vocab: true}, options);

		      expandedValue = await _expandIndexMap({
		        activeCtx: termCtx,
		        options,
		        activeProperty: key,
		        value,
		        asGraph,
		        indexKey,
		        propertyIndex
		      });
		    } else if(container.includes('@id') && _isObject(value)) {
		      // handle id container (skip if value is not an object)
		      const asGraph = container.includes('@graph');
		      expandedValue = await _expandIndexMap({
		        activeCtx: termCtx,
		        options,
		        activeProperty: key,
		        value,
		        asGraph,
		        indexKey: '@id'
		      });
		    } else if(container.includes('@type') && _isObject(value)) {
		      // handle type container (skip if value is not an object)
		      expandedValue = await _expandIndexMap({
		        // since container is `@type`, revert type scoped context when expanding
		        activeCtx: termCtx.revertToPreviousContext(),
		        options,
		        activeProperty: key,
		        value,
		        asGraph: false,
		        indexKey: '@type'
		      });
		    } else {
		      // recurse into @list or @set
		      const isList = expandedProperty === '@list';
		      if(isList || expandedProperty === '@set') {
		        let nextActiveProperty = activeProperty;
		        if(isList && expandedActiveProperty === '@graph') {
		          nextActiveProperty = null;
		        }
		        expandedValue = await api.expand({
		          activeCtx: termCtx,
		          activeProperty: nextActiveProperty,
		          element: value,
		          options,
		          insideList: isList
		        });
		      } else if(
		        _getContextValue(activeCtx, key, '@type') === '@json') {
		        expandedValue = {
		          '@type': '@json',
		          '@value': value
		        };
		      } else {
		        // recursively expand value with key as new active property
		        expandedValue = await api.expand({
		          activeCtx: termCtx,
		          activeProperty: key,
		          element: value,
		          options,
		          insideList: false
		        });
		      }
		    }

		    // drop null values if property is not @value
		    if(expandedValue === null && expandedProperty !== '@value') {
		      // FIXME: event?
		      //unmappedValue: value,
		      //expandedProperty,
		      //key,
		      continue;
		    }

		    // convert expanded value to @list if container specifies it
		    if(expandedProperty !== '@list' && !_isList(expandedValue) &&
		      container.includes('@list')) {
		      // ensure expanded value in @list is an array
		      expandedValue = {'@list': _asArray(expandedValue)};
		    }

		    // convert expanded value to @graph if container specifies it
		    // and value is not, itself, a graph
		    // index cases handled above
		    if(container.includes('@graph') &&
		      !container.some(key => key === '@id' || key === '@index')) {
		      // ensure expanded values are in an array
		      expandedValue = _asArray(expandedValue);
		      if(!options.isFrame) {
		        // drop items if needed
		        expandedValue = expandedValue.filter(v => {
		          const count = Object.keys(v).length;
		          return _dropUnsafeObject({value: v, count, options}) !== null;
		        });
		      }
		      if(expandedValue.length === 0) {
		        // all items dropped, skip adding and continue
		        continue;
		      }
		      // convert to graph
		      expandedValue = expandedValue.map(v => ({'@graph': _asArray(v)}));
		    }

		    // FIXME: can this be merged with code above to simplify?
		    // merge in reverse properties
		    if(termCtx.mappings.has(key) && termCtx.mappings.get(key).reverse) {
		      const reverseMap =
		        expandedParent['@reverse'] = expandedParent['@reverse'] || {};
		      expandedValue = _asArray(expandedValue);
		      for(let ii = 0; ii < expandedValue.length; ++ii) {
		        const item = expandedValue[ii];
		        if(_isValue(item) || _isList(item)) {
		          throw new JsonLdError(
		            'Invalid JSON-LD syntax; "@reverse" value must not be a ' +
		            '@value or an @list.', 'jsonld.SyntaxError',
		            {code: 'invalid reverse property value', value: expandedValue});
		        }
		        _addValue(reverseMap, expandedProperty, item, {propertyIsArray: true});
		      }
		      continue;
		    }

		    // add value for property
		    // special keywords handled above
		    _addValue(expandedParent, expandedProperty, expandedValue, {
		      propertyIsArray: true
		    });
		  }

		  // @value must not be an object or an array (unless framing) or if @type is
		  // @json
		  if('@value' in expandedParent) {
		    if(expandedParent['@type'] === '@json' && _processingMode(activeCtx, 1.1)) ; else if((_isObject(unexpandedValue) || _isArray(unexpandedValue)) &&
		      !options.isFrame) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; "@value" value must not be an ' +
		        'object or an array.',
		        'jsonld.SyntaxError',
		        {code: 'invalid value object value', value: unexpandedValue});
		    }
		  }

		  // expand each nested key
		  for(const key of nests) {
		    const nestedValues = _isArray(element[key]) ? element[key] : [element[key]];
		    for(const nv of nestedValues) {
		      if(!_isObject(nv) || Object.keys(nv).some(k =>
		        _expandIri(activeCtx, k, {vocab: true}, options) === '@value')) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; nested value must be a node object.',
		          'jsonld.SyntaxError',
		          {code: 'invalid @nest value', value: nv});
		      }
		      await _expandObject({
		        activeCtx,
		        activeProperty,
		        expandedActiveProperty,
		        element: nv,
		        expandedParent,
		        options,
		        insideList,
		        typeScopedContext,
		        typeKey
		      });
		    }
		  }
		}

		/**
		 * Expands the given value by using the coercion and keyword rules in the
		 * given context.
		 *
		 * @param activeCtx the active context to use.
		 * @param activeProperty the active property the value is associated with.
		 * @param value the value to expand.
		 * @param {Object} [options] - processing options.
		 *
		 * @return the expanded value.
		 */
		function _expandValue({activeCtx, activeProperty, value, options}) {
		  // nothing to expand
		  if(value === null || value === undefined) {
		    return null;
		  }

		  // special-case expand @id and @type (skips '@id' expansion)
		  const expandedProperty = _expandIri(
		    activeCtx, activeProperty, {vocab: true}, options);
		  if(expandedProperty === '@id') {
		    return _expandIri(activeCtx, value, {base: true}, options);
		  } else if(expandedProperty === '@type') {
		    return _expandIri(activeCtx, value, {vocab: true, base: true},
		      {...options, typeExpansion: true});
		  }

		  // get type definition from context
		  const type = _getContextValue(activeCtx, activeProperty, '@type');

		  // do @id expansion (automatic for @graph)
		  if((type === '@id' || expandedProperty === '@graph') && _isString(value)) {
		    const expandedValue = _expandIri(activeCtx, value, {base: true}, options);
		    // NOTE: handle spec edge case and avoid invalid {"@id": null}
		    if(expandedValue === null && value.match(REGEX_KEYWORD)) {
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'reserved @id value',
		            level: 'warning',
		            message: 'Reserved @id found.',
		            details: {
		              id: activeProperty
		            }
		          },
		          options
		        });
		      }
		    }
		    return {'@id': expandedValue};
		  }
		  // do @id expansion w/vocab
		  if(type === '@vocab' && _isString(value)) {
		    return {
		      '@id': _expandIri(activeCtx, value, {vocab: true, base: true}, options)
		    };
		  }

		  // do not expand keyword values
		  if(_isKeyword(expandedProperty)) {
		    return value;
		  }

		  const rval = {};

		  if(type && !['@id', '@vocab', '@none'].includes(type)) {
		    // other type
		    rval['@type'] = type;
		  } else if(_isString(value)) {
		    // check for language tagging for strings
		    const language = _getContextValue(activeCtx, activeProperty, '@language');
		    if(language !== null) {
		      rval['@language'] = language;
		    }
		    const direction = _getContextValue(activeCtx, activeProperty, '@direction');
		    if(direction !== null) {
		      rval['@direction'] = direction;
		    }
		  }
		  // do conversion of values that aren't basic JSON types to strings
		  if(!['boolean', 'number', 'string'].includes(typeof value)) {
		    value = value.toString();
		  }
		  rval['@value'] = value;

		  return rval;
		}

		/**
		 * Expands a language map.
		 *
		 * @param activeCtx the active context to use.
		 * @param languageMap the language map to expand.
		 * @param direction the direction to apply to values.
		 * @param {Object} [options] - processing options.
		 *
		 * @return the expanded language map.
		 */
		function _expandLanguageMap(activeCtx, languageMap, direction, options) {
		  const rval = [];
		  const keys = Object.keys(languageMap).sort();
		  for(const key of keys) {
		    const expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);
		    let val = languageMap[key];
		    if(!_isArray(val)) {
		      val = [val];
		    }
		    for(const item of val) {
		      if(item === null) {
		        // null values are allowed (8.5) but ignored (3.1)
		        continue;
		      }
		      if(!_isString(item)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; language map values must be strings.',
		          'jsonld.SyntaxError',
		          {code: 'invalid language map value', languageMap});
		      }
		      const val = {'@value': item};
		      if(expandedKey !== '@none') {
		        if(!key.match(REGEX_BCP47)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'invalid @language value',
		                level: 'warning',
		                message: '@language value must be valid BCP47.',
		                details: {
		                  language: key
		                }
		              },
		              options
		            });
		          }
		        }
		        val['@language'] = key.toLowerCase();
		      }
		      if(direction) {
		        val['@direction'] = direction;
		      }
		      rval.push(val);
		    }
		  }
		  return rval;
		}

		async function _expandIndexMap({
		  activeCtx, options, activeProperty, value, asGraph, indexKey, propertyIndex
		}) {
		  const rval = [];
		  const keys = Object.keys(value).sort();
		  const isTypeIndex = indexKey === '@type';
		  for(let key of keys) {
		    // if indexKey is @type, there may be a context defined for it
		    if(isTypeIndex) {
		      const ctx = _getContextValue(activeCtx, key, '@context');
		      if(!_isUndefined(ctx)) {
		        activeCtx = await _processContext({
		          activeCtx,
		          localCtx: ctx,
		          propagate: false,
		          options
		        });
		      }
		    }

		    let val = value[key];
		    if(!_isArray(val)) {
		      val = [val];
		    }

		    val = await api.expand({
		      activeCtx,
		      activeProperty,
		      element: val,
		      options,
		      insideList: false,
		      insideIndex: true
		    });

		    // expand for @type, but also for @none
		    let expandedKey;
		    if(propertyIndex) {
		      if(key === '@none') {
		        expandedKey = '@none';
		      } else {
		        expandedKey = _expandValue(
		          {activeCtx, activeProperty: indexKey, value: key, options});
		      }
		    } else {
		      expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);
		    }

		    if(indexKey === '@id') {
		      // expand document relative
		      key = _expandIri(activeCtx, key, {base: true}, options);
		    } else if(isTypeIndex) {
		      key = expandedKey;
		    }

		    for(let item of val) {
		      // If this is also a @graph container, turn items into graphs
		      if(asGraph && !_isGraph(item)) {
		        item = {'@graph': [item]};
		      }
		      if(indexKey === '@type') {
		        if(expandedKey === '@none') ; else if(item['@type']) {
		          item['@type'] = [key].concat(item['@type']);
		        } else {
		          item['@type'] = [key];
		        }
		      } else if(_isValue(item) &&
		        !['@language', '@type', '@index'].includes(indexKey)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; Attempt to add illegal key to value ' +
		          `object: "${indexKey}".`,
		          'jsonld.SyntaxError',
		          {code: 'invalid value object', value: item});
		      } else if(propertyIndex) {
		        // index is a property to be expanded, and values interpreted for that
		        // property
		        if(expandedKey !== '@none') {
		          // expand key as a value
		          _addValue(item, propertyIndex, expandedKey, {
		            propertyIsArray: true,
		            prependValue: true
		          });
		        }
		      } else if(expandedKey !== '@none' && !(indexKey in item)) {
		        item[indexKey] = key;
		      }
		      rval.push(item);
		    }
		  }
		  return rval;
		}
		return expand;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var nodeMap;
	var hasRequiredNodeMap;

	function requireNodeMap () {
		if (hasRequiredNodeMap) return nodeMap;
		hasRequiredNodeMap = 1;

		const {isKeyword} = requireContext();
		const graphTypes = requireGraphTypes();
		const types = requireTypes();
		const util = requireUtil();
		const JsonLdError = requireJsonLdError();

		const api = {};
		nodeMap = api;

		/**
		 * Creates a merged JSON-LD node map (node ID => node).
		 *
		 * @param input the expanded JSON-LD to create a node map of.
		 * @param [options] the options to use:
		 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
		 *
		 * @return the node map.
		 */
		api.createMergedNodeMap = (input, options) => {
		  options = options || {};

		  // produce a map of all subjects and name each bnode
		  const issuer = options.issuer || new util.IdentifierIssuer('_:b');
		  const graphs = {'@default': {}};
		  api.createNodeMap(input, graphs, '@default', issuer);

		  // add all non-default graphs to default graph
		  return api.mergeNodeMaps(graphs);
		};

		/**
		 * Recursively flattens the subjects in the given JSON-LD expanded input
		 * into a node map.
		 *
		 * @param input the JSON-LD expanded input.
		 * @param graphs a map of graph name to subject map.
		 * @param graph the name of the current graph.
		 * @param issuer the blank node identifier issuer.
		 * @param name the name assigned to the current input if it is a bnode.
		 * @param list the list to append to, null for none.
		 */
		api.createNodeMap = (input, graphs, graph, issuer, name, list) => {
		  // recurse through array
		  if(types.isArray(input)) {
		    for(const node of input) {
		      api.createNodeMap(node, graphs, graph, issuer, undefined, list);
		    }
		    return;
		  }

		  // add non-object to list
		  if(!types.isObject(input)) {
		    if(list) {
		      list.push(input);
		    }
		    return;
		  }

		  // add values to list
		  if(graphTypes.isValue(input)) {
		    if('@type' in input) {
		      let type = input['@type'];
		      // rename @type blank node
		      if(type.indexOf('_:') === 0) {
		        input['@type'] = type = issuer.getId(type);
		      }
		    }
		    if(list) {
		      list.push(input);
		    }
		    return;
		  } else if(list && graphTypes.isList(input)) {
		    const _list = [];
		    api.createNodeMap(input['@list'], graphs, graph, issuer, name, _list);
		    list.push({'@list': _list});
		    return;
		  }

		  // Note: At this point, input must be a subject.

		  // spec requires @type to be named first, so assign names early
		  if('@type' in input) {
		    const types = input['@type'];
		    for(const type of types) {
		      if(type.indexOf('_:') === 0) {
		        issuer.getId(type);
		      }
		    }
		  }

		  // get name for subject
		  if(types.isUndefined(name)) {
		    name = graphTypes.isBlankNode(input) ?
		      issuer.getId(input['@id']) : input['@id'];
		  }

		  // add subject reference to list
		  if(list) {
		    list.push({'@id': name});
		  }

		  // create new subject or merge into existing one
		  const subjects = graphs[graph];
		  const subject = subjects[name] = subjects[name] || {};
		  subject['@id'] = name;
		  const properties = Object.keys(input).sort();
		  for(let property of properties) {
		    // skip @id
		    if(property === '@id') {
		      continue;
		    }

		    // handle reverse properties
		    if(property === '@reverse') {
		      const referencedNode = {'@id': name};
		      const reverseMap = input['@reverse'];
		      for(const reverseProperty in reverseMap) {
		        const items = reverseMap[reverseProperty];
		        for(const item of items) {
		          let itemName = item['@id'];
		          if(graphTypes.isBlankNode(item)) {
		            itemName = issuer.getId(itemName);
		          }
		          api.createNodeMap(item, graphs, graph, issuer, itemName);
		          util.addValue(
		            subjects[itemName], reverseProperty, referencedNode,
		            {propertyIsArray: true, allowDuplicate: false});
		        }
		      }
		      continue;
		    }

		    // recurse into graph
		    if(property === '@graph') {
		      // add graph subjects map entry
		      if(!(name in graphs)) {
		        graphs[name] = {};
		      }
		      api.createNodeMap(input[property], graphs, name, issuer);
		      continue;
		    }

		    // recurse into included
		    if(property === '@included') {
		      api.createNodeMap(input[property], graphs, graph, issuer);
		      continue;
		    }

		    // copy non-@type keywords
		    if(property !== '@type' && isKeyword(property)) {
		      if(property === '@index' && property in subject &&
		        (input[property] !== subject[property] ||
		        input[property]['@id'] !== subject[property]['@id'])) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; conflicting @index property detected.',
		          'jsonld.SyntaxError',
		          {code: 'conflicting indexes', subject});
		      }
		      subject[property] = input[property];
		      continue;
		    }

		    // iterate over objects
		    const objects = input[property];

		    // if property is a bnode, assign it a new id
		    if(property.indexOf('_:') === 0) {
		      property = issuer.getId(property);
		    }

		    // ensure property is added for empty arrays
		    if(objects.length === 0) {
		      util.addValue(subject, property, [], {propertyIsArray: true});
		      continue;
		    }
		    for(let o of objects) {
		      if(property === '@type') {
		        // rename @type blank nodes
		        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;
		      }

		      // handle embedded subject or subject reference
		      if(graphTypes.isSubject(o) || graphTypes.isSubjectReference(o)) {
		        // skip null @id
		        if('@id' in o && !o['@id']) {
		          continue;
		        }

		        // relabel blank node @id
		        const id = graphTypes.isBlankNode(o) ?
		          issuer.getId(o['@id']) : o['@id'];

		        // add reference and recurse
		        util.addValue(
		          subject, property, {'@id': id},
		          {propertyIsArray: true, allowDuplicate: false});
		        api.createNodeMap(o, graphs, graph, issuer, id);
		      } else if(graphTypes.isValue(o)) {
		        util.addValue(
		          subject, property, o,
		          {propertyIsArray: true, allowDuplicate: false});
		      } else if(graphTypes.isList(o)) {
		        // handle @list
		        const _list = [];
		        api.createNodeMap(o['@list'], graphs, graph, issuer, name, _list);
		        o = {'@list': _list};
		        util.addValue(
		          subject, property, o,
		          {propertyIsArray: true, allowDuplicate: false});
		      } else {
		        // handle @value
		        api.createNodeMap(o, graphs, graph, issuer, name);
		        util.addValue(
		          subject, property, o, {propertyIsArray: true, allowDuplicate: false});
		      }
		    }
		  }
		};

		/**
		 * Merge separate named graphs into a single merged graph including
		 * all nodes from the default graph and named graphs.
		 *
		 * @param graphs a map of graph name to subject map.
		 *
		 * @return the merged graph map.
		 */
		api.mergeNodeMapGraphs = graphs => {
		  const merged = {};
		  for(const name of Object.keys(graphs).sort()) {
		    for(const id of Object.keys(graphs[name]).sort()) {
		      const node = graphs[name][id];
		      if(!(id in merged)) {
		        merged[id] = {'@id': id};
		      }
		      const mergedNode = merged[id];

		      for(const property of Object.keys(node).sort()) {
		        if(isKeyword(property) && property !== '@type') {
		          // copy keywords
		          mergedNode[property] = util.clone(node[property]);
		        } else {
		          // merge objects
		          for(const value of node[property]) {
		            util.addValue(
		              mergedNode, property, util.clone(value),
		              {propertyIsArray: true, allowDuplicate: false});
		          }
		        }
		      }
		    }
		  }

		  return merged;
		};

		api.mergeNodeMaps = graphs => {
		  // add all non-default graphs to default graph
		  const defaultGraph = graphs['@default'];
		  const graphNames = Object.keys(graphs).sort();
		  for(const graphName of graphNames) {
		    if(graphName === '@default') {
		      continue;
		    }
		    const nodeMap = graphs[graphName];
		    let subject = defaultGraph[graphName];
		    if(!subject) {
		      defaultGraph[graphName] = subject = {
		        '@id': graphName,
		        '@graph': []
		      };
		    } else if(!('@graph' in subject)) {
		      subject['@graph'] = [];
		    }
		    const graph = subject['@graph'];
		    for(const id of Object.keys(nodeMap).sort()) {
		      const node = nodeMap[id];
		      // only add full subjects
		      if(!graphTypes.isSubjectReference(node)) {
		        graph.push(node);
		      }
		    }
		  }
		  return defaultGraph;
		};
		return nodeMap;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var flatten;
	var hasRequiredFlatten;

	function requireFlatten () {
		if (hasRequiredFlatten) return flatten;
		hasRequiredFlatten = 1;

		const {
		  isSubjectReference: _isSubjectReference
		} = requireGraphTypes();

		const {
		  createMergedNodeMap: _createMergedNodeMap
		} = requireNodeMap();

		const api = {};
		flatten = api;

		/**
		 * Performs JSON-LD flattening.
		 *
		 * @param input the expanded JSON-LD to flatten.
		 *
		 * @return the flattened output.
		 */
		api.flatten = input => {
		  const defaultGraph = _createMergedNodeMap(input);

		  // produce flattened output
		  const flattened = [];
		  const keys = Object.keys(defaultGraph).sort();
		  for(let ki = 0; ki < keys.length; ++ki) {
		    const node = defaultGraph[keys[ki]];
		    // only add full subjects to top-level
		    if(!_isSubjectReference(node)) {
		      flattened.push(node);
		    }
		  }
		  return flattened;
		};
		return flatten;
	}

	/*
	 * Copyright (c) 2017-2023 Digital Bazaar, Inc. All rights reserved.
	 */

	var fromRdf;
	var hasRequiredFromRdf;

	function requireFromRdf () {
		if (hasRequiredFromRdf) return fromRdf;
		hasRequiredFromRdf = 1;

		const JsonLdError = requireJsonLdError();
		const graphTypes = requireGraphTypes();
		const types = requireTypes();

		const {
		  REGEX_BCP47,
		  addValue: _addValue
		} = requireUtil();

		const {
		  handleEvent: _handleEvent
		} = requireEvents();

		// constants
		const {
		  // RDF,
		  RDF_LIST,
		  RDF_FIRST,
		  RDF_REST,
		  RDF_NIL,
		  RDF_TYPE,
		  // RDF_PLAIN_LITERAL,
		  // RDF_XML_LITERAL,
		  RDF_JSON_LITERAL,
		  // RDF_OBJECT,
		  // RDF_LANGSTRING,

		  // XSD,
		  XSD_BOOLEAN,
		  XSD_DOUBLE,
		  XSD_INTEGER,
		  XSD_STRING,
		} = requireConstants();

		const api = {};
		fromRdf = api;

		/**
		 * Converts an RDF dataset to JSON-LD.
		 *
		 * @param dataset the RDF dataset.
		 * @param options the RDF serialization options.
		 *
		 * @return a Promise that resolves to the JSON-LD output.
		 */
		api.fromRDF = async (
		  dataset,
		  options
		) => {
		  const {
		    useRdfType = false,
		    useNativeTypes = false,
		    rdfDirection = null
		  } = options;
		  // FIXME: use Maps?
		  const defaultGraph = {};
		  const graphMap = {'@default': defaultGraph};
		  const referencedOnce = {};
		  if(rdfDirection) {
		    if(rdfDirection === 'compound-literal') {
		      throw new JsonLdError(
		        'Unsupported rdfDirection value.',
		        'jsonld.InvalidRdfDirection',
		        {value: rdfDirection});
		    } else if(rdfDirection !== 'i18n-datatype') {
		      throw new JsonLdError(
		        'Unknown rdfDirection value.',
		        'jsonld.InvalidRdfDirection',
		        {value: rdfDirection});
		    }
		  }

		  for(const quad of dataset) {
		    // TODO: change 'name' to 'graph'
		    const name = (quad.graph.termType === 'DefaultGraph') ?
		      '@default' : quad.graph.value;
		    if(!(name in graphMap)) {
		      graphMap[name] = {};
		    }
		    if(name !== '@default' && !(name in defaultGraph)) {
		      defaultGraph[name] = {'@id': name};
		    }

		    const nodeMap = graphMap[name];

		    // get subject, predicate, object
		    const s = quad.subject.value;
		    const p = quad.predicate.value;
		    const o = quad.object;

		    if(!(s in nodeMap)) {
		      nodeMap[s] = {'@id': s};
		    }
		    const node = nodeMap[s];

		    const objectIsNode = o.termType.endsWith('Node');
		    if(objectIsNode && !(o.value in nodeMap)) {
		      nodeMap[o.value] = {'@id': o.value};
		    }

		    if(p === RDF_TYPE && !useRdfType && objectIsNode) {
		      _addValue(node, '@type', o.value, {propertyIsArray: true});
		      continue;
		    }

		    const value = _RDFToObject(o, useNativeTypes, rdfDirection, options);
		    _addValue(node, p, value, {propertyIsArray: true});

		    // object may be an RDF list/partial list node but we can't know easily
		    // until all triples are read
		    if(objectIsNode) {
		      if(o.value === RDF_NIL) {
		        // track rdf:nil uniquely per graph
		        const object = nodeMap[o.value];
		        if(!('usages' in object)) {
		          object.usages = [];
		        }
		        object.usages.push({
		          node,
		          property: p,
		          value
		        });
		      } else if(o.value in referencedOnce) {
		        // object referenced more than once
		        referencedOnce[o.value] = false;
		      } else {
		        // keep track of single reference
		        referencedOnce[o.value] = {
		          node,
		          property: p,
		          value
		        };
		      }
		    }
		  }

		  /*
		  for(let name in dataset) {
		    const graph = dataset[name];
		    if(!(name in graphMap)) {
		      graphMap[name] = {};
		    }
		    if(name !== '@default' && !(name in defaultGraph)) {
		      defaultGraph[name] = {'@id': name};
		    }
		    const nodeMap = graphMap[name];
		    for(let ti = 0; ti < graph.length; ++ti) {
		      const triple = graph[ti];

		      // get subject, predicate, object
		      const s = triple.subject.value;
		      const p = triple.predicate.value;
		      const o = triple.object;

		      if(!(s in nodeMap)) {
		        nodeMap[s] = {'@id': s};
		      }
		      const node = nodeMap[s];

		      const objectIsId = (o.type === 'IRI' || o.type === 'blank node');
		      if(objectIsId && !(o.value in nodeMap)) {
		        nodeMap[o.value] = {'@id': o.value};
		      }

		      if(p === RDF_TYPE && !useRdfType && objectIsId) {
		        _addValue(node, '@type', o.value, {propertyIsArray: true});
		        continue;
		      }

		      const value = _RDFToObject(o, useNativeTypes);
		      _addValue(node, p, value, {propertyIsArray: true});

		      // object may be an RDF list/partial list node but we can't know easily
		      // until all triples are read
		      if(objectIsId) {
		        if(o.value === RDF_NIL) {
		          // track rdf:nil uniquely per graph
		          const object = nodeMap[o.value];
		          if(!('usages' in object)) {
		            object.usages = [];
		          }
		          object.usages.push({
		            node: node,
		            property: p,
		            value: value
		          });
		        } else if(o.value in referencedOnce) {
		          // object referenced more than once
		          referencedOnce[o.value] = false;
		        } else {
		          // keep track of single reference
		          referencedOnce[o.value] = {
		            node: node,
		            property: p,
		            value: value
		          };
		        }
		      }
		    }
		  }*/

		  // convert linked lists to @list arrays
		  for(const name in graphMap) {
		    const graphObject = graphMap[name];

		    // no @lists to be converted, continue
		    if(!(RDF_NIL in graphObject)) {
		      continue;
		    }

		    // iterate backwards through each RDF list
		    const nil = graphObject[RDF_NIL];
		    if(!nil.usages) {
		      continue;
		    }
		    for(let usage of nil.usages) {
		      let node = usage.node;
		      let property = usage.property;
		      let head = usage.value;
		      const list = [];
		      const listNodes = [];

		      // ensure node is a well-formed list node; it must:
		      // 1. Be referenced only once.
		      // 2. Have an array for rdf:first that has 1 item.
		      // 3. Have an array for rdf:rest that has 1 item.
		      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,
		      //   optionally, @type where the value is rdf:List.
		      let nodeKeyCount = Object.keys(node).length;
		      while(property === RDF_REST &&
		        types.isObject(referencedOnce[node['@id']]) &&
		        types.isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&
		        types.isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&
		        (nodeKeyCount === 3 ||
		          (nodeKeyCount === 4 && types.isArray(node['@type']) &&
		          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {
		        list.push(node[RDF_FIRST][0]);
		        listNodes.push(node['@id']);

		        // get next node, moving backwards through list
		        usage = referencedOnce[node['@id']];
		        node = usage.node;
		        property = usage.property;
		        head = usage.value;
		        nodeKeyCount = Object.keys(node).length;

		        // if node is not a blank node, then list head found
		        if(!graphTypes.isBlankNode(node)) {
		          break;
		        }
		      }

		      // transform list into @list object
		      delete head['@id'];
		      head['@list'] = list.reverse();
		      for(const listNode of listNodes) {
		        delete graphObject[listNode];
		      }
		    }

		    delete nil.usages;
		  }

		  const result = [];
		  const subjects = Object.keys(defaultGraph).sort();
		  for(const subject of subjects) {
		    const node = defaultGraph[subject];
		    if(subject in graphMap) {
		      const graph = node['@graph'] = [];
		      const graphObject = graphMap[subject];
		      const graphSubjects = Object.keys(graphObject).sort();
		      for(const graphSubject of graphSubjects) {
		        const node = graphObject[graphSubject];
		        // only add full subjects to top-level
		        if(!graphTypes.isSubjectReference(node)) {
		          graph.push(node);
		        }
		      }
		    }
		    // only add full subjects to top-level
		    if(!graphTypes.isSubjectReference(node)) {
		      result.push(node);
		    }
		  }

		  return result;
		};

		/**
		 * Converts an RDF triple object to a JSON-LD object.
		 *
		 * @param o the RDF triple object to convert.
		 * @param useNativeTypes true to output native types, false not to.
		 * @param rdfDirection text direction mode [null, i18n-datatype]
		 * @param options top level API options
		 *
		 * @return the JSON-LD object.
		 */
		function _RDFToObject(o, useNativeTypes, rdfDirection, options) {
		  // convert NamedNode/BlankNode object to JSON-LD
		  if(o.termType.endsWith('Node')) {
		    return {'@id': o.value};
		  }

		  // convert literal to JSON-LD
		  const rval = {'@value': o.value};

		  // add language
		  if(o.language) {
		    if(!o.language.match(REGEX_BCP47)) {
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'invalid @language value',
		            level: 'warning',
		            message: '@language value must be valid BCP47.',
		            details: {
		              language: o.language
		            }
		          },
		          options
		        });
		      }
		    }
		    rval['@language'] = o.language;
		  } else {
		    let type = o.datatype.value;
		    if(!type) {
		      type = XSD_STRING;
		    }
		    if(type === RDF_JSON_LITERAL) {
		      type = '@json';
		      try {
		        rval['@value'] = JSON.parse(rval['@value']);
		      } catch(e) {
		        throw new JsonLdError(
		          'JSON literal could not be parsed.',
		          'jsonld.InvalidJsonLiteral',
		          {code: 'invalid JSON literal', value: rval['@value'], cause: e});
		      }
		    }
		    // use native types for certain xsd types
		    if(useNativeTypes) {
		      if(type === XSD_BOOLEAN) {
		        if(rval['@value'] === 'true') {
		          rval['@value'] = true;
		        } else if(rval['@value'] === 'false') {
		          rval['@value'] = false;
		        }
		      } else if(types.isNumeric(rval['@value'])) {
		        if(type === XSD_INTEGER) {
		          const i = parseInt(rval['@value'], 10);
		          if(i.toFixed(0) === rval['@value']) {
		            rval['@value'] = i;
		          }
		        } else if(type === XSD_DOUBLE) {
		          rval['@value'] = parseFloat(rval['@value']);
		        }
		      }
		      // do not add native type
		      if(![XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING].includes(type)) {
		        rval['@type'] = type;
		      }
		    } else if(rdfDirection === 'i18n-datatype' &&
		      type.startsWith('https://www.w3.org/ns/i18n#')) {
		      const [, language, direction] = type.split(/[#_]/);
		      if(language.length > 0) {
		        rval['@language'] = language;
		        if(!language.match(REGEX_BCP47)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'invalid @language value',
		                level: 'warning',
		                message: '@language value must be valid BCP47.',
		                details: {
		                  language
		                }
		              },
		              options
		            });
		          }
		        }
		      }
		      rval['@direction'] = direction;
		    } else if(type !== XSD_STRING) {
		      rval['@type'] = type;
		    }
		  }

		  return rval;
		}
		return fromRdf;
	}

	/* jshint esversion: 6 */

	var canonicalize;
	var hasRequiredCanonicalize;

	function requireCanonicalize () {
		if (hasRequiredCanonicalize) return canonicalize;
		hasRequiredCanonicalize = 1;

		canonicalize = function serialize (object) {
		  if (object === null || typeof object !== 'object' || object.toJSON != null) {
		    return JSON.stringify(object);
		  }

		  if (Array.isArray(object)) {
		    return '[' + object.reduce((t, cv, ci) => {
		      const comma = ci === 0 ? '' : ',';
		      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;
		      return t + comma + serialize(value);
		    }, '') + ']';
		  }

		  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {
		    if (object[cv] === undefined ||
		        typeof object[cv] === 'symbol') {
		      return t;
		    }
		    const comma = t.length === 0 ? '' : ',';
		    return t + comma + serialize(cv) + ':' + serialize(object[cv]);
		  }, '') + '}';
		};
		return canonicalize;
	}

	/*
	 * Copyright (c) 2017-2023 Digital Bazaar, Inc. All rights reserved.
	 */

	var toRdf;
	var hasRequiredToRdf;

	function requireToRdf () {
		if (hasRequiredToRdf) return toRdf;
		hasRequiredToRdf = 1;

		const {createNodeMap} = requireNodeMap();
		const {isKeyword} = requireContext();
		const graphTypes = requireGraphTypes();
		const jsonCanonicalize = requireCanonicalize();
		const JsonLdError = requireJsonLdError();
		const types = requireTypes();
		const util = requireUtil();

		const {
		  handleEvent: _handleEvent
		} = requireEvents();

		const {
		  // RDF,
		  // RDF_LIST,
		  RDF_FIRST,
		  RDF_REST,
		  RDF_NIL,
		  RDF_TYPE,
		  // RDF_PLAIN_LITERAL,
		  // RDF_XML_LITERAL,
		  RDF_JSON_LITERAL,
		  // RDF_OBJECT,
		  RDF_LANGSTRING,

		  // XSD,
		  XSD_BOOLEAN,
		  XSD_DOUBLE,
		  XSD_INTEGER,
		  XSD_STRING,
		} = requireConstants();

		const {
		  isAbsolute: _isAbsoluteIri
		} = requireUrl();

		const api = {};
		toRdf = api;

		/**
		 * Outputs an RDF dataset for the expanded JSON-LD input.
		 *
		 * @param input the expanded JSON-LD input.
		 * @param options the RDF serialization options.
		 *
		 * @return the RDF dataset.
		 */
		api.toRDF = (input, options) => {
		  // create node map for default graph (and any named graphs)
		  const issuer = new util.IdentifierIssuer('_:b');
		  const nodeMap = {'@default': {}};
		  createNodeMap(input, nodeMap, '@default', issuer);

		  const dataset = [];
		  const graphNames = Object.keys(nodeMap).sort();
		  for(const graphName of graphNames) {
		    let graphTerm;
		    if(graphName === '@default') {
		      graphTerm = {termType: 'DefaultGraph', value: ''};
		    } else if(_isAbsoluteIri(graphName)) {
		      if(graphName.startsWith('_:')) {
		        graphTerm = {termType: 'BlankNode'};
		      } else {
		        graphTerm = {termType: 'NamedNode'};
		      }
		      graphTerm.value = graphName;
		    } else {
		      // skip relative IRIs (not valid RDF)
		      if(options.eventHandler) {
		        _handleEvent({
		          event: {
		            type: ['JsonLdEvent'],
		            code: 'relative graph reference',
		            level: 'warning',
		            message: 'Relative graph reference found.',
		            details: {
		              graph: graphName
		            }
		          },
		          options
		        });
		      }
		      continue;
		    }
		    _graphToRDF(dataset, nodeMap[graphName], graphTerm, issuer, options);
		  }

		  return dataset;
		};

		/**
		 * Adds RDF quads for a particular graph to the given dataset.
		 *
		 * @param dataset the dataset to append RDF quads to.
		 * @param graph the graph to create RDF quads for.
		 * @param graphTerm the graph term for each quad.
		 * @param issuer a IdentifierIssuer for assigning blank node names.
		 * @param options the RDF serialization options.
		 *
		 * @return the array of RDF triples for the given graph.
		 */
		function _graphToRDF(dataset, graph, graphTerm, issuer, options) {
		  const ids = Object.keys(graph).sort();
		  for(const id of ids) {
		    const node = graph[id];
		    const properties = Object.keys(node).sort();
		    for(let property of properties) {
		      const items = node[property];
		      if(property === '@type') {
		        property = RDF_TYPE;
		      } else if(isKeyword(property)) {
		        continue;
		      }

		      for(const item of items) {
		        // RDF subject
		        const subject = {
		          termType: id.startsWith('_:') ? 'BlankNode' : 'NamedNode',
		          value: id
		        };

		        // skip relative IRI subjects (not valid RDF)
		        if(!_isAbsoluteIri(id)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'relative subject reference',
		                level: 'warning',
		                message: 'Relative subject reference found.',
		                details: {
		                  subject: id
		                }
		              },
		              options
		            });
		          }
		          continue;
		        }

		        // RDF predicate
		        const predicate = {
		          termType: property.startsWith('_:') ? 'BlankNode' : 'NamedNode',
		          value: property
		        };

		        // skip relative IRI predicates (not valid RDF)
		        if(!_isAbsoluteIri(property)) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'relative predicate reference',
		                level: 'warning',
		                message: 'Relative predicate reference found.',
		                details: {
		                  predicate: property
		                }
		              },
		              options
		            });
		          }
		          continue;
		        }

		        // skip blank node predicates unless producing generalized RDF
		        if(predicate.termType === 'BlankNode' &&
		          !options.produceGeneralizedRdf) {
		          if(options.eventHandler) {
		            _handleEvent({
		              event: {
		                type: ['JsonLdEvent'],
		                code: 'blank node predicate',
		                level: 'warning',
		                message: 'Dropping blank node predicate.',
		                details: {
		                  // FIXME: add better issuer API to get reverse mapping
		                  property: issuer.getOldIds()
		                    .find(key => issuer.getId(key) === property)
		                }
		              },
		              options
		            });
		          }
		          continue;
		        }

		        // convert list, value or node object to triple
		        const object = _objectToRDF(
		          item, issuer, dataset, graphTerm, options.rdfDirection, options);
		        // skip null objects (they are relative IRIs)
		        if(object) {
		          dataset.push({
		            subject,
		            predicate,
		            object,
		            graph: graphTerm
		          });
		        }
		      }
		    }
		  }
		}

		/**
		 * Converts a @list value into linked list of blank node RDF quads
		 * (an RDF collection).
		 *
		 * @param list the @list value.
		 * @param issuer a IdentifierIssuer for assigning blank node names.
		 * @param dataset the array of quads to append to.
		 * @param graphTerm the graph term for each quad.
		 * @param options the RDF serialization options.
		 *
		 * @return the head of the list.
		 */
		function _listToRDF(list, issuer, dataset, graphTerm, rdfDirection, options) {
		  const first = {termType: 'NamedNode', value: RDF_FIRST};
		  const rest = {termType: 'NamedNode', value: RDF_REST};
		  const nil = {termType: 'NamedNode', value: RDF_NIL};

		  const last = list.pop();
		  // Result is the head of the list
		  const result = last ? {termType: 'BlankNode', value: issuer.getId()} : nil;
		  let subject = result;

		  for(const item of list) {
		    const object = _objectToRDF(
		      item, issuer, dataset, graphTerm, rdfDirection, options);
		    const next = {termType: 'BlankNode', value: issuer.getId()};
		    dataset.push({
		      subject,
		      predicate: first,
		      object,
		      graph: graphTerm
		    });
		    dataset.push({
		      subject,
		      predicate: rest,
		      object: next,
		      graph: graphTerm
		    });
		    subject = next;
		  }

		  // Tail of list
		  if(last) {
		    const object = _objectToRDF(
		      last, issuer, dataset, graphTerm, rdfDirection, options);
		    dataset.push({
		      subject,
		      predicate: first,
		      object,
		      graph: graphTerm
		    });
		    dataset.push({
		      subject,
		      predicate: rest,
		      object: nil,
		      graph: graphTerm
		    });
		  }

		  return result;
		}

		/**
		 * Converts a JSON-LD value object to an RDF literal or a JSON-LD string,
		 * node object to an RDF resource, or adds a list.
		 *
		 * @param item the JSON-LD value or node object.
		 * @param issuer a IdentifierIssuer for assigning blank node names.
		 * @param dataset the dataset to append RDF quads to.
		 * @param graphTerm the graph term for each quad.
		 * @param options the RDF serialization options.
		 *
		 * @return the RDF literal or RDF resource.
		 */
		function _objectToRDF(
		  item, issuer, dataset, graphTerm, rdfDirection, options
		) {
		  const object = {};

		  // convert value object to RDF
		  if(graphTypes.isValue(item)) {
		    object.termType = 'Literal';
		    object.value = undefined;
		    object.datatype = {
		      termType: 'NamedNode'
		    };
		    let value = item['@value'];
		    const datatype = item['@type'] || null;

		    // convert to XSD/JSON datatypes as appropriate
		    if(datatype === '@json') {
		      object.value = jsonCanonicalize(value);
		      object.datatype.value = RDF_JSON_LITERAL;
		    } else if(types.isBoolean(value)) {
		      object.value = value.toString();
		      object.datatype.value = datatype || XSD_BOOLEAN;
		    } else if(types.isDouble(value) || datatype === XSD_DOUBLE) {
		      if(!types.isDouble(value)) {
		        value = parseFloat(value);
		      }
		      // canonical double representation
		      object.value = value.toExponential(15).replace(/(\d)0*e\+?/, '$1E');
		      object.datatype.value = datatype || XSD_DOUBLE;
		    } else if(types.isNumber(value)) {
		      object.value = value.toFixed(0);
		      object.datatype.value = datatype || XSD_INTEGER;
		    } else if('@direction' in item && rdfDirection === 'i18n-datatype') {
		      const language = (item['@language'] || '').toLowerCase();
		      const direction = item['@direction'];
		      const datatype = `https://www.w3.org/ns/i18n#${language}_${direction}`;
		      object.datatype.value = datatype;
		      object.value = value;
		    } else if('@direction' in item && rdfDirection === 'compound-literal') {
		      throw new JsonLdError(
		        'Unsupported rdfDirection value.',
		        'jsonld.InvalidRdfDirection',
		        {value: rdfDirection});
		    } else if('@direction' in item && rdfDirection) {
		      throw new JsonLdError(
		        'Unknown rdfDirection value.',
		        'jsonld.InvalidRdfDirection',
		        {value: rdfDirection});
		    } else if('@language' in item) {
		      if('@direction' in item && !rdfDirection) {
		        if(options.eventHandler) {
		          // FIXME: only emit once?
		          _handleEvent({
		            event: {
		              type: ['JsonLdEvent'],
		              code: 'rdfDirection not set',
		              level: 'warning',
		              message: 'rdfDirection not set for @direction.',
		              details: {
		                object: object.value
		              }
		            },
		            options
		          });
		        }
		      }
		      object.value = value;
		      object.datatype.value = datatype || RDF_LANGSTRING;
		      object.language = item['@language'];
		    } else {
		      if('@direction' in item && !rdfDirection) {
		        if(options.eventHandler) {
		          // FIXME: only emit once?
		          _handleEvent({
		            event: {
		              type: ['JsonLdEvent'],
		              code: 'rdfDirection not set',
		              level: 'warning',
		              message: 'rdfDirection not set for @direction.',
		              details: {
		                object: object.value
		              }
		            },
		            options
		          });
		        }
		      }
		      object.value = value;
		      object.datatype.value = datatype || XSD_STRING;
		    }
		  } else if(graphTypes.isList(item)) {
		    const _list = _listToRDF(
		      item['@list'], issuer, dataset, graphTerm, rdfDirection, options);
		    object.termType = _list.termType;
		    object.value = _list.value;
		  } else {
		    // convert string/node object to RDF
		    const id = types.isObject(item) ? item['@id'] : item;
		    object.termType = id.startsWith('_:') ? 'BlankNode' : 'NamedNode';
		    object.value = id;
		  }

		  // skip relative IRIs, not valid RDF
		  if(object.termType === 'NamedNode' && !_isAbsoluteIri(object.value)) {
		    if(options.eventHandler) {
		      _handleEvent({
		        event: {
		          type: ['JsonLdEvent'],
		          code: 'relative object reference',
		          level: 'warning',
		          message: 'Relative object reference found.',
		          details: {
		            object: object.value
		          }
		        },
		        options
		      });
		    }
		    return null;
		  }

		  return object;
		}
		return toRdf;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var frame;
	var hasRequiredFrame;

	function requireFrame () {
		if (hasRequiredFrame) return frame;
		hasRequiredFrame = 1;

		const {isKeyword} = requireContext();
		const graphTypes = requireGraphTypes();
		const types = requireTypes();
		const util = requireUtil();
		const url = requireUrl();
		const JsonLdError = requireJsonLdError();
		const {
		  createNodeMap: _createNodeMap,
		  mergeNodeMapGraphs: _mergeNodeMapGraphs
		} = requireNodeMap();

		const api = {};
		frame = api;

		/**
		 * Performs JSON-LD `merged` framing.
		 *
		 * @param input the expanded JSON-LD to frame.
		 * @param frame the expanded JSON-LD frame to use.
		 * @param options the framing options.
		 *
		 * @return the framed output.
		 */
		api.frameMergedOrDefault = (input, frame, options) => {
		  // create framing state
		  const state = {
		    options,
		    embedded: false,
		    graph: '@default',
		    graphMap: {'@default': {}},
		    subjectStack: [],
		    link: {},
		    bnodeMap: {}
		  };

		  // produce a map of all graphs and name each bnode
		  // FIXME: currently uses subjects from @merged graph only
		  const issuer = new util.IdentifierIssuer('_:b');
		  _createNodeMap(input, state.graphMap, '@default', issuer);
		  if(options.merged) {
		    state.graphMap['@merged'] = _mergeNodeMapGraphs(state.graphMap);
		    state.graph = '@merged';
		  }
		  state.subjects = state.graphMap[state.graph];

		  // frame the subjects
		  const framed = [];
		  api.frame(state, Object.keys(state.subjects).sort(), frame, framed);

		  // If pruning blank nodes, find those to prune
		  if(options.pruneBlankNodeIdentifiers) {
		    // remove all blank nodes appearing only once, done in compaction
		    options.bnodesToClear =
		      Object.keys(state.bnodeMap).filter(id => state.bnodeMap[id].length === 1);
		  }

		  // remove @preserve from results
		  options.link = {};
		  return _cleanupPreserve(framed, options);
		};

		/**
		 * Frames subjects according to the given frame.
		 *
		 * @param state the current framing state.
		 * @param subjects the subjects to filter.
		 * @param frame the frame.
		 * @param parent the parent subject or top-level array.
		 * @param property the parent property, initialized to null.
		 */
		api.frame = (state, subjects, frame, parent, property = null) => {
		  // validate the frame
		  _validateFrame(frame);
		  frame = frame[0];

		  // get flags for current frame
		  const options = state.options;
		  const flags = {
		    embed: _getFrameFlag(frame, options, 'embed'),
		    explicit: _getFrameFlag(frame, options, 'explicit'),
		    requireAll: _getFrameFlag(frame, options, 'requireAll')
		  };

		  // get link for current graph
		  if(!state.link.hasOwnProperty(state.graph)) {
		    state.link[state.graph] = {};
		  }
		  const link = state.link[state.graph];

		  // filter out subjects that match the frame
		  const matches = _filterSubjects(state, subjects, frame, flags);

		  // add matches to output
		  const ids = Object.keys(matches).sort();
		  for(const id of ids) {
		    const subject = matches[id];

		    /* Note: In order to treat each top-level match as a compartmentalized
		    result, clear the unique embedded subjects map when the property is null,
		    which only occurs at the top-level. */
		    if(property === null) {
		      state.uniqueEmbeds = {[state.graph]: {}};
		    } else {
		      state.uniqueEmbeds[state.graph] = state.uniqueEmbeds[state.graph] || {};
		    }

		    if(flags.embed === '@link' && id in link) {
		      // TODO: may want to also match an existing linked subject against
		      // the current frame ... so different frames could produce different
		      // subjects that are only shared in-memory when the frames are the same

		      // add existing linked subject
		      _addFrameOutput(parent, property, link[id]);
		      continue;
		    }

		    // start output for subject
		    const output = {'@id': id};
		    if(id.indexOf('_:') === 0) {
		      util.addValue(state.bnodeMap, id, output, {propertyIsArray: true});
		    }
		    link[id] = output;

		    // validate @embed
		    if((flags.embed === '@first' || flags.embed === '@last') && state.is11) {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; invalid value of @embed.',
		        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});
		    }

		    if(!state.embedded && state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {
		      // skip adding this node object to the top level, as it was
		      // already included in another node object
		      continue;
		    }

		    // if embed is @never or if a circular reference would be created by an
		    // embed, the subject cannot be embedded, just add the reference;
		    // note that a circular reference won't occur when the embed flag is
		    // `@link` as the above check will short-circuit before reaching this point
		    if(state.embedded &&
		      (flags.embed === '@never' ||
		      _createsCircularReference(subject, state.graph, state.subjectStack))) {
		      _addFrameOutput(parent, property, output);
		      continue;
		    }

		    // if only the first (or once) should be embedded
		    if(state.embedded &&
		       (flags.embed == '@first' || flags.embed == '@once') &&
		       state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {
		      _addFrameOutput(parent, property, output);
		      continue;
		    }

		    // if only the last match should be embedded
		    if(flags.embed === '@last') {
		      // remove any existing embed
		      if(id in state.uniqueEmbeds[state.graph]) {
		        _removeEmbed(state, id);
		      }
		    }

		    state.uniqueEmbeds[state.graph][id] = {parent, property};

		    // push matching subject onto stack to enable circular embed checks
		    state.subjectStack.push({subject, graph: state.graph});

		    // subject is also the name of a graph
		    if(id in state.graphMap) {
		      let recurse = false;
		      let subframe = null;
		      if(!('@graph' in frame)) {
		        recurse = state.graph !== '@merged';
		        subframe = {};
		      } else {
		        subframe = frame['@graph'][0];
		        recurse = !(id === '@merged' || id === '@default');
		        if(!types.isObject(subframe)) {
		          subframe = {};
		        }
		      }

		      if(recurse) {
		        // recurse into graph
		        api.frame(
		          {...state, graph: id, embedded: false},
		          Object.keys(state.graphMap[id]).sort(), [subframe], output, '@graph');
		      }
		    }

		    // if frame has @included, recurse over its sub-frame
		    if('@included' in frame) {
		      api.frame(
		        {...state, embedded: false},
		        subjects, frame['@included'], output, '@included');
		    }

		    // iterate over subject properties
		    for(const prop of Object.keys(subject).sort()) {
		      // copy keywords to output
		      if(isKeyword(prop)) {
		        output[prop] = util.clone(subject[prop]);

		        if(prop === '@type') {
		          // count bnode values of @type
		          for(const type of subject['@type']) {
		            if(type.indexOf('_:') === 0) {
		              util.addValue(
		                state.bnodeMap, type, output, {propertyIsArray: true});
		            }
		          }
		        }
		        continue;
		      }

		      // explicit is on and property isn't in the frame, skip processing
		      if(flags.explicit && !(prop in frame)) {
		        continue;
		      }

		      // add objects
		      for(const o of subject[prop]) {
		        const subframe = (prop in frame ?
		          frame[prop] : _createImplicitFrame(flags));

		        // recurse into list
		        if(graphTypes.isList(o)) {
		          const subframe =
		            (frame[prop] && frame[prop][0] && frame[prop][0]['@list']) ?
		              frame[prop][0]['@list'] :
		              _createImplicitFrame(flags);

		          // add empty list
		          const list = {'@list': []};
		          _addFrameOutput(output, prop, list);

		          // add list objects
		          const src = o['@list'];
		          for(const oo of src) {
		            if(graphTypes.isSubjectReference(oo)) {
		              // recurse into subject reference
		              api.frame(
		                {...state, embedded: true},
		                [oo['@id']], subframe, list, '@list');
		            } else {
		              // include other values automatically
		              _addFrameOutput(list, '@list', util.clone(oo));
		            }
		          }
		        } else if(graphTypes.isSubjectReference(o)) {
		          // recurse into subject reference
		          api.frame(
		            {...state, embedded: true},
		            [o['@id']], subframe, output, prop);
		        } else if(_valueMatch(subframe[0], o)) {
		          // include other values, if they match
		          _addFrameOutput(output, prop, util.clone(o));
		        }
		      }
		    }

		    // handle defaults
		    for(const prop of Object.keys(frame).sort()) {
		      // skip keywords
		      if(prop === '@type') {
		        if(!types.isObject(frame[prop][0]) ||
		           !('@default' in frame[prop][0])) {
		          continue;
		        }
		        // allow through default types
		      } else if(isKeyword(prop)) {
		        continue;
		      }

		      // if omit default is off, then include default values for properties
		      // that appear in the next frame but are not in the matching subject
		      const next = frame[prop][0] || {};
		      const omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');
		      if(!omitDefaultOn && !(prop in output)) {
		        let preserve = '@null';
		        if('@default' in next) {
		          preserve = util.clone(next['@default']);
		        }
		        if(!types.isArray(preserve)) {
		          preserve = [preserve];
		        }
		        output[prop] = [{'@preserve': preserve}];
		      }
		    }

		    // if embed reverse values by finding nodes having this subject as a value
		    // of the associated property
		    for(const reverseProp of Object.keys(frame['@reverse'] || {}).sort()) {
		      const subframe = frame['@reverse'][reverseProp];
		      for(const subject of Object.keys(state.subjects)) {
		        const nodeValues =
		          util.getValues(state.subjects[subject], reverseProp);
		        if(nodeValues.some(v => v['@id'] === id)) {
		          // node has property referencing this subject, recurse
		          output['@reverse'] = output['@reverse'] || {};
		          util.addValue(
		            output['@reverse'], reverseProp, [], {propertyIsArray: true});
		          api.frame(
		            {...state, embedded: true},
		            [subject], subframe, output['@reverse'][reverseProp],
		            property);
		        }
		      }
		    }

		    // add output to parent
		    _addFrameOutput(parent, property, output);

		    // pop matching subject from circular ref-checking stack
		    state.subjectStack.pop();
		  }
		};

		/**
		 * Replace `@null` with `null`, removing it from arrays.
		 *
		 * @param input the framed, compacted output.
		 * @param options the framing options used.
		 *
		 * @return the resulting output.
		 */
		api.cleanupNull = (input, options) => {
		  // recurse through arrays
		  if(types.isArray(input)) {
		    const noNulls = input.map(v => api.cleanupNull(v, options));
		    return noNulls.filter(v => v); // removes nulls from array
		  }

		  if(input === '@null') {
		    return null;
		  }

		  if(types.isObject(input)) {
		    // handle in-memory linked nodes
		    if('@id' in input) {
		      const id = input['@id'];
		      if(options.link.hasOwnProperty(id)) {
		        const idx = options.link[id].indexOf(input);
		        if(idx !== -1) {
		          // already visited
		          return options.link[id][idx];
		        }
		        // prevent circular visitation
		        options.link[id].push(input);
		      } else {
		        // prevent circular visitation
		        options.link[id] = [input];
		      }
		    }

		    for(const key in input) {
		      input[key] = api.cleanupNull(input[key], options);
		    }
		  }
		  return input;
		};

		/**
		 * Creates an implicit frame when recursing through subject matches. If
		 * a frame doesn't have an explicit frame for a particular property, then
		 * a wildcard child frame will be created that uses the same flags that the
		 * parent frame used.
		 *
		 * @param flags the current framing flags.
		 *
		 * @return the implicit frame.
		 */
		function _createImplicitFrame(flags) {
		  const frame = {};
		  for(const key in flags) {
		    if(flags[key] !== undefined) {
		      frame['@' + key] = [flags[key]];
		    }
		  }
		  return [frame];
		}

		/**
		 * Checks the current subject stack to see if embedding the given subject
		 * would cause a circular reference.
		 *
		 * @param subjectToEmbed the subject to embed.
		 * @param graph the graph the subject to embed is in.
		 * @param subjectStack the current stack of subjects.
		 *
		 * @return true if a circular reference would be created, false if not.
		 */
		function _createsCircularReference(subjectToEmbed, graph, subjectStack) {
		  for(let i = subjectStack.length - 1; i >= 0; --i) {
		    const subject = subjectStack[i];
		    if(subject.graph === graph &&
		      subject.subject['@id'] === subjectToEmbed['@id']) {
		      return true;
		    }
		  }
		  return false;
		}

		/**
		 * Gets the frame flag value for the given flag name.
		 *
		 * @param frame the frame.
		 * @param options the framing options.
		 * @param name the flag name.
		 *
		 * @return the flag value.
		 */
		function _getFrameFlag(frame, options, name) {
		  const flag = '@' + name;
		  let rval = (flag in frame ? frame[flag][0] : options[name]);
		  if(name === 'embed') {
		    // default is "@last"
		    // backwards-compatibility support for "embed" maps:
		    // true => "@last"
		    // false => "@never"
		    if(rval === true) {
		      rval = '@once';
		    } else if(rval === false) {
		      rval = '@never';
		    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link' &&
		      rval !== '@first' && rval !== '@last' && rval !== '@once') {
		      throw new JsonLdError(
		        'Invalid JSON-LD syntax; invalid value of @embed.',
		        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});
		    }
		  }
		  return rval;
		}

		/**
		 * Validates a JSON-LD frame, throwing an exception if the frame is invalid.
		 *
		 * @param frame the frame to validate.
		 */
		function _validateFrame(frame) {
		  if(!types.isArray(frame) || frame.length !== 1 || !types.isObject(frame[0])) {
		    throw new JsonLdError(
		      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',
		      'jsonld.SyntaxError', {frame});
		  }

		  if('@id' in frame[0]) {
		    for(const id of util.asArray(frame[0]['@id'])) {
		      // @id must be wildcard or an IRI
		      if(!(types.isObject(id) || url.isAbsolute(id)) ||
		        (types.isString(id) && id.indexOf('_:') === 0)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; invalid @id in frame.',
		          'jsonld.SyntaxError', {code: 'invalid frame', frame});
		      }
		    }
		  }

		  if('@type' in frame[0]) {
		    for(const type of util.asArray(frame[0]['@type'])) {
		      // @type must be wildcard, IRI, or @json
		      if(!(types.isObject(type) || url.isAbsolute(type) ||
		          (type === '@json')) ||
		        (types.isString(type) && type.indexOf('_:') === 0)) {
		        throw new JsonLdError(
		          'Invalid JSON-LD syntax; invalid @type in frame.',
		          'jsonld.SyntaxError', {code: 'invalid frame', frame});
		      }
		    }
		  }
		}

		/**
		 * Returns a map of all of the subjects that match a parsed frame.
		 *
		 * @param state the current framing state.
		 * @param subjects the set of subjects to filter.
		 * @param frame the parsed frame.
		 * @param flags the frame flags.
		 *
		 * @return all of the matched subjects.
		 */
		function _filterSubjects(state, subjects, frame, flags) {
		  // filter subjects in @id order
		  const rval = {};
		  for(const id of subjects) {
		    const subject = state.graphMap[state.graph][id];
		    if(_filterSubject(state, subject, frame, flags)) {
		      rval[id] = subject;
		    }
		  }
		  return rval;
		}

		/**
		 * Returns true if the given subject matches the given frame.
		 *
		 * Matches either based on explicit type inclusion where the node has any
		 * type listed in the frame. If the frame has empty types defined matches
		 * nodes not having a @type. If the frame has a type of {} defined matches
		 * nodes having any type defined.
		 *
		 * Otherwise, does duck typing, where the node must have all of the
		 * properties defined in the frame.
		 *
		 * @param state the current framing state.
		 * @param subject the subject to check.
		 * @param frame the frame to check.
		 * @param flags the frame flags.
		 *
		 * @return true if the subject matches, false if not.
		 */
		function _filterSubject(state, subject, frame, flags) {
		  // check ducktype
		  let wildcard = true;
		  let matchesSome = false;

		  for(const key in frame) {
		    let matchThis = false;
		    const nodeValues = util.getValues(subject, key);
		    const isEmpty = util.getValues(frame, key).length === 0;

		    if(key === '@id') {
		      // match on no @id or any matching @id, including wildcard
		      if(types.isEmptyObject(frame['@id'][0] || {})) {
		        matchThis = true;
		      } else if(frame['@id'].length >= 0) {
		        matchThis = frame['@id'].includes(nodeValues[0]);
		      }
		      if(!flags.requireAll) {
		        return matchThis;
		      }
		    } else if(key === '@type') {
		      // check @type (object value means 'any' type,
		      // fall through to ducktyping)
		      wildcard = false;
		      if(isEmpty) {
		        if(nodeValues.length > 0) {
		          // don't match on no @type
		          return false;
		        }
		        matchThis = true;
		      } else if(frame['@type'].length === 1 &&
		        types.isEmptyObject(frame['@type'][0])) {
		        // match on wildcard @type if there is a type
		        matchThis = nodeValues.length > 0;
		      } else {
		        // match on a specific @type
		        for(const type of frame['@type']) {
		          if(types.isObject(type) && '@default' in type) {
		            // match on default object
		            matchThis = true;
		          } else {
		            matchThis = matchThis || nodeValues.some(tt => tt === type);
		          }
		        }
		      }
		      if(!flags.requireAll) {
		        return matchThis;
		      }
		    } else if(isKeyword(key)) {
		      continue;
		    } else {
		      // Force a copy of this frame entry so it can be manipulated
		      const thisFrame = util.getValues(frame, key)[0];
		      let hasDefault = false;
		      if(thisFrame) {
		        _validateFrame([thisFrame]);
		        hasDefault = '@default' in thisFrame;
		      }

		      // no longer a wildcard pattern if frame has any non-keyword properties
		      wildcard = false;

		      // skip, but allow match if node has no value for property, and frame has
		      // a default value
		      if(nodeValues.length === 0 && hasDefault) {
		        continue;
		      }

		      // if frame value is empty, don't match if subject has any value
		      if(nodeValues.length > 0 && isEmpty) {
		        return false;
		      }

		      if(thisFrame === undefined) {
		        // node does not match if values is not empty and the value of property
		        // in frame is match none.
		        if(nodeValues.length > 0) {
		          return false;
		        }
		        matchThis = true;
		      } else {
		        if(graphTypes.isList(thisFrame)) {
		          const listValue = thisFrame['@list'][0];
		          if(graphTypes.isList(nodeValues[0])) {
		            const nodeListValues = nodeValues[0]['@list'];

		            if(graphTypes.isValue(listValue)) {
		              // match on any matching value
		              matchThis = nodeListValues.some(lv => _valueMatch(listValue, lv));
		            } else if(graphTypes.isSubject(listValue) ||
		              graphTypes.isSubjectReference(listValue)) {
		              matchThis = nodeListValues.some(lv => _nodeMatch(
		                state, listValue, lv, flags));
		            }
		          }
		        } else if(graphTypes.isValue(thisFrame)) {
		          matchThis = nodeValues.some(nv => _valueMatch(thisFrame, nv));
		        } else if(graphTypes.isSubjectReference(thisFrame)) {
		          matchThis =
		            nodeValues.some(nv => _nodeMatch(state, thisFrame, nv, flags));
		        } else if(types.isObject(thisFrame)) {
		          matchThis = nodeValues.length > 0;
		        } else {
		          matchThis = false;
		        }
		      }
		    }

		    // all non-defaulted values must match if requireAll is set
		    if(!matchThis && flags.requireAll) {
		      return false;
		    }

		    matchesSome = matchesSome || matchThis;
		  }

		  // return true if wildcard or subject matches some properties
		  return wildcard || matchesSome;
		}

		/**
		 * Removes an existing embed.
		 *
		 * @param state the current framing state.
		 * @param id the @id of the embed to remove.
		 */
		function _removeEmbed(state, id) {
		  // get existing embed
		  const embeds = state.uniqueEmbeds[state.graph];
		  const embed = embeds[id];
		  const parent = embed.parent;
		  const property = embed.property;

		  // create reference to replace embed
		  const subject = {'@id': id};

		  // remove existing embed
		  if(types.isArray(parent)) {
		    // replace subject with reference
		    for(let i = 0; i < parent.length; ++i) {
		      if(util.compareValues(parent[i], subject)) {
		        parent[i] = subject;
		        break;
		      }
		    }
		  } else {
		    // replace subject with reference
		    const useArray = types.isArray(parent[property]);
		    util.removeValue(parent, property, subject, {propertyIsArray: useArray});
		    util.addValue(parent, property, subject, {propertyIsArray: useArray});
		  }

		  // recursively remove dependent dangling embeds
		  const removeDependents = id => {
		    // get embed keys as a separate array to enable deleting keys in map
		    const ids = Object.keys(embeds);
		    for(const next of ids) {
		      if(next in embeds && types.isObject(embeds[next].parent) &&
		        embeds[next].parent['@id'] === id) {
		        delete embeds[next];
		        removeDependents(next);
		      }
		    }
		  };
		  removeDependents(id);
		}

		/**
		 * Removes the @preserve keywords from expanded result of framing.
		 *
		 * @param input the framed, framed output.
		 * @param options the framing options used.
		 *
		 * @return the resulting output.
		 */
		function _cleanupPreserve(input, options) {
		  // recurse through arrays
		  if(types.isArray(input)) {
		    return input.map(value => _cleanupPreserve(value, options));
		  }

		  if(types.isObject(input)) {
		    // remove @preserve
		    if('@preserve' in input) {
		      return input['@preserve'][0];
		    }

		    // skip @values
		    if(graphTypes.isValue(input)) {
		      return input;
		    }

		    // recurse through @lists
		    if(graphTypes.isList(input)) {
		      input['@list'] = _cleanupPreserve(input['@list'], options);
		      return input;
		    }

		    // handle in-memory linked nodes
		    if('@id' in input) {
		      const id = input['@id'];
		      if(options.link.hasOwnProperty(id)) {
		        const idx = options.link[id].indexOf(input);
		        if(idx !== -1) {
		          // already visited
		          return options.link[id][idx];
		        }
		        // prevent circular visitation
		        options.link[id].push(input);
		      } else {
		        // prevent circular visitation
		        options.link[id] = [input];
		      }
		    }

		    // recurse through properties
		    for(const prop in input) {
		      // potentially remove the id, if it is an unreference bnode
		      if(prop === '@id' && options.bnodesToClear.includes(input[prop])) {
		        delete input['@id'];
		        continue;
		      }

		      input[prop] = _cleanupPreserve(input[prop], options);
		    }
		  }
		  return input;
		}

		/**
		 * Adds framing output to the given parent.
		 *
		 * @param parent the parent to add to.
		 * @param property the parent property.
		 * @param output the output to add.
		 */
		function _addFrameOutput(parent, property, output) {
		  if(types.isObject(parent)) {
		    util.addValue(parent, property, output, {propertyIsArray: true});
		  } else {
		    parent.push(output);
		  }
		}

		/**
		 * Node matches if it is a node, and matches the pattern as a frame.
		 *
		 * @param state the current framing state.
		 * @param pattern used to match value
		 * @param value to check
		 * @param flags the frame flags.
		 */
		function _nodeMatch(state, pattern, value, flags) {
		  if(!('@id' in value)) {
		    return false;
		  }
		  const nodeObject = state.subjects[value['@id']];
		  return nodeObject && _filterSubject(state, nodeObject, pattern, flags);
		}

		/**
		 * Value matches if it is a value and matches the value pattern
		 *
		 * * `pattern` is empty
		 * * @values are the same, or `pattern[@value]` is a wildcard, and
		 * * @types are the same or `value[@type]` is not null
		 *   and `pattern[@type]` is `{}`, or `value[@type]` is null
		 *   and `pattern[@type]` is null or `[]`, and
		 * * @languages are the same or `value[@language]` is not null
		 *   and `pattern[@language]` is `{}`, or `value[@language]` is null
		 *   and `pattern[@language]` is null or `[]`.
		 *
		 * @param pattern used to match value
		 * @param value to check
		 */
		function _valueMatch(pattern, value) {
		  const v1 = value['@value'];
		  const t1 = value['@type'];
		  const l1 = value['@language'];
		  const v2 = pattern['@value'] ?
		    (types.isArray(pattern['@value']) ?
		      pattern['@value'] : [pattern['@value']]) :
		    [];
		  const t2 = pattern['@type'] ?
		    (types.isArray(pattern['@type']) ?
		      pattern['@type'] : [pattern['@type']]) :
		    [];
		  const l2 = pattern['@language'] ?
		    (types.isArray(pattern['@language']) ?
		      pattern['@language'] : [pattern['@language']]) :
		    [];

		  if(v2.length === 0 && t2.length === 0 && l2.length === 0) {
		    return true;
		  }
		  if(!(v2.includes(v1) || types.isEmptyObject(v2[0]))) {
		    return false;
		  }
		  if(!(!t1 && t2.length === 0 || t2.includes(t1) || t1 &&
		    types.isEmptyObject(t2[0]))) {
		    return false;
		  }
		  if(!(!l1 && l2.length === 0 || l2.includes(l1) || l1 &&
		    types.isEmptyObject(l2[0]))) {
		    return false;
		  }
		  return true;
		}
		return frame;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var compact;
	var hasRequiredCompact;

	function requireCompact () {
		if (hasRequiredCompact) return compact;
		hasRequiredCompact = 1;

		const JsonLdError = requireJsonLdError();

		const {
		  isArray: _isArray,
		  isObject: _isObject,
		  isString: _isString,
		  isUndefined: _isUndefined
		} = requireTypes();

		const {
		  isList: _isList,
		  isValue: _isValue,
		  isGraph: _isGraph,
		  isSimpleGraph: _isSimpleGraph,
		  isSubjectReference: _isSubjectReference
		} = requireGraphTypes();

		const {
		  expandIri: _expandIri,
		  getContextValue: _getContextValue,
		  isKeyword: _isKeyword,
		  process: _processContext,
		  processingMode: _processingMode
		} = requireContext();

		const {
		  removeBase: _removeBase,
		  prependBase: _prependBase
		} = requireUrl();

		const {
		  REGEX_KEYWORD,
		  addValue: _addValue,
		  asArray: _asArray,
		  compareShortestLeast: _compareShortestLeast
		} = requireUtil();

		const api = {};
		compact = api;

		/**
		 * Recursively compacts an element using the given active context. All values
		 * must be in expanded form before this method is called.
		 *
		 * @param activeCtx the active context to use.
		 * @param activeProperty the compacted property associated with the element
		 *          to compact, null for none.
		 * @param element the element to compact.
		 * @param options the compaction options.
		 *
		 * @return a promise that resolves to the compacted value.
		 */
		api.compact = async ({
		  activeCtx,
		  activeProperty = null,
		  element,
		  options = {}
		}) => {
		  // recursively compact array
		  if(_isArray(element)) {
		    let rval = [];
		    for(let i = 0; i < element.length; ++i) {
		      const compacted = await api.compact({
		        activeCtx,
		        activeProperty,
		        element: element[i],
		        options
		      });
		      if(compacted === null) {
		        // FIXME: need event?
		        continue;
		      }
		      rval.push(compacted);
		    }
		    if(options.compactArrays && rval.length === 1) {
		      // use single element if no container is specified
		      const container = _getContextValue(
		        activeCtx, activeProperty, '@container') || [];
		      if(container.length === 0) {
		        rval = rval[0];
		      }
		    }
		    return rval;
		  }

		  // use any scoped context on activeProperty
		  const ctx = _getContextValue(activeCtx, activeProperty, '@context');
		  if(!_isUndefined(ctx)) {
		    activeCtx = await _processContext({
		      activeCtx,
		      localCtx: ctx,
		      propagate: true,
		      overrideProtected: true,
		      options
		    });
		  }

		  // recursively compact object
		  if(_isObject(element)) {
		    if(options.link && '@id' in element &&
		      options.link.hasOwnProperty(element['@id'])) {
		      // check for a linked element to reuse
		      const linked = options.link[element['@id']];
		      for(let i = 0; i < linked.length; ++i) {
		        if(linked[i].expanded === element) {
		          return linked[i].compacted;
		        }
		      }
		    }

		    // do value compaction on @values and subject references
		    if(_isValue(element) || _isSubjectReference(element)) {
		      const rval =
		        api.compactValue({activeCtx, activeProperty, value: element, options});
		      if(options.link && _isSubjectReference(element)) {
		        // store linked element
		        if(!(options.link.hasOwnProperty(element['@id']))) {
		          options.link[element['@id']] = [];
		        }
		        options.link[element['@id']].push({expanded: element, compacted: rval});
		      }
		      return rval;
		    }

		    // if expanded property is @list and we're contained within a list
		    // container, recursively compact this item to an array
		    if(_isList(element)) {
		      const container = _getContextValue(
		        activeCtx, activeProperty, '@container') || [];
		      if(container.includes('@list')) {
		        return api.compact({
		          activeCtx,
		          activeProperty,
		          element: element['@list'],
		          options
		        });
		      }
		    }

		    // FIXME: avoid misuse of active property as an expanded property?
		    const insideReverse = (activeProperty === '@reverse');

		    const rval = {};

		    // original context before applying property-scoped and local contexts
		    const inputCtx = activeCtx;

		    // revert to previous context, if there is one,
		    // and element is not a value object or a node reference
		    if(!_isValue(element) && !_isSubjectReference(element)) {
		      activeCtx = activeCtx.revertToPreviousContext();
		    }

		    // apply property-scoped context after reverting term-scoped context
		    const propertyScopedCtx =
		      _getContextValue(inputCtx, activeProperty, '@context');
		    if(!_isUndefined(propertyScopedCtx)) {
		      activeCtx = await _processContext({
		        activeCtx,
		        localCtx: propertyScopedCtx,
		        propagate: true,
		        overrideProtected: true,
		        options
		      });
		    }

		    if(options.link && '@id' in element) {
		      // store linked element
		      if(!options.link.hasOwnProperty(element['@id'])) {
		        options.link[element['@id']] = [];
		      }
		      options.link[element['@id']].push({expanded: element, compacted: rval});
		    }

		    // apply any context defined on an alias of @type
		    // if key is @type and any compacted value is a term having a local
		    // context, overlay that context
		    let types = element['@type'] || [];
		    if(types.length > 1) {
		      types = Array.from(types).sort();
		    }
		    // find all type-scoped contexts based on current context, prior to
		    // updating it
		    const typeContext = activeCtx;
		    for(const type of types) {
		      const compactedType = api.compactIri(
		        {activeCtx: typeContext, iri: type, relativeTo: {vocab: true}});

		      // Use any type-scoped context defined on this value
		      const ctx = _getContextValue(inputCtx, compactedType, '@context');
		      if(!_isUndefined(ctx)) {
		        activeCtx = await _processContext({
		          activeCtx,
		          localCtx: ctx,
		          options,
		          propagate: false
		        });
		      }
		    }

		    // process element keys in order
		    const keys = Object.keys(element).sort();
		    for(const expandedProperty of keys) {
		      const expandedValue = element[expandedProperty];

		      // compact @id
		      if(expandedProperty === '@id') {
		        let compactedValue = _asArray(expandedValue).map(
		          expandedIri => api.compactIri({
		            activeCtx,
		            iri: expandedIri,
		            relativeTo: {vocab: false},
		            base: options.base
		          }));
		        if(compactedValue.length === 1) {
		          compactedValue = compactedValue[0];
		        }

		        // use keyword alias and add value
		        const alias = api.compactIri(
		          {activeCtx, iri: '@id', relativeTo: {vocab: true}});

		        rval[alias] = compactedValue;
		        continue;
		      }

		      // compact @type(s)
		      if(expandedProperty === '@type') {
		        // resolve type values against previous context
		        let compactedValue = _asArray(expandedValue).map(
		          expandedIri => api.compactIri({
		            activeCtx: inputCtx,
		            iri: expandedIri,
		            relativeTo: {vocab: true}
		          }));
		        if(compactedValue.length === 1) {
		          compactedValue = compactedValue[0];
		        }

		        // use keyword alias and add value
		        const alias = api.compactIri(
		          {activeCtx, iri: '@type', relativeTo: {vocab: true}});
		        const container = _getContextValue(
		          activeCtx, alias, '@container') || [];

		        // treat as array for @type if @container includes @set
		        const typeAsSet =
		          container.includes('@set') &&
		          _processingMode(activeCtx, 1.1);
		        const isArray =
		          typeAsSet || (_isArray(compactedValue) && expandedValue.length === 0);
		        _addValue(rval, alias, compactedValue, {propertyIsArray: isArray});
		        continue;
		      }

		      // handle @reverse
		      if(expandedProperty === '@reverse') {
		        // recursively compact expanded value
		        const compactedValue = await api.compact({
		          activeCtx,
		          activeProperty: '@reverse',
		          element: expandedValue,
		          options
		        });

		        // handle double-reversed properties
		        for(const compactedProperty in compactedValue) {
		          if(activeCtx.mappings.has(compactedProperty) &&
		            activeCtx.mappings.get(compactedProperty).reverse) {
		            const value = compactedValue[compactedProperty];
		            const container = _getContextValue(
		              activeCtx, compactedProperty, '@container') || [];
		            const useArray = (
		              container.includes('@set') || !options.compactArrays);
		            _addValue(
		              rval, compactedProperty, value, {propertyIsArray: useArray});
		            delete compactedValue[compactedProperty];
		          }
		        }

		        if(Object.keys(compactedValue).length > 0) {
		          // use keyword alias and add value
		          const alias = api.compactIri({
		            activeCtx,
		            iri: expandedProperty,
		            relativeTo: {vocab: true}
		          });
		          _addValue(rval, alias, compactedValue);
		        }

		        continue;
		      }

		      if(expandedProperty === '@preserve') {
		        // compact using activeProperty
		        const compactedValue = await api.compact({
		          activeCtx,
		          activeProperty,
		          element: expandedValue,
		          options
		        });

		        if(!(_isArray(compactedValue) && compactedValue.length === 0)) {
		          _addValue(rval, expandedProperty, compactedValue);
		        }
		        continue;
		      }

		      // handle @index property
		      if(expandedProperty === '@index') {
		        // drop @index if inside an @index container
		        const container = _getContextValue(
		          activeCtx, activeProperty, '@container') || [];
		        if(container.includes('@index')) {
		          continue;
		        }

		        // use keyword alias and add value
		        const alias = api.compactIri({
		          activeCtx,
		          iri: expandedProperty,
		          relativeTo: {vocab: true}
		        });
		        _addValue(rval, alias, expandedValue);
		        continue;
		      }

		      // skip array processing for keywords that aren't
		      // @graph, @list, or @included
		      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&
		        expandedProperty !== '@included' &&
		        _isKeyword(expandedProperty)) {
		        // use keyword alias and add value as is
		        const alias = api.compactIri({
		          activeCtx,
		          iri: expandedProperty,
		          relativeTo: {vocab: true}
		        });
		        _addValue(rval, alias, expandedValue);
		        continue;
		      }

		      // Note: expanded value must be an array due to expansion algorithm.
		      if(!_isArray(expandedValue)) {
		        throw new JsonLdError(
		          'JSON-LD expansion error; expanded value must be an array.',
		          'jsonld.SyntaxError');
		      }

		      // preserve empty arrays
		      if(expandedValue.length === 0) {
		        const itemActiveProperty = api.compactIri({
		          activeCtx,
		          iri: expandedProperty,
		          value: expandedValue,
		          relativeTo: {vocab: true},
		          reverse: insideReverse
		        });
		        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?
		          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;
		        let nestResult = rval;
		        if(nestProperty) {
		          _checkNestProperty(activeCtx, nestProperty, options);
		          if(!_isObject(rval[nestProperty])) {
		            rval[nestProperty] = {};
		          }
		          nestResult = rval[nestProperty];
		        }
		        _addValue(
		          nestResult, itemActiveProperty, expandedValue, {
		            propertyIsArray: true
		          });
		      }

		      // recusively process array values
		      for(const expandedItem of expandedValue) {
		        // compact property and get container type
		        const itemActiveProperty = api.compactIri({
		          activeCtx,
		          iri: expandedProperty,
		          value: expandedItem,
		          relativeTo: {vocab: true},
		          reverse: insideReverse
		        });

		        // if itemActiveProperty is a @nest property, add values to nestResult,
		        // otherwise rval
		        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?
		          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;
		        let nestResult = rval;
		        if(nestProperty) {
		          _checkNestProperty(activeCtx, nestProperty, options);
		          if(!_isObject(rval[nestProperty])) {
		            rval[nestProperty] = {};
		          }
		          nestResult = rval[nestProperty];
		        }

		        const container = _getContextValue(
		          activeCtx, itemActiveProperty, '@container') || [];

		        // get simple @graph or @list value if appropriate
		        const isGraph = _isGraph(expandedItem);
		        const isList = _isList(expandedItem);
		        let inner;
		        if(isList) {
		          inner = expandedItem['@list'];
		        } else if(isGraph) {
		          inner = expandedItem['@graph'];
		        }

		        // recursively compact expanded item
		        let compactedItem = await api.compact({
		          activeCtx,
		          activeProperty: itemActiveProperty,
		          element: (isList || isGraph) ? inner : expandedItem,
		          options
		        });

		        // handle @list
		        if(isList) {
		          // ensure @list value is an array
		          if(!_isArray(compactedItem)) {
		            compactedItem = [compactedItem];
		          }

		          if(!container.includes('@list')) {
		            // wrap using @list alias
		            compactedItem = {
		              [api.compactIri({
		                activeCtx,
		                iri: '@list',
		                relativeTo: {vocab: true}
		              })]: compactedItem
		            };

		            // include @index from expanded @list, if any
		            if('@index' in expandedItem) {
		              compactedItem[api.compactIri({
		                activeCtx,
		                iri: '@index',
		                relativeTo: {vocab: true}
		              })] = expandedItem['@index'];
		            }
		          } else {
		            _addValue(nestResult, itemActiveProperty, compactedItem, {
		              valueIsArray: true,
		              allowDuplicate: true
		            });
		            continue;
		          }
		        }

		        // Graph object compaction cases
		        if(isGraph) {
		          if(container.includes('@graph') && (container.includes('@id') ||
		            container.includes('@index') && _isSimpleGraph(expandedItem))) {
		            // get or create the map object
		            let mapObject;
		            if(nestResult.hasOwnProperty(itemActiveProperty)) {
		              mapObject = nestResult[itemActiveProperty];
		            } else {
		              nestResult[itemActiveProperty] = mapObject = {};
		            }

		            // index on @id or @index or alias of @none
		            const key = (container.includes('@id') ?
		              expandedItem['@id'] : expandedItem['@index']) ||
		              api.compactIri({activeCtx, iri: '@none',
		                relativeTo: {vocab: true}});
		            // add compactedItem to map, using value of `@id` or a new blank
		            // node identifier

		            _addValue(
		              mapObject, key, compactedItem, {
		                propertyIsArray:
		                  (!options.compactArrays || container.includes('@set'))
		              });
		          } else if(container.includes('@graph') &&
		            _isSimpleGraph(expandedItem)) {
		            // container includes @graph but not @id or @index and value is a
		            // simple graph object add compact value
		            // if compactedItem contains multiple values, it is wrapped in
		            // `@included`
		            if(_isArray(compactedItem) && compactedItem.length > 1) {
		              compactedItem = {'@included': compactedItem};
		            }
		            _addValue(
		              nestResult, itemActiveProperty, compactedItem, {
		                propertyIsArray:
		                  (!options.compactArrays || container.includes('@set'))
		              });
		          } else {
		            // wrap using @graph alias, remove array if only one item and
		            // compactArrays not set
		            if(_isArray(compactedItem) && compactedItem.length === 1 &&
		              options.compactArrays) {
		              compactedItem = compactedItem[0];
		            }
		            compactedItem = {
		              [api.compactIri({
		                activeCtx,
		                iri: '@graph',
		                relativeTo: {vocab: true}
		              })]: compactedItem
		            };

		            // include @id from expanded graph, if any
		            if('@id' in expandedItem) {
		              compactedItem[api.compactIri({
		                activeCtx,
		                iri: '@id',
		                relativeTo: {vocab: true}
		              })] = expandedItem['@id'];
		            }

		            // include @index from expanded graph, if any
		            if('@index' in expandedItem) {
		              compactedItem[api.compactIri({
		                activeCtx,
		                iri: '@index',
		                relativeTo: {vocab: true}
		              })] = expandedItem['@index'];
		            }
		            _addValue(
		              nestResult, itemActiveProperty, compactedItem, {
		                propertyIsArray:
		                  (!options.compactArrays || container.includes('@set'))
		              });
		          }
		        } else if(container.includes('@language') ||
		          container.includes('@index') || container.includes('@id') ||
		          container.includes('@type')) {
		          // handle language and index maps
		          // get or create the map object
		          let mapObject;
		          if(nestResult.hasOwnProperty(itemActiveProperty)) {
		            mapObject = nestResult[itemActiveProperty];
		          } else {
		            nestResult[itemActiveProperty] = mapObject = {};
		          }

		          let key;
		          if(container.includes('@language')) {
		            // if container is a language map, simplify compacted value to
		            // a simple string
		            if(_isValue(compactedItem)) {
		              compactedItem = compactedItem['@value'];
		            }
		            key = expandedItem['@language'];
		          } else if(container.includes('@index')) {
		            const indexKey = _getContextValue(
		              activeCtx, itemActiveProperty, '@index') || '@index';
		            const containerKey = api.compactIri(
		              {activeCtx, iri: indexKey, relativeTo: {vocab: true}});
		            if(indexKey === '@index') {
		              key = expandedItem['@index'];
		              delete compactedItem[containerKey];
		            } else {
		              let others;
		              [key, ...others] = _asArray(compactedItem[indexKey] || []);
		              if(!_isString(key)) {
		                // Will use @none if it isn't a string.
		                key = null;
		              } else {
		                switch(others.length) {
		                  case 0:
		                    delete compactedItem[indexKey];
		                    break;
		                  case 1:
		                    compactedItem[indexKey] = others[0];
		                    break;
		                  default:
		                    compactedItem[indexKey] = others;
		                    break;
		                }
		              }
		            }
		          } else if(container.includes('@id')) {
		            const idKey = api.compactIri({activeCtx, iri: '@id',
		              relativeTo: {vocab: true}});
		            key = compactedItem[idKey];
		            delete compactedItem[idKey];
		          } else if(container.includes('@type')) {
		            const typeKey = api.compactIri({
		              activeCtx,
		              iri: '@type',
		              relativeTo: {vocab: true}
		            });
		            let types;
		            [key, ...types] = _asArray(compactedItem[typeKey] || []);
		            switch(types.length) {
		              case 0:
		                delete compactedItem[typeKey];
		                break;
		              case 1:
		                compactedItem[typeKey] = types[0];
		                break;
		              default:
		                compactedItem[typeKey] = types;
		                break;
		            }

		            // If compactedItem contains a single entry
		            // whose key maps to @id, recompact without @type
		            if(Object.keys(compactedItem).length === 1 &&
		              '@id' in expandedItem) {
		              compactedItem = await api.compact({
		                activeCtx,
		                activeProperty: itemActiveProperty,
		                element: {'@id': expandedItem['@id']},
		                options
		              });
		            }
		          }

		          // if compacting this value which has no key, index on @none
		          if(!key) {
		            key = api.compactIri({activeCtx, iri: '@none',
		              relativeTo: {vocab: true}});
		          }
		          // add compact value to map object using key from expanded value
		          // based on the container type
		          _addValue(
		            mapObject, key, compactedItem, {
		              propertyIsArray: container.includes('@set')
		            });
		        } else {
		          // use an array if: compactArrays flag is false,
		          // @container is @set or @list , value is an empty
		          // array, or key is @graph
		          const isArray = (!options.compactArrays ||
		            container.includes('@set') || container.includes('@list') ||
		            (_isArray(compactedItem) && compactedItem.length === 0) ||
		            expandedProperty === '@list' || expandedProperty === '@graph');

		          // add compact value
		          _addValue(
		            nestResult, itemActiveProperty, compactedItem,
		            {propertyIsArray: isArray});
		        }
		      }
		    }

		    return rval;
		  }

		  // only primitives remain which are already compact
		  return element;
		};

		/**
		 * Compacts an IRI or keyword into a term or prefix if it can be. If the
		 * IRI has an associated value it may be passed.
		 *
		 * @param activeCtx the active context to use.
		 * @param iri the IRI to compact.
		 * @param value the value to check or null.
		 * @param relativeTo options for how to compact IRIs:
		 *          vocab: true to split after @vocab, false not to.
		 * @param reverse true if a reverse property is being compacted, false if not.
		 * @param base the absolute URL to use for compacting document-relative IRIs.
		 *
		 * @return the compacted term, prefix, keyword alias, or the original IRI.
		 */
		api.compactIri = ({
		  activeCtx,
		  iri,
		  value = null,
		  relativeTo = {vocab: false},
		  reverse = false,
		  base = null
		}) => {
		  // can't compact null
		  if(iri === null) {
		    return iri;
		  }

		  // if context is from a property term scoped context composed with a
		  // type-scoped context, then use the previous context instead
		  if(activeCtx.isPropertyTermScoped && activeCtx.previousContext) {
		    activeCtx = activeCtx.previousContext;
		  }

		  const inverseCtx = activeCtx.getInverse();

		  // if term is a keyword, it may be compacted to a simple alias
		  if(_isKeyword(iri) &&
		    iri in inverseCtx &&
		    '@none' in inverseCtx[iri] &&
		    '@type' in inverseCtx[iri]['@none'] &&
		    '@none' in inverseCtx[iri]['@none']['@type']) {
		    return inverseCtx[iri]['@none']['@type']['@none'];
		  }

		  // use inverse context to pick a term if iri is relative to vocab
		  if(relativeTo.vocab && iri in inverseCtx) {
		    const defaultLanguage = activeCtx['@language'] || '@none';

		    // prefer @index if available in value
		    const containers = [];
		    if(_isObject(value) && '@index' in value && !('@graph' in value)) {
		      containers.push('@index', '@index@set');
		    }

		    // if value is a preserve object, use its value
		    if(_isObject(value) && '@preserve' in value) {
		      value = value['@preserve'][0];
		    }

		    // prefer most specific container including @graph, prefering @set
		    // variations
		    if(_isGraph(value)) {
		      // favor indexmap if the graph is indexed
		      if('@index' in value) {
		        containers.push(
		          '@graph@index', '@graph@index@set', '@index', '@index@set');
		      }
		      // favor idmap if the graph is has an @id
		      if('@id' in value) {
		        containers.push(
		          '@graph@id', '@graph@id@set');
		      }
		      containers.push('@graph', '@graph@set', '@set');
		      // allow indexmap if the graph is not indexed
		      if(!('@index' in value)) {
		        containers.push(
		          '@graph@index', '@graph@index@set', '@index', '@index@set');
		      }
		      // allow idmap if the graph does not have an @id
		      if(!('@id' in value)) {
		        containers.push('@graph@id', '@graph@id@set');
		      }
		    } else if(_isObject(value) && !_isValue(value)) {
		      containers.push('@id', '@id@set', '@type', '@set@type');
		    }

		    // defaults for term selection based on type/language
		    let typeOrLanguage = '@language';
		    let typeOrLanguageValue = '@null';

		    if(reverse) {
		      typeOrLanguage = '@type';
		      typeOrLanguageValue = '@reverse';
		      containers.push('@set');
		    } else if(_isList(value)) {
		      // choose the most specific term that works for all elements in @list
		      // only select @list containers if @index is NOT in value
		      if(!('@index' in value)) {
		        containers.push('@list');
		      }
		      const list = value['@list'];
		      if(list.length === 0) {
		        // any empty list can be matched against any term that uses the
		        // @list container regardless of @type or @language
		        typeOrLanguage = '@any';
		        typeOrLanguageValue = '@none';
		      } else {
		        let commonLanguage = (list.length === 0) ? defaultLanguage : null;
		        let commonType = null;
		        for(let i = 0; i < list.length; ++i) {
		          const item = list[i];
		          let itemLanguage = '@none';
		          let itemType = '@none';
		          if(_isValue(item)) {
		            if('@direction' in item) {
		              const lang = (item['@language'] || '').toLowerCase();
		              const dir = item['@direction'];
		              itemLanguage = `${lang}_${dir}`;
		            } else if('@language' in item) {
		              itemLanguage = item['@language'].toLowerCase();
		            } else if('@type' in item) {
		              itemType = item['@type'];
		            } else {
		              // plain literal
		              itemLanguage = '@null';
		            }
		          } else {
		            itemType = '@id';
		          }
		          if(commonLanguage === null) {
		            commonLanguage = itemLanguage;
		          } else if(itemLanguage !== commonLanguage && _isValue(item)) {
		            commonLanguage = '@none';
		          }
		          if(commonType === null) {
		            commonType = itemType;
		          } else if(itemType !== commonType) {
		            commonType = '@none';
		          }
		          // there are different languages and types in the list, so choose
		          // the most generic term, no need to keep iterating the list
		          if(commonLanguage === '@none' && commonType === '@none') {
		            break;
		          }
		        }
		        commonLanguage = commonLanguage || '@none';
		        commonType = commonType || '@none';
		        if(commonType !== '@none') {
		          typeOrLanguage = '@type';
		          typeOrLanguageValue = commonType;
		        } else {
		          typeOrLanguageValue = commonLanguage;
		        }
		      }
		    } else {
		      if(_isValue(value)) {
		        if('@language' in value && !('@index' in value)) {
		          containers.push('@language', '@language@set');
		          typeOrLanguageValue = value['@language'];
		          const dir = value['@direction'];
		          if(dir) {
		            typeOrLanguageValue = `${typeOrLanguageValue}_${dir}`;
		          }
		        } else if('@direction' in value && !('@index' in value)) {
		          typeOrLanguageValue = `_${value['@direction']}`;
		        } else if('@type' in value) {
		          typeOrLanguage = '@type';
		          typeOrLanguageValue = value['@type'];
		        }
		      } else {
		        typeOrLanguage = '@type';
		        typeOrLanguageValue = '@id';
		      }
		      containers.push('@set');
		    }

		    // do term selection
		    containers.push('@none');

		    // an index map can be used to index values using @none, so add as a low
		    // priority
		    if(_isObject(value) && !('@index' in value)) {
		      // allow indexing even if no @index present
		      containers.push('@index', '@index@set');
		    }

		    // values without type or language can use @language map
		    if(_isValue(value) && Object.keys(value).length === 1) {
		      // allow indexing even if no @index present
		      containers.push('@language', '@language@set');
		    }

		    const term = _selectTerm(
		      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);
		    if(term !== null) {
		      return term;
		    }
		  }

		  // no term match, use @vocab if available
		  if(relativeTo.vocab) {
		    if('@vocab' in activeCtx) {
		      // determine if vocab is a prefix of the iri
		      const vocab = activeCtx['@vocab'];
		      if(iri.indexOf(vocab) === 0 && iri !== vocab) {
		        // use suffix as relative iri if it is not a term in the active context
		        const suffix = iri.substr(vocab.length);
		        if(!activeCtx.mappings.has(suffix)) {
		          return suffix;
		        }
		      }
		    }
		  }

		  // no term or @vocab match, check for possible CURIEs
		  let choice = null;
		  // TODO: make FastCurieMap a class with a method to do this lookup
		  const partialMatches = [];
		  let iriMap = activeCtx.fastCurieMap;
		  // check for partial matches of against `iri`, which means look until
		  // iri.length - 1, not full length
		  const maxPartialLength = iri.length - 1;
		  for(let i = 0; i < maxPartialLength && iri[i] in iriMap; ++i) {
		    iriMap = iriMap[iri[i]];
		    if('' in iriMap) {
		      partialMatches.push(iriMap[''][0]);
		    }
		  }
		  // check partial matches in reverse order to prefer longest ones first
		  for(let i = partialMatches.length - 1; i >= 0; --i) {
		    const entry = partialMatches[i];
		    const terms = entry.terms;
		    for(const term of terms) {
		      // a CURIE is usable if:
		      // 1. it has no mapping, OR
		      // 2. value is null, which means we're not compacting an @value, AND
		      //   the mapping matches the IRI
		      const curie = term + ':' + iri.substr(entry.iri.length);
		      const isUsableCurie = (activeCtx.mappings.get(term)._prefix &&
		        (!activeCtx.mappings.has(curie) ||
		        (value === null && activeCtx.mappings.get(curie)['@id'] === iri)));

		      // select curie if it is shorter or the same length but lexicographically
		      // less than the current choice
		      if(isUsableCurie && (choice === null ||
		        _compareShortestLeast(curie, choice) < 0)) {
		        choice = curie;
		      }
		    }
		  }

		  // return chosen curie
		  if(choice !== null) {
		    return choice;
		  }

		  // If iri could be confused with a compact IRI using a term in this context,
		  // signal an error
		  for(const [term, td] of activeCtx.mappings) {
		    if(td && td._prefix && iri.startsWith(term + ':')) {
		      throw new JsonLdError(
		        `Absolute IRI "${iri}" confused with prefix "${term}".`,
		        'jsonld.SyntaxError',
		        {code: 'IRI confused with prefix', context: activeCtx});
		    }
		  }

		  // compact IRI relative to base
		  if(!relativeTo.vocab) {
		    if('@base' in activeCtx) {
		      if(!activeCtx['@base']) {
		        // The None case preserves rval as potentially relative
		        return iri;
		      } else {
		        const _iri = _removeBase(_prependBase(base, activeCtx['@base']), iri);
		        return REGEX_KEYWORD.test(_iri) ? `./${_iri}` : _iri;
		      }
		    } else {
		      return _removeBase(base, iri);
		    }
		  }

		  // return IRI as is
		  return iri;
		};

		/**
		 * Performs value compaction on an object with '@value' or '@id' as the only
		 * property.
		 *
		 * @param activeCtx the active context.
		 * @param activeProperty the active property that points to the value.
		 * @param value the value to compact.
		 * @param {Object} [options] - processing options.
		 *
		 * @return the compaction result.
		 */
		api.compactValue = ({activeCtx, activeProperty, value, options}) => {
		  // value is a @value
		  if(_isValue(value)) {
		    // get context rules
		    const type = _getContextValue(activeCtx, activeProperty, '@type');
		    const language = _getContextValue(activeCtx, activeProperty, '@language');
		    const direction = _getContextValue(activeCtx, activeProperty, '@direction');
		    const container =
		      _getContextValue(activeCtx, activeProperty, '@container') || [];

		    // whether or not the value has an @index that must be preserved
		    const preserveIndex = '@index' in value && !container.includes('@index');

		    // if there's no @index to preserve ...
		    if(!preserveIndex && type !== '@none') {
		      // matching @type or @language specified in context, compact value
		      if(value['@type'] === type) {
		        return value['@value'];
		      }
		      if('@language' in value && value['@language'] === language &&
		         '@direction' in value && value['@direction'] === direction) {
		        return value['@value'];
		      }
		      if('@language' in value && value['@language'] === language) {
		        return value['@value'];
		      }
		      if('@direction' in value && value['@direction'] === direction) {
		        return value['@value'];
		      }
		    }

		    // return just the value of @value if all are true:
		    // 1. @value is the only key or @index isn't being preserved
		    // 2. there is no default language or @value is not a string or
		    //   the key has a mapping with a null @language
		    const keyCount = Object.keys(value).length;
		    const isValueOnlyKey = (keyCount === 1 ||
		      (keyCount === 2 && '@index' in value && !preserveIndex));
		    const hasDefaultLanguage = ('@language' in activeCtx);
		    const isValueString = _isString(value['@value']);
		    const hasNullMapping = (activeCtx.mappings.has(activeProperty) &&
		      activeCtx.mappings.get(activeProperty)['@language'] === null);
		    if(isValueOnlyKey &&
		      type !== '@none' &&
		      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {
		      return value['@value'];
		    }

		    const rval = {};

		    // preserve @index
		    if(preserveIndex) {
		      rval[api.compactIri({
		        activeCtx,
		        iri: '@index',
		        relativeTo: {vocab: true}
		      })] = value['@index'];
		    }

		    if('@type' in value) {
		      // compact @type IRI
		      rval[api.compactIri({
		        activeCtx,
		        iri: '@type',
		        relativeTo: {vocab: true}
		      })] = api.compactIri(
		        {activeCtx, iri: value['@type'], relativeTo: {vocab: true}});
		    } else if('@language' in value) {
		      // alias @language
		      rval[api.compactIri({
		        activeCtx,
		        iri: '@language',
		        relativeTo: {vocab: true}
		      })] = value['@language'];
		    }

		    if('@direction' in value) {
		      // alias @direction
		      rval[api.compactIri({
		        activeCtx,
		        iri: '@direction',
		        relativeTo: {vocab: true}
		      })] = value['@direction'];
		    }

		    // alias @value
		    rval[api.compactIri({
		      activeCtx,
		      iri: '@value',
		      relativeTo: {vocab: true}
		    })] = value['@value'];

		    return rval;
		  }

		  // value is a subject reference
		  const expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true},
		    options);
		  const type = _getContextValue(activeCtx, activeProperty, '@type');
		  const compacted = api.compactIri({
		    activeCtx,
		    iri: value['@id'],
		    relativeTo: {vocab: type === '@vocab'},
		    base: options.base});

		  // compact to scalar
		  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {
		    return compacted;
		  }

		  return {
		    [api.compactIri({
		      activeCtx,
		      iri: '@id',
		      relativeTo: {vocab: true}
		    })]: compacted
		  };
		};

		/**
		 * Picks the preferred compaction term from the given inverse context entry.
		 *
		 * @param activeCtx the active context.
		 * @param iri the IRI to pick the term for.
		 * @param value the value to pick the term for.
		 * @param containers the preferred containers.
		 * @param typeOrLanguage either '@type' or '@language'.
		 * @param typeOrLanguageValue the preferred value for '@type' or '@language'.
		 *
		 * @return the preferred term.
		 */
		function _selectTerm(
		  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {
		  if(typeOrLanguageValue === null) {
		    typeOrLanguageValue = '@null';
		  }

		  // preferences for the value of @type or @language
		  const prefs = [];

		  // determine prefs for @id based on whether or not value compacts to a term
		  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&
		    _isObject(value) && '@id' in value) {
		    // prefer @reverse first
		    if(typeOrLanguageValue === '@reverse') {
		      prefs.push('@reverse');
		    }
		    // try to compact value to a term
		    const term = api.compactIri(
		      {activeCtx, iri: value['@id'], relativeTo: {vocab: true}});
		    if(activeCtx.mappings.has(term) &&
		      activeCtx.mappings.get(term) &&
		      activeCtx.mappings.get(term)['@id'] === value['@id']) {
		      // prefer @vocab
		      prefs.push.apply(prefs, ['@vocab', '@id']);
		    } else {
		      // prefer @id
		      prefs.push.apply(prefs, ['@id', '@vocab']);
		    }
		  } else {
		    prefs.push(typeOrLanguageValue);

		    // consider direction only
		    const langDir = prefs.find(el => el.includes('_'));
		    if(langDir) {
		      // consider _dir portion
		      prefs.push(langDir.replace(/^[^_]+_/, '_'));
		    }
		  }
		  prefs.push('@none');

		  const containerMap = activeCtx.inverse[iri];
		  for(const container of containers) {
		    // if container not available in the map, continue
		    if(!(container in containerMap)) {
		      continue;
		    }

		    const typeOrLanguageValueMap = containerMap[container][typeOrLanguage];
		    for(const pref of prefs) {
		      // if type/language option not available in the map, continue
		      if(!(pref in typeOrLanguageValueMap)) {
		        continue;
		      }

		      // select term
		      return typeOrLanguageValueMap[pref];
		    }
		  }

		  return null;
		}

		/**
		 * The value of `@nest` in the term definition must either be `@nest`, or a term
		 * which resolves to `@nest`.
		 *
		 * @param activeCtx the active context.
		 * @param nestProperty a term in the active context or `@nest`.
		 * @param {Object} [options] - processing options.
		 */
		function _checkNestProperty(activeCtx, nestProperty, options) {
		  if(_expandIri(activeCtx, nestProperty, {vocab: true}, options) !== '@nest') {
		    throw new JsonLdError(
		      'JSON-LD compact error; nested property must have an @nest value ' +
		      'resolving to @nest.',
		      'jsonld.SyntaxError', {code: 'invalid @nest value'});
		  }
		}
		return compact;
	}

	/*
	 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
	 */

	var JsonLdProcessor;
	var hasRequiredJsonLdProcessor;

	function requireJsonLdProcessor () {
		if (hasRequiredJsonLdProcessor) return JsonLdProcessor;
		hasRequiredJsonLdProcessor = 1;

		JsonLdProcessor = jsonld => {
		  class JsonLdProcessor {
		    toString() {
		      return '[object JsonLdProcessor]';
		    }
		  }
		  Object.defineProperty(JsonLdProcessor, 'prototype', {
		    writable: false,
		    enumerable: false
		  });
		  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {
		    writable: true,
		    enumerable: false,
		    configurable: true,
		    value: JsonLdProcessor
		  });

		  // The Web IDL test harness will check the number of parameters defined in
		  // the functions below. The number of parameters must exactly match the
		  // required (non-optional) parameters of the JsonLdProcessor interface as
		  // defined here:
		  // https://www.w3.org/TR/json-ld-api/#the-jsonldprocessor-interface

		  JsonLdProcessor.compact = function(input, ctx) {
		    if(arguments.length < 2) {
		      return Promise.reject(
		        new TypeError('Could not compact, too few arguments.'));
		    }
		    return jsonld.compact(input, ctx);
		  };
		  JsonLdProcessor.expand = function(input) {
		    if(arguments.length < 1) {
		      return Promise.reject(
		        new TypeError('Could not expand, too few arguments.'));
		    }
		    return jsonld.expand(input);
		  };
		  JsonLdProcessor.flatten = function(input) {
		    if(arguments.length < 1) {
		      return Promise.reject(
		        new TypeError('Could not flatten, too few arguments.'));
		    }
		    return jsonld.flatten(input);
		  };

		  return JsonLdProcessor;
		};
		return JsonLdProcessor;
	}

	/**
	 * A JavaScript implementation of the JSON-LD API.
	 *
	 * @author Dave Longley
	 *
	 * @license BSD 3-Clause License
	 * Copyright (c) 2011-2022 Digital Bazaar, Inc.
	 * All rights reserved.
	 *
	 * Redistribution and use in source and binary forms, with or without
	 * modification, are permitted provided that the following conditions are met:
	 *
	 * Redistributions of source code must retain the above copyright notice,
	 * this list of conditions and the following disclaimer.
	 *
	 * Redistributions in binary form must reproduce the above copyright
	 * notice, this list of conditions and the following disclaimer in the
	 * documentation and/or other materials provided with the distribution.
	 *
	 * Neither the name of the Digital Bazaar, Inc. nor the names of its
	 * contributors may be used to endorse or promote products derived from
	 * this software without specific prior written permission.
	 *
	 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
	 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
	 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
	 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
	 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
	 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
	 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
	 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
	 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
	 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
	 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
	 */

	var jsonld$1;
	var hasRequiredJsonld;

	function requireJsonld () {
		if (hasRequiredJsonld) return jsonld$1;
		hasRequiredJsonld = 1;
		const canonize = requireRdfCanonize();
		const platform = requirePlatformBrowser();
		const util = requireUtil();
		const ContextResolver = requireContextResolver();
		const IdentifierIssuer = util.IdentifierIssuer;
		const JsonLdError = requireJsonLdError();
		const LRU = requireLruCache();
		const NQuads = requireNQuads();

		const {expand: _expand} = requireExpand();
		const {flatten: _flatten} = requireFlatten();
		const {fromRDF: _fromRDF} = requireFromRdf();
		const {toRDF: _toRDF} = requireToRdf();

		const {
		  frameMergedOrDefault: _frameMergedOrDefault,
		  cleanupNull: _cleanupNull
		} = requireFrame();

		const {
		  isArray: _isArray,
		  isObject: _isObject,
		  isString: _isString
		} = requireTypes();

		const {
		  isSubjectReference: _isSubjectReference,
		} = requireGraphTypes();

		const {
		  expandIri: _expandIri,
		  getInitialContext: _getInitialContext,
		  process: _processContext,
		  processingMode: _processingMode
		} = requireContext();

		const {
		  compact: _compact,
		  compactIri: _compactIri
		} = requireCompact();

		const {
		  createNodeMap: _createNodeMap,
		  createMergedNodeMap: _createMergedNodeMap,
		  mergeNodeMaps: _mergeNodeMaps
		} = requireNodeMap();

		const {
		  logEventHandler: _logEventHandler,
		  logWarningEventHandler: _logWarningEventHandler,
		  safeEventHandler: _safeEventHandler,
		  setDefaultEventHandler: _setDefaultEventHandler,
		  setupEventHandler: _setupEventHandler,
		  strictEventHandler: _strictEventHandler,
		  unhandledEventHandler: _unhandledEventHandler
		} = requireEvents();

		/* eslint-disable indent */
		// attaches jsonld API to the given object
		const wrapper = function(jsonld) {

		/** Registered RDF dataset parsers hashed by content-type. */
		const _rdfParsers = {};

		// resolved context cache
		// TODO: consider basing max on context size rather than number
		const RESOLVED_CONTEXT_CACHE_MAX_SIZE = 100;
		const _resolvedContextCache = new LRU({max: RESOLVED_CONTEXT_CACHE_MAX_SIZE});

		/* Core API */

		/**
		 * Performs JSON-LD compaction.
		 *
		 * @param input the JSON-LD input to compact.
		 * @param ctx the context to compact with.
		 * @param [options] options to use:
		 *          [base] the base IRI to use.
		 *          [compactArrays] true to compact arrays to single values when
		 *            appropriate, false not to (default: true).
		 *          [compactToRelative] true to compact IRIs to be relative to document
		 *            base, false to keep absolute (default: true)
		 *          [graph] true to always output a top-level graph (default: false).
		 *          [expandContext] a context to expand with.
		 *          [skipExpansion] true to assume the input is expanded and skip
		 *            expansion, false not to, defaults to false. Some well-formed
		 *            and safe-mode checks may be omitted.
		 *          [documentLoader(url, options)] the document loader.
		 *          [framing] true if compaction is occuring during a framing operation.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the compacted output.
		 */
		jsonld.compact = async function(input, ctx, options) {
		  if(arguments.length < 2) {
		    throw new TypeError('Could not compact, too few arguments.');
		  }

		  if(ctx === null) {
		    throw new JsonLdError(
		      'The compaction context must not be null.',
		      'jsonld.CompactError', {code: 'invalid local context'});
		  }

		  // nothing to compact
		  if(input === null) {
		    return null;
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : '',
		    compactArrays: true,
		    compactToRelative: true,
		    graph: false,
		    skipExpansion: false,
		    link: false,
		    issuer: new IdentifierIssuer('_:b'),
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });
		  if(options.link) {
		    // force skip expansion when linking, "link" is not part of the public
		    // API, it should only be called from framing
		    options.skipExpansion = true;
		  }
		  if(!options.compactToRelative) {
		    delete options.base;
		  }

		  // expand input
		  let expanded;
		  if(options.skipExpansion) {
		    expanded = input;
		  } else {
		    expanded = await jsonld.expand(input, options);
		  }

		  // process context
		  const activeCtx = await jsonld.processContext(
		    _getInitialContext(options), ctx, options);

		  // do compaction
		  let compacted = await _compact({
		    activeCtx,
		    element: expanded,
		    options
		  });

		  // perform clean up
		  if(options.compactArrays && !options.graph && _isArray(compacted)) {
		    if(compacted.length === 1) {
		      // simplify to a single item
		      compacted = compacted[0];
		    } else if(compacted.length === 0) {
		      // simplify to an empty object
		      compacted = {};
		    }
		  } else if(options.graph && _isObject(compacted)) {
		    // always use array if graph option is on
		    compacted = [compacted];
		  }

		  // follow @context key
		  if(_isObject(ctx) && '@context' in ctx) {
		    ctx = ctx['@context'];
		  }

		  // build output context
		  ctx = util.clone(ctx);
		  if(!_isArray(ctx)) {
		    ctx = [ctx];
		  }
		  // remove empty contexts
		  const tmp = ctx;
		  ctx = [];
		  for(let i = 0; i < tmp.length; ++i) {
		    if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {
		      ctx.push(tmp[i]);
		    }
		  }

		  // remove array if only one context
		  const hasContext = (ctx.length > 0);
		  if(ctx.length === 1) {
		    ctx = ctx[0];
		  }

		  // add context and/or @graph
		  if(_isArray(compacted)) {
		    // use '@graph' keyword
		    const graphAlias = _compactIri({
		      activeCtx, iri: '@graph', relativeTo: {vocab: true}
		    });
		    const graph = compacted;
		    compacted = {};
		    if(hasContext) {
		      compacted['@context'] = ctx;
		    }
		    compacted[graphAlias] = graph;
		  } else if(_isObject(compacted) && hasContext) {
		    // reorder keys so @context is first
		    const graph = compacted;
		    compacted = {'@context': ctx};
		    for(const key in graph) {
		      compacted[key] = graph[key];
		    }
		  }

		  return compacted;
		};

		/**
		 * Performs JSON-LD expansion.
		 *
		 * @param input the JSON-LD input to expand.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [keepFreeFloatingNodes] true to keep free-floating nodes,
		 *            false not to, defaults to false.
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the expanded output.
		 */
		jsonld.expand = async function(input, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not expand, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    keepFreeFloatingNodes: false,
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // build set of objects that may have @contexts to resolve
		  const toResolve = {};

		  // build set of contexts to process prior to expansion
		  const contextsToProcess = [];

		  // if an `expandContext` has been given ensure it gets resolved
		  if('expandContext' in options) {
		    const expandContext = util.clone(options.expandContext);
		    if(_isObject(expandContext) && '@context' in expandContext) {
		      toResolve.expandContext = expandContext;
		    } else {
		      toResolve.expandContext = {'@context': expandContext};
		    }
		    contextsToProcess.push(toResolve.expandContext);
		  }

		  // if input is a string, attempt to dereference remote document
		  let defaultBase;
		  if(!_isString(input)) {
		    // input is not a URL, do not need to retrieve it first
		    toResolve.input = util.clone(input);
		  } else {
		    // load remote doc
		    const remoteDoc = await jsonld.get(input, options);
		    defaultBase = remoteDoc.documentUrl;
		    toResolve.input = remoteDoc.document;
		    if(remoteDoc.contextUrl) {
		      // context included in HTTP link header and must be resolved
		      toResolve.remoteContext = {'@context': remoteDoc.contextUrl};
		      contextsToProcess.push(toResolve.remoteContext);
		    }
		  }

		  // set default base
		  if(!('base' in options)) {
		    options.base = defaultBase || '';
		  }

		  // process any additional contexts
		  let activeCtx = _getInitialContext(options);
		  for(const localCtx of contextsToProcess) {
		    activeCtx = await _processContext({activeCtx, localCtx, options});
		  }

		  // expand resolved input
		  let expanded = await _expand({
		    activeCtx,
		    element: toResolve.input,
		    options
		  });

		  // optimize away @graph with no other properties
		  if(_isObject(expanded) && ('@graph' in expanded) &&
		    Object.keys(expanded).length === 1) {
		    expanded = expanded['@graph'];
		  } else if(expanded === null) {
		    expanded = [];
		  }

		  // normalize to an array
		  if(!_isArray(expanded)) {
		    expanded = [expanded];
		  }

		  return expanded;
		};

		/**
		 * Performs JSON-LD flattening.
		 *
		 * @param input the JSON-LD to flatten.
		 * @param ctx the context to use to compact the flattened output, or null.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [documentLoader(url, options)] the document loader.
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the flattened output.
		 */
		jsonld.flatten = async function(input, ctx, options) {
		  if(arguments.length < 1) {
		    return new TypeError('Could not flatten, too few arguments.');
		  }

		  if(typeof ctx === 'function') {
		    ctx = null;
		  } else {
		    ctx = ctx || null;
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : '',
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // expand input
		  const expanded = await jsonld.expand(input, options);

		  // do flattening
		  const flattened = _flatten(expanded);

		  if(ctx === null) {
		    // no compaction required
		    return flattened;
		  }

		  // compact result (force @graph option to true, skip expansion)
		  options.graph = true;
		  options.skipExpansion = true;
		  const compacted = await jsonld.compact(flattened, ctx, options);

		  return compacted;
		};

		/**
		 * Performs JSON-LD framing.
		 *
		 * @param input the JSON-LD input to frame.
		 * @param frame the JSON-LD frame to use.
		 * @param [options] the framing options.
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [embed] default @embed flag: '@last', '@always', '@never', '@link'
		 *            (default: '@last').
		 *          [explicit] default @explicit flag (default: false).
		 *          [requireAll] default @requireAll flag (default: true).
		 *          [omitDefault] default @omitDefault flag (default: false).
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the framed output.
		 */
		jsonld.frame = async function(input, frame, options) {
		  if(arguments.length < 2) {
		    throw new TypeError('Could not frame, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : '',
		    embed: '@once',
		    explicit: false,
		    requireAll: false,
		    omitDefault: false,
		    bnodesToClear: [],
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // if frame is a string, attempt to dereference remote document
		  if(_isString(frame)) {
		    // load remote doc
		    const remoteDoc = await jsonld.get(frame, options);
		    frame = remoteDoc.document;

		    if(remoteDoc.contextUrl) {
		      // inject link header @context into frame
		      let ctx = frame['@context'];
		      if(!ctx) {
		        ctx = remoteDoc.contextUrl;
		      } else if(_isArray(ctx)) {
		        ctx.push(remoteDoc.contextUrl);
		      } else {
		        ctx = [ctx, remoteDoc.contextUrl];
		      }
		      frame['@context'] = ctx;
		    }
		  }

		  const frameContext = frame ? frame['@context'] || {} : {};

		  // process context
		  const activeCtx = await jsonld.processContext(
		    _getInitialContext(options), frameContext, options);

		  // mode specific defaults
		  if(!options.hasOwnProperty('omitGraph')) {
		    options.omitGraph = _processingMode(activeCtx, 1.1);
		  }
		  if(!options.hasOwnProperty('pruneBlankNodeIdentifiers')) {
		    options.pruneBlankNodeIdentifiers = _processingMode(activeCtx, 1.1);
		  }

		  // expand input
		  const expanded = await jsonld.expand(input, options);

		  // expand frame
		  const opts = {...options};
		  opts.isFrame = true;
		  opts.keepFreeFloatingNodes = true;
		  const expandedFrame = await jsonld.expand(frame, opts);

		  // if the unexpanded frame includes a key expanding to @graph, frame the
		  // default graph, otherwise, the merged graph
		  const frameKeys = Object.keys(frame)
		    .map(key => _expandIri(activeCtx, key, {vocab: true}));
		  opts.merged = !frameKeys.includes('@graph');
		  opts.is11 = _processingMode(activeCtx, 1.1);

		  // do framing
		  const framed = _frameMergedOrDefault(expanded, expandedFrame, opts);

		  opts.graph = !options.omitGraph;
		  opts.skipExpansion = true;
		  opts.link = {};
		  opts.framing = true;
		  let compacted = await jsonld.compact(framed, frameContext, opts);

		  // replace @null with null, compacting arrays
		  opts.link = {};
		  compacted = _cleanupNull(compacted, opts);

		  return compacted;
		};

		/**
		 * **Experimental**
		 *
		 * Links a JSON-LD document's nodes in memory.
		 *
		 * @param input the JSON-LD document to link.
		 * @param [ctx] the JSON-LD context to apply.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the linked output.
		 */
		jsonld.link = async function(input, ctx, options) {
		  // API matches running frame with a wildcard frame and embed: '@link'
		  // get arguments
		  const frame = {};
		  if(ctx) {
		    frame['@context'] = ctx;
		  }
		  frame['@embed'] = '@link';
		  return jsonld.frame(input, frame, options);
		};

		/**
		 * Performs RDF dataset normalization on the given input. The input is JSON-LD
		 * unless the 'inputFormat' option is used. The output is an RDF dataset
		 * unless the 'format' option is used.
		 *
		 * Note: Canonicalization sets `safe` to `true` and `base` to `null` by
		 * default in order to produce safe outputs and "fail closed" by default. This
		 * is different from the other API transformations in this version which
		 * allow unsafe defaults (for cryptographic usage) in order to comply with the
		 * JSON-LD 1.1 specification.
		 *
		 * @param input the input to normalize as JSON-LD or as a format specified by
		 *          the 'inputFormat' option.
		 * @param [options] the options to use:
		 *          [algorithm] the normalization algorithm to use, `URDNA2015` or
		 *            `URGNA2012` (default: `URDNA2015`).
		 *          [base] the base IRI to use (default: `null`).
		 *          [expandContext] a context to expand with.
		 *          [skipExpansion] true to assume the input is expanded and skip
		 *            expansion, false not to, defaults to false. Some well-formed
		 *            and safe-mode checks may be omitted.
		 *          [inputFormat] the format if input is not JSON-LD:
		 *            'application/n-quads' for N-Quads.
		 *          [format] the format if output is a string:
		 *            'application/n-quads' for N-Quads.
		 *          [documentLoader(url, options)] the document loader.
		 *          [useNative] true to use a native canonize algorithm
		 *          [rdfDirection] null or 'i18n-datatype' to support RDF
		 *             transformation of @direction (default: null).
		 *          [safe] true to use safe mode. (default: true).
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the normalized output.
		 */
		jsonld.normalize = jsonld.canonize = async function(input, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not canonize, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : null,
		    algorithm: 'URDNA2015',
		    skipExpansion: false,
		    safe: true,
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });
		  if('inputFormat' in options) {
		    if(options.inputFormat !== 'application/n-quads' &&
		      options.inputFormat !== 'application/nquads') {
		      throw new JsonLdError(
		        'Unknown canonicalization input format.',
		        'jsonld.CanonizeError');
		    }
		    // TODO: `await` for async parsers
		    const parsedInput = NQuads.parse(input);

		    // do canonicalization
		    return canonize.canonize(parsedInput, options);
		  }

		  // convert to RDF dataset then do normalization
		  const opts = {...options};
		  delete opts.format;
		  opts.produceGeneralizedRdf = false;
		  const dataset = await jsonld.toRDF(input, opts);

		  // do canonicalization
		  return canonize.canonize(dataset, options);
		};

		/**
		 * Converts an RDF dataset to JSON-LD.
		 *
		 * @param dataset a serialized string of RDF in a format specified by the
		 *          format option or an RDF dataset to convert.
		 * @param [options] the options to use:
		 *          [format] the format if dataset param must first be parsed:
		 *            'application/n-quads' for N-Quads (default).
		 *          [rdfParser] a custom RDF-parser to use to parse the dataset.
		 *          [useRdfType] true to use rdf:type, false to use @type
		 *            (default: false).
		 *          [useNativeTypes] true to convert XSD types into native types
		 *            (boolean, integer, double), false not to (default: false).
		 *          [rdfDirection] null or 'i18n-datatype' to support RDF
		 *             transformation of @direction (default: null).
		 *          [safe] true to use safe mode. (default: false)
		 *
		 * @return a Promise that resolves to the JSON-LD document.
		 */
		jsonld.fromRDF = async function(dataset, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not convert from RDF, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    format: _isString(dataset) ? 'application/n-quads' : undefined
		  });

		  const {format} = options;
		  let {rdfParser} = options;

		  // handle special format
		  if(format) {
		    // check supported formats
		    rdfParser = rdfParser || _rdfParsers[format];
		    if(!rdfParser) {
		      throw new JsonLdError(
		        'Unknown input format.',
		        'jsonld.UnknownFormat', {format});
		    }
		  } else {
		    // no-op parser, assume dataset already parsed
		    rdfParser = () => dataset;
		  }

		  // rdfParser must be synchronous or return a promise, no callback support
		  const parsedDataset = await rdfParser(dataset);
		  return _fromRDF(parsedDataset, options);
		};

		/**
		 * Outputs the RDF dataset found in the given JSON-LD object.
		 *
		 * @param input the JSON-LD input.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [skipExpansion] true to assume the input is expanded and skip
		 *            expansion, false not to, defaults to false. Some well-formed
		 *            and safe-mode checks may be omitted.
		 *          [format] the format to use to output a string:
		 *            'application/n-quads' for N-Quads.
		 *          [produceGeneralizedRdf] true to output generalized RDF, false
		 *            to produce only standard RDF (default: false).
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [rdfDirection] null or 'i18n-datatype' to support RDF
		 *             transformation of @direction (default: null).
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the RDF dataset.
		 */
		jsonld.toRDF = async function(input, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not convert to RDF, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : '',
		    skipExpansion: false,
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // TODO: support toRDF custom map?
		  let expanded;
		  if(options.skipExpansion) {
		    expanded = input;
		  } else {
		    // expand input
		    expanded = await jsonld.expand(input, options);
		  }

		  // output RDF dataset
		  const dataset = _toRDF(expanded, options);
		  if(options.format) {
		    if(options.format === 'application/n-quads' ||
		      options.format === 'application/nquads') {
		      return NQuads.serialize(dataset);
		    }
		    throw new JsonLdError(
		      'Unknown output format.',
		      'jsonld.UnknownFormat', {format: options.format});
		  }

		  return dataset;
		};

		/**
		 * **Experimental**
		 *
		 * Recursively flattens the nodes in the given JSON-LD input into a merged
		 * map of node ID => node. All graphs will be merged into the default graph.
		 *
		 * @param input the JSON-LD input.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
		 *          [documentLoader(url, options)] the document loader.
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the merged node map.
		 */
		jsonld.createNodeMap = async function(input, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not create node map, too few arguments.');
		  }

		  // set default options
		  options = _setDefaults(options, {
		    base: _isString(input) ? input : '',
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // expand input
		  const expanded = await jsonld.expand(input, options);

		  return _createMergedNodeMap(expanded, options);
		};

		/**
		 * **Experimental**
		 *
		 * Merges two or more JSON-LD documents into a single flattened document.
		 *
		 * @param docs the JSON-LD documents to merge together.
		 * @param ctx the context to use to compact the merged result, or null.
		 * @param [options] the options to use:
		 *          [base] the base IRI to use.
		 *          [expandContext] a context to expand with.
		 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
		 *          [mergeNodes] true to merge properties for nodes with the same ID,
		 *            false to ignore new properties for nodes with the same ID once
		 *            the ID has been defined; note that this may not prevent merging
		 *            new properties where a node is in the `object` position
		 *            (default: true).
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the merged output.
		 */
		jsonld.merge = async function(docs, ctx, options) {
		  if(arguments.length < 1) {
		    throw new TypeError('Could not merge, too few arguments.');
		  }
		  if(!_isArray(docs)) {
		    throw new TypeError('Could not merge, "docs" must be an array.');
		  }

		  if(typeof ctx === 'function') {
		    ctx = null;
		  } else {
		    ctx = ctx || null;
		  }

		  // set default options
		  options = _setDefaults(options, {
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // expand all documents
		  const expanded = await Promise.all(docs.map(doc => {
		    const opts = {...options};
		    return jsonld.expand(doc, opts);
		  }));

		  let mergeNodes = true;
		  if('mergeNodes' in options) {
		    mergeNodes = options.mergeNodes;
		  }

		  const issuer = options.issuer || new IdentifierIssuer('_:b');
		  const graphs = {'@default': {}};

		  for(let i = 0; i < expanded.length; ++i) {
		    // uniquely relabel blank nodes
		    const doc = util.relabelBlankNodes(expanded[i], {
		      issuer: new IdentifierIssuer('_:b' + i + '-')
		    });

		    // add nodes to the shared node map graphs if merging nodes, to a
		    // separate graph set if not
		    const _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};
		    _createNodeMap(doc, _graphs, '@default', issuer);

		    if(_graphs !== graphs) {
		      // merge document graphs but don't merge existing nodes
		      for(const graphName in _graphs) {
		        const _nodeMap = _graphs[graphName];
		        if(!(graphName in graphs)) {
		          graphs[graphName] = _nodeMap;
		          continue;
		        }
		        const nodeMap = graphs[graphName];
		        for(const key in _nodeMap) {
		          if(!(key in nodeMap)) {
		            nodeMap[key] = _nodeMap[key];
		          }
		        }
		      }
		    }
		  }

		  // add all non-default graphs to default graph
		  const defaultGraph = _mergeNodeMaps(graphs);

		  // produce flattened output
		  const flattened = [];
		  const keys = Object.keys(defaultGraph).sort();
		  for(let ki = 0; ki < keys.length; ++ki) {
		    const node = defaultGraph[keys[ki]];
		    // only add full subjects to top-level
		    if(!_isSubjectReference(node)) {
		      flattened.push(node);
		    }
		  }

		  if(ctx === null) {
		    return flattened;
		  }

		  // compact result (force @graph option to true, skip expansion)
		  options.graph = true;
		  options.skipExpansion = true;
		  const compacted = await jsonld.compact(flattened, ctx, options);

		  return compacted;
		};

		/**
		 * The default document loader for external documents.
		 *
		 * @param url the URL to load.
		 *
		 * @return a promise that resolves to the remote document.
		 */
		Object.defineProperty(jsonld, 'documentLoader', {
		  get: () => jsonld._documentLoader,
		  set: v => jsonld._documentLoader = v
		});
		// default document loader not implemented
		jsonld.documentLoader = async url => {
		  throw new JsonLdError(
		    'Could not retrieve a JSON-LD document from the URL. URL ' +
		    'dereferencing not implemented.', 'jsonld.LoadDocumentError',
		    {code: 'loading document failed', url});
		};

		/**
		 * Gets a remote JSON-LD document using the default document loader or
		 * one given in the passed options.
		 *
		 * @param url the URL to fetch.
		 * @param [options] the options to use:
		 *          [documentLoader] the document loader to use.
		 *
		 * @return a Promise that resolves to the retrieved remote document.
		 */
		jsonld.get = async function(url, options) {
		  let load;
		  if(typeof options.documentLoader === 'function') {
		    load = options.documentLoader;
		  } else {
		    load = jsonld.documentLoader;
		  }

		  const remoteDoc = await load(url);

		  try {
		    if(!remoteDoc.document) {
		      throw new JsonLdError(
		        'No remote document found at the given URL.',
		        'jsonld.NullRemoteDocument');
		    }
		    if(_isString(remoteDoc.document)) {
		      remoteDoc.document = JSON.parse(remoteDoc.document);
		    }
		  } catch(e) {
		    throw new JsonLdError(
		      'Could not retrieve a JSON-LD document from the URL.',
		      'jsonld.LoadDocumentError', {
		        code: 'loading document failed',
		        cause: e,
		        remoteDoc
		      });
		  }

		  return remoteDoc;
		};

		/**
		 * Processes a local context, resolving any URLs as necessary, and returns a
		 * new active context.
		 *
		 * @param activeCtx the current active context.
		 * @param localCtx the local context to process.
		 * @param [options] the options to use:
		 *          [documentLoader(url, options)] the document loader.
		 *          [safe] true to use safe mode. (default: false)
		 *          [contextResolver] internal use only.
		 *
		 * @return a Promise that resolves to the new active context.
		 */
		jsonld.processContext = async function(
		  activeCtx, localCtx, options) {
		  // set default options
		  options = _setDefaults(options, {
		    base: '',
		    contextResolver: new ContextResolver(
		      {sharedCache: _resolvedContextCache})
		  });

		  // return initial context early for null context
		  if(localCtx === null) {
		    return _getInitialContext(options);
		  }

		  // get URLs in localCtx
		  localCtx = util.clone(localCtx);
		  if(!(_isObject(localCtx) && '@context' in localCtx)) {
		    localCtx = {'@context': localCtx};
		  }

		  return _processContext({activeCtx, localCtx, options});
		};

		// backwards compatibility
		jsonld.getContextValue = requireContext().getContextValue;

		/**
		 * Document loaders.
		 */
		jsonld.documentLoaders = {};

		/**
		 * Assigns the default document loader for external document URLs to a built-in
		 * default. Supported types currently include: 'xhr' and 'node'.
		 *
		 * @param type the type to set.
		 * @param [params] the parameters required to use the document loader.
		 */
		jsonld.useDocumentLoader = function(type) {
		  if(!(type in jsonld.documentLoaders)) {
		    throw new JsonLdError(
		      'Unknown document loader type: "' + type + '"',
		      'jsonld.UnknownDocumentLoader',
		      {type});
		  }

		  // set document loader
		  jsonld.documentLoader = jsonld.documentLoaders[type].apply(
		    jsonld, Array.prototype.slice.call(arguments, 1));
		};

		/**
		 * Registers an RDF dataset parser by content-type, for use with
		 * jsonld.fromRDF. An RDF dataset parser will always be given one parameter,
		 * a string of input. An RDF dataset parser can be synchronous or
		 * asynchronous (by returning a promise).
		 *
		 * @param contentType the content-type for the parser.
		 * @param parser(input) the parser function (takes a string as a parameter
		 *          and either returns an RDF dataset or a Promise that resolves to one.
		 */
		jsonld.registerRDFParser = function(contentType, parser) {
		  _rdfParsers[contentType] = parser;
		};

		/**
		 * Unregisters an RDF dataset parser by content-type.
		 *
		 * @param contentType the content-type for the parser.
		 */
		jsonld.unregisterRDFParser = function(contentType) {
		  delete _rdfParsers[contentType];
		};

		// register the N-Quads RDF parser
		jsonld.registerRDFParser('application/n-quads', NQuads.parse);
		jsonld.registerRDFParser('application/nquads', NQuads.parse);

		/* URL API */
		jsonld.url = requireUrl();

		/* Events API and handlers */
		jsonld.logEventHandler = _logEventHandler;
		jsonld.logWarningEventHandler = _logWarningEventHandler;
		jsonld.safeEventHandler = _safeEventHandler;
		jsonld.setDefaultEventHandler = _setDefaultEventHandler;
		jsonld.strictEventHandler = _strictEventHandler;
		jsonld.unhandledEventHandler = _unhandledEventHandler;

		/* Utility API */
		jsonld.util = util;
		// backwards compatibility
		Object.assign(jsonld, util);

		// reexpose API as jsonld.promises for backwards compatability
		jsonld.promises = jsonld;

		// backwards compatibility
		jsonld.RequestQueue = requireRequestQueue();

		/* WebIDL API */
		jsonld.JsonLdProcessor = requireJsonLdProcessor()(jsonld);

		platform.setupGlobals(jsonld);
		platform.setupDocumentLoaders(jsonld);

		function _setDefaults(options, {
		  documentLoader = jsonld.documentLoader,
		  ...defaults
		}) {
		  // fail if obsolete options present
		  if(options && 'compactionMap' in options) {
		    throw new JsonLdError(
		      '"compactionMap" not supported.',
		      'jsonld.OptionsError');
		  }
		  if(options && 'expansionMap' in options) {
		    throw new JsonLdError(
		      '"expansionMap" not supported.',
		      'jsonld.OptionsError');
		  }
		  return Object.assign(
		    {},
		    {documentLoader},
		    defaults,
		    options,
		    {eventHandler: _setupEventHandler({options})}
		  );
		}

		// end of jsonld API `wrapper` factory
		return jsonld;
		};

		// external APIs:

		// used to generate a new jsonld API instance
		const factory = function() {
		  return wrapper(function() {
		    return factory();
		  });
		};

		// wrap the main jsonld API instance
		wrapper(factory);
		// export API
		jsonld$1 = factory;
		return jsonld$1;
	}

	var jsonldExports = requireJsonld();
	var jsonld = /*@__PURE__*/getDefaultExportFromCjs(jsonldExports);

	class Sink {
	  constructor (Impl, options) {
	    this.Impl = Impl;
	    this.options = options;
	  }

	  import (input, options) {
	    const output = new this.Impl(input, { ...this.options, ...options });

	    input.on('end', () => {
	      if (!output.readable) {
	        output.emit('end');
	      }
	    });

	    input.on('error', err => {
	      output.emit('error', err);
	    });

	    return output
	  }
	}

	class ObjectEncoder {
	  constructor (stream) {
	    this.stream = stream;
	    this.array = [];
	  }

	  push (jsonld) {
	    this.array.push(jsonld);
	  }

	  end () {
	    this.stream.push(this.array);
	    this.stream.push(null);
	  }
	}

	class StringEncoder {
	  constructor (stream) {
	    this.stream = stream;
	    this.first = true;

	    this.stream.push('[');
	  }

	  push (jsonld) {
	    if (this.first) {
	      this.first = false;
	    } else {
	      this.stream.push(',');
	    }

	    this.stream.push(JSON.stringify(jsonld));
	  }

	  end () {
	    this.stream.push(']');
	    this.stream.push(null);
	  }
	}

	class SerializerStream extends browserExports.Readable {
	  constructor (input, { encoding = 'object' } = {}) {
	    super({
	      objectMode: true,
	      read: () => {}
	    });

	    if (encoding === 'object') {
	      this.encoder = new ObjectEncoder(this);
	    }

	    if (encoding === 'string') {
	      this.encoder = new StringEncoder(this);
	    }

	    if (!this.encoder) {
	      throw new Error(`unknown encoding: ${encoding}`)
	    }

	    input.on('data', quad => {
	      const jsonld = {};
	      let triple = jsonld;

	      if (quad.graph.termType !== 'DefaultGraph') {
	        jsonld['@id'] = quad.graph.value;
	        jsonld['@graph'] = {};
	        triple = jsonld['@graph'];
	      }

	      triple['@id'] = SerializerStream.subjectValue(quad.subject);

	      if (quad.predicate.value === 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type') {
	        triple['@type'] = SerializerStream.subjectValue(quad.object);
	      } else {
	        triple[quad.predicate.value] = SerializerStream.objectValue(quad.object);
	      }

	      this.encoder.push(jsonld);
	    });

	    input.on('end', () => this.encoder.end());

	    input.on('error', err => this.emit('error', err));
	  }

	  static subjectValue (subject) {
	    return subject.termType === 'BlankNode' ? '_:' + subject.value : subject.value
	  }

	  static objectValue (object) {
	    if (object.termType === 'NamedNode') {
	      return { '@id': object.value }
	    }

	    if (object.termType === 'BlankNode') {
	      return { '@id': '_:' + object.value }
	    }

	    if (object.language) {
	      return { '@language': object.language, '@value': object.value }
	    } else if (object.datatype && object.datatype.value !== 'http://www.w3.org/2001/XMLSchema#string') {
	      return { '@type': object.datatype.value, '@value': object.value }
	    } else {
	      return object.value
	    }
	  }
	}

	class Serializer extends Sink {
	  constructor (options) {
	    super(SerializerStream, options);
	  }
	}

	// UMD global for browser
	var index = {
	    parseMarkdownLD,
	    fromRDFToMarkdownLD,
	    markdownLDToTurtle,
	    validateSHACL,
	    generateSampleOntology
	};
	// Use the DataFactory from N3 for all N3 operations.
	const dataFactory = DataFactory;
	const { namedNode, literal, blankNode, quad } = dataFactory;
	const LIBRARY_METADATA = {
	    parsedBy: 'markdown-ld-star v1.5.0',
	    libraryUrl: 'https://github.com/mediaprophet/markdown-ld-star'
	};
	function parseMarkdownLD(content, options = {}) {
	    const format = options.format || 'turtle';
	    const processor = unified().use(remarkParse).use(remarkStringify);
	    const ast = processor.parse(content);
	    const prefixes = {};
	    const store = new N3.Store();
	    const constraints = [];
	    let currentSection = null;
	    const resolveUri = (part, defaultPrefix = 'ex') => {
	        if (part.startsWith('http'))
	            return part;
	        const [prefix, local] = part.includes(':') ? part.split(':') : [defaultPrefix, part];
	        return prefixes[prefix] ? `${prefixes[prefix]}${local}` : part;
	    };
	    const parseValue = (value) => {
	        if (value.startsWith('<<') && value.endsWith('>>')) {
	            const match = value.match(/<<\s*\[([^\]]+)\]\s+([^\s]+)\s+\[([^\]]+)\]\s*>>/);
	            if (match) {
	                const [, s, p, o] = match;
	                // Only allow NamedNode or BlankNode for subject/predicate, NamedNode/BlankNode/Literal for object
	                const subj = namedNode(resolveUri(s));
	                const pred = namedNode(resolveUri(p));
	                let obj;
	                if (o.startsWith('_:')) {
	                    obj = blankNode(o.slice(2));
	                }
	                else if (o.startsWith('"')) {
	                    obj = literal(o.slice(1, -1));
	                }
	                else {
	                    obj = namedNode(resolveUri(o));
	                }
	                return quotedTriple(subj, pred, obj);
	            }
	            throw new Error('Invalid quoted triple');
	        }
	        else if (value.startsWith('"')) {
	            return literal(value.slice(1, -1));
	        }
	        else if (value.startsWith('_:')) {
	            return blankNode(value.slice(2));
	        }
	        else {
	            return namedNode(resolveUri(value));
	        }
	    };
	    for (const node of ast.children) {
	        if (node.type === 'definition' && node.label && node.url) {
	            prefixes[node.label] = node.url;
	        }
	        else if (node.type === 'heading' && node.children[0]?.type === 'text') {
	            currentSection = node.children[0].value.toLowerCase();
	        }
	        else if (node.type === 'paragraph' && currentSection?.includes('shacl constraint')) {
	            const sparqlNode = node.children.find((c) => c.type === 'code' && c.lang === 'sparql');
	            if (sparqlNode)
	                constraints.push(sparqlNode.value);
	        }
	        else if (node.type === 'paragraph') {
	            const text = processor.stringify({ type: 'root', children: [node] }).trim();
	            // Node syntax: [Label]{typeof=type; prop=value; ...}
	            const nodeMatch = text.match(/\[([^\]]+)\](?:\{([^}]+)\})?/);
	            if (nodeMatch) {
	                const label = nodeMatch[1].trim();
	                const uri = resolveUri(label.replace(/\s+/g, '_'));
	                const subject = namedNode(uri);
	                if (nodeMatch[2]) {
	                    const props = nodeMatch[2].split(';').map((p) => p.trim());
	                    for (const prop of props) {
	                        if (!prop)
	                            continue;
	                        const [key, val] = prop.split('=').map((s) => s.trim());
	                        const [prefix, local] = key.includes(':') ? key.split(':') : ['ex', key];
	                        const predUri = resolveUri(`${prefix}:${local}`);
	                        const predicate = namedNode(predUri);
	                        if (key === 'typeof') {
	                            store.addQuad(subject, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), parseValue(val));
	                        }
	                        else {
	                            store.addQuad(subject, predicate, parseValue(val));
	                        }
	                    }
	                }
	            }
	            else {
	                // Quoted triple as subject: <<[S] p [O]>> q [R]
	                const qtMatch = text.match(/<<\s*\[([^\]]+)\]\s+([^\s]+)\s+\[([^\]]+)\]\s*>>\s+([^\s]+)\s+(.+)/);
	                if (qtMatch) {
	                    const [, s, p, o, q, r] = qtMatch;
	                    const qt = quad(namedNode(resolveUri(s)), namedNode(resolveUri(p)), namedNode(resolveUri(o)));
	                    store.addQuad(qt, namedNode(resolveUri(q)), parseValue(r));
	                }
	                // Annotation syntax: [S] p [O] {| q r ; ... |}
	                const annMatch = text.match(/\[([^\]]+)\]\s+([^\s]+)\s+\[([^\]]+)\]\s*\{\|\s*([^|]+)\s*\|}/);
	                if (annMatch) {
	                    const [, s, p, o, anns] = annMatch;
	                    const sub = namedNode(resolveUri(s));
	                    const pred = namedNode(resolveUri(p));
	                    const obj = namedNode(resolveUri(o));
	                    store.addQuad(sub, pred, obj); // Assert the triple
	                    const qt = quad(sub, pred, obj);
	                    const annProps = anns.split(';').map((a) => a.trim());
	                    for (const ann of annProps) {
	                        if (!ann)
	                            continue;
	                        const [key, val] = ann.split('=').map((kv) => kv.trim());
	                        const annPred = namedNode(resolveUri(key));
	                        store.addQuad(qt, annPred, parseValue(val));
	                    }
	                }
	            }
	        }
	    }
	    let output;
	    if (format === 'turtle') {
	        const writer = new N3.Writer({ prefixes });
	        store.forEach((quad, _dataset) => writer.addQuad(quad));
	        writer.end((error, result) => {
	            if (error)
	                throw error;
	            output = result;
	        });
	    }
	    else if (format === 'jsonld') {
	        const jsonldSerializer = new Serializer();
	        const quads = store.getQuads(null, null, null, null);
	        const quadStream = new stream$1.Readable({
	            objectMode: true,
	            read() {
	                quads.forEach((q) => this.push(q));
	                this.push(null);
	            }
	        });
	        const jsonldStream = jsonldSerializer.import(quadStream);
	        let jsonldString = '';
	        jsonldStream.on('data', (chunk) => {
	            jsonldString += chunk.toString();
	        });
	        jsonldStream.on('end', () => {
	            output = JSON.parse(jsonldString);
	            output.metadata = LIBRARY_METADATA;
	        });
	    }
	    else if (format === 'rdfjson') {
	        output = toRDFJSON(store);
	        output.metadata = LIBRARY_METADATA;
	    }
	    else if (format === 'jsonldstar') {
	        output = toJSONLDStar(store);
	        output.metadata = LIBRARY_METADATA;
	    }
	    return { output, constraints };
	}
	async function fromRDFToMarkdownLD(input, inputFormat) {
	    const store = new N3.Store();
	    if (inputFormat === 'turtle' || inputFormat === 'n3' || inputFormat === 'trig') {
	        const parser = new N3.Parser({ format: inputFormat === 'trig' ? 'TriG' : 'Turtle' });
	        const quads = parser.parse(input);
	        store.addQuads(quads);
	    }
	    else if (inputFormat === 'jsonld') {
	        const doc = JSON.parse(input);
	        const nquads = await jsonld.toRDF(doc, { format: 'application/n-quads' });
	        const parser = new N3.Parser({ format: 'N-Quads' });
	        const quads = parser.parse(nquads);
	        store.addQuads(quads);
	    }
	    // Skipped RDF/JSON-LD* streaming parse for now (rdfParse/textStream not defined)
	    // Generate Markdown-LD
	    const namespaceMap = new Map();
	    const uris = new Set();
	    store.forEach((quad, _store) => {
	        if (quad.subject.termType === 'NamedNode')
	            uris.add(quad.subject.value);
	        if (quad.predicate.termType === 'NamedNode')
	            uris.add(quad.predicate.value);
	        if (quad.object.termType === 'NamedNode')
	            uris.add(quad.object.value);
	        if (quad.graph.termType === 'NamedNode')
	            uris.add(quad.graph.value);
	        if (isQuotedTriple(quad.subject)) {
	            const subj = quad.subject;
	            [subj.subject, subj.predicate, subj.object].forEach((term) => {
	                if (term.termType === 'NamedNode')
	                    uris.add(term.value);
	            });
	        }
	        if (isQuotedTriple(quad.object)) {
	            const obj = quad.object;
	            [obj.subject, obj.predicate, obj.object].forEach((term) => {
	                if (term.termType === 'NamedNode')
	                    uris.add(term.value);
	            });
	        }
	    });
	    const commonPrefixes = {
	        rdf: 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',
	        rdfs: 'http://www.w3.org/2000/01/rdf-schema#',
	        owl: 'http://www.w3.org/2002/07/owl#',
	        sh: 'http://www.w3.org/ns/shacl#',
	        schema: 'http://schema.org/',
	        xsd: 'http://www.w3.org/2001/XMLSchema#',
	    };
	    let prefixCounter = 0;
	    for (const uri of uris) {
	        const ns = uri.replace(/[^\/#][^\/]*$/, '');
	        if (ns && !Array.from(namespaceMap.values()).includes(ns)) {
	            let prefix = Object.keys(commonPrefixes).find(p => commonPrefixes[p] === ns);
	            if (!prefix)
	                prefix = `ns${prefixCounter++}`;
	            namespaceMap.set(prefix, ns);
	        }
	    }
	    if (!namespaceMap.has('ex'))
	        namespaceMap.set('ex', 'http://example.org/');
	    new Map(Array.from(namespaceMap, a => [a[1], a[0]]));
	    // Refactor getPrefixed to handle Term objects directly
	    const getPrefixed = (term) => {
	        if (isQuotedTriple(term)) {
	            // Recursively handle quoted triples
	            return `<<${getPrefixed(term.subject)} ${getPrefixed(term.predicate)} ${getPrefixed(term.object)}>>`;
	        }
	        else if (term.termType === 'NamedNode' || term.termType === 'BlankNode') {
	            return term.value;
	        }
	        else if (term.termType === 'Literal') {
	            return '"' + term.value + '"';
	        }
	        else {
	            throw new Error('Unsupported term type');
	        }
	    };
	    let md = '';
	    // Prefixes
	    for (const [prefix, ns] of namespaceMap) {
	        md += `[${prefix}]: ${ns}\n`;
	    }
	    md += '\n';
	    // Typed nodes
	    const typedSubjects = store.getSubjects(namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), null, null).filter((s) => s.termType === 'NamedNode');
	    for (const subj of typedSubjects) {
	        const label = getPrefixed(subj);
	        const types = store.getObjects(subj, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), null);
	        const type = types.length > 0 ? `typeof=${getPrefixed(types[0])}; ` : '';
	        const props = store.getQuads(subj, null, null, null).filter((q) => q.predicate.termType === 'NamedNode' && !isQuotedTriple(q.object));
	        let nodeRepresentation = `[${label}]{`;
	        nodeRepresentation += type;
	        props.forEach((prop) => {
	            const p = getPrefixed(prop.predicate);
	            const o = prop.object.termType === 'Literal' ? `"${prop.object.value}"` : getPrefixed(prop.object);
	            nodeRepresentation += `${p}=${o}; `;
	        });
	        nodeRepresentation = nodeRepresentation.trimEnd() + '}\n';
	        md += nodeRepresentation;
	    }
	    // Annotations
	    const assertedQuads = store.getQuads(null, null, null, dataFactory.defaultGraph()).filter((q) => q.subject.termType === 'NamedNode' && q.object.termType === 'NamedNode');
	    for (const q of assertedQuads) {
	        const qt = quotedTriple(q.subject, q.predicate, q.object);
	        const annQuads = store.getQuads(qt, null, null, null);
	        if (annQuads.length > 0) {
	            const s = getPrefixed(q.subject);
	            const p = getPrefixed(q.predicate);
	            const o = getPrefixed(q.object);
	            md += `[${s}] ${p} [${o}] {| `;
	            for (const ann of annQuads) {
	                const ap = getPrefixed(ann.predicate);
	                const ao = ann.object.termType === 'Literal' ? `"${ann.object.value}"` : getPrefixed(ann.object);
	                md += `${ap}=${ao}; `;
	            }
	            md = md.trimEnd() + ' |}\n';
	        }
	    }
	    // Quoted triples as subject (not annotated)
	    const quotedSubjects = store.getQuads(null, null, null, null).filter((q) => isQuotedTriple(q.subject) && store.countQuads(q.subject, null, null, null) === 0);
	    for (const q of quotedSubjects) {
	        if (isQuotedTriple(q.subject)) {
	            const subj = q.subject;
	            const s = getPrefixed(subj.subject);
	            const p = getPrefixed(subj.predicate);
	            const o = getPrefixed(subj.object);
	            const qp = getPrefixed(q.predicate);
	            const qo = getPrefixed(q.object);
	            md += `<<[${s}] ${p} [${o}]>> ${qp} [${qo}]\n`;
	        }
	    }
	    // Quoted triples as object
	    const quotedObjects = store.getQuads(null, null, null, null).filter((q) => isQuotedTriple(q.object));
	    for (const q of quotedObjects) {
	        if (isQuotedTriple(q.object)) {
	            const obj = q.object;
	            const s = getPrefixed(q.subject);
	            const p = getPrefixed(q.predicate);
	            const os = getPrefixed(obj.subject);
	            const op = getPrefixed(obj.predicate);
	            const oo = getPrefixed(obj.object);
	            md += `[${s}] ${p} <<[${os}] ${op} [${oo}]>>\n`;
	        }
	    }
	    // SHACL constraints
	    const shaclNodes = store.getQuads(null, namedNode('http://www.w3.org/ns/shacl#select'), null, null);
	    if (shaclNodes.length > 0) {
	        md += '\n## SHACL Constraints\n\n';
	        for (const sh of shaclNodes) {
	            if (sh.object.termType === 'Literal') {
	                md += '```sparql\n' + sh.object.value + '\n```\n';
	            }
	        }
	    }
	    return md.trim();
	}
	function toRDFJSON(store) {
	    const rdfjson = {};
	    store.forEach((quad) => {
	        let subjStr;
	        if (isQuotedTriple(quad.subject)) {
	            // Reify quoted triple
	            const bnode = blankNode();
	            const subj = quad.subject;
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#subject'), subj.subject);
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate'), subj.predicate);
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#object'), subj.object);
	            subjStr = '_:' + bnode.value;
	            // Then treat as blank
	        }
	        else {
	            subjStr = quad.subject.termType === 'BlankNode' ? '_:' + quad.subject.value : quad.subject.value;
	        }
	        if (!rdfjson[subjStr])
	            rdfjson[subjStr] = {};
	        const predStr = quad.predicate.value;
	        if (!rdfjson[subjStr][predStr])
	            rdfjson[subjStr][predStr] = [];
	        let objEntry = { value: quad.object.value };
	        if (quad.object.termType === 'NamedNode')
	            objEntry.type = 'uri';
	        else if (quad.object.termType === 'BlankNode')
	            objEntry.type = 'bnode';
	        else if (quad.object.termType === 'Literal') {
	            objEntry.type = 'literal';
	            if (quad.object.language)
	                objEntry.lang = quad.object.language;
	            if (quad.object.datatype.value !== 'http://www.w3.org/2001/XMLSchema#string')
	                objEntry.datatype = quad.object.datatype.value;
	        }
	        else if (isQuotedTriple(quad.object)) {
	            // Reify object
	            const bnode = blankNode();
	            const obj = quad.object;
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#subject'), obj.subject);
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate'), obj.predicate);
	            store.addQuad(bnode, namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#object'), obj.object);
	            objEntry = { type: 'bnode', value: '_:' + bnode.value };
	        }
	        rdfjson[subjStr][predStr].push(objEntry);
	    });
	    return rdfjson;
	}
	function toJSONLDStar(store) {
	    const graph = { '@graph': [] };
	    const nodeMap = new Map();
	    // Build node map
	    store.forEach((quad) => {
	        const subjId = isQuotedTriple(quad.subject) ? serializeQuoted(quad.subject) : quad.subject.value;
	        if (!nodeMap.has(subjId))
	            nodeMap.set(subjId, { '@id': subjId });
	        const node = nodeMap.get(subjId);
	        const pred = quad.predicate.value;
	        let obj;
	        if (quad.object.termType === 'Literal') {
	            obj = { '@value': quad.object.value };
	            if (quad.object.language)
	                obj['@language'] = quad.object.language;
	            if (quad.object.datatype)
	                obj['@type'] = quad.object.datatype.value;
	        }
	        else if (isQuotedTriple(quad.object)) {
	            obj = { '@id': serializeQuoted(quad.object) };
	        }
	        else {
	            obj = { '@id': quad.object.value };
	        }
	        if (!node[pred])
	            node[pred] = [];
	        node[pred].push(obj);
	    });
	    // Handle annotations: Find quads where subject/object is quoted, add @annotation
	    store.forEach((quad) => {
	        if (isQuotedTriple(quad.subject) || isQuotedTriple(quad.object)) {
	            const targetQuad = isQuotedTriple(quad.subject) ? quad.subject : quad.object;
	            if (isQuotedTriple(targetQuad)) {
	                const tq = targetQuad;
	                const embedded = {
	                    '@id': tq.subject.value,
	                    [tq.predicate.value]: { '@id': tq.object.value }
	                };
	                // Add annotation if it's an annotation on the triple
	                const annNode = { [quad.predicate.value]: { '@id': quad.object.value } };
	                if (!Array.isArray(embedded['@annotation']))
	                    embedded['@annotation'] = [];
	                embedded['@annotation'].push(annNode);
	                // Replace in graph
	            }
	        }
	    });
	    graph['@graph'] = Array.from(nodeMap.values());
	    return graph;
	}
	function serializeQuoted(qt) {
	    // Simple string representation for map key, e.g., JSON.stringify({ s: qt.subject.value, p: qt.predicate.value, o: qt.object.value })
	    return JSON.stringify({ '@id': qt.subject.value, [qt.predicate.value]: { '@id': qt.object.value } });
	}
	async function markdownLDToTurtle(content) {
	    const { output } = parseMarkdownLD(content, { format: 'turtle' });
	    return output;
	}
	// Dummy validateSHACL for now (Parser/query not implemented)
	async function validateSHACL(content, ontologyTtl) {
	    return [{ error: 'SHACL validation not implemented in this build.' }];
	}
	function generateSampleOntology() {
	    return `
[ex]: http://example.org/
[schema]: http://schema.org/
[sh]: http://www.w3.org/ns/shacl#

[Person]{typeof=schema:Person; schema:name="Jane Doe"}

[Person] schema:knows [Bob] {| ex:certainty=0.9 |}

<<[Person] schema:knows [Bob]>> ex:statedBy [Alice]

## SHACL Constraints

\`\`\`sparql
SELECT ?this WHERE { ?this schema:name ?name . FILTER(!isLiteral(?name)) }
\`\`\`
  `.trim();
	}
	// quotedTriple now returns a true N3 quad using N3.DataFactory.quad
	function quotedTriple(subject, predicate, object) {
	    return dataFactory.quad(subject, predicate, object);
	}
	// Type guard for quoted triple (RDF-star)
	function isQuotedTriple(term) {
	    return (term &&
	        term.termType === 'Quad' &&
	        'subject' in term &&
	        'predicate' in term &&
	        'object' in term);
	}
	// When passing to N3 APIs, cast as unknown as N3.Quad_Subject or N3.Quad_Object as needed
	// Example: store.addQuad(qt as unknown as N3.Quad_Subject, ...)

	exports.default = index;
	exports.fromRDFToMarkdownLD = fromRDFToMarkdownLD;
	exports.generateSampleOntology = generateSampleOntology;
	exports.markdownLDToTurtle = markdownLDToTurtle;
	exports.parseMarkdownLD = parseMarkdownLD;
	exports.validateSHACL = validateSHACL;

	Object.defineProperty(exports, '__esModule', { value: true });

}));
if (typeof window !== "undefined" && window.MarkdownLDStar === undefined && typeof MarkdownLDStar !== "undefined") { window.MarkdownLDStar = MarkdownLDStar; }
